[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Notes on behavioural economics",
    "section": "",
    "text": "Preface\nWelcome to these notes on behavioural economics.\nThese are the notes for the UTS undergraduate subject 23005 Behavioural Economics.\nI take a traditional approach. I start with the basic economic and game theory foundations. I then examine what happens when we introduce a richer view of human behaviour. I look at how we make decisions under risk and uncertainty, and over time, how we judge probability and how we interact with others.\nThe result is a new set of predictions as to how humans might behave and what economic phenomena might emerge.\nThere are no mathematical prerequisites for this subject. Hence, the mathematics is kept at a basic level.\nI have created videos to accompany these notes. You can find links to them and other teaching materials on my website at www.jasoncollins.blog/teaching/.\nThese notes cover the following areas:",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#what-is-behavioural-economics",
    "href": "index.html#what-is-behavioural-economics",
    "title": "Notes on behavioural economics",
    "section": "What is behavioural economics?",
    "text": "What is behavioural economics?\nBehavioural economics is a discipline that seeks to increase the explanatory power of traditional economic approaches by incorporating more realistic psychological foundations.\nBehavioural economics retains the general framework and tools used by economists, but deviates from some assumptions to generate new insights and better predictions. These deviations are generally grounded in observed behaviour rather than abstract principles.\n\nWhat is not behavioural economics?\nYou have probably heard the term behavioural economics in the popular press and books. Many of those references are not what I would consider to be behavioural economics. As a result, it is worth identifying what is not behavioural economics.\nThe word economics is the key. Economics is the study of how economic agents make decisions under conditions of scarcity and the study of the interactions between those agents.\nAs I noted, behavioural economics involves the introduction of more realistic psychological foundations to that economic approach.\nBehavioural economics is not the general study of human behaviour. Behavioural science is a better term for that general study.\nSimilarly, psychology is the study of the human mind, decisions and behaviour. Psychology is part of the behavioural sciences. Behavioural economics draws on a small subset of psychology to develop a better understanding of human behaviour.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#three-thought-experiments",
    "href": "index.html#three-thought-experiments",
    "title": "Notes on behavioural economics",
    "section": "Three thought experiments",
    "text": "Three thought experiments\nMany early ideas in behavioural economics emerged from thought experiments concerning human behaviour that was hard to explain with traditional economic frameworks.\nHere are three thought experiments to illustrate the types of problems that concern behavioural economists. In this course I will examine potential explanations for each of these behaviours.\n\nThought experiment 1\nThis first thought experiment comes from Kahneman and Tversky (1984).\nA. Imagine that you have decided to see a play and paid the admission price of $100 per ticket. As you enter the theatre, you discover that you have lost the ticket. The seat was not marked, and the ticket cannot be recovered.\nWould you pay $100 for another ticket?\nB. Imagine that you have decided to see a play where admission is $100 per ticket. As you enter the theatre, you discover that you have lost a $100 bill.\nWould you still pay $100 for a ticket for the play?\nThe two situations appear equivalent, yet people are more likely to pay $100 for a ticket in scenario B.\n\n\nThought experiment 2\nThis second thought experiment comes from Thaler (1980).\nMr. R bought a case of good wine … for about $5 a bottle. A few years later his wine merchant offered to buy the wine back for $100 a bottle. He refused, although he has never paid more than $35 for a bottle of wine.\nWhy is there such a large difference between the price at which he is willing to buy and the price at which he is willing to sell?\n\n\nThought experiment 3\nThis third thought experiment also comes from Thaler (1980).\nA group of hungry economists is awaiting dinner when a large can of cashews is opened and placed on the coffee table. After half the can is devoured in three minutes, everyone agrees to put the rest of the cashews into the pantry.\nWhy did they agree to remove the cashews when they simply could have not eaten them? Why did they deliberately reduce their choice set?\n\n\n\n\nKahneman, D., and Tversky, A. (1984). Choices, values, and frames. American Psychologist, 39(4), 341–350. https://doi.org/10.1037/0003-066X.39.4.341\n\n\nThaler, R. (1980). Toward a positive theory of consumer choice. Journal of Economic Behavior & Organization, 1(1), 39–60. https://doi.org/10.1016/0167-2681(80)90051-7",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "economic-foundations/economic-foundations.html",
    "href": "economic-foundations/economic-foundations.html",
    "title": "Economic foundations",
    "section": "",
    "text": "Behavioural economics builds on the frameworks and tools used by economists. In this part, I introduce some of the core economic concepts that we will build on or explicitly deviate from in our exploration of behavioural economics.\nI will first examine the preference relation used by economists.\nThen I will discuss how economists define rationality, and the foundational axioms of rationality, completeness and transitivity.\nFinally, I will describe how the preference relation and axioms form the basis of utility functions.",
    "crumbs": [
      "Economic foundations"
    ]
  },
  {
    "objectID": "economic-foundations/preferences.html",
    "href": "economic-foundations/preferences.html",
    "title": "1  Preferences",
    "section": "",
    "text": "Summary\nEconomists use the preference relation to capture the ordering that an agent gives to options between which they might choose. There are three forms of the preference relation.\nThe first is the strong (or strict) preference relation. We use the strong preference relation to indicate that an agent considers one option “better than” another. We represent strong preference with the symbol \\succ.\nThe second is the weak preference relation. We use the weak preference relation to indicate that an agent considers one option “at least as good as” another. We represent weak preference with the symbol \\succcurlyeq.\nThe third is indifference. Indifference occurs when an agent considers that each option is “as good as” the other or that the agent is “indifferent between” the options. We represent indifference with the symbol \\sim.\nHere are a couple of illustrations of these relations.\nSuppose I strongly prefer bananas to apples. I would write:\nBananas are better than apples.\nSimilarly, if I am indifferent between bananas and oranges, I would write:\nBananas are as good as oranges. Oranges are as good as bananas.\nThere is an important link between indifference and the weak preference relation. I am indifferent between x and y (x \\sim y) if and only if I weakly prefer x to y (x \\succcurlyeq y) and I weakly prefer y to x (y \\succcurlyeq x). The weak preference relation includes the possibility of indifference.\nIn that case of the example of my indifference between oranges and bananas, I could also say that I weakly prefer bananas to oranges and that I weakly prefer oranges to bananas:",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preferences</span>"
    ]
  },
  {
    "objectID": "economic-foundations/preferences.html#summary",
    "href": "economic-foundations/preferences.html#summary",
    "title": "1  Preferences",
    "section": "",
    "text": "Economists use preference relations to capture how agents order their choices.\nThe strong preference relation (\\succ) indicates one option is “better than” another.\nThe weak preference relation (\\succcurlyeq) indicates one option is “at least as good as” another.\nThe indifference relation (\\sim) indicates two options are “as good as” each other. Indifference is linked to weak preference: x \\sim y if and only if x \\succcurlyeq y and y \\succcurlyeq x.\n\n\n\n\n\n\n\n\n\n\n\nbananas \\succ apples\n\n\n\n\nbananas \\sim oranges\n\n\n\n\n\nbananas \\succcurlyeq oranges and oranges \\succcurlyeq bananas",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preferences</span>"
    ]
  },
  {
    "objectID": "economic-foundations/rationality.html",
    "href": "economic-foundations/rationality.html",
    "title": "2  Rationality",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rationality</span>"
    ]
  },
  {
    "objectID": "economic-foundations/rationality.html#summary",
    "href": "economic-foundations/rationality.html#summary",
    "title": "2  Rationality",
    "section": "",
    "text": "In economics, rationality means that preferences respect certain principles, not that decisions are necessarily reasonable or self-interested.\nThe completeness axiom states that an agent can always compare any two options: for all x and y, either x \\succcurlyeq y or y \\succcurlyeq x (or both).\nThe transitivity axiom states that if an agent prefers A to B and B to C, they will prefer A to C: if x \\succcurlyeq y and y \\succcurlyeq z, then x \\succcurlyeq z.\nThese axioms allow for the construction of a preference ordering, but they provide minimal constraints on the nature of preferences themselves.",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rationality</span>"
    ]
  },
  {
    "objectID": "economic-foundations/rationality.html#introduction",
    "href": "economic-foundations/rationality.html#introduction",
    "title": "2  Rationality",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nA standard economic assumption is that decision makers are rational.\nHowever, rationality in economics has a different definition to the ‘lay’ definition of rationality.\nRationality simply means that preferences respect some desirable principles. These principles are assumptions, not rules of behaviour.\nEconomists tend to keep the number of assumptions as small as possible. They choose the assumptions that they need for the particular analytical problem they have at hand.\nIn its most stripped-back form, analysis of consumer choice rests on just two assumptions. These are completeness and transitivity.",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rationality</span>"
    ]
  },
  {
    "objectID": "economic-foundations/rationality.html#completeness",
    "href": "economic-foundations/rationality.html#completeness",
    "title": "2  Rationality",
    "section": "2.2 Completeness",
    "text": "2.2 Completeness\nCompleteness means that an agent can always compare any two options. The agent cannot fail to have a preference between two options (although that preference may be indifference).\nFor example, if an agent was presented with a choice between an apple and a banana, or a choice between a Mercedes and a BMW, they will always strictly prefer one of them or be indifferent between the two. They will never not know what to choose or be unable to make a choice. They cannot be indecisive.\nFormally, we can state the completeness axiom as follows:\n\nFor all x and y, either x \\succcurlyeq y or y \\succcurlyeq x (or both).\n\nCompleteness means people always prefer x or y, or are indifferent between the two.\nWhile the completeness axiom appears sensible, it is possible to develop examples where it may not hold. Consider a choice between two possible holiday destinations. Or two potential dates or spouses. If you are torn between the options and unable to make up your mind, this would represent a breach of the completeness axiom.\nIncomplete preferences are different from indifference. If you are indifferent, you would be able to decide by, say, flipping a coin. You will be equally satisfied whatever the outcome. Incompleteness makes choice impossible.",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rationality</span>"
    ]
  },
  {
    "objectID": "economic-foundations/rationality.html#transitivity",
    "href": "economic-foundations/rationality.html#transitivity",
    "title": "2  Rationality",
    "section": "2.3 Transitivity",
    "text": "2.3 Transitivity\nUnder transitivity, if a person prefers A to B and B to C, they will prefer A to C.\nFormally, we can state the transitivity axiom as follows:\n\nFor all x, y and z, if x \\succcurlyeq y and y \\succcurlyeq z, then x \\succcurlyeq z.\n\nOne classic argument for transitivity is the concept of a “money pump” (Davidson et al. (1955)).\nSuppose you have a person who prefers A to B, B to C and C to A. That is, they have intransitive preferences. They have $20 and an endowment of C.\n\nThey are offered B in exchange for their endowment of C for some small nominal cost (say $1). If they make the trade they now have B and $19.\n\nThey are then offered A in exchange for their endowment of B, again for a nominal cost.\n\nFinally, they are offered C in exchange for their endowment of A for a further nominal cost. They now have an endowment of C and $17. This process can be repeated until the agent has no money.",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rationality</span>"
    ]
  },
  {
    "objectID": "economic-foundations/rationality.html#preference-orderings",
    "href": "economic-foundations/rationality.html#preference-orderings",
    "title": "2  Rationality",
    "section": "2.4 Preference Orderings",
    "text": "2.4 Preference Orderings\nWhen preferences are transitive and complete, we can create a ranking of options from most to least preferred. We can construct a preference ordering.\nCompleteness guarantees that there will be only one ordering. There are no gaps or ambiguous comparisons. If you have three options (A, B and C), you must be able to rank them fully, such as A is better than B is better than C, or I am indifferent between A and B which are both better than C.\nTransitivity guarantees that there will be no cycles in strict preference. Weak preferences can cycle, so that one can prefer A to B and B to C and C to A, but this entails indifference.\nThat preference ordering, a simple rank of which options an agent prefers, is all that is required for some analysis of consumer choice.",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rationality</span>"
    ]
  },
  {
    "objectID": "economic-foundations/rationality.html#defining-rationality",
    "href": "economic-foundations/rationality.html#defining-rationality",
    "title": "2  Rationality",
    "section": "2.5 Defining rationality",
    "text": "2.5 Defining rationality\nThis definition of rationality, accordance to the axioms of completeness and transitivity, provides little constraint on preferences, while allowing for diverse preferences and behaviours.\nYou could prefer less money to more. You could prefer sums of money divisible by seven with no remainder. You could prefer more for yourself or more for someone else.\nThese axioms do not lead to an assumption that people are selfish, unless you define selfishness to be simply acting in accordance with their preferences.\nThese axioms place some constraints on behaviour, and empirical evidence suggests those constraints are sometimes breached by decision makers. But they are constraints that allow much behaviour to be described as rational.",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rationality</span>"
    ]
  },
  {
    "objectID": "economic-foundations/rationality.html#independence-of-irrelevant-alternatives",
    "href": "economic-foundations/rationality.html#independence-of-irrelevant-alternatives",
    "title": "2  Rationality",
    "section": "2.6 Independence of irrelevant alternatives",
    "text": "2.6 Independence of irrelevant alternatives\nWhile completeness and transitivity are the most basic axioms of rationality, there are others that can be added to provide more structure to preferences. One such axiom is the independence of irrelevant alternatives.\nThe axiom of independence of irrelevant alternatives states that if an agent prefers x to y, the introduction of a third option z should not change the preference order between x and y. A new option shouldn’t flip how you rank two existing options. For example, if you select fish rather than chicken from a restaurant menu, being told by the waiter that there is a vegetarian option should not lead you to change your selection to chicken.\nMathematically, we can state that:\n\nIf x \\succ y in choice set S = \\{x,y\\}, then:\nx \\succ y in choice set T = \\{x,y,z\\}\n\nThe axiom has important implications:\n\nIt allows preferences to be context-independent. An agent’s choice between two options can be analysed without needing to know the full choice set.\nIt simplifies economic models by making preference orderings more stable and predictable. It eliminates the need to consider complex interactions between irrelevant and relevant options.\nIt prevents the outcomes of decision-making processes from being manipulated by the strategic inclusion or exclusion of alternatives.\n\nThe axiom of independence of irrelevant alternatives is used in utility theory, mechanism design, and social choice theory, where it helps establish important results about preference aggregation and voting systems. For example, in voting systems, the axiom prevents a candidate’s elimination from changing the relative ranking of other candidates.\n\n\n\n\nDavidson, D., McKinsey, J. C. C., and Suppes, P. (1955). Outlines of a Formal Theory of Value, I. Philosophy of Science, 22(2), 140–160. https://doi.org/10.1086/287412",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rationality</span>"
    ]
  },
  {
    "objectID": "economic-foundations/utility.html",
    "href": "economic-foundations/utility.html",
    "title": "3  Utility",
    "section": "",
    "text": "Summary\nx \\succcurlyeq y \\Leftrightarrow u(x) \\geq u(y) \\\\[6pt]\nx \\succ y \\Leftrightarrow u(x) &gt; u(y) \\\\[6pt]\nx \\sim y \\Leftrightarrow u(x) = u(y)\nEconomists often use numbers to represent strength of preference. This is done through utility functions.\nA utility function associates a number with each member of the universe. For example:\nThis does not mean that I rate bananas three times higher than apples. It simply means that I prefer bananas to apples. This utility scale is ordinal, not cardinal. The following is equivalent:\nFormally, the utility function u(\\cdot):\nFor example, we might write:\n\\begin{align*}\nu(\\text{banana})&=3 \\\\[6pt]\nu(\\text{orange})&=2 \\\\[6pt]\nu(\\text{apple})&=1\n\\end{align*}\nThe rank of those numbers gives us the preference relation:\nx\\succcurlyeq y \\Longleftrightarrow u(x)\\geq u(y)\nx\\succ y \\Longleftrightarrow u(x)&gt;u(y)\nx\\sim y \\Longleftrightarrow u(x)=u(y)\nAgain, following from the above:\nu(\\text{banana})=3&gt;2=u(\\text{orange})\\Longleftrightarrow \\text{banana}\\succ \\text{orange}\nThis calculation of utility is not how the mind actually works. But under the axioms of completeness and transitivity, the consumer behaves as if they have a utility function u(x_i) over outcomes x_i.",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Utility</span>"
    ]
  },
  {
    "objectID": "economic-foundations/utility.html#summary",
    "href": "economic-foundations/utility.html#summary",
    "title": "3  Utility",
    "section": "",
    "text": "Economists use utility functions to represent strength of preference, assigning numbers to different options.\nFormally, a utility function u(\\cdot) maps alternatives to real numbers, assigning larger numbers to preferred alternatives.\nThe preference relation can be expressed using the utility function:\n\n\n\n\n\n\n\n\nBanana: 3\nOrange: 2\nApple: 1\n\n\n\nBanana: 300\nOrange: 2\nApple: 1\n\n\n\nmaps the set of alternatives into the set of real numbers\nassigns larger numbers to preferred alternatives.",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Utility</span>"
    ]
  },
  {
    "objectID": "economic-foundations/economic-foundation-exercises.html",
    "href": "economic-foundations/economic-foundation-exercises.html",
    "title": "4  Economic foundation exercises",
    "section": "",
    "text": "4.1 Buridan’s ass\nThe paradox of Buridan’s ass runs as follows: An ass that is equally hungry and thirsty is placed halfway between a pile of hay and a bucket of water. The ass cannot decide between the hay and water, so dies of dehydration and starvation.\nWhat axioms of choice are relevant to this fable? Are any axioms violated?",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Economic foundation exercises</span>"
    ]
  },
  {
    "objectID": "economic-foundations/economic-foundation-exercises.html#buridans-ass",
    "href": "economic-foundations/economic-foundation-exercises.html#buridans-ass",
    "title": "4  Economic foundation exercises",
    "section": "",
    "text": "Answer\n\n\n\n\n\nThe axiom of completeness is violated. Under this axiom an agent cannot fail to have a preference between two options (although that preference may be indifference).\nIncompleteness is different from indifference. Is the ass was merely indifferent it would be happy taking either option and be equally satisfied. Indifference does not make a choice impossible.",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Economic foundation exercises</span>"
    ]
  },
  {
    "objectID": "economic-foundations/economic-foundation-exercises.html#picking-a-mobile-plan",
    "href": "economic-foundations/economic-foundation-exercises.html#picking-a-mobile-plan",
    "title": "4  Economic foundation exercises",
    "section": "4.2 Picking a mobile plan",
    "text": "4.2 Picking a mobile plan\nYou are considering two mobile phone plans. Each has different monthly fees, data caps, excess data charges, international inclusions and 5G coverage. You realise it will take all day to work through the fine print to understand the plans.\nYou decide that your options are:\n\nPick a plan by flipping a coin.\nSpend the day working through the plans and choose one.\nAvoid the work by reading a book instead.\n\nDoes this decision accord with the axioms we have discussed?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAll three choices could be considered to accord with the axioms we have discussed. What we have effectively done in each case is created a richer choice set. In no case are their preferences incomplete. You could think of the choice set as {Plan A, Plan B, invest to understand plans, do something else}.\nYou would only state that the preferences are incomplete if the agent wasn’t able to express a preference between Plan A and Plan B. However, if they were forced to choose and happy to flip a coin, that would suggest indifference.",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Economic foundation exercises</span>"
    ]
  },
  {
    "objectID": "economic-foundations/economic-foundation-exercises.html#rationality",
    "href": "economic-foundations/economic-foundation-exercises.html#rationality",
    "title": "4  Economic foundation exercises",
    "section": "4.3 Rationality",
    "text": "4.3 Rationality\nConsider the following statements about rationality in economics. How do these criticisms relate to the definition of rationality we have discussed?\na) From Robert Frank in the New York Times:\n\nTRADITIONAL economic models assume that people are self-interested in the narrow sense. If “homo economicus” - the stereotypical rational actor in these models - finds a wallet on the sidewalk, he keeps the cash inside. He doesn’t leave tips after dining in restaurants that he will never visit again. And he would never vote in a presidential election, much less make an anonymous donation of money or time to a presidential campaign.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe traditional economic axioms assume self-interest in a narrow sense, in that people make decisions in accordance with their preferences. However, completeness and transitivity say nothing about the content of those preferences. A person might prefer to return the wallet or leave a large tip for the good feeling they get. They might enjoy voting and care about outcomes for others.\nEven auxiliary axioms such as monotonicity or non-satiation leave these possibilities open in that while the agent will always want more, they do not require that it is purely for their own benefit.\n\n\n\nb) From Brian Easton in interest.co.nz:\n\nFor the last 150 years much economic analysis has been based on homo economicus, an ‘economic’ man who is rational and narrowly self-interested and who pursues his subjectively defined ends optimally.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFirst, “man who is rational” accords with the technical definition in economics but differs from how used in common speech (and likely that of readers of the article).\nIf we read “narrowly self-interested” to mean that they make decisions in accordance with their preferences, then we might agree with that statement. However, we cannot place any further content into that idea of self-interest.\nSimilarly, the statement “pursues his subjectively defined ends optimally” accords with the idea that under the axioms of completeness and transitivity, the consumer behaves as if they have a utility function U(x_i) over outcomes x_i. They are able to choose between any two options. They also do not make errors (although randomness can be built into utility functions). This definition of “optimally” is narrower than might be used in common speech.",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Economic foundation exercises</span>"
    ]
  },
  {
    "objectID": "economic-foundations/economic-foundation-exercises.html#apples-and-oranges",
    "href": "economic-foundations/economic-foundation-exercises.html#apples-and-oranges",
    "title": "4  Economic foundation exercises",
    "section": "4.4 Apples and oranges",
    "text": "4.4 Apples and oranges\nElmer claims he has no preference between apples and oranges and is genuinely indifferent between the two. Is this stance consistent with the completeness axiom? Explain why or why not. (2 marks) [200 word limit.]\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nElmer’s stance of being indifferent between apples and oranges is consistent with the completeness axiom.\nThe completeness axiom states that for any two options A and B, an individual can always specify exactly one of these three possibilities: A is preferred to B, B is preferred to A, or the individual is indifferent between A and B.\nElmer’s claim of indifference between apples and oranges satisfies this axiom. He has a clear preference relation between the two options (indifference), which is one of the three possibilities allowed by the completeness axiom.",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Economic foundation exercises</span>"
    ]
  },
  {
    "objectID": "economic-foundations/economic-foundation-exercises.html#small-or-medium-coffee",
    "href": "economic-foundations/economic-foundation-exercises.html#small-or-medium-coffee",
    "title": "4  Economic foundation exercises",
    "section": "4.5 Small or medium coffee?",
    "text": "4.5 Small or medium coffee?\nSam’s local cafe offers two sizes of coffee: small and regular. Each day, Sam orders a small coffee.\nThe cafe then introduces a new large size. Sam starts ordering the regular.\nWhat axiom is Sam violating? Explain. (2 marks) [200 word limit]\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSam’s action is inconsistent with the independence of irrelevant alternatives.\nUnder the independence of irrelevant alternatives, if A is preferred to B, then this preference should remain unchanged in the presence of a third option C.\nInitially, Sam prefers small to regular. After the introduction of the large size, Sam switches to preferring regular to small. This change in preference between small and regular, triggered solely by the presence of the large option (which Sam doesn’t even choose), contradicts the axiom.\nThis scenario does not involve probabilities, as the independence axiom is defined, so we can’t evaluate it in terms of the independence axiom.",
    "crumbs": [
      "Economic foundations",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Economic foundation exercises</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/decision-making-under-risk.html",
    "href": "decision-making-under-risk/decision-making-under-risk.html",
    "title": "Decision making under risk",
    "section": "",
    "text": "On leaving university, you receive two job offers.\nThe first is from an established company offering a guaranteed salary of $150,000.\nThe second is from a promising startup offering a base salary of $100,000, plus stock options that will be worth either $300,000 or nothing, with equal probability.\nDespite the potential for a large windfall, many people would choose the established company’s lower but guaranteed amount. This common preference reveals something fundamental about how people make decisions under risk.\nIn this part, I examine the basic frameworks by which economists analyse such decisions under risk. I will explore questions such as:\n\nHow do people evaluate risky choices?\nHow can we mathematically model risk preferences?\nWhere do standard economic models fail in predicting decisions under risk?\n\nI begin by setting out some mathematical foundations, including the concept of expected value. I then lay out the axioms that underlie Expected Utility Theory, the classical economic framework for analysing decisions under risk. Expected utility theory suggests people maximize their expected utility rather than expected value, helping explain phenomena like risk aversion.\nHowever, research has identified anomalies where people’s choices systematically deviate from Expected Utility Theory’s predictions. We’ll examine several anomalies, including the Allais Paradox, where people make inconsistent choices between pairs of gambles. We will look at how framing and reference points affect risk preferences. We will also see cases where small-stakes risk aversion implies implausibly extreme large-stakes risk aversion\nUnderstanding the insights and limitations of Expected Utility Theory provides a foundation for us to later examine alternative theories from behavioural economics to explain decision making under risk.",
    "crumbs": [
      "Decision making under risk"
    ]
  },
  {
    "objectID": "decision-making-under-risk/notation-and-mathematical-background.html",
    "href": "decision-making-under-risk/notation-and-mathematical-background.html",
    "title": "5  Notation and mathematical background",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Notation and mathematical background</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/notation-and-mathematical-background.html#summary",
    "href": "decision-making-under-risk/notation-and-mathematical-background.html#summary",
    "title": "5  Notation and mathematical background",
    "section": "",
    "text": "Lotteries can be represented as L = (p_1, x_1; p_2, x_2; ...; p_n, x_n), where p_i is the probability of outcome x_i.\nMathematical functions used in expected utility theory include exponentiation (x^a), exponential (e^x), and logarithmic (\\ln(x)) functions.\nDifferentiation finds the rate of change of a function, written as \\frac{d}{dx} f(x) or f'(x).\nThe second derivative (\\frac{d^2}{dx^2} f(x) or f''(x)) measures a function’s curvature, indicating whether it’s convex (f''(x) &gt; 0) or concave (f''(x) &lt; 0).",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Notation and mathematical background</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/notation-and-mathematical-background.html#notation",
    "href": "decision-making-under-risk/notation-and-mathematical-background.html#notation",
    "title": "5  Notation and mathematical background",
    "section": "5.1 Notation",
    "text": "5.1 Notation\n\n\nBefore analysing decision-making under risk and uncertainty, I will introduce some notation.\nSuppose we have a lottery L with n possible outcomes x_1, x_2, ..., x_n each with probabilities p_1, p_2, ..., p_n. A shorthand way to write this is:\n\nL=(p_1,x_1; p_2,x_2; ...; p_n,x_n)\n\nFor example, suppose you are offered a gamble with a 50% probability of winning $200 and a 50% probability of losing $100. We can write this as:\n\nL=(0.5, −100; 0.5, 200)\n\nThe order of each outcome-probability pair does not matter. I could also write:\n\nL=(0.5, 200; 0.5, -100)\n\nYou may also see gambles represented with the outcome and probability in a different order, such as:\n\nL=(x_1,p_1; x_2,p_2; ...; x_n,p_n)\n\nOr:\n\nL=(x_1,x_2,...,x_n;p_1,p_2,...,p_n)\n\nIt is typically not difficult to determine which is which.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Notation and mathematical background</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/notation-and-mathematical-background.html#mathematical-background",
    "href": "decision-making-under-risk/notation-and-mathematical-background.html#mathematical-background",
    "title": "5  Notation and mathematical background",
    "section": "5.2 Mathematical background",
    "text": "5.2 Mathematical background\nWe will use some basic mathematical concepts to analyse expected utility. I will briefly review these concepts here.\n\n5.2.1 Functions\n\n\n\n5.2.1.1 Exponentiation\nExponentiation is a mathematical operation where a number is multiplied by itself a certain number of times.\nExponentiation is written as f(x)=x^a. That is, x is multiplied by itself a times. For example, 2^3=2\\times2\\times2=8.\nThe exponent a can be any real number, including fractions and negative numbers. For example, a plot of the function f(x)=x^{0.5} is shown in Figure 5.1.\n\n\nCode\nlibrary(ggplot2)\n\nx &lt;- seq(0, 5, 0.1)\n\ny &lt;- x^0.5\n\ndf &lt;- data.frame(x, y)\n\nggplot(df, aes(x, y)) +\n  geom_line() +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"f(x)=x^0.5\") +\n  theme_minimal()\n\n\n\n\n\nFigure 5.1: Square root function\n\n\n\n\n\n\n\n\n\n\n5.2.1.2 The exponential function\nThe exponential function is written as f(x)=e^x. The letter e is a constant, approximately equal to 2.71828. It is a special case of exponentiation where the base is e, which is multiplied by itself x times.\nA plot of the exponential function is shown in Figure 5.2.\n\n\nCode\nlibrary(ggplot2)\n\nx &lt;- seq(-5, 5, 0.1)\ny &lt;- exp(x)\n\ndf &lt;- data.frame(x, y)\n\nggplot(df, aes(x, y)) +\n  geom_line() +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"f(x)=e^x\") +\n  theme_minimal()\n\n\n\n\n\nFigure 5.2: The exponential function\n\n\n\n\n\n\n\n\n\n\n5.2.1.3 The logarithmic function\nThe logarithmic function is written as f(x)=\\ln(x) or \\log_e(x).\nThe logarithmic function is the inverse of the exponential function. That is, if f(x)=e^x, then x=\\ln(f(x)).\nA plot of the logarithmic function is shown in Figure 5.3.\n\n\nCode\nx &lt;- seq(0.01, 5, 0.01)\ny &lt;- log(x)\n\ndf &lt;- data.frame(x, y)\n\nggplot(df, aes(x, y)) +\n  geom_line() +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"f(x)=ln(x)\") +\n  theme_minimal()\n\n\n\n\n\nFigure 5.3: The logarithmic function\n\n\n\n\n\n\n\n\nNote that the logarithmic function is only defined for positive values of x. The logarithm of zero is undefined.\n\n\n\n5.2.2 Differentiation\n\n\nDifferentiation is a mathematical operation that finds the rate of change (or slope) of a function. It is written as \\frac{d}{dx}f(x) or \\frac{dy}{dx} or f'(x).\nThere are several simple rules to differentiate a function. The rules relevant to these notes are as follows.\nThe derivative of a constant is zero.\n\n\\frac{d}{dx}c=0\n\nThe derivative of an exponentiation is:\n\n\\frac{d}{dx}x^a=ax^{a-1}\n\nFor example:\n\n\\frac{d}{dx}x^2=2x\n\nYou can see from this that for any value of x greater than zero, the derivative of x^2 is greater than zero, signifying that the function f(x)=x^2 is increasing and has positive slope. For any value of x less than zero, the derivative is less than zero, signifying that the function is decreasing and has negative slope.\nAs another example:\n\n\\frac{d}{dx}x^{0.5}=0.5x^{-0.5}\n\nYou can see from this that for any value of x greater than zero, the derivative of x^{0.5} is greater than zero, signifying that the function f(x)=x^{0.5} is increasing and has positive slope. The function is not defined for x&lt;0. This is shown in Figure 5.1.\nThe derivative of the logarithmic function is:\n\n\\frac{d}{dx}\\ln(x)=\\frac{1}{x}\n\nThis derivative is positive for all values of x for which \\ln(x) is defined. Therefore \\ln(x) is increasing in x. You can see this in Figure 5.3.\nThe derivative of a fraction is:\n\n\\frac{d}{dx}\\frac{1}{f(x)}=-\\frac{f'(x)}{f(x)^2}\n\nFor example:\n\n\\frac{d}{dx}\\frac{1}{x}=-\\frac{1}{x^2}\n\nWhere you have a function \\frac{1}{x^a}, it is often easier to write it as x^{-a} and use the rule for exponentiation. For example:\n\n\\frac{d}{dx}\\frac{1}{x}=\\frac{d}{dx}x^{-1}=-1x^{-2}=-\\frac{1}{x^2}\n\n\n5.2.2.1 The second derivative\nThe second derivative of the function is a measure of the curvature of the function or the rate of change of the slope. We can calculate the second derivative by taking the derivative of the first derivative.\n\n\\frac{d^2}{dx^2}f(x)=\\frac{d}{dx}\\left(\\frac{d}{dx}f(x)\\right)\n\nWe can use the second derivative to determine whether a function is concave or convex. A function is concave if the second derivative is negative and convex if the second derivative is positive.\n\n\\frac{d^2}{dx^2}f(x)&gt;0 \\text{ for all } x \\Rightarrow \\text{f(x) is convex}\n \n\\frac{d^2}{dx^2}f(x)&lt;0 \\text{ for all } x \\Rightarrow \\text{f(x) is concave}\n\nThe second derivative of a function is written as \\frac{d^2}{dx^2}f(x) or \\frac{d^2 y}{dx^2} or f''(x).\nFor example, if f(x)=x^2, then:\n\n\\frac{d^2}{dx^2}x^2=\\frac{d}{dx}2x=2\n\nThe second derivative is positive (equal to 2) for all values of x. This implies that f(x)=x^2 is increasing at an increasing rate. The function is convex.\nThe second derivative of x^{0.5} is:\n\n\\frac{d^2}{dx^2}x^{0.5}=\\frac{d}{dx}0.5x^{-0.5}=-0.25x^{-1.5}\n\nThe second derivative is negative for all values of x for which x^{0.5} is defined. This implies that x^{0.5} is increasing at a decreasing rate. The function is concave. You can see this in Figure 5.1.\nThe second derivative of the logarithmic function is:\n\n\\frac{d^2}{dx^2}\\ln(x)=\\frac{d}{dx}\\frac{1}{x}=-\\frac{1}{x^2}\n\nThis second derivative is negative for all values of x for which \\ln(x) is defined. This implies that \\ln(x) is increasing at a decreasing rate. The function is concave. You can see this in Figure 5.3.\nWhen working through these notes, you will not be asked to differentiate any functions. However, understanding what differentiation is and what it shows will help you understand the intuition behind the concepts I discuss. I will use the functions f(x)=\\ln(x) and f(x)=x^{0.5} in future sections.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Notation and mathematical background</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/expected-value.html",
    "href": "decision-making-under-risk/expected-value.html",
    "title": "6  Expected value",
    "section": "",
    "text": "Summary\n\\begin{align*}\n\\mathbb{E}[X]&= p_1x_1 + p_2x_2 + ... + p_nx_n \\\\[6pt]\n&=\\sum_{i=1}^n p_ix_i\n\\end{align*}",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expected value</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/expected-value.html#summary",
    "href": "decision-making-under-risk/expected-value.html#summary",
    "title": "6  Expected value",
    "section": "",
    "text": "The expected value of a gamble is the average outcome in the long run, calculated as the probability-weighted sum of potential outcomes.\nFor a gamble with n possible outcomes x_i, each occuring the probability p_i, the expected value is expressed as:",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expected value</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/expected-value.html#introduction",
    "href": "decision-making-under-risk/expected-value.html#introduction",
    "title": "6  Expected value",
    "section": "6.1 Introduction",
    "text": "6.1 Introduction\nThe expected value of a gamble is the amount you can expect to win on average, in the long run, when you play a gamble.\nSuppose I offer to flip a coin. I give you $1 if it is heads and you will give me $1 if it is tails. What is the expected value of this gamble?\nThe expected value is $0. You lose $1 half the time and gain $1 half the time.\nFormally, given a gamble, the expected value E[X] of the random variable X is the probability-weighted sum of the potential outcomes. That is, we calculate the expected value by multiplying each possible outcome by the probability with which it occurs.\nFor the coin flip example, you multiply the 50% probability of heads by the $1 outcome and the 50% probability of tails by the -$1 outcome.\n\n\n\nProbability\nOutcome\n\n\n\n\n50%\n+$1\n\n\n50%\n-$1\n\n\n\n\nE[X]=0.5 \\times 1 + 0.5 \\times (-1) = 0\n\nWe calculate the expected value of a gamble with n possible outcomes using the following equation:\n\\begin{align*}\nE[X]&=p_1x_1+p_2x_2+...+p_nx_n \\\\[6pt]\n&=\\sum_{i=1}^np_ix_i\n\\end{align*}\nIn this equation, p_i is the probability of outcome x_i.\nFor those unfamiliar with the mathematical notation in the second line, the large symbol sigma allows us to write what could be a long expression much more succinctly. It means that we sum the term p_ix_i for each value of i for 1 through to n. We sum p_1x_1 with p_2x_2 and so on until we reach p_nx_n. Breaking it down this way shows that the second line is equivalent to what I wrote in the first line.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expected value</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/expected-value.html#expected-value-examples",
    "href": "decision-making-under-risk/expected-value.html#expected-value-examples",
    "title": "6  Expected value",
    "section": "6.2 Expected value examples",
    "text": "6.2 Expected value examples\nI will now illustrate the concept of expected value with some simple examples.\n\n6.2.1 Example 1\nYou are offered a bet with a 50% chance of winning $10 and a 50% chance of losing $8.\nThe expected value of the gamble X is:\n\\begin{align*}\nE[X]&=\\sum_{i=1}^n p_ix_i \\\\[12pt]\n&=0.5\\times 10+0.5\\times (-8) \\\\[6pt]\n&=\\$1\n\\end{align*}\nRelating back to my earlier explanation of the summation symbol, here we have n=2 outcomes. We sum p_1=0.5 multiplied by x_1=10 with p_2=0.5 multiplied by x_2=-8.\nSuppose your chance of winning increases to 60%. The expected value of the gamble is:\n\\begin{align*}\nE[X]&=\\sum_{i=1}^n p_ix_i \\\\[12pt]\n&=0.6\\times 10+0.4\\times (-8) \\\\[6pt]\n&=\\$2.80\n\\end{align*}\n\n\n6.2.2 Example 2\nYou are offered a bet with a 50% chance of winning 50% of your wealth and a 50% chance of losing 40% of your wealth.\nThe expected value of the bet is:\n\\begin{align*}\nE[X]&=\\sum_{i=1}^n p_ix_i \\\\[12pt]\n&=0.5\\times 0.5W+0.5\\times (-0.4W) \\\\[6pt]\n&=0.05W\n\\end{align*}\nThe expected value is 5% of your wealth.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Expected value</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/axioms-for-expected-utility-theory.html",
    "href": "decision-making-under-risk/axioms-for-expected-utility-theory.html",
    "title": "7  Axioms for Expected Utility Theory",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Axioms for Expected Utility Theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/axioms-for-expected-utility-theory.html#summary",
    "href": "decision-making-under-risk/axioms-for-expected-utility-theory.html#summary",
    "title": "7  Axioms for Expected Utility Theory",
    "section": "",
    "text": "Expected Utility Theory is based on four main axioms: completeness, transitivity, continuity, and independence.\nThe continuity axiom states that if an agent prefers option A to B, and B to C, there exists some probability mixture of A and C that the agent finds equally desirable to B.\nThe independence axiom asserts that a preference between two lotteries should not be affected by mixing both with an identical third lottery.\nThese axioms allow for the construction of a cardinal utility function that represents an agent’s preferences over lotteries.\nAdditional auxiliary axioms often adopted include a reference point of zero wealth, non-satiation, monotonicity, convexity, and diminishing marginal utility.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Axioms for Expected Utility Theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/axioms-for-expected-utility-theory.html#introduction",
    "href": "decision-making-under-risk/axioms-for-expected-utility-theory.html#introduction",
    "title": "7  Axioms for Expected Utility Theory",
    "section": "7.1 Introduction",
    "text": "7.1 Introduction\n\n\nIn my discussion of rationality, I noted that in its most basic form analysis of consumer choice rests on just two assumptions: completeness and transitivity.\nFor decision-making under risk, we require two additional axioms of desirable behaviour to develop a predictive or descriptive model. These additional axioms are continuity and the independence.\nThat gives us four axioms:\n\nCompleteness\nTransitivity\nContinuity\nIndependence\n\nUnder these axioms, a decision maker behaves as if choosing between risky prospects by selecting the one with the highest expected utility.\nThe four axioms are often called the von Neumann–Morgenstern axioms for a rational agent. This gives us another benchmark of “rationality”. An agent is rational if they conform with these four axioms.\nOne important feature of preferences under these assumptions is that utility is cardinal. The magnitude, not just rank, of the numbers matters.\nIf you look at other resources on the axioms underlying expected utility theory, you may come across an axiom called the Archimedean property. The Archimedean property is an alternative assumption to continuity. Only one of continuity or the Archimedean property need be assumed. I will not cover the Archimedean property in these notes.\nBeyond the axioms of completeness, transitivity, continuity and independence, some additional axioms are often adopted for practical purposes. These include using a reference point of zero wealth, non-satiation, monotonicity, convexity and diminishing marginal utility.\nIn the following sections, I discuss each of the von Neumann-Morgenstern axioms and the auxiliary axioms we use in examining decision making under risk.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Axioms for Expected Utility Theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/axioms-for-expected-utility-theory.html#continuity",
    "href": "decision-making-under-risk/axioms-for-expected-utility-theory.html#continuity",
    "title": "7  Axioms for Expected Utility Theory",
    "section": "7.2 Continuity",
    "text": "7.2 Continuity\n\n\nThe idea behind continuity is that people have similar preferences for similar bundles. If x is preferred to y, bundles close to x are preferred to bundles close to y. There are no “jumps” in utility.\nContinuity guarantees that every preference relation can be represented by a continuous utility function (and vice versa).\nHere are two formal definitions.\n\n7.2.1 Definition 1\nA preference relation is continuous if for any x \\succ y there exists a number \\epsilon &gt; 0 such that every bundle a that is less distant from x than \\epsilon and every bundle b that is less distant from y than \\epsilon results in a \\succ b.\nTo put this another way, a preference relation is continuous if for any x \\succ y there are some neighbourhoods N_\\epsilon x and N_\\epsilon y around x and y such that for every a\\in N_\\epsilon x and b\\in N_\\epsilon y we have a \\succ b.\nOne way to picture this is to imagine a circle around bundles x and y of radius \\epsilon. These circles represent the neighbourhood. There will always exist some circle - even if very small - within which every bundle a within the neighbourhood of x is preferred to bundle b within the neighbourhood of y.\n\n\nCode\nlibrary(ggplot2)\n\n# Plot the points\nggplot()+\n  geom_point(aes(x=1, y=1.5)) +\n  geom_text(aes(x=1, y=1.58, label=\"x\")) +\n  geom_point(aes(x=1.5, y=1)) +\n  geom_text(aes(x=1.5, y=1.08, label=\"y\")) +\n  geom_point(aes(x = 1, y = 1.5), pch=21, size=30) +\n  geom_point(aes(x = 1.5, y = 1), pch=21, size=30) +\n  geom_point(aes(x=1.125, y=1.3)) +\n  geom_text(aes(x=1.125, y=1.38, label=\"a\")) +\n  geom_point(aes(x=1.45, y=1.15)) +\n  geom_text(aes(x=1.45, y=1.23, label=\"b\")) +\n\n  # Add a line representing the radius of each circle and label the line epsilon\n  geom_segment(aes(x = 1, y = 1.5, xend = 1.25, yend = 1.5), linetype=\"dashed\") +\n  geom_segment(aes(x = 1.5, y = 1, xend = 1.25, yend = 1), linetype=\"dashed\") +\n  \n  # Add label epsilon to each circle\n  geom_text(aes(x=1.125, y=1.55, label=\"\\u03B5\")) +\n  geom_text(aes(x=1.375, y=1.05, label=\"\\u03B5\")) +\n  \n  # Add vertical and horizontal axis lines\n  geom_vline(aes(xintercept = 0), linewidth=0.25) + \n  geom_hline(aes(yintercept = 0), linewidth=0.25) +\n\n  # Remove x and y axis labels\n  labs(x = \"\", y = \"\") +\n  \n  # Set the limits of the plot\n  coord_fixed(xlim = c(0,2.2), ylim = c(0,2.2))+\n\n  # Set the theme\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe intuition behind this definition is that a very small change in your bundle should not result in a sudden switch of your preferences. If you prefer 5 bananas to 2 oranges, you will likely prefer 4.9 bananas to 2 oranges. (And if not, there will be some amount of bananas between 4.9 and 5 that you prefer over 2 oranges.)\nHere’s another intuitive example: if you prefer a Mercedes to a Toyota, there will be some level of defect in the Mercedes that you would be willing to accept while still preferring the Mercedes to the Toyota.\n\n\n7.2.2 Definition 2\nIf x, y and z are lotteries with x\\succcurlyeq y\\succcurlyeq z, the continuity axiom requires that there exists a probability p such that y is equally as good as a mix of x and z. That is, there exists p such that:\npx+(1-p)z \\sim y\nThe below diagram illustrates continuity under this definition.\nOn the diagram are three bundles: x, y and z, and each sits on a different indifference curve. The indifference curve that x is on is higher than that of y which is higher than that of z. That is, x\\succcurlyeq y\\succcurlyeq z.\nNow consider a gamble that pays x with probability p and z with probability 1-p. Each value of p would result in a gamble with utility falling between that of x and z. If we were to draw a line between x and z, you could think of the utility of the gamble for each value of p as having the same utility as a bundle on that line. Under the continuity axiom, there would be no holes in that line. For some value of p, that gamble will be on the same indifference curve for y. At that point, px+(1-p)z \\sim y.\n\n\nCode\nlibrary(ggplot2)\n\n# Create a data frame\ndf &lt;- data.frame(\n  n = seq(0.05,20,0.05),\n  x=NA,\n  y=NA,\n  z=NA\n)\n\n# Fill columns of the data frame\ndf$x &lt;- (7-df$n^0.5)^2\ndf$y &lt;- (6-df$n^0.5)^2\ndf$z &lt;- (5-df$n^0.5)^2\n\n# Plot the line and points\nggplot()+\n  geom_line(data = df, mapping = aes(n, x))+ \n  geom_line(data = df, mapping = aes(n, y))+ \n  geom_line(data = df, mapping = aes(n, z))+\n  geom_point(aes(x=15, y=(7-15^0.5)^2)) +\n  geom_text(aes(x=15, y=10.5, label=\"x\"))+\n  geom_point(aes(x=10, y=(6-10^0.5)^2)) +\n  geom_text(aes(x=10, y=9, label=\"y\"))+\n  geom_point(aes(x=12, y=(5-12^0.5)^2)) +\n  geom_text(aes(x=12, y=1.8, label=\"z\"))+\n\n  # Add vertical and horizontal axis lines\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n\n  # Add a dashed line segment between two points\n  geom_segment(aes(x = 15, y = (7-15^0.5)^2), xend = 12, yend = (5-12^0.5)^2, linetype=2)+\n\n  # Remove the axes labels\n  labs(x = \"\", y = \"\") +\n\n  # Set the limits of the plot\n  coord_fixed(xlim = c(0,20), ylim = c(0,20))+\n\n  # Set the theme\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n7.2.3 Example of discontinuous preferences\nLexicographic preferences occur where an agent prefers any amount of a good x to any amount of another good y. If choosing between bundles of goods, the agent will choose the bundle with the most x, regardless of the amount of y. They will only consider the amount of y if the amount of x in two bundles is identical.\nConsider an agent with lexicographic preferences who is offered the following combinations of x and y.\nA. (1, 1)\nB. (1, 2)\nC. (1.1, 1)\nTheir preference ranking will be C\\succ B \\succ A. They prefer C as it has more x than the other two options. As A and B have the same amount of x, the agent distinguishes them based on the quantity of y, preferring B.\nThis function is not continuous as there is a “jump” whenever there is an increase in x, even if y is large. Add an infinitesimal amount \\epsilon of x to bundle A and the preference relation between bundle A and bundle B flips.\nThese three bundles A, B and C are represented graphically below.\nFirst, let’s consider these preferences in terms of the first definition, being that there are some neighbourhoods around A and B such that we will always prefer another bundle of goods within the neighbourhood of B to any bundles within the neighbourhood of A. Around A I have drawn a circle of radius \\epsilon, which we can consider to be the neighbourhood. No matter how small I draw this circle - that is, no matter how small \\epsilon - any bundle within the circle that lies to the right of A (that is, contains x&gt;1) is preferred to bundle B. There is a jump in preferences to the right of A.\n\n\nCode\nlibrary(ggplot2)\n\n# Plot the points\nggplot()+\n  geom_point(aes(x=1, y=1)) +\n  geom_text(aes(x=1, y=1.1, label=\"A\")) +\n  geom_point(aes(x=1, y=2)) +\n  geom_text(aes(x=1, y=2.1, label=\"B\")) +\n  geom_point(aes(x=1.1, y=1)) +\n  geom_text(aes(x=1.1, y=1.1, label=\"C\")) +\n  geom_point(aes(x = 1, y = 1), pch=21, size=7) +\n\n  # Add vertical and horizontal axis lines\n  geom_vline(aes(xintercept = 0), linewidth=0.25) + \n  geom_hline(aes(yintercept = 0), linewidth=0.25) +\n\n  # Remove x and y axis labels\n  labs(x = \"x\", y = \"y\") +\n\n  # Set the limits of the plot\n  coord_fixed(xlim = c(0,2.2), ylim = c(0,2.2))+\n\n  # Set the theme\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nOne interesting feature of lexicographic preferences is that you cannot draw indifference curves on this figure. If a bundle differs from another, it must be strictly preferred to the other as no amount of y can make up for any amount of x.\nWe can also consider lexicographic preferences in terms of the second definition of continuity. There is no p for which:\npA+(1-p)C \\sim B\nWhen p=1, B \\succ A. For any p&lt;1, pA+(1-p)C \\succ B as any non-zero share of C makes the combination of A and C preferred.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Axioms for Expected Utility Theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/axioms-for-expected-utility-theory.html#sec-independence",
    "href": "decision-making-under-risk/axioms-for-expected-utility-theory.html#sec-independence",
    "title": "7  Axioms for Expected Utility Theory",
    "section": "7.3 Independence",
    "text": "7.3 Independence\n\n\nConsider the following scenarios.\nIn the first, a person has a choice between an orange and an apple. They state that they strictly prefer the orange.\nIn the second, they are offered a choice between two gambles. The first gamble is a 50% chance of an orange and a 50% chance of a pear. The second is a 50% chance of an apple and a 50% chance of a pear. They state that they strictly prefer the gamble with a 50% chance of an orange.\nCompare the two scenarios. The choice between an apple or an orange from the first scenario is mixed with a 50% probability of a pear in the second.\nUnder the axiom of independence, a person who prefers the orange in the first will prefer the gamble with the orange in the second. Mixing those two lotteries (a 100% chance of an orange or a 100% chance of an apple) with a third lottery - in this case, a pear - will not change their order of preference.\nMore generally, under the axiom of independence, a person who mixes two lotteries with a third lottery will maintain the same order of preference when the lotteries are mixed as they had for the two original lotteries when presented independently of the third.\nA formal definition states that if:\n\nx and y are lotteries with x\\succcurlyeq y and\np is the probability that a third option z is present, then:\n\npz+(1-p)x\\succcurlyeq pz+(1-p)y\nThe third choice, z does not change the preference ordering. The order of preference for x over y holds. It is independent of the presence of z.\n\n7.3.1 Example of the axiom of independence\nLet us put our earlier example into this formal definition.\nSuppose x is a 100% probability of an orange and y is a 100% probability of an apple. I strictly prefer an orange to an apple.\nSuppose there is now a third possibility z of receiving a pear, which will be present with p=50\\% probability.\nUnder the axiom of independence, if I prefer oranges to apples, I will prefer a gamble with a 1-p=50\\% chance of getting an orange and p=50\\% chance of receiving a pear to a gamble with a 1-p=50\\% chance of getting an apple and a p=50\\% chance of receiving a pear.\nThat is:\n\\begin{align*}\n\\text{orange}\\succ \\text{apple}  \\Longrightarrow 50\\% \\text{ chance of orange} + 50\\% \\text{ chance of pear}\\succ \\\\\n50\\% \\text{ chance of apple}+50\\% \\text{chance of pear}\n\\end{align*}\n\n\n7.3.2 Distinguishing the independence of irrelevant alternatives from the independence axiom\nThe independence axiom is distinct from the principle of the independence of irrelevant alternatives.\nThe independence of irrelevant alternatives states that if an agent prefers x to y, the introduction of a third option z should not change the preference order between x and y. For example, if you select fish rather than chicken from a restaurant menu, being told by the waiter that there is a vegetarian option should not lead you to change your selection to chicken.\nThe independence axiom is specific to lotteries. The logic behind this specificity is that the outcomes of a lottery are never realised together. They can be treated as independent. In my illustration involving apples, oranges and pears, there is no outcome where the agent receives more than a single piece of fruit. They will receive an apple, an orange or a pear. They will not receive a mix of fruit.\nThis is not the case for goods. Consider the following example with goods drawn from Page (2022). You are again in a restaurant and have a choice between chicken with mashed potato and beef with mashed potato. You choose the chicken. You are then told that the restaurant has run out of mashed potato, and the options are now chicken or beef with peas. Under the axiom of independence, you would not change your choice to beef. However, beef may go better with peas than chicken. There is an interaction between the two, with the options realised together. Due to this interaction, the axiom of independence is less compelling for the case of goods than it is for lotteries.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Axioms for Expected Utility Theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/axioms-for-expected-utility-theory.html#auxiliary-axioms-for-expected-utility-theory",
    "href": "decision-making-under-risk/axioms-for-expected-utility-theory.html#auxiliary-axioms-for-expected-utility-theory",
    "title": "7  Axioms for Expected Utility Theory",
    "section": "7.4 Auxiliary axioms for expected utility theory",
    "text": "7.4 Auxiliary axioms for expected utility theory\n\n\nBeyond completeness, transitivity, continuity and independence, economists often adopt other axioms. These are not required for expected utility theory, but make analysis more practicable.\nThese include:\n\nReference point of zero wealth\nNon-satiation\nMonotonicity\nConvexity\nDiminishing marginal utility\n\nI provide further detail on these.\n\n7.4.1 Reference point of zero wealth\nWhen people are considering whether to accept or gamble or compare options, they do not decide from a blank slate. They come with an existing set of resources (wealth), and that wealth may affect their decision. A gamble may be more attractive if someone has more or less wealth.\nThis necessitates the setting of a “reference point” from which utility is calculated. In Expected Utility Theory, that reference point is typically considered to be zero wealth.\nThe way this is implemented is we typically calculate utility over total wealth. For example, if offered a gamble where they could win or lose $10, we do not calculate the utility of each option as U(\\$10) and U(-\\$10). Rather, the utility of each option is calculated as U(W+\\$10) and U(W-\\$10).\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  log(x)\n}\n\ndf &lt;- data.frame(\n  x=seq(1,220,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\nx1&lt;-30 #loss\nW &lt;- 115\nx2&lt;-200 #win\npx2&lt;-(W-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"U(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #set limits - need to include room for labels\n  coord_cartesian(xlim = c(-25, 220), ylim = c(-0.25, 6))+\n\n  #Add labels W-10, W-10 and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"W-10\", size = 4, hjust = 0.5, vjust = 1.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"U(W-10)\", size = 4, hjust = 1.05, vjust = 0.6)+\n\n  #Add line to curve indicating utility of wealth\n  annotate(\"segment\", x = W, y = 0, xend = W, yend = u(W), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(W), xend = W, yend = u(W), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(W), label = \"U(W)\", size = 4, hjust = 1.05, vjust = 0.3)+\n\n  #Add labels W+10, U(W+10) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"W+10\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"U(W+10)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels W, E[U(X)] and curve indicating each\n  annotate(\"text\", x = W, y = 0, label = \"W\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = W, y = 0, xend = W, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")\n\n\n\n\n\n\n\n\n\nThe practical impact of this implementation is that people’s choices may differ depending on their wealth. The same gamble may be accepted or rejected at different levels of wealth.\n\n\n7.4.2 Non-satiation\nThe idea behind non-satiation is that no matter what you have, there is always another (nearby) bundle that you would rather have. There is no “maximum” level of utility that you can achieve. Whatever your utility now, you can always increase it.\nIn this diagram I have plotted an indifference curve. Point x is on the curve. For non-satiation, there will always be a point, such as y, that is strictly preferred to x.\n\n\nCode\n## Load ggplot2\nlibrary(ggplot2)\n\n## Create a data frame with 2 columns and 4 rows\ndf &lt;- data.frame(\n  x = c(1, 4, 8, 15, 20),\n  y = c(20, 10, 5, 10, 8)\n)\n\n# Plot a smooth line through the points\n  ggplot()+\n    geom_smooth(data = df, mapping = aes(x, y), color = \"black\", na.rm = TRUE)+\n\n    # Add points and labels\n    geom_point(aes(x=8, y=5)) +\n    geom_text(aes(x=7.5, y=4.5, label=\"x\"))+\n    geom_point(aes(x=8, y=8)) +\n    geom_text(aes(x=8, y=7.5, label=\"y\"))+\n\n    # Add vertical and horizontal axis lines\n    geom_vline(xintercept = 0, linewidth=0.25)+ \n    geom_hline(yintercept = 0, linewidth=0.25)+\n\n    # Remove x and y axis labels \n    labs(x = \"\", y = \"\")+\n\n    # Set the limits of the plot\n    coord_fixed(xlim = c(0,20), ylim = c(0,20))+\n\n    # Set the theme\n    theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n7.4.3 Monotonicity\nPreferences are monotone if more of any good in the bundle makes the agent strictly better off. Non-satiation is implied by monotonicity, but not the other way around.\nMonotonicity implies downward-sloping indifference curves. This is because any increase of a good in your bundle would take you to a higher indifference curve. A horizontal indifference curve is not feasible as moving along that indifference curve implies more of the good, but that is not possible as monotonicity implies you are better off and hence on a higher indifference curve.\nThis can be seen in the following diagram. Point x lies on the indifference curve. Increasing the amount of either good will take you to a higher indifference curve. That is true for all points on that indifference curve.\n\n\nCode\n## Load ggplot2\nlibrary(ggplot2)\n\n## Create a data frame with 2 columns and 4 rows\ndf &lt;- data.frame(\n  x = c(1, 4, 8, 15, 20),\n  y = c(20, 10, 8, 6, 3)\n)\n\n# Plot a smooth line through the points\n  ggplot()+\n    geom_smooth(data = df, mapping = aes(x, y), color = \"black\", na.rm = TRUE)+\n\n    # Add points and labels\n    geom_point(aes(x=8, y=8)) +\n    geom_text(aes(x=8, y=7.5, label=\"x\"))+\n\n    # Add vertical and horizontal axis lines\n    geom_vline(xintercept = 0, linewidth=0.25)+ \n    geom_hline(yintercept = 0, linewidth=0.25)+\n\n    # Remove x and y axis labels \n    labs(x = \"\", y = \"\")+\n\n    # Set the limits of the plot\n    coord_fixed(xlim = c(0,20), ylim = c(0,20))+\n\n    # Set the theme\n    theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n7.4.4 Convexity\nConvexity means that people have a preference for variety or combination (indifference curves bulge toward the origin). Averages are better than extremes.\nIn many contexts this makes sense. For example, suppose you are indifferent between two beers and two meat pies. Under this assumption, any mix of the two, such as a beer and a pie will be at least as preferred as the two beers or two pies.\nFormally, a preference relation is convex if, for any x\\succcurlyeq y and for every \\theta\\in[0,1]:\n\n\\theta x+(1-\\theta)y\\succcurlyeq y\n\nThis definition is illustrated in the following diagram. The curve represents an indifference curve for different combinations of two goods. There are two bundles, x and y. In this case, x\\succcurlyeq y (as x\\sim y). Any weighted combination of x and y, which would be on the line between the two, can be seen to be strictly preferred to either x or y as it would be on a higher indifference curve (a curve further from the origin).\n\n\nCode\nlibrary(ggplot2)\n\n# Create a data frame\ndf &lt;- data.frame(\n  n = seq(0.05,20,0.05),\n  x=NA\n)\n\n# Fill column x of the data frame\ndf$x &lt;- (5-df$n^0.5)^2\n\n# Plot the line and points\nggplot()+\n  geom_line(data = df, mapping = aes(n, x))+ \n  geom_point(aes(x=5, y=(5-5^0.5)^2)) +\n  geom_text(aes(x=5, y=7, label=\"x\"))+\n  geom_point(aes(x=15, y=(5-15^0.5)^2)) +\n  geom_text(aes(x=15, y=1, label=\"y\"))+\n\n  # Add vertical and horizontal axis lines\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  \n  # Add a dashed line segment between the two points\n  geom_segment(aes(x = 5, y = (5-5^0.5)^2), xend = 15, yend = (5-15^0.5)^2, linetype=2)+\n\n  # Remove x and y axis labels\n  labs(x = \"\", y = \"\") +\n\n  # Set the limits of the plot\n  coord_fixed(xlim = c(0,20), ylim = c(0,20))+\n\n  # Set the theme\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nOne point to note from this diagram is that if the indifference curve were a straight line, any point on a line between x and y would also be on that line, and weakly preferred to x and y. This would still be a convex curve.\nThis contrasts with strict convexity. Strict convexity is where, for any x\\sim y, x\\neq y and for every \\theta\\in[0,1]:\n\\theta x+(1-\\theta)y\\succcurlyeq y\n\\theta x+(1-\\theta)y\\succcurlyeq x\nFor two equivalent goods or bundles, a weighted average of the two bundles is better than each of those bundles.\n\n\n7.4.5 Diminishing marginal utility\nSuppose you want some chocolate. You eat a piece. You then eat another. And another. How much utility do you imagine getting from the first piece compared to the 100th piece? The first piece will likely be much more satisfying than the 100th. This is the idea of diminishing marginal utility.\nMarginal utility is how much utility you get or lose from an incremental decrease or increase in consumption. Under diminishing marginal utility, each successive additional unit of consumption delivers a smaller (diminishing) amount of utility than the last.\nThis concept is illustrated in the following diagram. The curve represents an indifference curve for the good x. The curve is concave, which means that the slope of the curve decreases in x and the marginal utility of each additional unit of good x decreases as you consume more of it. One additional unit of good x when the agent has a units of the good leads to a much larger increase in utility than one additional unit when the agent has b units of the good.\n\n\nCode\nlibrary(ggplot2)\n\n# Create a data frame\ndf &lt;- data.frame(\n  x = seq(0.05,20,0.05),\n  y=NA\n)\n\n# Fill column x of the data frame\ndf$y &lt;- 6*log(df$x)\n\n# Plot the line\nggplot()+\n  geom_line(data = df, mapping = aes(x, y))+\n\n  # Add lines showing U(2), U(3), U(18) and U(19)\n  geom_segment(aes(x = 2, y = 6*log(2), xend = 2, yend = 0), linetype=2)+\n  geom_segment(aes(x = 3, y = 6*log(3), xend = 3, yend = 0), linetype=2)+\n  geom_segment(aes(x = 18, y = 6*log(18), xend = 18, yend = 0), linetype=2)+\n  geom_segment(aes(x = 19, y = 6*log(19), xend = 19, yend = 0), linetype=2)+\n  \n  # Add labels for 2, 3, 18 and 19 on x-axis\n  geom_text(aes(x = 2, y = -0.5, label=\"a\"), size=3)+\n  geom_text(aes(x = 3.5, y = -0.5, label=\"a+1\"), size=3)+\n  geom_text(aes(x = 18, y = -0.5, label=\"b\"), size=3)+\n  geom_text(aes(x = 19.5, y = -0.5, label=\"b+1\"), size=3)+\n  \n  # Add lines projecting to y-axis from U(2), U(3), U(18) and U(19)\n  geom_segment(aes(x = 0, y = 6*log(2), xend = 2, yend = 6*log(2)), linetype=2)+\n  geom_segment(aes(x = 0, y = 6*log(3), xend = 3, yend = 6*log(3)), linetype=2)+\n  geom_segment(aes(x = 0, y = 6*log(18), xend = 18, yend = 6*log(18)), linetype=2)+\n  geom_segment(aes(x = 0, y = 6*log(19), xend = 19, yend = 6*log(19)), linetype=2)+\n  \n  # Add labels for U(2), U(3), U(18) and U(19) on y-axis\n  geom_text(aes(x = -0.5, y = 6*log(2), label=\"U(a)\"), hjust=1, size=3)+\n  geom_text(aes(x = -0.5, y = 6*log(3), label=\"U(a+1)\"), hjust=1, size=3)+\n  geom_text(aes(x = -0.5, y = 6*log(18)-0.25, label=\"U(b)\"), hjust=1, size=3)+\n  geom_text(aes(x = -0.5, y = 6*log(19)+0.25, label=\"U(b+1)\"), hjust=1, size=3)+\n  \n  # Add vertical and horizontal axis lines\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n\n  # Add x and y axis labels\n  labs(x = \"x\", y = \"U(x)\") +\n\n  # Set the limits of the plot while keeping plot square\n  coord_fixed(xlim = c(-2,20), ylim = c(0,20))+\n  \n  # Set the theme\n  theme_minimal()+\n  \n  # Remove numbers from axis\n  theme(axis.text.x = element_blank(), axis.text.y = element_blank())\n\n\n\n\n\n\n\n\n\nDiminishing marginal utility leads to risk-averse preferences. Someone is risk averse if they strictly prefer the expected value of a gamble to the gamble itself.\nDiminishing marginal utility is related to the axiom of convexity. Diminishing marginal utility will lead to convex indifference curves. However, the reverse relationship does not always hold.\n\n\n\n\nPage, L. (2022). Optimally Irrational: The Good Reasons We Behave the Way We Do. Cambridge University Press. https://www.cambridge.org/au/academic/subjects/economics/microeconomics/optimally-irrational-good-reasons-we-behave-way-we-do, https://www.cambridge.org/au/academic/subjects/economics/microeconomics",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Axioms for Expected Utility Theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/expected-utility-theory.html",
    "href": "decision-making-under-risk/expected-utility-theory.html",
    "title": "8  Expected Utility Theory",
    "section": "",
    "text": "Summary\n\\mathbb{E}[U(X)] = \\sum_{i=1}^n p_i U(x_i)\n\\mathbb{E}[U(W+X)] = \\sum_{i=1}^n p_i U(W+x_i)\nU(\\mathbb{E}[X]) &gt; \\mathbb{E}[U(X)]\nU(\\mathbb{E}[X]) &lt; \\mathbb{E}[U(X)]\nU(\\mathbb{E}[X]) = \\mathbb{E}[U(X)]",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Expected Utility Theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/expected-utility-theory.html#summary",
    "href": "decision-making-under-risk/expected-utility-theory.html#summary",
    "title": "8  Expected Utility Theory",
    "section": "",
    "text": "Expected utility theory states people maximise expected utility, not expected value, in choosing between risky prospects.\nExpected utility is calculated by weighting the utility of each outcome by its probability and summing.\n\n\n\nOutcomes typically represent final wealth positions, not just payoffs, so decisions depend on current wealth. The formula incorporating initial wealth used for calculating expected utility is:\n\n\n\nExpected utility theory allows the examination of an agent’s attitude toward risk, which can be risk aversion, risk neutrality, or risk seeking.\nA risk-averse person prefers a sure amount to a gamble with the same expected value.\n\n\n\nA risk-seeking person prefers a gamble to a sure amount of the same expected value.\n\n\n\nA risk-neutral person is indifferent between a gamble and receiving its expected value with certainty.\n\n\n\nCertainty equivalent (CE) is the amount of money that makes a person indifferent between taking a gamble and taking the money. For risk-averse individuals, CE &lt; \\mathbb{E}[X]; for risk-neutral, CE = \\mathbb{E}[X]; for risk-seeking, CE &gt; \\mathbb{E}[X].",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Expected Utility Theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/expected-utility-theory.html#introduction",
    "href": "decision-making-under-risk/expected-utility-theory.html#introduction",
    "title": "8  Expected Utility Theory",
    "section": "8.1 Introduction",
    "text": "8.1 Introduction\nUnder expected utility theory, people do not seek to maximize expected value but instead, maximize expected utility.\nUnder expected utility theory, people choose between risky prospects (prospect being another word for lottery or gamble common in the literature) by comparing expected utility values. An agent would pick the option that maximises their expected utility.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Expected Utility Theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/expected-utility-theory.html#calculating-expected-utility",
    "href": "decision-making-under-risk/expected-utility-theory.html#calculating-expected-utility",
    "title": "8  Expected Utility Theory",
    "section": "8.2 Calculating expected utility",
    "text": "8.2 Calculating expected utility\nConsider a prospect with final outcomes x_1, ..., x_n, with each outcome occurring with probability p_1, ..., p_n. Each outcome would deliver utility U(x_i).\n\nX=(p_1, x_1;\\ p_2, x_2; ...\\ ;\\ p_n, x_n)\n\nFor example, the prospect might be a coin flip that delivers a win of $10 for heads and a loss of $10 for tails. We would represent this prospect as:\n\nX=(0.5, \\$10;\\ 0.5, -\\$10)\n\nExpected utility, E[U(X)], is calculated using the following formula:\n\\begin{align*}\nE[U(X)]&=p_1U(x_1)+p_2U(x_2)+ ... +p_nU(x_n) \\\\[6pt]\n&=\\sum_{i=1}^n p_iU(x_i)\n\\end{align*}\nYou can think of this formula as comprising the following steps:\n\nDefine utility U(x_i) over final outcomes x_1, ..., x_n\nWeight the utility of each outcome U(x_i) by the probability p_i of outcome x_i\nAdd the weighted utilities.\n\nFor the coin toss that delivers a win or loss of $10, we would write:\n\nE[U(X)]=0.5\\times U(\\$10)+0.5\\times U(-\\$10)\n\nThere is an important note regarding outcomes x_1, ..., x_n. Typically, these outcomes are not just the payoffs from the gamble, but rather the agent’s final position. If the agent has wealth of $100 and is offered a coin flip to win or lose $10, the outcomes are typically taken to be $90 and $110. Their decision depends on their current wealth. As a result, expected utility is often represented as in this equation:\n\\begin{align*}\nE[U(W+X)]&=p_1U(W+x_1)+p_2U(W+x_2)  \\\\[6pt]\n&\\qquad +...+p_nU(W+x_n) \\\\[6pt]\n&=\\sum_{i=1}^n p_iU(W+x_i)\n\\end{align*}\nReturning to our coin toss example, if our starting wealth was $100, the expected utility of the coin toss is:\n\nE[U(X)]=0.5\\times U(\\$110)+0.5\\times U(\\$90)",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Expected Utility Theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/expected-utility-theory.html#attitudes-toward-risk",
    "href": "decision-making-under-risk/expected-utility-theory.html#attitudes-toward-risk",
    "title": "8  Expected Utility Theory",
    "section": "8.3 Attitudes toward risk",
    "text": "8.3 Attitudes toward risk\n\n\nExpected utility theory allows us to examine an agent’s attitude toward risk.\nThere are three possible attitudes toward risk: risk aversion, risk neutrality, and risk seeking.\nIf a person prefers a sure amount to a gamble with the same expected value, they are risk averse. That is, the utility of the expected value of X is greater than the expected utility of X.\n\nU(E[X])&gt;E[U(X)]\n\nIf a person prefers a gamble to a sure amount of the same expected value, they are risk-seeking. That is, the expected utility of X is greater than the utility of the expected value of X.\n\nU(E[X])&lt;E[U(X)]\n\nIf a person is indifferent between a gamble and receiving the expected value of the gamble with certainty, they are risk neutral. That is. the utility of the expected value of X is equal to the expected utility of X.\n\nU(E[X])=E[U(X)]\n\n\n8.3.1 Certainty equivalent\nOne useful concept in the analysis of attitudes to risk is the certainty equivalent. The certainty equivalent (CE) of a gamble X is the amount of money such that you are indifferent between taking the gamble and taking the money. That is, the utility of the certainty equivalent is equal to the expected utility of the gamble.\n\nu(CE)=E[U(X)]\n\nFor a risk-averse person, the certainty equivalent of the bet is less than the expected value of the gamble. The certainty equivalent is equal to the expected value in the case of risk neutrality. A risk-seeking person would have a certainty equivalent higher than the expected value of the gamble.\nI will now look at each of the attitudes in turn.\n\n\n8.3.2 Risk aversion\nA risk-averse person prefers a sure amount to a gamble with the same expected value. If I strongly prefer $10 for certain to a gamble with an expected value of $10, I am risk averse. The certainty equivalent of the prospect for this person would be less than $10.\nThe following chart illustrates. The x-axis is the amount of the good over which the person receives utility. In the case of monetary gambles of the type we are talking about, the x-axis is the amount of money. The y-axis is the utility the person receives from that money.\nThe utility curve is a plot of the utility function for each amount of money.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  log(x)\n}\n\ndf &lt;- data.frame(\n  x=seq(1,220,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\np1 &lt;- 0.5\nx1 &lt;- 30 #loss\np2 &lt;- 0.5\nx2 &lt;- 200 #win\nev &lt;- p1*x1+p2*x2 #expected value of gamble\nxc &lt;-115 #certain outcome\nce &lt;-exp(p1*u(x1)+p2*u(x2)) #certainty equivalent\npx2 &lt;-(ev-x1)/(x2-x1)\n\nrisk_aversion_plot_1 &lt;- ggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"U(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #set limits - need to include room for labels\n  coord_cartesian(xlim = c(-25, 220), ylim = c(-0.1, 6))\n\nrisk_aversion_plot_1\n\n\n\n\n\nFigure 8.1: Risk aversion 1\n\n\n\n\n\n\n\n\nThe gamble shown in this chart has two possible outcomes, x_1 and x_2. An outcome of x_1 would result in utility U(x_1). An outcome of x_2 would result in utility U(x_2).\n\n\nCode\nrisk_aversion_plot_2 &lt;- risk_aversion_plot_1+\n\n  #Add labels x1, U(x1) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"x1\", size = 4, hjust = 0.5, vjust = 1.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"U(x1)\", size = 4, hjust = 1.05, vjust = 0.6)+\n\n  #Add labels x2, U(x2) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"x2\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"U(x2)\", size = 4, hjust = 1.05, vjust = 0.45)\n\nrisk_aversion_plot_2\n\n\n\n\n\nFigure 8.2: Risk aversion 2\n\n\n\n\n\n\n\n\nI have drawn a straight dash-dot line between the points on the utility curve for each of those outcomes. The expected utility from any gamble involving those two outcomes would fall on that line. Where on that line would depend on the probability of each outcome, and it would occur at a point in line with the expected value of the gamble. You can see the expected value of the gamble marked on the x-axis. If we extend up from that point, we can read the expected utility of the gamble, E[U(X)], from the y-axis.\n\n\nCode\nrisk_aversion_plot_3 &lt;- risk_aversion_plot_2+\n\n  #Add line to curve indicating utility of expected value\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"U[E(X)]\", size = 4, hjust = 1.05, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels E[X], E[U(X)] and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[X]\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"E[U(X)]\", size = 4, hjust = 1.05, vjust = 0.45)\n\nrisk_aversion_plot_3\n\n\n\n\n\nFigure 8.3: Risk aversion 3\n\n\n\n\n\n\n\n\nOne way to think about why projecting the expected value onto the expected utility line identifies the expected utility of the bet is that each of the expected value and expected utility are weighted by the same probabilities. They both lie the same horizontal distance between the two potential outcomes.\nIn this example, the line between the utility of the two outcomes is always below the utility curve. That is, for any probabilities involving those two outcomes (except one of those outcomes with certainty), the expected utility of the prospect is less than the utility of the expected value of the prospect. In mathematical terms:\n\nU(E[x])&gt;E[U(x)]\n\nThe expected utility line between the two outcomes is always below the utility curve as the curve is concave. A concave curve leads to risk aversion. The greater the curvature, the more risk averse the agent is.\nFinally, the horizontal dashed line identifying E[U(X)] allows us to identify the certainty equivalent of the gamble. At the point on the x-axis marked CE, the utility from the certainty equivalent is equal to the expected utility of the prospect with expected value E[X]. As the certainty equivalent is less than the expected value, this provides another way of saying that the person is risk averse.\n\n\nCode\nrisk_aversion_plot_4 &lt;- risk_aversion_plot_3+\n\n  #Add vertical line indicating certainty equivalent and labelled \"CE\"\n  annotate(\"segment\", x = ce, xend = ce, y = 0, yend = u(ce), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = ce, y = 0, label = \"CE\", size = 4, hjust = 0.4, vjust = 1.5)\n\nrisk_aversion_plot_4\n\n\n\n\n\nFigure 8.4: Risk aversion 4\n\n\n\n\n\n\n\n\n\n8.3.2.1 Absolute and relative risk aversion\nIn studying economics, you may encounter two measures of risk aversion: absolute risk aversion and relative risk aversion.\nAbsolute risk aversion is a measure of how risk averse a person is at any particular level of wealth. A person with constant absolute risk aversion (CARA) responds to a fixed sum bet in the same way, whatever their wealth.\nFor example, when faced with a 50-50 bet to win $20 or lose $10, they will make the same decision regardless of whether they have $100 or $1,000,000 in their bank account.\nRelative risk aversion is a measure of how an individual’s risk aversion scales with their wealth. A person with constant relative risk aversion (CRRA) would respond to a bet risking a certain proportion of their wealth in the same way, whatever their wealth. This means that as their wealth increases, the absolute amount they’re willing to risk increases, but it remains a constant proportion of their total wealth.\nFor example, someone with constant relative risk aversion would always respond in the same way to a 50-50 bet to win 50% of their wealth, lose 40% of their wealth, regardless of whether that loss involves a possible $400 out of $1,000 or $400,000 out of $1,000,000.\nConstant absolute risk aversion utility functions are often used in theoretical models due to their mathematical simplicity. However, constant relative risk aversion utility functions are generally considered more realistic for modelling human behaviour, as people tend to adjust their risk-taking based on their wealth.\nOne feature of constant relative risk aversion utility functions, such as log utility, is that people become less risk averse (as measured by absolute risk aversion) as their wealth increases. For a bet of a certain sum, they will be more likely to accept that bet at higher wealth.\nThis above plot is of a utility function with constant relative risk aversion. You can see that as the level of wealth increases, the utility function becomes increasingly linear. This reduction in curvature reflects the declining absolute risk aversion and results in bets of fixed value being more likely to be accepted at higher wealth.\n\n\n\n8.3.3 Risk neutrality\nA risk-neutral person is an expected value maximiser. They are indifferent between $10 for certain and a gamble with an expected value of $10. The certainty equivalent of the prospect for a person considering this gamble would also be $10.\nThe following chart illustrates. Again, we have two possible outcomes, x_1 and x_2, with resulting utility U(x_1) and U(x_2).\nA line between the points on the utility curve for each of those outcomes lies on the utility curve itself. For any probability, the utility of the expected value and the expected utility are the same.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  x\n}\n\ndf &lt;- data.frame(\n  x=seq(1,220,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\np1 &lt;- 0.5\nx1 &lt;- 30 #loss\np2 &lt;- 0.5\nx2 &lt;- 200 #win\nev &lt;- p1*x1+p2*x2 #expected value of gamble\nxc &lt;-115 #certain outcome\nce &lt;-p1*u(x1)+p2*u(x2) #certainty equivalent\npx2 &lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"U(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #set limits - need to include room for labels\n  coord_cartesian(xlim = c(-40, 220), ylim = c(-0.25, 220))+\n\n  #Add labels x1, U(x1) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"x1\", size = 4, hjust = 0.5, vjust = 1.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"U(x1)\", size = 4, hjust = 1.05, vjust = 0.6)+\n\n  #Add line to curve indicating utility of expected value\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"U[E(X)]=E[U(X)]\", size = 4, hjust = 1.05, vjust = 0.3)+\n\n  #Add labels x2, U(x2) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"x2\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"U(x2)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels E[X], E[U(X)] and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[X]=CE\", size = 4, hjust = 0.4, vjust = 1.5)\n\n\n\n\n\nFigure 8.5: Risk neutral\n\n\n\n\n\n\n\n\n\n\n8.3.4 Risk seeking\nA risk-seeking person prefers a gamble to a sure sum equal to the expected value of that gamble. The certainty equivalent is more than the expected value of the gamble. The gamble has value in and of itself.\nThe following chart illustrates. Again I have drawn a dash-dot-dot line between the points on the utility curve for each of those outcomes. That line is always above the utility curve. That is, for any probabilities involving those two outcomes (except one of those outcomes with certainty), the expected utility of the prospect is more than the utility of the expected value of the prospect.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  x^1.5\n}\n\ndf &lt;- data.frame(\n  x=seq(1,220,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\np1 &lt;- 0.5\nx1 &lt;- 30 #loss\np2 &lt;- 0.5\nx2 &lt;- 200 #win\nev &lt;- p1*x1+p2*x2 #expected value of gamble\nxc &lt;-115 #certain outcome\nce &lt;-(p1*u(x1)+p2*u(x2))^(1/1.5) #certainty equivalent\npx2 &lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"U(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #set limits - need to include room for labels\n  coord_cartesian(xlim = c(-25, 220), ylim = c(-0.25, 3000))+\n\n  #Add labels x1, U(x1) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"x1\", size = 4, hjust = 0.5, vjust = 1.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"U(x1)\", size = 4, hjust = 1.05, vjust = 0.6)+\n\n  #Add line to curve indicating utility of expected value\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"U[E(X)]\", size = 4, hjust = 1.05, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels x2, U(x2) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"x2\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"U(x2)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels E[X], E[U(X)] and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[X]\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"E[U(X)]\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add vertical line indicating certainty equivalent and labelled \"CE\" plus line extending to utility curve\n  annotate(\"segment\", x = ce, xend = ce, y = 0, yend = u(ce), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = ce, y = 0, label = \"CE\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = 0, y = u(ce), xend = ce, yend = u(ce), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")\n\n\n\n\n\nFigure 8.6: Risk seeking\n\n\n\n\n\n\n\n\nThe expected utility line between the two outcomes is always above the utility curve as the curve is convex. A convex curve leads to risk-seeking behaviour.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Expected Utility Theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/expected-utility-examples.html",
    "href": "decision-making-under-risk/expected-utility-examples.html",
    "title": "9  Expected utility examples",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Expected utility examples</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/expected-utility-examples.html#summary",
    "href": "decision-making-under-risk/expected-utility-examples.html#summary",
    "title": "9  Expected utility examples",
    "section": "",
    "text": "In the following examples I demonstrate the operation of expected utility theory and concepts such as expected value, expected utility and certainty equivalent through various betting scenarios, illustrating how individuals with risk-averse utility functions make decisions under uncertainty.\nIn a 50:50 bet example with a logarithmic utility function, a gamble with zero expected value reduces utility, demonstrating risk aversion.\nAn 80:20 bet example shows that even risk-averse individuals may accept favourable bets, but the certainty equivalent is still less than the expected value.\nA bet involving proportions of wealth demonstrates that positive expected value does not always lead to acceptance of a gamble for risk-averse individuals.\nThe St. Petersburg game demonstrates a paradox where the expected value is infinite, yet most people would not pay an infinite amount to play. This paradox can be resolved by introducing expected utility theory, which shows that risk-averse individuals with diminishing marginal utility would only pay a finite amount to play the game.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Expected utility examples</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/expected-utility-examples.html#introduction",
    "href": "decision-making-under-risk/expected-utility-examples.html#introduction",
    "title": "9  Expected utility examples",
    "section": "9.1 Introduction",
    "text": "9.1 Introduction\nIn this section, I present a series of mathematical examples of expected utility theory.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Expected utility examples</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/expected-utility-examples.html#a-5050-bet",
    "href": "decision-making-under-risk/expected-utility-examples.html#a-5050-bet",
    "title": "9  Expected utility examples",
    "section": "9.2 A 50:50 bet",
    "text": "9.2 A 50:50 bet\nSuppose your utility function is U(x)=\\text{ln}(x).\nYou have a 50% chance of winning $10 and a 50% chance of losing $10. Assume your starting wealth is $20.\nWhat is the expected value of this game?\n\\begin{align*}\nE[X]&=\\sum_{i=1}^n p_ix_i \\\\[6pt]\n&=0.5\\times 10+0.5\\times (-10) \\\\[6pt]\n&=0\n\\end{align*}\nThe expected value of the game is $0.\nWhat is the expected utility of this game?\n\\begin{align*}\nE[U(W+X)]&=\\sum_{i=1}^n p_iU(x_i+W) \\\\[6pt]\n&=0.5U(20-10)+0.5U(20+10) \\\\[6pt]\n&=0.5\\text{ln}(10)+0.5\\text{ln}(30) \\\\[6pt]\n&=2.85\n\\end{align*}\nWhat does an expected utility of 2.85 mean? To make it tangible, we can ask what wealth would give that utility.\nU(W)=\\text{ln}(W)=2.85 W=e^{2.85}=\\$17.30\nThis gamble with an expected value of zero reduces utility by an amount equivalent to $2.70.\nWe could also say that the certainty equivalent of this gamble is the final wealth of $17.30, or a loss of $2.70.\nFigure 9.1 illustrates the example.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  log(x)\n}\n\ndf &lt;- data.frame(\n  x=seq(1,220,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;-30 #loss\nx2&lt;-200 #win\nev&lt;-115 #expected value of gamble\nxc&lt;-115 #certain outcome\nce&lt;-79 #certainty equivalent\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"U(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #set limits - need to include room for labels\n  coord_cartesian(xlim = c(-25, 220), ylim = c(-0.25, 6))+\n\n  #Add labels W-10, W-10 and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"W-10\", size = 4, hjust = 0.5, vjust = 1.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"U(W-10)\", size = 4, hjust = 1.05, vjust = 0.6)+\n\n  #Add line to curve indicating utility of wealth\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"U(W)\", size = 4, hjust = 1.05, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels W+10, U(W+10) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"W+10\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"U(W+10)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels E[X]=W, E[U(X)] and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[X]=W\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"E[U(X)]\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add vertical line indicating certainty equivalent and labelled \"W-2.70\"\n  annotate(\"segment\", x = ce, xend = ce, y = 0, yend = u(ce), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = ce, y = 0, label = \"W-2.70\", size = 4, hjust = 0.4, vjust = 1.5)\n\n\n\n\n\nFigure 9.1: A 50:50 bet\n\n\n\n\n\n\n\n\nOn the x-axis, we have the outcomes and on the y-axis, we have the utility.\nI have added points on the x-axis for the outcomes of the two gambles, being W-10 and W+10. They deliver utility U(W+10) and U(W-10) respectively. The expected utility of the gamble is the probability-weighted average of these two points. It sits on the straight dash-dot-dot line between those two outcomes.\nYou can see that the expected utility of the gamble is lower than the utility of the expected value (being current wealth).\nAlso plotted is the certainty equivalent. We can identify it as the point on the utility curve where the utility of that certainty equivalent is equal to the expected utility.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Expected utility examples</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/expected-utility-examples.html#an-8020-bet",
    "href": "decision-making-under-risk/expected-utility-examples.html#an-8020-bet",
    "title": "9  Expected utility examples",
    "section": "9.3 An 80:20 bet",
    "text": "9.3 An 80:20 bet\nSuppose your utility function is U(x)=\\text{ln}(x).\nYou have an 80% chance of winning $10 and a 20% chance of losing $10. Assume your starting wealth is $20.\nWhat are the expected value and the expected utility of this game?\n\\begin{align*}\nE[X]&=\\sum_{i=1}^n p_ix_i \\\\[6pt]\n&=0.8\\times 10+0.2\\times (-10) \\\\[6pt]\n&=\\$6\n\\end{align*}\nThe expected value of the game is $6.\nWhat is the expected utility of this game?\n\\begin{align*}\nE[U(W+x)]&=\\sum_{i=1}^n p_iU(x_i+W) \\\\[6pt]\n&=0.8U(20+10)+0.2U(20-10) \\\\[6pt]\n&=0.8\\text{ln}(30)+0.2\\text{ln}(10) \\\\[6pt]\n&=3.18\n\\end{align*}\nWhat does an expected utility of 3.18 mean? To make it tangible, we can ask what wealth would give that utility.\nU(W)=\\text{ln}(W)=3.18 W=e^{3.18}=\\$24.08\nThis gamble with an expected value of $6 increases utility by an amount equivalent to $4.08.\nWe could also say that the certainty equivalent of this gamble is the final wealth of $24.08.\nFigure 9.2 illustrates the example.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  log(x)\n}\n\ndf &lt;- data.frame(\n  x=seq(1,220,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;-30 #loss\nx2&lt;-200 #win\nev&lt;-166 #expected value of gamble\nxc&lt;-95 #certain outcome\nce&lt;-135 #certainty equivalent\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"U(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n#set limits - need to include room for labels\n  coord_cartesian(xlim = c(-25, 220), ylim = c(-0.25, 6))+\n\n  #Add labels W-10, U(W+10) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"W-10\", size = 4, hjust = 0.5, vjust = 1.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"U(W-10)\", size = 4, hjust = 1.05, vjust = 0.6)+\n\n  #Add labels W, U(W) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"W\", size = 4, hjust = 0.6, vjust = 1.5)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"U(W)\", size = 4, hjust = 1.05, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels W+10, U(W+10) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"W+10\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"U(W+10)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels E[X]=W+6, E[U(X)] and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[X]=W+6\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"E[U(X)]\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add vertical line indicating certainty equivalent and labelled \"CE\"\n  annotate(\"segment\", x = ce, xend = ce, y = 0, yend = u(ce), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = ce, y = 0, label = \"W+4.08\", size = 4, hjust = 0.4, vjust = 1.5)\n\n\n\n\n\nFigure 9.2: An 80:20 bet\n\n\n\n\n\n\n\n\nThe expected utility of the gamble \\text{E}[U(X)] is higher than the utility from current wealth but lower than the utility of the expected value. That is, they are risk averse but would still accept this highly favourable bet.\nAlso plotted is the certainty equivalent. We can identify it as the point on the utility curve where the utility of that certainty equivalent is equal to the expected utility. In this case, it is at $4.08 above current wealth.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Expected utility examples</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/expected-utility-examples.html#betting-a-proportion-of-wealth",
    "href": "decision-making-under-risk/expected-utility-examples.html#betting-a-proportion-of-wealth",
    "title": "9  Expected utility examples",
    "section": "9.4 Betting a proportion of wealth",
    "text": "9.4 Betting a proportion of wealth\nSuppose your utility function is U(x)=\\text{ln}(x).\nYou have a 50% chance of increasing your wealth by 50% and a 50% chance of decreasing your wealth by 40%.\nWhat are the expected value and the expected utility of this game?\n\\begin{align*}\nE[X]&=\\sum_{i=1}^n p_ix_i \\\\[6pt]\n&=0.5\\times 0.6W+0.5\\times 1.5W \\\\[6pt]\n&=0.3W+0.75W \\\\[6pt]\n&=1.05W\n\\end{align*}\nThe expected value of the gamble is 5% of your wealth. The gamble has a positive expected value.\n\\begin{align*}\nE[U(X)]&=\\sum_{i=1}^n p_iU(X_i) \\\\[6pt]\n&=0.5U(0.6W)+0.5U(1.5W) \\\\[6pt]\n&=0.5\\text{ln}(0.6)+0.5\\times \\text{ln}(W)+0.5\\text{ln}(1.5)+0.5\\times \\text{ln}(W) \\\\[6pt]\n&=-0.255+0.203+\\text{ln}(W) \\\\[6pt]\n&=−0.053+\\text{ln}(W)\n\\end{align*}\nHere we have a gamble with a positive expected value, 5% of your wealth, but lower expected utility. Someone with log utility would reject this bet.\nFigure 9.3 illustrates the example.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  log(x)\n}\n\ndf &lt;- data.frame(\n  x=seq(1,220,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;-30 #loss\nx2&lt;-200 #win\nev&lt;-115 #expected value of gamble\nxc&lt;-95 #certain outcome\nce&lt;-79 #certainty equivalent\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"U(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #set limits - need to include room for labels\n  coord_cartesian(xlim = c(-25, 220), ylim = c(-0.25, 6))+\n\n  #Add labels 0.6W, U(0.6W) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"0.6W\", size = 4, hjust = 0.5, vjust = 1.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"U(0.6W)\", size = 4, hjust = 1.05, vjust = 0.6)+\n\n  #Add labels W, U(W) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"W\", size = 4, hjust = 0.6, vjust = 1.5)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"U(W)\", size = 4, hjust = 1.05, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels 1.5W, U(1.5W) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"1.5W\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"U(1.5W)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels E[X]=1.05W, E[U(X)] and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[X]=1.05W\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"E[U(X)]\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add vertical line indicating certainty equivalent and labelled \"CE\"\n  annotate(\"segment\", x = ce, xend = ce, y = 0, yend = u(ce), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = ce, y = 0, label = \"CE\", size = 4, hjust = 0.4, vjust = 1.5)\n\n\n\n\n\nFigure 9.3: Betting a proportion of wealth\n\n\n\n\n\n\n\n\nI have added points on the x-axis for the outcomes of the two gambles, a 40% reduction in wealth and a 50% gain in wealth. The expected utility of the gamble is the probability-weighted average of these two points. It sits on the straight dash-dot-dot line between those two outcomes.\nYou can see that the expected utility of the gamble is lower than the utility of current wealth. They would reject an offer of this bet.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Expected utility examples</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/expected-utility-examples.html#the-st.-petersburg-game",
    "href": "decision-making-under-risk/expected-utility-examples.html#the-st.-petersburg-game",
    "title": "9  Expected utility examples",
    "section": "9.5 The St. Petersburg game",
    "text": "9.5 The St. Petersburg game\n\n\nThe St. Petersburg game was invented by the Swiss mathematician Nicolas Bernoulli.\nThe game starts with a pot containing $2. A dealer then flips a coin. The pot doubles every time a head appears. The game ends, and the player wins the pot when a tail appears.\n\nA tail on the first flip leads to a payment of $2.\nA tail on the second flip leads to a payment of $4\nA tail on the third flip leads to a payment of $8\n\nAnd so on.\nConsider what you would be willing to pay to play this game. Would you pay $5? $10? $25? $50? More?\nThe expected value of this game is equal to the sum of the following series.\n\\begin{align*}\nE[X]&=\\underbrace{\\frac{1}{2}\\times 2}_\\textrm{Tail first}+\\underbrace{\\bigg(\\frac{1}{2}\\times \\frac{1}{2}\\bigg)\\times 4}_\\textrm{Tail second}+\\underbrace{\\bigg(\\frac{1}{2}\\times \\frac{1}{2}\\times \\frac{1}{2}\\bigg)\\times 8}_\\textrm{Tail third} \\\\[24pt]\n&\\qquad +\\underbrace{\\bigg(\\frac{1}{2}\\times \\frac{1}{2}\\times \\frac{1}{2}\\times \\frac{1}{2}\\bigg)\\times 16}_\\textrm{Tail fourth}+... \\\\[24pt]\n&=1+1+1+1+... \\\\\n&=\\sum_{k=1}^\\infty 1 \\\\\n&=\\infty\n\\end{align*}\nThe first term in the series captures the 50% chance of a tail on the first flip, paying $2. The second term represents the 50% chance of a head on the first flip, followed by the 50% chance of the tail second flip, paying $4. The third term represents the 50% chance of a head on the first flip, followed by the 50% chance of a head on the second flip, followed by the 50% chance of a tail on the third flip, paying $8. And so on.\nMultiplying out each of those terms results in a series of 1s.\nThe \\sum operator means “sum for k=1 to k=\\infty”.\nContrast this expected value of \\infty with the sum you would pay to play the game. You were likely not willing to pay an infinite amount.\nThis “paradox” is often resolved by introducing an expected utility function.\nThe expected utility of this game is equal to:\n\\begin{align*}\nE[U(X)]&=\\underbrace{\\frac{1}{2}\\times U(W+2)}_\\textrm{Tail first}+\\underbrace{\\bigg(\\frac{1}{2}\\times \\frac{1}{2}\\bigg)\\times U(W+4)}_\\textrm{Tail second} \\\\[24pt]\n&\\qquad +\\underbrace{\\bigg(\\frac{1}{2}\\times \\frac{1}{2}\\times \\frac{1}{2}\\bigg)\\times U(W+8)}_\\textrm{Tail third}  \\\\[24pt]\n&\\qquad +\\underbrace{\\bigg(\\frac{1}{2}\\times \\frac{1}{2}\\times \\frac{1}{2}\\times \\frac{1}{2}\\bigg)\\times U(W+16)}_\\textrm{Tail fourth}+... \\\\[24pt]\n&=\\frac{1}{2}U(W+2)+\\frac{1}{4}U(W+4)+\\frac{1}{8}U(W+8)+\\frac{1}{16}U(W+16)+...  \\\\[12pt]\n&=\\sum_{k=1}^{k=\\infty}\\frac{1}{2^k}U(W+2^k)\n\\end{align*}\nSimilar to the calculation of the expected value, the first term in the series captures the 50% chance of a tail on the first flip, paying $2. The second term represents the 50% chance of a head on the first flip, followed by the 50% chance of the tail on the second flip, paying $4. And so on. But here, we are using the utility function U(x).\nIn the second line, I multiplied the probabilities of each coin flip together.\nIn the third line, I expressed this infinite sum more compactly.\nTo take this equation further, we need to consider the particular utility function of the decision maker.\nWhat maximum sum would a risk-neutral player with U(x)=x be willing to pay to play the game?\nOne strategy to determine this sum is to ask what sum would result in the player being indifferent between paying and rejecting a chance to play. That is the maximum sum c that they would be willing to pay. They will be indifferent when U(W)=E[U(X-c)].\nWe can solve this equation as follows.\n\\begin{align*}\nU(W)&=E[U(X-c)] \\\\[6pt]\n&=\\sum_{k=1}^{k=\\infty}\\frac{1}{2^k}U(W+\\$2^k-c) \\\\[6pt]\nW&=\\sum_{k=1}^{k=\\infty}\\frac{1}{2^k}(W+2^k-c)  \\qquad \\text{(substituting in the utility function)}\\\\[6pt]\n&=W-c+\\sum_{k=1}^{k=\\infty}1 \\qquad \\Bigg(\\text{as }\\sum_{k=1}^{k=\\infty}\\frac{1}{2^k}=1\\Bigg) \\\\[12pt]\nc&=\\sum_{k=1}^{k=\\infty}1 \\\\[6pt]\n&=\\infty\n\\end{align*}\nIn the second line, we use the sum we created earlier. In the third line, I substitute the utility function U(x)=x. We can then simplify as in the fourth line, which allows us to see that, given the infinite expected value of the game, the player would be willing to pay an infinite amount to play.\nThat is, a risk-neutral player would pay any amount $c to play.\nWe could also have inferred this from the game’s expected value being infinite.\nWhat is the maximum sum a risk-averse player with U(x)=\\text{ln}(x) would be willing to pay to play the game? How does their wealth affect their willingness to pay?\nAgain we will determine at what $c the player is indifferent between accepting and rejecting a chance to play, which occurs when U(W)=E[U(X-c)].\n\\begin{align*}\nU(W)&=E[U(X-c)] \\\\[6pt]\nU(W)&=\\sum_{k=1}^{k=\\infty}\\frac{1}{2^k}U(W+\\$2^k-c) \\\\[6pt]\n\\text{ln}(W)&=\\sum_{k=1}^{k=\\infty}\\frac{1}{2^k}\\text{ln}(W+\\$2^k-c)\n\\end{align*}\n\n\nCode\n# Calculation of value of gamble for the following paragraph\n# Code based on: https://math.stackexchange.com/questions/2882484/log-utility-function-and-the-st-petersburg-paradox\nEU = function(W, c, epsilon){\n    ans = 0\n    k = 1\n    while(abs(val &lt;- (log(max(epsilon, W + 2^k - c)) - log(W)) / 2^k) &gt; epsilon){\n        k &lt;- k + 1;\n        ans &lt;- ans + val;\n    }\n    ans\n}\n\nfind_c = function(W, epsilon=10^(-10)){\n    low = 0\n    c = 0\n    high = 10^10\n    while(abs(low - high) &gt; epsilon){\n        c = (high + low) / 2\n        exp_value = EU(W, c, epsilon)\n        ifelse(exp_value &gt; 0, low &lt;- c, high &lt;- c)\n    }\n    c\n}\n\n# Value of bet to someone with wealth of $1,000,000\nc1000000 &lt;- round(find_c(10^6), 2)\n# Value of bet to someone with wealth of $1,000\nc1000 &lt;- round(find_c(10^3), 2)\n# Value of bet to someone with wealth of $0.01\nc001 &lt;- round(find_c(0.01), 2)\n\n\nThere is no closed-form solution to this equation to enable us to determine c. We need to solve via numerical methods (such as testing and iterating to a solution).\nIf we did solve this, we would find that someone who has wealth of $0.01 would be willing to pay up to $2.01. They would need to borrow. Someone with wealth $1000 would be willing to pay $10.95. A person with a wealth of $1 million would be willing to pay $20.87.\nWe cannot solve for a person with no wealth as \\text{ln}⁡(0) is undefined.\nWhy does willingness to pay increase with wealth?\nWith log utility, as wealth increases, the slope of the log function increasingly approximates a linear function (the second derivative approaches zero). Hence, the gambler displays less risk-averse (closer to risk-neutral) behaviour.\nOne way to gain an intuition for why this gamble now has a finite value is to calculate the utility of a risk-averse player whose only asset is the opportunity to play this game.\n\\begin{align*}\nE[U(X)]&=\\sum_{k=1}^{k=\\infty}\\frac{1}{2^k}U(\\$2^k) \\\\[12pt]\n&=\\sum_{k=1}^{k=\\infty}\\frac{1}{2^k}\\text{ln}(2^k) \\qquad \\text{(substituting in the utility function)}\\\\[12pt]\n&=\\sum_{k=1}^{k=\\infty}\\frac{k}{2^k}\\text{ln}(2)  \\qquad \\text{(using the rule }\\ln(x^a)=a\\ln(x)) \\\\[12pt]\n&=\\bigg(\\frac{1}{2}+\\frac{2}{4}+\\frac{3}{8}+\\frac{4}{16}+\\frac{5}{32}+...\\bigg)\\text{ln}(2) \\\\[12pt]\n&=2\\text{ln}(2)\n\\end{align*}\nThe change in the utility from each flip rapidly declines. Ultimately the series of fractions sum to two.\nWe can then calculate what wealth is equivalent to this expected utility.\n\\begin{align*}\nU(W)&=\\text{ln}(W)=2\\text{ln}(2) \\\\[6pt]\nW&=e^{2\\text{ln}2}=4\n\\end{align*}\nThe expected utility from the game is equal to the utility of $4.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Expected utility examples</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/anomalies-in-expected-utility-theory.html",
    "href": "decision-making-under-risk/anomalies-in-expected-utility-theory.html",
    "title": "10  Anomalies in expected utility theory",
    "section": "",
    "text": "Summary\nIn this part, I show several anomalies in expected utility theory.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Anomalies in expected utility theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/anomalies-in-expected-utility-theory.html#summary",
    "href": "decision-making-under-risk/anomalies-in-expected-utility-theory.html#summary",
    "title": "10  Anomalies in expected utility theory",
    "section": "",
    "text": "The Allais Paradox demonstrates that people’s choices between pairs of bets often violate expected utility theory, as their preferences can be inconsistent when a common consequence (a shared outcome with equal probability in both options) is changed.\nRejection of small-scale bets implies unreasonably high risk aversion for larger bets under expected utility theory. For example, rejecting a 50:50 bet to win $110 or lose $100 at all wealth levels implies rejecting a 50:50 bet to win $1 billion or lose $1,000.\nPeople’s choices are influenced by how options are framed, contradicting expected utility theory’s assumption of description invariance.\nPeople evaluate outcomes relative to reference points rather than absolute wealth.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Anomalies in expected utility theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/anomalies-in-expected-utility-theory.html#sec-allais",
    "href": "decision-making-under-risk/anomalies-in-expected-utility-theory.html#sec-allais",
    "title": "10  Anomalies in expected utility theory",
    "section": "10.1 The Allais Paradox",
    "text": "10.1 The Allais Paradox\n\n\nThe Allais paradox is one of the most famous anomalies in expected utility theory.\nThe paradox was first identified by Maurice Allais (1953). It emerges from the pattern of response to two pairs of bets. The following example comes from Kahneman and Tversky (1979).\nFor choice 1, the player is asked to choose one of the following bets:\nUnder Bet A, the player wins:\n\n$2500 with probability 33%\n$2400 with probability 66%\n$0 with probability 1%\n\nUnder Bet B, the player wins:\n\n$2400 with probability 100%\n\nWhich do you prefer?\nWhen Kahneman and Tversky (1979) ran this experiment, 82% of participants chose option B.\nFor choice 2, the player is again asked to choose one of two bets:\nUnder Bet C, the player wins:\n\n$2500 with probability 33%\n\n$0 with probability 67%\n\nUnder Bet D, the player wins:\n\n$2400 with probability 34%\n$0 with probability 66%\n\nWhich do you prefer?\nWhen Kahneman and Tversky (1979) ran this experiment, 83% of participants chose option C.\nLet’s examine this pair of preferences, with over 80% of experimental participants selecting B in Choice 1 and C in Choice 2.\nAccording to expected utility theory, if an agent selects B, the expected utility of B must be greater than the expected utility of A. That is:\n\nU(2400)&gt;0.33U(2500)+0.66U(2400)+0.01U(0)\n\nWe can simplify that to:\n\n0.34U(2400)&gt;0.33U(2500)+0.01U(0)\n\nWe can do the same analysis with the second choice. According to expected utility theory, if an agent selects C, the expected utility of C must be greater than the expected utility of D. That is:\n\n0.33U(2500)+0.67U(0)&gt; 0.34U(2400)+ 0.66U(0)\n\nWe can simplify that to:\n\n0.33U(2500)+0.01U(0)&gt; 0.34U(2400)\n\nThis is a contradiction. The two inequalities point in opposite directions. Under expected utility theory, if an agent chooses A it should choose C. And if the agent chooses B, it should choose D.\nWhy does this occur? What axiom is being breached?\nTo understand this, I will show you another representation of the choices in this table. The left half of the table shows the bets for choice 1, and the right half for choice 2. Within each choice, the bets are represented as a payoff-chance pair. For example, I can read from the table that bet A involves a 66% chance of $2400, a 1% chance of $0, and a 33% chance of $2500. Bet B involves a 100% chance of $2400.\n\nI can then break up these payoff-chance pairs to create an equivalent representation as in this second table. I have split the outcomes in bets B and C. For example, I have written the 100% chance of $2400 in option B as a 66% chance of $2400 and a 34% chance of $2400. I have written the 67% chance of $0 in bet C as a 66% chance of $0 and a 1% chance of $0.\n\nWith this split, you can see that the bets in the bottom two rows of choice 1 and choice 2 are the same. Both choice 1 and choice 2 involve a choice between, in one bet, a 1% chance of nothing and a 33% chance of $2,500 and in the other bet, a 34% chance of $2,400.\nThat shared bet in choice 1 and choice 2 is paired with a 66% chance of the same payoff regardless of the preferred bet. For choice 1 that “common consequence” across bet A and bet B is $2400. For choice 2, that common consequence across bet C and bet D is $0.\n\nThis representation allows us to see that preferring bet B to bet A and bet C to bet D violates the axiom of independence. Under that axiom, two gambles mixed with a third gamble will maintain the same order of preference as when the two are presented independently of the third gamble. In this case, the two gambles are contained in the last two rows. The third gamble is the 66% chance of $2400 or $0. The third gamble is called a “common consequence” as the payoff is the same regardless of whether you choose A or B, or C and D.\nI can express this in terms of the formal definition of the independence axiom. The formal definition states that if:\n\nx and y are lotteries with x\\succcurlyeq y and\np is the probability that a third option z is present, then:\n\n\npz+(1-p)x\\succcurlyeq pz+(1-p)y\n\nFor each of the choices in our lottery:\n\nx is a 1 in 34 chance of $0 and a 33 in 34 chance of $2500\ny is a 100% chance of $2400\nz is $2400 in choice 1 and $0 in choice 2.\n\nIf p=0, we simply have x\\succcurlyeq y. For any non-zero value of p, such as the 66% in both choices, the preference between x and y should not change.\nHere’s another intuitive way to think about this bet.\nSuppose I am going to generate one number between 1 and 100 randomly.\nIf a number between 1 and 66 is generated, you win the prize in the first row. If number 67 is generated, you win the amount in the second. If a number from 68 to 100 is generated, you win the sum in the third.\nSuppose that you know that the number generated is between 1 and 66. Would you prefer bet A or B in choice 1? As you would win $2400 with either choice, you will be indifferent. You will similarly be indifferent between bet C and D in choice 2, winning $0 no matter what.\nSuppose instead that a number between 67 and 100 is generated, but you don’t know which. If you prefer A to B, you should also prefer C to D. In each choice, you effectively face the same bet. Let’s assume for the moment that you prefer A and C.\nFinally, suppose you don’t know what number will be generated. We have just determined that if you know the ticket is between 1 and 66, you are indifferent between the options, but if between 67 and 100 is drawn, you prefer A and C. You do not prefer B or D when the ticket range is 1 to 66 or 67 to 100, so you should not prefer B or D when the ticket number is unknown.\nHowever, the responses to the bets generated by Kahneman and Tversky (1979) and many other experimentalists suggest that when the number is unknown, the size of the common consequence for numbers 1 through 66 does matter. This common consequence is changing the preferences of the experimental participants.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Anomalies in expected utility theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/anomalies-in-expected-utility-theory.html#sec-absurd",
    "href": "decision-making-under-risk/anomalies-in-expected-utility-theory.html#sec-absurd",
    "title": "10  Anomalies in expected utility theory",
    "section": "10.2 Absurd rates of risk aversion",
    "text": "10.2 Absurd rates of risk aversion\n\n\nAn important anomaly in expected utility theory concerns the level of risk aversion required to explain observed behaviour.\nPeople reject many small-scale bets. The crux of the anomaly is that if we are expected utility maximisers, rejection implies that we would reject some highly favourable larger-scale bets so favourable almost no one would reject them.\nConsider the following one-off bet involving the flip of a coin:\n\nHead: You win $110\nTail: You lose $100\n\nSuppose you reject. You would not be alone in doing this. There is ample evidence that people reject favourable low-stakes bets, even when they have material wealth. Barberis et al. (2006) described an experiment where they offered a 50:50 bet to win $550 or lose $500 to a group of wealthy experimental participants. These participants included clients of a bank’s private wealth management division, with a median wealth above $10 million. Seventy-one percent of the private wealth clients turned down the bet.\nUnder the axiom of diminishing marginal utility, we could conclude that you rejected it as you are risk averse. However, the minimum utility function curvature required to reconcile an expected utility maximiser declining bets of this nature when you hold any material level of wealth implies that you would reject immensely favourable bets.\nExamples in Rabin (2000) and Rabin and Thaler (2001) illustrate this. Suppose a person who acts consistent with expected utility theory always turns down a 50:50 bet to win $110 or lose $100, whatever their wealth. That person will also turn down a 50:50 bet to win $1 billion, lose $1,000. Another expected utility maximiser turns down a 50:50 bet to win $11, lose $10 at all levels of wealth. That person will turn down any 50:50 bet where they could lose $100, no matter the upside.\nAt face value, that is ridiculous. But that is the crux of the argument. Turning down a low-value bet with a positive expected value implies that the marginal utility of money must decline quickly for small changes in wealth. Rejection of a low-value bet to win $110 or lose $100 would lead to absurd responses to higher-value bets. This leads Rabin (2000) to argue that risk aversion or the diminishing value of money has nothing to do with the rejection of low-value bets.\nThe intuition behind the rejection of small-scale bets leading to the rejection of immensely favourable bets is as follows.\nSuppose we have an expected utility maximiser with a weakly concave utility curve. That is, they are risk neutral or risk averse at all levels of wealth. If we drew their utility curve, it would always be increasing at a constant or decreasing rate, depending on where you were on the utility curve.\n\n\nCode\nlibrary(ggplot2)\n\nabsurdBase &lt;- ggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_vline(xintercept = 0, linewidth=0.5)+ \n  geom_hline(yintercept = 0, linewidth=0.5)+\n  labs(x = \"Wealth\", y = \"Utility\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))\n\nannotate_plot &lt;- function(plot, W1=250, UW1=3, win=150, loss=100, bets, labels, points=TRUE) {\n  for (i in seq_along(bets)) {\n    bet &lt;- bets[i]\n    label &lt;- labels[i]\n    \n    W &lt;- W1+(win+loss)*(bet-1)\n    \n    if (bet == 1){\n      UW &lt;- UW1\n    } else {\n      UW &lt;- UW1\n      for (j in 1:(bet-1)) {\n        UW &lt;- UW + (loss/win)^(j-1)+(loss/win)^(j)\n      }\n    }\n    \n    if (label){\n      plot &lt;- plot + annotate(\"text\", x = W, y = 0, label = paste0(\"W+\",W-250), size = 3, hjust = 0.5, vjust = 1.5)\n    }\n    if (label){\n      plot &lt;- plot + annotate(\"segment\", x = W, y = 0, xend = W, yend = UW, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")\n    }\n    plot &lt;- plot +\n      annotate(\"segment\", x = W, y = UW, xend = W-loss, yend = UW-(2/3)^(bet-1), linewidth = 0.5, colour = \"black\") +\n      annotate(\"segment\", x = W, y = UW, xend = W+win, yend = UW+(2/3)^(bet-1), linewidth = 0.5, colour = \"black\")\n    if (points){\n      plot &lt;- plot +\n              annotate(\"point\", x = W, y = UW, size = 2)\n    }\n  }\n  \n  return(plot)\n}\n\nabsurd0 &lt;- annotate_plot(absurdBase, bets=c(1:15), labels=rep(FALSE, 15), points=FALSE)\n\nabsurd0\n\n\n\n\n\nFigure 10.1: Weakly concave utility curve\n\n\n\n\n\n\n\n\nThis person rejects a 50:50 bet to gain $150, lose $100. (I have chosen this size bet so I can draw this visually to scale and make the point clear. The argument follows the same logic for a win $110, lose $100 bet.) We also assume this person would reject the bet regardless of their level of wealth at the time the bet was offered to them.\nI can plot this on a chart. I will develop this chart step by step so that you can understand each element.\nIn Figure 10.2, the horizontal axis is wealth and the vertical axis is utility. I have marked the current wealth, W, and utility of that person’s wealth, U(W).\n\n\nCode\nlibrary(ggplot2)\n\nW1 &lt;- 250\nwin &lt;- 150\nloss &lt;- 100\nUW1=3\n\nabsurdBase &lt;- ggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_vline(xintercept = 0, linewidth=0.5)+ \n  geom_hline(yintercept = 0, linewidth=0.5)+\n  labs(x = \"Wealth\", y = \"Utility\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))\n\n\nabsurd1 &lt;- absurdBase+\n  \n  #set limits - need to include room for labels\n  coord_cartesian(xlim = c(-45, 720), ylim = c(-0.25, 6))+\n\n  #Add labels W, U(W), dot at W/U(W) and line to curve indicating each\n  annotate(\"text\", x = W1, y = 0, label = \"W\", size = 3, hjust = 0.5, vjust = 1.5)+\n  annotate(\"segment\", x = W1, y = 0, xend = W1, yend = UW1, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = UW1, xend = W1, yend = UW1, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = UW1, label = \"U(W)\", size = 3, hjust = 1.05, vjust = 0.5)+\n  annotate(\"point\", x = W1, y = UW1, size = 2)\n\nabsurd1\n\n\n\n\n\nFigure 10.2: Utility of current wealth\n\n\n\n\n\n\n\n\nI can then mark in Figure 10.3 the two possible outcomes of the bet, the gain of $150 (W+150) and the loss of $100 (W-100). The utility of each outcome will be a point on these vertical lines.\nThe expected value of the bet is a gain of $25. That is also marked.\n\n\nCode\nabsurd2 &lt;- absurd1+\n\n  #Add vertical line for the possible win of the first bet\n  annotate(\"segment\", x = W1+win, y = 0, xend = W1+win, yend = 4, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = W1+win, y = 0, label = \"W+150\", size = 3, hjust = 0.5, vjust = 1.5)\n\nabsurd2+\n  \n  #Add vertical line for the possible loss of the first bet\n  annotate(\"segment\", x = W1-loss, y = 0, xend = W1-loss, yend = 4, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = W1-loss, y = 0, label = \"W-100\", size = 3, hjust = 0.5, vjust = 1.5)+\n  \n  #Add vertical line for the expected value of the first bet\n  annotate(\"segment\", x = W1+25, y = 0, xend = W1+25, yend = 4, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = W1+25, y = 0, label = \"W+25\", size = 3, hjust = 0.1, vjust = 1.5)\n\n\n\n\n\nFigure 10.3: Outcomes of the bet\n\n\n\n\n\n\n\n\nAs the person rejected the bet, the expected utility of the bet must be less than or equal to the utility of current wealth. The point on the vertical line at W+25 where I mark expected utility must be level with or below the point on the vertical line at W where we mark current utility (U(W)). I have placed a dot on the W+25 line in Figure 10.4 indicating the highest that the expected utility can be.\n\n\nCode\nabsurd3 &lt;- absurd2+\n  \n  #Extend line for expected utility of the first bet including dot\n  annotate(\"segment\", x = W1, y = UW1, xend = W1+25, yend = UW1, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"point\", x = W1+25, y = UW1, size = 2)\n\nabsurd3+\n  \n  #Add vertical line for the possible loss of the first bet\n  annotate(\"segment\", x = W1-loss, y = 0, xend = W1-loss, yend = 4, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = W1-loss, y = 0, label = \"W-100\", size = 3, hjust = 0.5, vjust = 1.5)+\n  \n  #Add vertical line for the expected value of the first bet\n  annotate(\"segment\", x = W1+25, y = 0, xend = W1+25, yend = 4, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = W1+25, y = 0, label = \"W+25\", size = 3, hjust = 0.1, vjust = 1.5)\n\n\n\n\n\nFigure 10.4: Expected utility of the bet\n\n\n\n\n\n\n\n\nThe expected utility of the bet is the probability-weighted utility of each of the two possible outcomes. Therefore, If I draw a line between the utility of each outcome, that line will pass through the expected utility of the bet.\nI have added a line in Figure 10.5 between the utility for the two possible outcomes, with the expected utility of the bet on that line (or more specifically, in the middle of the line as each outcome has probability 50%).\n\n\nCode\nabsurd4 &lt;- absurd3+\n\n  #Add line between utility for possible outcomes of the first bet plus dots\n  annotate(\"segment\", x = W1-loss, y = UW1-1, xend = W1+win, yend = UW1+1, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"point\", x = W1-loss, y = UW1-1, size = 2)+\n  annotate(\"point\", x = W1+win, y = UW1+1, size = 2)+\n\n  #Add vertical line for the possible loss of the first bet\n  annotate(\"segment\", x = W1-loss, y = 0, xend = W1-loss, yend = 2, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = W1-loss, y = 0, label = \"W-100\", size = 3, hjust = 0.5, vjust = 1.5)+\n  \n  #Add vertical line for the expected value of the first bet\n  annotate(\"segment\", x = W1+25, y = 0, xend = W1+25, yend = 3, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = W1+25, y = 0, label = \"W+25\", size = 3, hjust = 0.1, vjust = 1.5)+\n\n  #Add horizontal line for U(W+150) and U(W-100) and expected value\n  annotate(\"segment\", x = 0, y = UW1+1, xend = W1+150, yend = UW1+1, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = UW1+1, label = \"U(W+150)\", size = 3, hjust = 1.05, vjust = 0.5)+\n  annotate(\"segment\", x = 0, y = UW1-1, xend = W1-loss, yend = UW1-1, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = UW1-1, label = \"U(W-100)\", size = 3, hjust = 1.05, vjust = 0.5)\n\nabsurd4\n\n\n\n\n\nFigure 10.5: Utility of the outcomes of the bet\n\n\n\n\n\n\n\n\nWe now have three points on the utility curve: current wealth and their utility if the person lost or won the bet.\nAs the person is risk averse at all levels of wealth, we know that all parts of the utility curve are at a minimum weakly concave. We can therefore draw in Figure 10.6 part of the utility curve as the least risk averse they could be while still rejecting the bet. This is drawn in the solid black line.\n\n\nCode\nabsurd5 &lt;- absurd4+\n  \n  #Add line linking the utility of the two first bet outcomes and utility of current wealth\n  annotate(\"segment\", x = W1, y = UW1, xend = W1-loss, yend = UW1-1, linewidth = 0.5, colour = \"black\")+\n  annotate(\"segment\", x = W1, y = UW1, xend = W1+win, yend = UW1+1, linewidth = 0.5, colour = \"black\")\n\nabsurd5\n\n\n\n\n\nFigure 10.6: Utility curve\n\n\n\n\n\n\n\n\nFrom the rejection of the bet, we know that:\n\nU(W+150)-U(W)\\leq U(W)-U(W-100)\n\n\n\nCode\nabsurd5a &lt;- absurd5+\n  \n  #add curly bracket indicating increase in utility with win\n  annotate(\"text\", x = 425, y = 3.44, label = '{', angle = 180, size = 20, family = 'Source Sans Pro ExtraLight')+\n  annotate(\"text\", x = 500, y = 3.62, label = \"U(W+150) - U(W)\", size = 3, hjust = 0.4, vjust = 1.5)+\n  \n  #add curly bracket indicating decrease in utility with loss\n  annotate(\"text\", x = 425, y = 2.44, label = '{', angle = 180, size = 20, family = 'Source Sans Pro ExtraLight')+\n  annotate(\"text\", x = 500, y = 2.62, label = \"U(W) - U(W-100)\", size = 3, hjust = 0.4, vjust = 1.5)\n\nabsurd5a\n\n\n\n\n\nFigure 10.7: Utility curve\n\n\n\n\n\n\n\n\nThis means that you value each dollar between W and W+150, on average, by at most 100/150ths (or 2/3rds) as much as you value each dollar, on average, between W and W-100. We can see this in the slope of the two black lines forming the part of the utility curve we have drawn. The second part has two thirds the slope of the first.\nFurther, by weak concavity, we can say that you value your W+150th dollar at most two thirds as much as you value your W-100th dollar. The relative value of each dollar has declined by at least one third over the span of $250.\nLet us now consider what would happen if this person had $250 more wealth: that is, they have W+250. They are then offered the same bet.\nWe have assumed that they will reject the bet at all levels of wealth, so they will also reject at this wealth. We can, therefore, infer another piece of the utility curve (or, more specifically, a curve for the least risk averse they could be). I have marked in Figure 10.8 the utility of their wealth, the highest the expected utility of the bet can be if they reject the bet, and the utility of the two possible outcomes of the bet. The next section of solid black line represents another part of the utility curve that is at the minimum risk aversion they could be while still rejecting the bet.\n\n\nCode\nW2 &lt;- W1 + 250\nUW2 &lt;- UW1 + 1 + 2/3\n\nabsurd6 &lt;- annotate_plot(absurdBase, bets=c(1, 2), labels=c(TRUE, FALSE))\n\nabsurd6+\n  \n  #Add horizontal line for U(W2) and expected value\n  annotate(\"segment\", x = 0, y = UW2, xend = W2+25, yend = UW2, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = UW2, label = \"U(W+250)\", size = 3, hjust = 1.05, vjust = 0.6)+\n  \n  #Add vertical line and dot for the possible win of the first bet\n  annotate(\"segment\", x = W1+win, y = 0, xend = W1+win, yend = UW1+1, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = W1+win, y = 0, label = \"W+150\", size = 3, hjust = 0.5, vjust = 1.5)+\n  annotate(\"point\", x = W1+win, y = UW1+1, size = 2)+\n  \n  #Add vertical line and dot for the possible loss of the first bet\n  annotate(\"segment\", x = W1-loss, y = 0, xend = W1-loss, yend = UW1-1, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = W1-loss, y = 0, label = \"W-100\", size = 3, hjust = 0.5, vjust = 1.5)+\n  annotate(\"point\", x = W1-loss, y = UW1-1, size = 2)+\n  \n  #Add labels and line W+250 - doing here as want to remove later\n  annotate(\"text\", x = W2, y = 0, label = \"W+250\", size = 3, hjust = 0.8, vjust = 1.5)+\n  annotate(\"segment\", x = W2, y = 0, xend = W2, yend = UW2, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n\n  #Add vertical line for the possible win of the second bet, including a dot\n  annotate(\"segment\", x = W2+150, y = 0, xend = W2+150, yend = UW2+2/3, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"point\", x = W2+150, y = 5.333, size = 2)+\n  annotate(\"text\", x = W2+150, y = 0, label = \"W+400\", size = 3, hjust = 0.5, vjust = 1.5)+\n  \n  #Add line linking for the expected utility of the two second bet outcomes\n  annotate(\"segment\", x = W2-100, y = UW2-2/3, xend = W2+150, yend = UW2+2/3, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  \n  #Add vertical line and dot for the expected value of the second bet\n  annotate(\"segment\", x = W2+25, y = 0, xend = W2+25, yend = UW2, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = W2+25, y = 0, label = \"W+275\", size = 3, hjust = 0.1, vjust = 1.5)+\n  annotate(\"point\", x = W2+25, y = UW2, size = 2)+\n  \n  #set limits - need to include room for labels\n  coord_cartesian(xlim = c(-45, 720), ylim = c(-0.25, 6))\n\n\n\n\n\nFigure 10.8: Utility curve extended\n\n\n\n\n\n\n\n\nIterating the previous calculations, I can say that they will weight their W+400th dollar only two thirds as much as their W+150th dollar. This means they value their W+400th dollar only (2/3)2 or 4/9 as much as their W-100th dollar. Or put another way, over the span of $500, the relative value of each dollar has declined by five ninths.\nAs we infer additional pieces, we can see in Figure 10.9 that this person rapidly declines in the rate at which they place utility on further wealth. The increase in slope for each additional sum becomes less and less.\n\n\nCode\nW3 &lt;- W2 + 250\nUW3 &lt;- UW2 + 2/3 + 4/9\n\nabsurd7 &lt;- annotate_plot(absurd6, bets=c(3), labels=c(FALSE))+\n  annotate(\"segment\", x = W3, y = 0, xend = W3, yend = UW3, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")\n\n\nabsurd7+\n  \n  #Add line for U(W2) and expected value\n  annotate(\"segment\", x = 0, y = UW3, xend = W3+25, yend = UW3, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = UW3, label = \"U(W+500)\", size = 3, hjust = 1.05, vjust = 0.6)+\n  \n  #Add labels W+500 - doing here so can centre later\n  annotate(\"text\", x = W3, y = 0, label = \"W+500\", size = 3, hjust = 0.8, vjust = 1.5)+\n  \n  #Add vertical line for the possible win of the second bet, including a dot\n  annotate(\"segment\", x = W2+150, y = 0, xend = W2+150, yend = UW2+2/3, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"point\", x = W2+150, y = 5.333, size = 2)+\n  annotate(\"text\", x = W2+150, y = 0, label = \"W+400\", size = 3, hjust = 0.5, vjust = 1.5)+\n  \n  #Add vertical line and dot for the possible win of the third bet\n  annotate(\"segment\", x = W3+win, y = 0, xend = W3+win, yend = UW3+4/9, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = W3+win, y = 0, label = \"W+650\", size = 3, hjust = 0.5, vjust = 1.5)+\n  annotate(\"point\", x = W3+win, y = UW3+4/9, size = 2)+\n  \n  #Add line linking for the expected utility of the two third bet outcomes\n  annotate(\"segment\", x = W3-100, y = UW3-4/9, xend = W3+150, yend = UW3+4/9, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  \n  #Add vertical line and dot for the expected value of the third bet\n  annotate(\"segment\", x = W3+25, y = 0, xend = W3+25, yend = UW3, linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = W3+25, y = 0, label = \"W+525\", size = 3, hjust = 0.1, vjust = 1.5)+\n  annotate(\"point\", x = W3+25, y = UW3, size = 2)+\n  \n  #set limits - need to include room for labels\n  coord_cartesian(xlim = c(-55, 920), ylim = c(-0.25, 8))\n\n\n\n\n\nFigure 10.9: Utility curve further extended\n\n\n\n\n\n\n\n\nOver time, the slope approaches a horizontal asymptote: effectively, a cap on the level of utility they can achieve, however wealthy they may become. This is shown in Figure 10.10.\n\n\nCode\nabsurd8 &lt;- annotate_plot(absurd7, bets=c(4, 5, 6, 7, 8, 9), labels=c(FALSE, TRUE, FALSE, TRUE, FALSE, TRUE))+\n  \n  #Add labels W+500\n  annotate(\"text\", x = W3, y = 0, label = \"W+500\", size = 3, hjust = 0.5, vjust = 1.5)\n\nabsurd8+  \n  \n  #set limits - need to include room for labels\n  coord_cartesian(xlim = c(-45, 2500), ylim = c(-0.25, 8))\n\n\n\n\n\nFigure 10.10: Utility curve asymptote\n\n\n\n\n\n\n\n\nKeep iterating in this way and you end up with some ridiculous results. You value the 2500th dollar above your current wealth only 2% as much as your last current dollar of your wealth - (2/3)10 - reducing by a constant factor of 2/3 every $250. This is an absurd rate of discounting.\nTaking this iteration to the extreme, it doesn’t take long for additional money to have effectively zero value. In Figure 10.11, we see the utility curve approaching a limit. Any gain of money from W+3000 upwards is valued at almost nothing, meaning a gain beyond that level, no matter how large, could compensate for the possibility of losing $1,000.\n\n\nCode\nabsurd9 &lt;- annotate_plot(absurd8, bets=c(10, 11, 12, 13, 14,15), labels=c(FALSE, TRUE, FALSE, TRUE, FALSE, TRUE))\n\nabsurd9 +\n  \n  #set limits - need to include room for labels\n  coord_cartesian(xlim = c(-45, 4000), ylim = c(-0.25, 8))\n\n\n\n\n\nFigure 10.11: Utility curve limit",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Anomalies in expected utility theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/anomalies-in-expected-utility-theory.html#framing",
    "href": "decision-making-under-risk/anomalies-in-expected-utility-theory.html#framing",
    "title": "10  Anomalies in expected utility theory",
    "section": "10.3 Framing",
    "text": "10.3 Framing\n\n\nUnder expected utility theory, a person’s choices should not be affected by how the options are described or by how their preferences are elicited.\nKahneman and Tversky (1984) reported the following experiment.\n\nA group of experimental participants were shown the following:\nImagine that the U.S. is preparing for the outbreak of an unusual Asian disease, which is expected to kill 600 people. Two alternative programs to combat the disease have been proposed. Assume that the exact scientific estimates of the consequences of the programs are as follows:\nIf Program A is adopted, 200 people will be saved.\nIf Program B is adopted, there is a one-third probability that 600 people will be saved and a two-thirds probability that no people will be saved.\nWhich of the two programs would you favour?\n\n72% of participants chose option A.\nAnother group of experimental participants were shown the following:\n\nImagine that the U.S. is preparing for the outbreak of an unusual Asian disease, which is expected to kill 600 people. Two alternative programs to combat the disease have been proposed. Assume that the exact scientific estimates of the consequences of the programs are as follows:\nIf Program C is adopted, 400 people will die.\nIf Program D is adopted, there is a one-third probability that nobody will die and a two-thirds probability that 600 people will die.\nWhich of the two programs would you favour?\n\n22% of participants chose option C.\n72% of participants chose A and 22% of participants chose option C. Yet these two options are equivalent. The only difference is the framing of the options, which under expected utility theory should not matter.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Anomalies in expected utility theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/anomalies-in-expected-utility-theory.html#reference-points",
    "href": "decision-making-under-risk/anomalies-in-expected-utility-theory.html#reference-points",
    "title": "10  Anomalies in expected utility theory",
    "section": "10.4 Reference points",
    "text": "10.4 Reference points\nAn auxiliary axiom of expected utility theory is that people use a reference point of zero wealth. They consider the utility of the absolute outcomes.\nHowever, consider the following two scenarios:\n\nYou have not checked your share portfolio in a while. You expect that the portfolio is worth around $40,000. Today when you check, it is worth $30,000. Do you feel rich or poor?\nYou have not checked your share portfolio in a while. You expect that the portfolio is worth around $20,000. Today when you check, it is worth $30,000. Do you feel rich or poor?\n\nUnder expected utility theory, those two scenarios should feel the same as you have U(\\$30,000) in both cases.\nHowever, in the first case, you feel poor and in the second case you feel rich. This is because you are comparing the outcome to your reference point of $40,000 in the first case and $20,000 in the second case. You are not assessing the absolute outcome but appear to be using a reference point.\nThat is, U(W) \\neq U(W') when W = W' but reference points differ.\n\n\n\n\nAllais, M. (1953). Le comportement de l’homme rationnel devant le risque: Critique des postulats et axiomes de l’ecole americaine. Econometrica, 21(4), 503–546. https://doi.org/10.2307/1907921\n\n\nBarberis, N., Huang, M., and Thaler, R. H. (2006). Individual Preferences, Monetary Gambles, and Stock Market Participation: A Case for Narrow Framing. American Economic Review, 96(4), 1069–1090. https://doi.org/10.1257/aer.96.4.1069\n\n\nKahneman, D., and Tversky, A. (1979). Prospect theory: An analysis of decision under risk. Econometrica, 47(2), 263–291. https://doi.org/10.2307/1914185\n\n\nKahneman, D., and Tversky, A. (1984). Choices, values, and frames. American Psychologist, 39(4), 341–350. https://doi.org/10.1037/0003-066X.39.4.341\n\n\nRabin, M. (2000). Risk Aversion and Expected-Utility Theory: A Calibration Theorem. Econometrica, 68(5), 1281–1292. http://www.jstor.org/stable/2999450\n\n\nRabin, M., and Thaler, R. H. (2001). Anomalies: Risk Aversion. Journal of Economic Perspectives, 15(1), 219–232. https://doi.org/10.1257/jep.15.1.219",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Anomalies in expected utility theory</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/decision-making-under-risk-exercises.html",
    "href": "decision-making-under-risk/decision-making-under-risk-exercises.html",
    "title": "11  Decision making under risk exercises",
    "section": "",
    "text": "11.1 Expected value of roulette\nYou are playing roulette at the casino. There are 37 numbered pockets around the edge of the wheel (0 through 36). If you make a straight up bet on one of the 37 single numbers, you are paid $35 for every dollar you bet (in addition to receiving back your bet). What is the expected value of a $20 bet.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Decision making under risk exercises</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/decision-making-under-risk-exercises.html#expected-value-of-roulette",
    "href": "decision-making-under-risk/decision-making-under-risk-exercises.html#expected-value-of-roulette",
    "title": "11  Decision making under risk exercises",
    "section": "",
    "text": "Answer\n\n\n\n\n\nThe expected value of the Roulette bet is:\n\\begin{align*}\nE[X]&=\\sum_{i=1}^n p_ix_i \\\\[6pt]\n&=\\frac{36}{37}\\times(-\\$20)+\\frac{1}{37}\\times(35\\times\\$20) \\\\[6pt]\n&=\\$-0.54\n\\end{align*}",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Decision making under risk exercises</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/decision-making-under-risk-exercises.html#a-bet-or-a-certain-payment",
    "href": "decision-making-under-risk/decision-making-under-risk-exercises.html#a-bet-or-a-certain-payment",
    "title": "11  Decision making under risk exercises",
    "section": "11.2 A bet or a certain payment?",
    "text": "11.2 A bet or a certain payment?\nAnika is an expected utility maximiser with the following utility function:\nU(x)=\\sqrt{x}\nAnika is offered the following choice:\n\nA 50% chance of winning $10 and a 50% chance of winning nothing\n$4 for certain\n\nAnika has zero wealth besides this offer.\na) What is the expected value of option A?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe expected value of option A) is:\n\\begin{align*}\nE[A]&=\\sum_{i=1}^n p_ix_i \\\\[12pt]\n&=0.5\\times \\$10+0.5\\times 0 \\\\[6pt]\n&=\\$5\n\\end{align*}\n\n\n\nb) Will Anika choose A or B? Why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe need to determine the expected utility of each option. Anika will selection the option with the highest expected utility.\nThe expected utility of option A) is:\n\\begin{align*}\nEU(A)&=p_1U(x_1)+p_2U(x_2) \\\\\n&=0.5\\times \\sqrt{10}+0.5\\times \\sqrt{0} \\\\\n&=1.58\n\\end{align*}\nThe expected utility of option B) is:\n\\begin{align*}\nEU(B)&=U(4) \\\\\n&=\\sqrt{4} \\\\\n&=2\n\\end{align*}\nAnika will choose option B) as it gives her higher expected utility. Anika is risk averse.\n\n\n\nc) What is the certainty equivalent of option A?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTo calculate the certainty equivalent of option A, we calculate what payment with certainty would deliver equivalent expected utility. That is:\n\\begin{align*}\nEU(CE)&=1.58 \\\\\n\\sqrt{CE}&=1.58 \\\\\nCE&=1.58^2 \\\\\n&=2.5\n\\end{align*}\nThe certainty equivalent of option A is $2.50. That is, Anika would be indifferent between option A and a payment of $2.50 for certain.\n\n\n\nd) Draw a graph showing Anika’s utility curve, the expected value of option A, the expected utility of options A) and B) and the certainty equivalent of option A).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\nlibrary(svglite)\n\nu &lt;- function(x){\n  x^(1/2)\n}\n\ndf &lt;- data.frame(\n  x=seq(0,220,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;-0 #loss\nx2&lt;-200 #win\nev&lt;-100 #expected value of gamble\nxc&lt;-80 #certain outcome\nce&lt;-50 #certainty equivalent\npx2&lt;-(ev-x1)/(x2-x1)\n\nanika &lt;- ggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"U(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-25, 220), ylim = c(0, 16))+\n\n  #Add labels 4, U(4) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"4\", size = 4, hjust = 0.6, vjust = 1.5)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"U(4)\", size = 4, hjust = 1.05, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels 10, U(10) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"10\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"U(10)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels E[A]=5, E[U(A)] and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[A]=5\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"E[U(A)]\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add vertical line indicating certainty equivalent and labelled \"CE\"\n  annotate(\"segment\", x = ce, xend = ce, y = 0, yend = u(ce), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = ce, y = 0, label = \"CE\", size = 4, hjust = 0.4, vjust = 1.5)\n\nanika\n\n\n\n\n\nFigure 11.1: A bet or a certain payment?",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Decision making under risk exercises</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/decision-making-under-risk-exercises.html#a-5050-gamble",
    "href": "decision-making-under-risk/decision-making-under-risk-exercises.html#a-5050-gamble",
    "title": "11  Decision making under risk exercises",
    "section": "11.3 A 50:50 gamble",
    "text": "11.3 A 50:50 gamble\nConsider the following gamble:\n\n(0.5; $550; 0.5, -$500)\n\nThis gamble provides a 50% chance of winning $550 and a 50% chance of losing $500.\na) Would a risk neutral agent (who maximises expected value) be willing to pay $20 to play this gamble? What is the most they would be willing to pay to play?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe expected value of the gamble is:\n\\begin{align*}\nE[X]&=\\sum_{i=1}^n p_ix_i \\\\[12pt]\n&=0.5(550)+0.5(-500) \\\\[6pt]\n&=25\n\\end{align*}\nThis is greater than $20, so a risk neutral agent will be willing to pay $20 to participate in the gamble. The most they would be willing to pay is $25.\nWe could also have solved this by determining the expected value if they had paid $20:\n\\begin{align*}\nE[X]-c&=\\sum_{i=1}^n p_ix_i-c \\\\[12pt]\n&=0.5(550)+0.5(-500)-20 \\\\[6pt]\n&=5\n\\end{align*}\nAs the expected value is positive, the agent would be willing to pay $20.\n\n\n\nb) Would a risk averse expected utility maximiser with wealth $1000 and utility function U(x)=x^{1/2} be willing to pay $20 to play this gamble? What is the most they would be willing to pay to play?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe expected utility of the gamble for the risk averse agent if they paid $20 to play is:\n\\begin{align*}\nEU(x)&=p_1(W+x_1-c)+p_2(W+x_2-c) \\\\[6pt]\n&=0.5(1000+550-20)^{1/2}+0.5(1000-500-20)^{1/2} \\\\[6pt]\n&=30.51\n\\end{align*}\nThe expected utility of not playing the gamble is:\n\\begin{align*}\nEU(x)&=(1000)^{1/2} \\\\[6pt]\n&=31.62\n\\end{align*}\nThey would not pay $20 as they would have higher utility if they turned down the gamble.\nIn fact, they would not pay any positive sum to participate in the gamble. If they were offered the gamble for free, their expected utility would be:\n\\begin{align*}\nEU(x)&=0.5(1000+550)^{1/2}+0.5(1000-500)^{1/2} \\\\[6pt]\n&=30.87\n\\end{align*}\nThis is less than if they simply turned down the gamble. They would be willing to pay to avoid the gamble. How much?\nWe can determine this by asking what wealth a utility of 30.87 is:\n\\begin{align*}\nW^{1/2}&=30.87 \\\\[6pt]\nW&=30.87^2 \\\\[6pt]\n&=\\$952.67\n\\end{align*}\nThe certainty equivalent of the gamble is $952.67. The agent would be willing to pay up to $47.33 to avoid the gamble.\n\n\n\nc) Would the expected utility maximiser with utility function U(x)=x^{1/2} change their decision if they had $1 million in wealth? Explain.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIf they now have $1 million in wealth, we simply repeat the calculations above with the new wealth.\n\\begin{align*}\nEU(x)&=0.5(1000000+550-20)^{1/2}+0.5(1000000-500-20)^{1/2} \\\\[6pt]\n&=1000.00247\n\\end{align*}\nThe expected utility of not playing the gamble is:\n\\begin{align*}\nEU(x)&=(1000000)^{1/2} \\\\[6pt]\n&=1000\n\\end{align*}\nThey would be willing to pay $20 as they would have higher utility if they accepted the gamble.\nWhat is the most they would be willing to pay? If they were offered the gamble for free, their expected utility would be:\n\\begin{align*}\nEU(x)&=0.5(1000000+550)^{1/2}+0.5(1000000-500)^{1/2} \\\\[6pt]\n&=1000.0125\n\\end{align*}\nHow much would they be willing to pay for this opportunity? We can determine this by asking what wealth a utility of 1000.0125 is:\n\\begin{align*}\nW&=(1000.0124655)^2 \\\\[6pt]\n&=\\$1000024.93\n\\end{align*}\nThe agent would be willing to pay up to $24.93 for the gamble. This is close to the expected value of $25.\nIntuitively, as the agent’s wealth increases their utility function becomes increasingly linear (second derivative approaches zero) and they become closer to risk neutral.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Decision making under risk exercises</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/decision-making-under-risk-exercises.html#sec-purchasing-insurance",
    "href": "decision-making-under-risk/decision-making-under-risk-exercises.html#sec-purchasing-insurance",
    "title": "11  Decision making under risk exercises",
    "section": "11.4 Purchasing insurance",
    "text": "11.4 Purchasing insurance\nAn agent is considering insurance against bushfire for their house valued at H=\\$1,000,000. The house has a 1 in 1000 (p=0.001) chance of burning down. An insurer is willing to offer full coverage for a premium (R) of $1100.\na) What is the expected value of purchasing insurance?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIf the agent purchases insurance, they pay the premium and do not suffer any loss regardless of whether there is a bushfire or not.\n\nE[\\text{I}]=-R=-\\$1,100\n\nThe expected value of purchasing insurance is the guaranteed loss of the premium, $1100.\nYou could also think of the expected value of purchasing insurance as involving:\n\nin 1 in 1000 instances, the loss of the house and the insurance payout in case of fire, minus the cost of the premium\nin the other 999 in 1000 instances, payment of the premium only.\n\nIn that case, you would write:\n\\begin{align*}\nE[\\text{I}]&=p\\times(-H+H-R)+(1-p)\\times(-R) \\\\[6pt]\n&=0.001\\times(-1000000+1000000-1100)+0.999\\times(-1100) \\\\[6pt]\n&=-\\$1,100\n\\end{align*}\nThis gives the same answer as the first method.\n\n\n\nb) What is the expected value of not purchasing insurance?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIf the agent does not purchase insurance, they face the 1 in 1000 possibility of an uninsured loss.\n\\begin{align*}\nE[\\neg \\text{I}]&=p\\times(-H) \\\\[6pt]\n&=-0.001\\times 1000000 \\\\[6pt]\n&=-\\$1000\n\\end{align*}\n\n\n\nc) Would a risk-neutral agent purchase the insurance?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAbove, we calculated that purchasing insurance in this case has a lower expected value than not purchasing the insurance. A risk-neutral agent would not purchase the insurance.\n\n\n\nd) Suppose an agent has a logarithmic utility function (U(x)=\\ln(x)) and they have $10,000 in cash in addition to their house, giving them wealth (W) of $1,010,000.\nAre they risk seeking, risk neutral or risk averse?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe logarithmic utility function has diminishing marginal utility. Diminishing marginal utility is the principle the marginal utility from each additional unit decreases. In the context of wealth, this means that each additional dollar provides less satisfaction than the previous one.\nDiminishing marginal utility means that the agent will be risk averse. They will prefer a certain outcome to a gamble with the same expected value.\n\n\n\ne) Would this agent with logarithmic utility purchase the insurance?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe need to compare the expected utility of purchasing insurance with the expected utility of not purchasing insurance.\nThe expected utility of purchasing insurance is:\n\\begin{align*}\nE[U(\\text{I})]&=\\ln(W-R) \\\\[6pt]\n&=\\ln(1,008,900) \\\\[6pt]\n&=13.8244\\\\\n\\end{align*}\nThe expected utility of not purchasing insurance is:\n\\begin{align*}\nE[U(\\neg \\text{I})]&=0.999\\times \\ln(W)+0.001\\times \\ln(W-H)) \\\\[6pt]\n&=0.999\\times \\ln(1,010,000)+0.001\\times \\ln(10,000) \\\\[6pt]\n&=13.8208\n\\end{align*}\nThe expected utility of purchasing insurance is greater than the expected utility from not purchasing insurance. This agent will purchase insurance.\nThe following diagram illustrates. The agent’s utility function is plotted, with the outcome on the horizontal axis and the utility of each outcome on the vertical axis. Each outcome and the utility of that outcome is marked: wealth after losing the house when uninsured (W-H), wealth after paying the insurance premium (W-R), and wealth if uninsured but the house does not burn down (W).\nThe expected utility of not purchasing insurance is on the dash-dot line between U(W-H) and U(W). The location of this point is determined by the probability p of incurring a loss. This point lies at a distance of p from U(W) along the line (or equivalently, at a distance of 1-p from U(W-H)). This point aligns with the expected value of leaving the house uninsured E[\\neg I].\nThe utility of purchasing insurance (U(W-R)) is greater than the expected utility of not purchasing insurance (E[U(\\neg I)]). The agent will purchase insurance.\n\n\nCode\nlibrary(ggplot2)\nlibrary(latex2exp)\n\nu &lt;- function(x){\n  log(x)\n}\n\ndf &lt;- data.frame(\n  x=seq(1,100,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;-3 #loss\nx2&lt;-90 #win\nev&lt;-77 #expected value of gamble\nxc&lt;-70 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n    geom_line(data = df) +\n    geom_vline(xintercept = 0, linewidth=0.25)+ \n    geom_hline(yintercept = 0, linewidth=0.25)+\n    labs(x = \"x\", y = \"U(x)\")+\n\n    # Set the theme\n    theme_minimal()+\n\n    #remove numbers on each axis\n    theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n    #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n    coord_cartesian(xlim = c(-8, 100), ylim = c(0, 5))+\n\n    #Add labels W, U(W) and line to curve indicating each\n    annotate(\"text\", x = x2, y = 0, label = \"W\", size = 4, hjust = 0.4, vjust = 1.5)+\n    annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n    annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n    annotate(\"text\", x = 0, y = u(x2), label = \"U(W)\", size = 4, hjust = 1.1, vjust = 0.4)+\n\n    #Add labels W-R, U(W_R) and line to curve indicating each\n    annotate(\"text\", x = xc, y = 0, label = \"W-R\", size = 4, hjust = 0.5, vjust = 1.5)+\n    annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n    annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n    annotate(\"text\", x = 0, y = u(xc), label = \"U(W-R)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n    #Add expected utility line\n    annotate(\"segment\", x = x2, xend = x1, y = u(x2), yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n    #Add labels W-H, U(W-H) and line to curve indicating each\n    annotate(\"text\", x = x1, y = 0, label = \"W-H\", size = 4, hjust = 0.4, vjust = 1.5)+\n    annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n    annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n    annotate(\"text\", x = 0, y = u(x1), label = \"U(W-H)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n    #Add labels E[not I], E[U(not I)] and curve indicating each\n    annotate(\"text\", x = ev, y = 0, label = TeX(\"E[$\\\\neg$ I]\", output='character'), parse=TRUE, size = 4, hjust = 0.4, vjust = 1.4)+\n    annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n    annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n    annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = TeX(\"E[U($\\\\neg$ I)]\", output='character'), parse=TRUE, size = 4, hjust = 1.05, vjust = 0.45)\n\n\n\n\n\nFigure 11.2: Insurance choice by a risk averse expected utility maximiser\n\n\n\n\n\n\n\n\nWhat is the intuition for this agent’s purchase of insurance?\nConsider the following scenario. You will experience one of two outcomes with equal probability: $0 in one case and $200 in the other. Your average wealth in this scenario is:\n\n\\frac{\\$0 + \\$200}{2} = \\$100\n\nYour average utility (which is expected utility) is:\n\n\\frac{U(\\$0) + U(\\$200)}{2}\n\nWhat if you can insure (costlessly) to give you wealth of $100 with certainty? In that case, your average wealth is $100, as per the first scenario, with utility of U(\\$100).\nDoes insurance result in higher utility?\nFor a risk-averse person with diminishing marginal utility, the jump from $0 to $100 provides a larger increase in utility than the jump from $100 to $200. Therefore:\n\nU(\\$100) &gt; \\frac{U(\\$0) + U(\\$200)}{2}\n\nThe utility of average wealth is greater than the average utility of wealth.\nThis inequality demonstrates why people with diminishing marginal utility purchase insurance. When wealth is unevenly distributed across potential outcomes, the utility gained from the best outcome is relatively less than the utility lost from the worst outcome. Insurance helps distribute wealth more evenly across all possible outcomes. In good times, the person has slightly less wealth (due to the premium). In bad times, the person avoids a catastrophic loss. This even distribution of wealth across possible outcomes results in higher expected utility for the consumer.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Decision making under risk exercises</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/decision-making-under-risk-exercises.html#insurance-but-not-a-lottery-ticket",
    "href": "decision-making-under-risk/decision-making-under-risk-exercises.html#insurance-but-not-a-lottery-ticket",
    "title": "11  Decision making under risk exercises",
    "section": "11.5 Insurance but not a lottery ticket",
    "text": "11.5 Insurance but not a lottery ticket\nIn your own words but using concepts from this subject explain why a risk averse agent who makes decisions according to expected utility theory might purchase insurance but not a lottery ticket.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBoth lotteries and insurance have a negative expected value.\nThe risk averse agent will typically reject a lottery as it has a small probability of a large win for the price of a small loss. Due to diminishing marginal returns, the average weight given to each dollar in the large gain is weighted much less than the average weight given to each dollar in the small price. This makes the lottery unattractive.\nIn contrast, a risk averse agent may purchase insurance as for a small price they can avoid the possibility of a large loss. Due to diminishing marginal returns, the large loss can have much higher average weight given to each dollar than to the weight given to each dollar for the small premium.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Decision making under risk exercises</span>"
    ]
  },
  {
    "objectID": "decision-making-under-risk/decision-making-under-risk-exercises.html#an-anomaly-in-expected-utility",
    "href": "decision-making-under-risk/decision-making-under-risk-exercises.html#an-anomaly-in-expected-utility",
    "title": "11  Decision making under risk exercises",
    "section": "11.6 An anomaly in expected utility",
    "text": "11.6 An anomaly in expected utility\nConsider the following two choices:\nChoice 1: Choose one of the following bets:\nBet A:\n\n$10,000 with probability: 11%\n$0 with probability: 89%\n\nBet B:\n\n$50,000 with probability: 10%\n$0 with probability: 90%\n\nChoice 2: Choose one of the following bets:\nBet A’:\n\n$10,000 with probability: 100%\n\nBet B’:\n\n$50,000 with probability: 10%\n$10,000 with probability: 89%\n$0 with probability: 1%\n\nMany people pick B for Choice 1 and A’ for Choice 2.\nDoes this pair of choices conform with Expected Utility Theory? Why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAccording to Expected Utility Theory, if an agent selects B:\n\\begin{align*}\n0.10U(50,000)+0.90U(0)&&gt; 0.11U(10,000)+ 0.89U(0) \\\\[6pt]\n0.10U(50,000)+0.01U(0)&&gt; 0.11U(10,000)\n\\end{align*}\nAccording to Expected Utility Theory, if an agent selects A’:\n\\begin{align*}\nU(10,000)&&gt;0.10U(50,000)+0.89U(10,000)+0.01U(0) \\\\[6pt]\n0.11U(10,000)&&gt;0.89U(50,000)+0.01U(0)\n\\end{align*}\nThis is a contradiction. Under expected utility theory, if an agent chooses B it should choose B’. And if the agent chooses A it should choose A’.\nThis occurs due to a breach in the principle of independence.\nHere is a representation of the choices.\n\nThe bets in the two shaded areas are the same. They are paired with an outcomes of either $10,000 or $0. Preferring B to A and A’ to B’ is a violation of the axiom of the independence of irrelevant alternatives. Under that axiom, two gambles mixed with an irrelevant third gamble will maintain the same order of preference as when the two are presented independently of the third gamble.\nUsing this representation in the table, here is another way of understanding why this combination of choices is an anomaly. Imagine there are 100 tickets numbered 1 to 100. One ticket will be drawn. If a ticket between 1 and 89 is drawn, you win the prize in the first column. If a ticket between 90 and 99 is drawn, you win the amount in the second. If a 100 is drawn, you win the sum in the third.\nSuppose that you know the ticket that is drawn is between 1 and 89. Would you prefer A or B? As you would win $0 with either choice, you will be indifferent. You will similarly be indifferent between A’ and B’, winning $10,00 no matter what.\nSuppose instead that a ticket between 90 and 100 is drawn, but you don’t know which. You can see that if you prefer A to B, you should also prefer A’ to B’. In each choice you are effectively facing the same bet. Let’s assume for the moment that you prefer B and B’.\nFinally, suppose you don’t know what ticket will be drawn. We have just determined that if you know the ticket is between 1 and 89 you are indifferent between the options, but if between 90 and 100 is drawn you prefer B and B’. You do not prefer A or A’ when the ticket range is 1 to 89 or 90 to 100, so you should not prefer A or A’ when the ticket number is unknown.\nFinally, using the formal definition for the independence of irrelevant alternatives axiom:\n\nif x and y are lotteries with x\\succcurlyeq y and\np is the probability that a third option z is present, then: \npz+(1-p)x\\succcurlyeq pz+(1-p)y\n\n\nFor each of the choices in our lottery:\n\np=89\\%\nx is a 100% chance of $10,000\ny is a 0.01/(1-0.89) chance of $0 and 0.10/(1-0.89) chance of $50,000\nz is $10,000 in choice 1 and $0 in choice 2, although z’s value does not matter due to its assumed irrelevance.",
    "crumbs": [
      "Decision making under risk",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Decision making under risk exercises</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory.html",
    "href": "prospect-theory/prospect-theory.html",
    "title": "Prospect theory",
    "section": "",
    "text": "Prospect theory is a descriptive theory of decision-making under risk. It was developed by Daniel Kahneman and Amos Tversky (1979) as a challenge to expected utility theory.\nProspect theory has the following features:\nFirst, it has a value function - that is a function that ascribes a value to each possible outcome. The value function incorporates reference dependence, loss aversion and the reflection effect:\n\nReference dependence means that the value of an outcome is judged relative to a reference point.\nLoss aversion means the value of a loss is greater than the value of an equivalent gain.\nThe reflection effect means that agents are risk-averse in the gain domain and risk-seeking in the loss domain\n\nSecond, prospect theory has a probability weighting function, whereby the agent subjectively weights objective probabilities. Small probabilities are weighted relatively more heavily than moderate probabilities. Those weights are then applied to the value of each outcome.\nProspect theory is an “as if” model of decision-making. People do not perform the calculations implicit in the application of prospect theory. Rather, they act “as if” they are performing those calculations. That makes prospect theory a descriptive theory, not a theory of how people actually make decisions.\nThe following sections break down each of these elements of prospect theory and explain how they are incorporated in its implementation.\n\n\n\n\nKahneman, D., and Tversky, A. (1979). Prospect theory: An analysis of decision under risk. Econometrica, 47(2), 263–291. https://doi.org/10.2307/1914185",
    "crumbs": [
      "Prospect theory"
    ]
  },
  {
    "objectID": "prospect-theory/reference-dependence.html",
    "href": "prospect-theory/reference-dependence.html",
    "title": "12  Reference dependence",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Reference dependence</span>"
    ]
  },
  {
    "objectID": "prospect-theory/reference-dependence.html#summary",
    "href": "prospect-theory/reference-dependence.html#summary",
    "title": "12  Reference dependence",
    "section": "",
    "text": "Prospect theory posits that people evaluate choices based on a reference point, coding outcomes as losses or gains relative to this point.\nSeveral theories exist for reference point formation, including status quo, lagged consumption, goals, and recent expectations.\nThe status quo as a reference point works well in lab experiments but may not fit many economic interactions or markets with intangible goods.\nLagged consumption as a reference point introduces the concept of adaptation, where people react to shocks initially, but the effect fades over time.\nGoals as reference points explain how people can react differently to the same outcome based on their set objectives.\nRecent expectations suggests that beliefs about future outcomes form the reference point, potentially aligning with other theories depending on the stability of expectations.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Reference dependence</span>"
    ]
  },
  {
    "objectID": "prospect-theory/reference-dependence.html#introduction",
    "href": "prospect-theory/reference-dependence.html#introduction",
    "title": "12  Reference dependence",
    "section": "12.1 Introduction",
    "text": "12.1 Introduction\nUnder prospect theory, people assess choices based on a reference point instead of an absolute assessment of their position. Outcomes are coded as losses and gains relative to that reference point.\nConsider the following two scenarios:\n\nScenario 1: You have not checked your share portfolio in a while. You expect it to be worth around $40,000. Today when you check, it is worth $30,000. Do you feel rich or poor?\nScenario 2: You have not checked your share portfolio in a while. You expect it to be worth around $20,000. Today when you check, it is worth $30,000. Do you feel rich or poor?\n\nUnder expected utility theory, those two scenarios should feel the same as you have U(\\$30,000) in both cases.\nIn contrast, under prospect theory, the value function - value function being what the utility function is typically called in prospect theory - applies to changes relative to the reference point.\nIf their initial reference point is their expectation, the value of that change is v(\\$10,000) or $v(-10,000), depending on whether their expectation is exceeded or not. The importance of that distinction becomes apparent when we examine how people consider choices involving either losses or gains.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Reference dependence</span>"
    ]
  },
  {
    "objectID": "prospect-theory/reference-dependence.html#theories-of-reference-dependence",
    "href": "prospect-theory/reference-dependence.html#theories-of-reference-dependence",
    "title": "12  Reference dependence",
    "section": "12.2 Theories of reference dependence",
    "text": "12.2 Theories of reference dependence\nThere are several theories on reference point formation. These include:\n\nThe status quo\nLagged consumption\nGoals\nRecent expectations\n\n\n12.2.1 The status quo\nA common assumption in prospect theory is that the reference point is the status quo, as it was for many examples in the original prospect theory paper by Kahneman and Tversky (1979). The status quo implies a preference for the current state. Any negative change is perceived as a loss.\nThe status quo appears straightforward and is a reasonable description in many contexts, such as lab experiments.\nHowever, the status quo as a reference point does not appear to be a useful assumption for describing many economic interactions. Suppose you decide to sell your bike. Do you see the foregoing of the bike as a loss?\nWhat if you run a bike shop? Does every sale involve a feeling of loss? For markets where intangible and fungible goods are exchanged (for example, the stock market) the status quo assumption appears a poor fit.\n\n\n12.2.2 Lagged consumption\nA second theory is that the reference point is lagged consumption.\nImagine you win the lottery.\nHow do you feel one week after the draw?\nHow do you feel one year after the draw?\nYour reference point likely reflects more recent consumption.\nLagged consumption introduces adaptation into reference point determination:\n\nFirst, we react to shocks\nThen the effect of the shock fades in time\n\n\n\n12.2.3 Goals\nAnother theory is that our goals are our reference points.\nConsider the following problem from Heath et al. (1999):\n\nSally and Trish both follow workout plans that usually involve doing 25 sit-ups.\nOne day, Sally sets a goal of performing 31 sit-ups. She finds herself very tired after performing 35 sit-ups and stops.\nTrish sets a goal of performing 39 sit-ups. She finds herself very tired after performing 35 sit-ups and stops.\nWhat emotion is each person experiencing?\n\nWith goals as reference points, people see success or failure to achieve a goal as a loss or gain. Although both Sally and Trish have the same performance, Sally will have a positive emotional reaction and Trish a negative reaction.\n\n\n12.2.4 Recent expectations\nA fourth theory of reference point determination is recent expectations.\nIn this approach, the reference point is beliefs about future outcomes (Kőszegi and Rabin (2006)). For example, a 5% pay rise when expecting 10% may be perceived as a loss.\nThe expectations-based theory can produce the same predictions as alternative theories:\n\nIf expectations are stable, recent expectations will reflect the status quo.\nRecent consumption will shape expectations, making lagged consumption a reasonable reference point.\nGoals can also shape (or be shaped by) expectations\n\n\n\n\n\nHeath, C., Larrick, R. P., and Wu, G. (1999). Goals as Reference Points. Cognitive Psychology, 38(1), 79–109. https://doi.org/10.1006/cogp.1998.0708\n\n\nKahneman, D., and Tversky, A. (1979). Prospect theory: An analysis of decision under risk. Econometrica, 47(2), 263–291. https://doi.org/10.2307/1914185\n\n\nKőszegi, B., and Rabin, M. (2006). A model of reference-dependent preferences. The Quarterly Journal of Economics, 121(4), 1133–1165. https://www.jstor.org/stable/25098823",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Reference dependence</span>"
    ]
  },
  {
    "objectID": "prospect-theory/loss-aversion.html",
    "href": "prospect-theory/loss-aversion.html",
    "title": "13  Loss aversion",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Loss aversion</span>"
    ]
  },
  {
    "objectID": "prospect-theory/loss-aversion.html#summary",
    "href": "prospect-theory/loss-aversion.html#summary",
    "title": "13  Loss aversion",
    "section": "",
    "text": "Loss aversion is the concept that losses have a stronger psychological impact than equivalent gains, often causing people to reject gambles with positive expected value.\nA value function with loss aversion can be represented mathematically, where losses are experienced with greater intensity than gains (e.g., twice the force).\nThe endowment effect, where people value items they own more highly, is considered an empirical expression of loss aversion.\nKahneman et al.’s (1991) experiment demonstrated the endowment effect with mugs, showing a significant difference between willingness to accept and willingness to pay for the same item.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Loss aversion</span>"
    ]
  },
  {
    "objectID": "prospect-theory/loss-aversion.html#introduction",
    "href": "prospect-theory/loss-aversion.html#introduction",
    "title": "13  Loss aversion",
    "section": "13.1 Introduction",
    "text": "13.1 Introduction\nLoss aversion is the concept that losses loom larger than gains. People feel more strongly about a loss than an equivalent gain, so they are often willing to reject gambles with a materially positive expected value.\nFor example, if someone feels losses with twice the feeling of gains, a 50:50 bet to win $550, lose $500 will be unattractive. This provides an alternative explanation to the absurd levels of risk aversion required to reject this bet (as discussed in Section 10.2).",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Loss aversion</span>"
    ]
  },
  {
    "objectID": "prospect-theory/loss-aversion.html#a-value-function-with-loss-aversion",
    "href": "prospect-theory/loss-aversion.html#a-value-function-with-loss-aversion",
    "title": "13  Loss aversion",
    "section": "13.2 A value function with loss aversion",
    "text": "13.2 A value function with loss aversion\nThis equation is an example of a value function with loss aversion:\n\nv(x)=\\left\\{\\begin{matrix}\nx \\space &\\textrm{where} \\space x \\geq 0\\\\\n2x \\space &\\textrm{where} \\space x&lt;0\n\\end{matrix}\\right.\n\nx is the outcome relative to the reference point.\nIn this value function, losses are experienced with twice the force of gains, with each loss multiplied by a factor of two.\nAs an example, suppose someone is given $100. If their initial reference point is their wealth before receiving the $100, x will be $100. Therefore their change in value is +100. If the same person instead loses $100, their change in value would be -200.\nThis plot shows the increased effect of the loss under this value function:\n\n\nCode\nlibrary(ggplot2)\n\nloss_fun &lt;- function(x){\n  2*x\n}\ngain_fun &lt;- function(x){\n  x\n}\n\nloss &lt;- data.frame(\n  x=seq(-10,0,0.05),\n  y=NA\n  )\nloss$y &lt;- loss_fun(loss$x)\n\ngain &lt;- data.frame(\n  x=seq(0,10,0.05),\n  y=NA\n  )\ngain$y &lt;- gain_fun(gain$x)\n\nggplot(mapping = aes(x, y)) +\n  geom_line(data = loss) +\n  geom_line(data = gain) + \n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"\", y = \"v(X)\")+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe greater slope of the curve in the loss domain, leading to a kink where the axes intercept, is indicative of the greater effect of losses.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Loss aversion</span>"
    ]
  },
  {
    "objectID": "prospect-theory/loss-aversion.html#the-endowment-effect",
    "href": "prospect-theory/loss-aversion.html#the-endowment-effect",
    "title": "13  Loss aversion",
    "section": "13.3 The endowment effect",
    "text": "13.3 The endowment effect\nThe endowment effect is often used to illustrate loss aversion.\nKahneman et al. (1991) ran one of the most famous and replicated experiments in economics.\nThey randomly assigned a free mug to members of a group and asked how much money they would accept for returning the mug (i.e. willingness to accept). The remaining participants were only shown a mug and asked about their willingness to pay for the mug.\nKahneman et al. (1991) found that the willingness to accept ($5.75) was substantially higher than the willingness to pay ($2.25).\nThe endowment effect is this phenomenon where people impute additional value to the items they own. The endowment effect is argued to be an empirical expression of loss aversion. Willingness to accept is higher as it is payment to incur the loss of the mug.\nThe endowment effect has been found in real estate markets, the stock market, with basketball tickets and in other domains.\n\n13.3.1 Endowment effect example\nBruce has the following reference-dependent value function:\n\nv(x)=\\left\\{\\begin{matrix}\nx \\space &\\textrm{where} \\space x \\geq 0\\\\\n2x \\space &\\textrm{where} \\space x&lt;0\n\\end{matrix}\\right.\n\nx is the outcome relative to the reference point.\nAssume Bruce has preferences over money (m) and mugs (c) as in this value function:\n\nV(x)=v(m-r_m)+v(5c-5r_c)\n\nr_m is Bruce’s reference point as it relates to money and r_c is his reference point as it relates to mugs.\nTo illustrate how this value function works, imagine Bruce has two mugs, and he drops one. It breaks. His change in the value function is:\n\\begin{align*}\nV(x)&=v(5c-5r_c) \\\\\n&=v(5\\times 1-5\\times 2) \\\\\n&=v(-5) \\\\\n&=-10 \\qquad(\\text{as } v(x)=2x \\text{ when } x&lt;0)\n\\end{align*}\nThe loss of a mug results in value of -10.\nAt the beginning of the experiment, Bruce is given a mug. Assuming Bruce’s reference point adapts such that he considers the mug his, how much would Bruce need to be paid to give up the mug?\nWe can calculate this by calculating what payment \\$p would make Bruce indifferent between losing the mug and gaining \\$p. That is the point where, after losing the mug and receiving payment, Bruce’s change in value is equal to zero.\nWe assume a reference point for money of his current wealth and are instructed that his reference point for mugs is ownership of the mug.\n\\begin{align*}\nV(x)&=0 \\\\[6pt]\nV(x)&=v(m-r_m)+v(5c-5r_c) \\\\[6pt]\n&=v(W+p-W)+v(5\\times 0-5\\times 1) \\\\[6pt]\n&=v(p)+v(-5) \\\\[6pt]\n&=p-2\\times 5 \\\\[6pt]\n&=p-10 \\\\[6pt]\np&=10\n\\end{align*}\nBruce would need to be paid at least $10 to give up the mug. Giving up the mug is seen as a loss and given greater weight than the money gained.\nNow assume Bruce was not given a mug, but rather an opportunity to purchase a mug. How much would Bruce be willing to pay for the mug?\nWe can calculate this by calculating what payment $p would make Bruce indifferent between gaining the mug and losing $p. That is the point where, after receiving the mug and making payment, Bruce’s change in value is equal to zero.\nWe assume a reference point for money of his current wealth and are instructed that his reference point for mugs is no mug.\n\\begin{align*}\nV(x)&=0 \\\\[6pt]\nV(x)&=v(m-r_m)+v(5c-5r_c) \\\\[6pt]\n&=v(W-p-W)+v(5\\times 1-5\\times 0) \\\\[6pt]\n&=v(-p)+v(5) \\\\[6pt]\n&=-2p+5 \\\\[6pt]\np&=2.5\n\\end{align*}\nThe most Bruce would be willing to pay for the mug is $2.50. He sees the foregone money as a loss, giving it greater weight than the mug gained.\n\n\n\n\nKahneman, D., Knetsch, J. L., and Thaler, R. H. (1991). Anomalies: The Endowment Effect, Loss Aversion, and Status Quo Bias. Journal of Economic Perspectives, 5(1), 193–206. https://doi.org/10.1257/jep.5.1.193",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Loss aversion</span>"
    ]
  },
  {
    "objectID": "prospect-theory/reflection-effect.html",
    "href": "prospect-theory/reflection-effect.html",
    "title": "14  The reflection effect",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>The reflection effect</span>"
    ]
  },
  {
    "objectID": "prospect-theory/reflection-effect.html#summary",
    "href": "prospect-theory/reflection-effect.html#summary",
    "title": "14  The reflection effect",
    "section": "",
    "text": "The reflection effect is an asymmetry in risk preferences: people are typically risk-averse for gains but risk-seeking for losses.\nThis effect can be illustrated through framing experiments, such as the Asian Disease problem, where equivalent outcomes are perceived differently when framed as gains versus losses.\nThe reflection effect can be represented in a value function with diminishing sensitivity to both gains and losses, resulting in a concave function in the gain domain (indicating risk aversion) and a convex function in the loss domain (indicating risk-seeking behaviour).",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>The reflection effect</span>"
    ]
  },
  {
    "objectID": "prospect-theory/reflection-effect.html#introduction",
    "href": "prospect-theory/reflection-effect.html#introduction",
    "title": "14  The reflection effect",
    "section": "14.1 Introduction",
    "text": "14.1 Introduction\nThe reflection effect involves an asymmetry in risk preferences in the gain and loss domains.\nWhen people make a risky choice related to gains, they are risk averse. They prefer a certain option with value lower than the expected value of the risky choice. When choosing an option in the loss domain, they become risk-seeking. This phenomenon is called the reflection effect.\nPut simply, people typically prefer to lock in a sure gain rather than risk it for more, but will take risks to avoid a sure loss.\nThe reflection effect might also be thought of as diminishing sensitivity to gains or losses in either direction. This contrasts with expected utility theory, where the pain of losses increases as they grow in size.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>The reflection effect</span>"
    ]
  },
  {
    "objectID": "prospect-theory/reflection-effect.html#the-asian-disease-problem",
    "href": "prospect-theory/reflection-effect.html#the-asian-disease-problem",
    "title": "14  The reflection effect",
    "section": "14.2 The Asian Disease problem",
    "text": "14.2 The Asian Disease problem\nThe reflection effect explains the framing effects in the following experiment by Kahneman and Tversky (1984).\nOne group of experimental subjects were asked the following hypothetical question that would be unlikely to be asked post-Covid-19.\n\nImagine that the U.S. is preparing for the outbreak of an unusual Asian disease, which is expected to kill 600 people. Two alternative programs to combat the disease have been proposed. Assume that the exact scientific estimates of the consequences of the programs are as follows:\nIf Program A is adopted, 200 people will be saved.\nIf Program B is adopted, there is a one-third probability that 600 people will be saved and a two-thirds probability that no people will be saved.\nWhich of the two programs would you favour?\n\n72% of participants chose option A.\nAnother group of experimental participants were shown the following:\n\nImagine that the U.S. is preparing for the outbreak of an unusual Asian disease, which is expected to kill 600 people. Two alternative programs to combat the disease have been proposed. Assume that the exact scientific estimates of the consequences of the programs are as follows:\nIf Program C is adopted, 400 people will die.\nIf Program D is adopted, there is a one-third probability that nobody will die and a two-thirds probability that 600 people will die.\nWhich of the two programs would you favour?\n\n22% of participants chose option C.\nDespite their differing presentation, these two scenarios are mathematically identical. Programs A and C both result in 200 people living and 400 dying. Similarly, Programs B and D offer a 1 in 3 chance of saving everyone and a 2 in 3 chance of everyone dying.\nThe difference is that the first scenario presents a ‘gain frame’, focusing on lives saved. The second scenario presents a ‘loss frame’, focusing on lives lost.” In the gain frame, 72% chose the certain option A over the risky option B. In the loss frame, only 22% chose the certain option C, meaning 78% preferred the risky option D.\nThis shift in preferences demonstrates the reflection effect. When the choice is framed in terms of gains - lives saved - people prefer the certain option. When framed in terms of losses - lives lost - they prefer the risky option.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>The reflection effect</span>"
    ]
  },
  {
    "objectID": "prospect-theory/reflection-effect.html#the-reflection-effect-in-the-value-function",
    "href": "prospect-theory/reflection-effect.html#the-reflection-effect-in-the-value-function",
    "title": "14  The reflection effect",
    "section": "14.3 The reflection effect in the value function",
    "text": "14.3 The reflection effect in the value function\nThe following value function is an example of a function with diminishing sensitivity to both gains and losses. This function generates the reflection effect.\n\\begin{equation*}\nv(x)= \\Bigg\\{\n\\begin{matrix}\nx^\\frac{1}{2} \\space \\text{where} \\space x \\geq 0\\\\\n-(-x)^\\frac{1}{2} \\space \\text{where} \\space x&lt;0\n\\end{matrix}\n\\end{equation*}\nAs x increases in magnitude in either direction, the marginal change in value from each incremental unit of x decreases. This decreasing marginal change is implemented via the power of one half. For the value of the gain or loss to double, the size of the gain or loss must quadruple.\nWhen x is less than zero, we apply a negative sign to x as the power of one half is only defined for positive numbers. We then apply another negative sign after applying the power to indicate the negative value of losses.\nThis value function results in risk-averse behaviour in the gain domain and risk-seeking behaviour in the loss domain. The following plot shows the diminishing effect in each direction.\n\n\nCode\nlibrary(ggplot2)\n\nloss_fun &lt;- function(x){\n  -(-x)^0.5\n}\ngain_fun &lt;- function(x){\n  x^0.5\n}\n\nloss &lt;- data.frame(\n  x=seq(-10,0,0.05),\n  y=NA\n  )\nloss$y &lt;- loss_fun(loss$x)\n\ngain &lt;- data.frame(\n  x=seq(0,10,0.05),\n  y=NA\n  )\ngain$y &lt;- gain_fun(gain$x)\n\nggplot(mapping = aes(x, y)) +\n  geom_line(data = loss) +\n  geom_line(data = gain) + \n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))\n\n\n\n\n\nFigure 14.1: The reflection effect\n\n\n\n\n\n\n\n\nIn the gain domain, the function is concave, indicating risk aversion. In the loss domain, the convex function indicates risk-seeking behaviour. The result is an S-shaped curve.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>The reflection effect</span>"
    ]
  },
  {
    "objectID": "prospect-theory/reflection-effect.html#an-example",
    "href": "prospect-theory/reflection-effect.html#an-example",
    "title": "14  The reflection effect",
    "section": "14.4 An example",
    "text": "14.4 An example\nThe following numerical example illustrates further.\nSuppose an agent has a value function that expresses the reflection effect, with the outcomes in either direction subject to a power of one half.\n\\begin{equation*}\nv(x)= \\Bigg\\{\n\\begin{matrix}\nx^\\frac{1}{2} \\space \\text{where} \\space x \\geq 0\\\\\n-(-x)^\\frac{1}{2} \\space \\text{where} \\space x&lt;0\n\\end{matrix}\n\\end{equation*}\nThis agent is offered a choice between $10 for certain and a 50:50 bet to win $20 or end up with nothing. We calculate the value of each option by substituting the outcomes into the value function.\nFor the certain gain, we substitute $10 into the value function.\n\\begin{align*}\nv(\\text{certainty})&=v(10) \\\\[6pt]\n&=10^{\\frac{1}{2}} \\\\[6pt]\n&=3.16\n\\end{align*}\nFor the bet, we calculate the probability weighted value of the potential outcomes.\n\\begin{align*}\nv(\\text{bet})&=0.5\\times v(20)+0.5\\times v(0) \\\\[6pt]\n&=0.5\\times 20^{\\frac{1}{2}}+0.5\\times 0 \\\\[6pt]\n&=2.24\n\\end{align*}\nThe $10 for certain has a higher value for the agent. This agent is risk averse in the gain domain and therefore prefers an amount for certain over a bet with the same expected value.\nThe following chart illustrates. Plotted are the value of the certain payment of $10 and the outcome from winning the gamble, $20. A loss results in value of 0.\nThe value of the gamble itself is the probability-weighted average of the two gamble outcomes. Due to diminishing marginal utility in the gain domain, the value of the gamble is less than the value of $10 with certainty. The extra $10 over the certain outcome from winning the bet is less than the value of the first $10. As a result, the agent does not want to risk the bet.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-25, 25, 0.1),\n  y = u(seq(-25, 25, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;-0 #loss\nx2&lt;-20 #win\nev&lt;-10 #expected value of gamble\nxc&lt;-10 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-25, 25), ylim = c(-5, 5))+\n\n  #Add labels 10, v(10) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"10\", size = 4, hjust = 0.6, vjust = 1.5)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"v(10)\", size = 4, hjust = 1.05, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels 20, v(20) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"20\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"v(20)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels v(bet) and curve indicating position\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"v(bet)\", size = 4, hjust = 1.05, vjust = 0.45)\n\n\n\n\n\nFigure 14.2: The reflection effect in the gain domain\n\n\n\n\n\n\n\n\nSuppose the agent is now offered another choice. They can now have a certain loss of $10 or a 50:50 bet to lose $20 or to lose nothing.\nAgain, we calculate the value of each option by substituting the outcomes into the value function.\nFor the certain loss, we substitute -$10 into the value function.\n\\begin{align*}\nv(\\text{certainty})&=v(-10) \\\\[6pt]\n&=-10^{\\frac{1}{2}} \\\\[6pt]\n&=-3.16\n\\end{align*}\nFor the bet, we calculate the probability weighted value of the potential outcomes.\n\\begin{align*}\nv(\\text{bet})&=0.5\\times v(-20)+0.5\\times v(0) \\\\[6pt]\n&=-0.5\\times 20^{\\frac{1}{2}}+0.5\\times 0 \\\\[6pt]\n&=-2.24\n\\end{align*}\nThis bet delivers higher value than the certain loss, despite the bet and the certain loss having the same expected value. The agent is willing to take a risk to avoid a loss. They are risk seeking in the loss domain.\nThe following chart illustrates. Plotted are the value of the certain payment of -$10 and the outcome from losing the gamble, -$20. A win results in value of 0.\nThe value of the gamble itself is the probability-weighted average of the two gamble outcomes. Due to diminishing marginal utility in the loss domain, the value of the gamble is greater than the value of -$10 with certainty. The potential loss of another $10 over and above the certain loss is given less weight than the first $10. As a result, the agent wants to take the risk.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-25, 25, 0.1),\n  y = u(seq(-25, 25, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;--20 #loss\nx2&lt;-0 #win\nev&lt;--10 #expected value of gamble\nxc&lt;--10 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-25, 25), ylim = c(-5, 5))+\n\n  #Add labels -10, v(-10) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"-10\", size = 4, hjust = 0.6, vjust = -0.5)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"v(-10)\", size = 4, hjust = -0.1, vjust = 0.3)+\n\n  #Add labels -20, v(-20) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"-20\", size = 4, hjust = 0.5, vjust = -0.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"v(-20)\", size = 4, hjust = -0.1, vjust = 0.6)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels v(bet) and curve indicating position\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"v(bet)\", size = 4, hjust = -0.1, vjust = 0.45)\n\n\n\n\n\nFigure 14.3: The reflection effect in the loss domain\n\n\n\n\n\n\n\n\n\n\n\n\nKahneman, D., and Tversky, A. (1984). Choices, values, and frames. American Psychologist, 39(4), 341–350. https://doi.org/10.1037/0003-066X.39.4.341",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>The reflection effect</span>"
    ]
  },
  {
    "objectID": "prospect-theory/value-function.html",
    "href": "prospect-theory/value-function.html",
    "title": "15  The value function",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>The value function</span>"
    ]
  },
  {
    "objectID": "prospect-theory/value-function.html#summary",
    "href": "prospect-theory/value-function.html#summary",
    "title": "15  The value function",
    "section": "",
    "text": "Prospect theory’s value function incorporates three phenomena: reference dependence, loss aversion, and the reflection effect.\nThe function is defined on changes relative to a reference point, rather than final wealth levels, with diminishing marginal sensitivity to both gains and losses.\nThe value function is characterised by a kink at the reference point, with losses weighted more heavily than gains.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>The value function</span>"
    ]
  },
  {
    "objectID": "prospect-theory/value-function.html#introduction",
    "href": "prospect-theory/value-function.html#introduction",
    "title": "15  The value function",
    "section": "15.1 Introduction",
    "text": "15.1 Introduction\nThe three phenomena, reference dependence, loss aversion and the reflection effect, are each incorporated into the prospect theory value function.\nFirst, the value function of prospect theory is defined on changes in wealth or welfare rather than on final wealth levels. In other words, gains and losses are defined relative to a reference point. The reference point might be the status quo, lagged consumption, a goal, or an expectation about the outcome.\nUtility from an outcome depends on the distance to the relevant reference level. A multi-millionaire may reject a 50:50 bet to win $550, lose $500 because they are not comparing the outcomes to their total wealth but rather are making a judgment relative to the reference point of the status quo.\nSecond, perceptions of both gains and losses are characterised by diminishing marginal sensitivity in either direction. Successive incremental changes have a smaller marginal impact.\nThis is similar to decreasing marginal utility of wealth in expected utility theory. Prospect theory and expected utility theory differ in the baseline. In expected utility theory, the starting value is typically zero wealth, with increases from there decreasing in marginal utility. In prospect theory, the starting value is the reference point, with both increases and decreases having smaller marginal effects as they increase in magnitude.\nThird, losses loom larger than gains. People feel more strongly about a loss than they do an equivalent gain. They are often willing to reject gambles with a materially positive expected value.\nThese phenomena result in the following famous figure from Kahneman and Tversky (1979).\n1. The value function is centred on the reference point at the origin\n2. There is a kink at the origin, with losses counting more than gains.\n3. There is diminishing sensitivity to further changes from the reference point in both directions.\n\nThe following diagrams illustrate the different shapes of the expected utility function and the Prospect Theory value function.\nThe expected utility function, in this case U(x)=ln(x), has diminishing marginal utility as utility increases. Utility is measured from a reference point of zero.\n\n\nCode\nlibrary(ggplot2)\ndf &lt;- data.frame(\n  x = seq(0.05,20,0.05),\n  y=NA\n)\ndf$y &lt;- log(df$x)\n\nggplot(mapping = aes(x, y))+\n  geom_line(data = df)+ \n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"\", y = \"U(X)\")+\n\n  # Set the theme\n  theme_minimal()\n\n\n\n\n\nFigure 15.1: Expected utility function\n\n\n\n\n\n\n\n\nFor the prospect theory function, you can see the kink at zero, with losses weighted more heavily than gains, with gains and losses determined relative to a reference point. There is diminishing sensitivity to further changes in both directions\n\n\nCode\nloss_fun &lt;- function(x){#| \n  -2*(-x)^0.5\n}\ngain_fun &lt;- function(x){\n  x^0.5\n}\n\nloss &lt;- data.frame(\n  x=seq(-10,0,0.05),\n  y=NA\n  )\nloss$y &lt;- loss_fun(loss$x)\n\ngain &lt;- data.frame(\n  x=seq(0,10,0.05),\n  y=NA\n  )\ngain$y &lt;- gain_fun(gain$x)\n\nggplot(mapping = aes(x, y)) +\n  geom_line(data = loss) +\n  geom_line(data = gain) + \n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"\", y = \"v(X)\")+\n\n  # Set the theme\n  theme_minimal()\n\n\n\n\n\nFigure 15.2: Prospect theory value function\n\n\n\n\n\n\n\n\nThe following equation is an example of a value function incorporating both loss aversion and the reflection effect.\n\\begin{equation*}\nv(x)= \\Bigg\\{\n\\begin{matrix}\nx^\\frac{1}{2} \\space \\text{where} \\space x \\geq 0\\\\\n-2(-x)^\\frac{1}{2} \\space \\text{where} \\space x&lt;0\n\\end{matrix}\n\\end{equation*}\nLosses are multiplied by 2, giving losses twice the weight of an equivalent gain in the value function. This is loss aversion.\nThe reflection effect is implemented through losses and gains being to the power of one-half. This leads to diminishing sensitivity to changes in both directions.\n\n\n\n\nKahneman, D., and Tversky, A. (1979). Prospect theory: An analysis of decision under risk. Econometrica, 47(2), 263–291. https://doi.org/10.2307/1914185",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>The value function</span>"
    ]
  },
  {
    "objectID": "prospect-theory/probability-weighting.html",
    "href": "prospect-theory/probability-weighting.html",
    "title": "16  Probability weighting",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Probability weighting</span>"
    ]
  },
  {
    "objectID": "prospect-theory/probability-weighting.html#summary",
    "href": "prospect-theory/probability-weighting.html#summary",
    "title": "16  Probability weighting",
    "section": "",
    "text": "Prospect theory incorporates non-linear weighting of probabilities, contrasting with expected utility theory’s linear approach.\nEmpirical evidence shows that people tend to overweight certain events and very low-probability events (the certainty effect and possibility effect) while approximating linear weights for intermediate probabilities.\nThis probability weighting helps explain phenomena like the Allais Paradox, where people’s choices in different scenarios appear inconsistent with expected utility theory.\nThe decision weight function, such as Prelec’s (1998) formula, mathematically represents this non-linear probability weighting in prospect theory, capturing the overweighting of small probabilities.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Probability weighting</span>"
    ]
  },
  {
    "objectID": "prospect-theory/probability-weighting.html#introduction",
    "href": "prospect-theory/probability-weighting.html#introduction",
    "title": "16  Probability weighting",
    "section": "16.1 Introduction",
    "text": "16.1 Introduction\nIn expected utility theory, probabilities enter the expected utility function linearly. For example, if an event is twice as likely as another outcome, it has double the weight.\nIn contrast, prospect theory incorporates non-linear weighting of probabilities by applying decision weights to each potential outcome.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Probability weighting</span>"
    ]
  },
  {
    "objectID": "prospect-theory/probability-weighting.html#empirical-evidence",
    "href": "prospect-theory/probability-weighting.html#empirical-evidence",
    "title": "16  Probability weighting",
    "section": "16.2 Empirical evidence",
    "text": "16.2 Empirical evidence\nExperimental observation indicates that we approximate linear weights for intermediate probabilities when making decisions under risk.\nBut, there is strong evidence that we overweight certain events, when the probability of the event is one, relative to near certain events, such as when the probability is, say, 99%. This overweighting of certainty is effectively the same as overweighting very low-probability events.\nThe following diagram from Tversky and Kahneman (1992) illustrates the relationship between objective probability and the decision weight applied to each outcome. On the x-axis is the probability of the outcome. On the y-axis is the weight applied to the value function for that probability. The straight line at 45 degrees represents linear weighting of probabilities. The curve represents the weighting function.\n\nFor this particular curve, where the probability is very low, such as around p=0.05, the weight is around 0.15. Similarly, at high probability, such as p=0.95, the weight is around 0.8. For intermediate probabilities, the observed weight is relatively closer to the objective probability.\nKahneman (2011) calls the large psychological value of the change from 0 to 5% (or some other small probability) the possibility effect. He calls the large psychological value of the change to 100% the certainty effect. We will pay a lot more for certainty than near certainty.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Probability weighting</span>"
    ]
  },
  {
    "objectID": "prospect-theory/probability-weighting.html#the-allais-paradox",
    "href": "prospect-theory/probability-weighting.html#the-allais-paradox",
    "title": "16  Probability weighting",
    "section": "16.3 The Allais Paradox",
    "text": "16.3 The Allais Paradox\nProbability weighting is often offered as an explanation for the Allais Paradox, which I discuss in Section 10.1.\nThe Allais paradox can be illustrated as follows.\nYou are given the following pair of choices.\nChoice 1: Choose one of the following bets:\nBet A:\n\n$2500 with probability: 33%\n$2400 with probability: 66%\n$0 with probability: 1%\n\nBet B:\n\n$2400 with probability: 100%\n\nPeople tend to prefer Bet B.\nChoice 2: Choose one of the following bets:\nBet C:\n\n$2500 with probability: 33%\n\n$0 with probability: 67%\n\nBet D:\n\n$2400 with probability: 34%\n$0 with probability: 66%\n\nPeople tend to prefer Bet C.\nIt can be shown that this pair of preferences, Bet B and Bet C, does not conform with expected utility theory.\nOne explanation for this pair of decisions comes from probability weighting. If you look at Bet B, the outcome is certain. Certain events tend to be overweighted relative to near-certain events, such as the 99% chance of $2400 or $2500 in Bet A. An alternative way of thinking about this is that the 1% probability of nothing in Bet A is overweighted.\nConversely, the intermediate probabilities in Bet C and Bet D are weighted closer to linearly, which can result in the slightly higher expected value Bet C being preferred.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Probability weighting</span>"
    ]
  },
  {
    "objectID": "prospect-theory/probability-weighting.html#the-decision-weight",
    "href": "prospect-theory/probability-weighting.html#the-decision-weight",
    "title": "16  Probability weighting",
    "section": "16.4 The decision weight",
    "text": "16.4 The decision weight\nThe weighting of probabilities is applied in prospect theory through a decision weight \\pi(p_i). The decision weight is a function of the probability of the outcome.\nThis decision-weighting function reflects the empirical regularity that people overweight certain events relative to near-certain events and overweight low-probability events.\nAn example probability weighting function of a type proposed by Prelec (1998) is as follows:\n\n\\pi(p)=e^{-(-ln(p))^\\alpha}\\\\[6pt]\no&lt;\\alpha&lt;1\n\nThis function, with \\alpha=0.6, is plotted below.\n\n\nCode\n#Plot of probability weighting function using ggplot2\nlibrary(ggplot2)\n\n#Define probability weighting function\nprob_weight &lt;- function(p, alpha){\n  exp(-(-log(p))^alpha)\n}\n\n#Create data frame of probabilities and weights\nprob &lt;- seq(0, 1, 0.001)\nprob_df &lt;- data.frame(prob = prob, weight = prob_weight(prob, 0.6))\n\n#Plot\nggplot(prob_df, aes(x = prob, y = weight)) +\n  geom_line() +\n\n  #Use geom_segment to add dashed light 45 degree line between 0 and 1\n  geom_segment(x = 0, y = 0, xend = 1, yend = 1, linetype = \"dashed\", color = \"grey\") +\n\n  #Add axes\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n\n  #Add labels\n  labs(x = \"Probability\", y = \"Weight\") +\n\n  #Make chart square\n  coord_fixed()+\n\n  #Set theme\n  theme_minimal()\n\n\n\n\n\nFigure 16.1: Probability weighting function\n\n\n\n\n\n\n\n\n\n\n\n\nKahneman, D. (2011). Thinking, fast and slow (1st edition). Farrar, Straus; Giroux.\n\n\nPrelec, D. (1998). The probability weighting function. Econometrica, 66(3), 497–527. https://doi.org/10.2307/2998573\n\n\nTversky, A., and Kahneman, D. (1992). Advances in prospect theory: Cumulative representation of uncertainty. Journal of Risk and Uncertainty, 5, 297–323. https://doi.org/10.1007/BF00122574",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Probability weighting</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-implementation.html",
    "href": "prospect-theory/prospect-theory-implementation.html",
    "title": "17  Prospect theory implementation",
    "section": "",
    "text": "17.1 Summary",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Prospect theory implementation</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-implementation.html#summary",
    "href": "prospect-theory/prospect-theory-implementation.html#summary",
    "title": "17  Prospect theory implementation",
    "section": "",
    "text": "Prospect theory involves two phases: editing and evaluation.\nThe editing phase simplifies prospects through four main operations: coding (as gains or losses), combination (of identical outcomes), segregation (of riskless components), and cancellation (of shared components).\nIn the evaluation phase, prospects are assessed using a formula that combines decision weights applied to probabilities and subjective values of outcomes.\nProspect theory results in a fourfold pattern of risk attitudes: risk aversion for high-probability gains and low-probability losses, and risk seeking for low-probability gains and high-probability losses.\nThis pattern explains real-world behaviours such as settlement negotiations in court cases, the attractiveness of lotteries despite typically low expected values, and the purchase of insurance against unlikely events.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Prospect theory implementation</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-implementation.html#introduction",
    "href": "prospect-theory/prospect-theory-implementation.html#introduction",
    "title": "17  Prospect theory implementation",
    "section": "17.2 Introduction",
    "text": "17.2 Introduction\nUnder prospect theory, people assess the weighted value of a prospect in two phases: editing and evaluation.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Prospect theory implementation</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-implementation.html#editing",
    "href": "prospect-theory/prospect-theory-implementation.html#editing",
    "title": "17  Prospect theory implementation",
    "section": "17.3 Editing",
    "text": "17.3 Editing\nEditing involves simplification of prospects for subsequent evaluation.\nKahneman and Tversky (1979) describe the editing phase as having four main operations: coding, combination, segregation and cancellation.\n\nIn the coding operation, prospects are coded as gains or losses relative to a reference point.\nIn the combination operation, prospects are simplified by combining probabilities for identical outcomes. For example, (0.25, 200; 0.25, 200; 0.50, 0) will become (0.50, 200; 0.50, 0).\nDuring segregation, riskless components are segregated from risky components. For example (0.80, 300; 0.20, 200) corresponds to a sure gain of 200 and the risky gamble (0.80, 100; 0.20, 0).\nFinally, in cancellation, components that are shared by two prospects are ignored.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Prospect theory implementation</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-implementation.html#evaluation",
    "href": "prospect-theory/prospect-theory-implementation.html#evaluation",
    "title": "17  Prospect theory implementation",
    "section": "17.4 Evaluation",
    "text": "17.4 Evaluation\nIn the evaluation phase, the prospects are evaluated, and the option with the highest weighted value is chosen.\nThe weighted value of a prospect is made up of:\n1. a decision weight applied to each probability \\pi(p_i)\n2. the subjective value of each outcome v(x_i)\nThese are applied through the following formula to calculate V(X), the weighted value of the outcomes from gamble X.\n\\begin{align*}\nV(X)&=\\sum_{i=1}^n\\pi(p_i)v(x_i)\\\\[6pt]\n&=\\pi(p_1)v(x_1)+\\pi(p_2)v(x_2)+...+\\pi(p_n)v(x_n)\n\\end{align*}",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Prospect theory implementation</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-implementation.html#fourfold-pattern-of-risk-attitudes",
    "href": "prospect-theory/prospect-theory-implementation.html#fourfold-pattern-of-risk-attitudes",
    "title": "17  Prospect theory implementation",
    "section": "17.5 Fourfold pattern of risk attitudes",
    "text": "17.5 Fourfold pattern of risk attitudes\nProspect theory results in a four-fold pattern of risk attitudes, as shown in this table.\n\n\n\n\nGains\nLosses\n\n\n\n\nHigh probability\nRisk aversion\nRisk seeking\n\n\nLow probability\nRisk seeking\nRisk aversion\n\n\n\nFor high-probability gambles, the reflection effect leads to people being people risk averse in the domain of gains and risk seeking in the domain of losses. For the top left quadrant, the low possibility of missing out on the gain is overweighted, making the gamble less attractive and amplifying the risk-averse behaviour. For the top right quadrant, the low probability of avoiding the loss is also overweighted, amplifying the risk-seeking behaviour we see in the domain of losses.\nThese top two quadrants can be illustrated by considering an offer to settle a court case.\nImagine one party has a 95% chance of winning a large settlement. The shape of the value function in the gain domain and the certainty effect make a settlement offer attractive. Conversely, the other party overweights their 5% chance of victory and is risk-seeking in the loss domain, making them unlikely to seek settlement unless it is very favourable.\nBut for low-probability gambles, as in the bottom two quadrants, the probability weighting pushes decisions in the opposite direction to the value function. The possibility of a gain is overweighted, making gambles attractive and inducing risk-seeking behaviour. A similar effect occurs for a low probability of loss, with the overweighted probability making the gamble less attractive, inducing risk-averse behaviour.\nThe bottom two quadrants can be related to the purchase of insurance and lotteries.\nLotteries involve a small probability of gains. As people overweight that small probability of a win, people will be risk-seeking when considering whether to purchase a lottery despite the gamble being in the gain domain where they are typically risk averse.\nInsurance involves a small probability of loss. As people overweight the small probability of a loss, people will be risk-averse when considering whether to purchase insurance despite normally being risk seeking in the loss domain.\n\n\n\n\nKahneman, D., and Tversky, A. (1979). Prospect theory: An analysis of decision under risk. Econometrica, 47(2), 263–291. https://doi.org/10.2307/1914185",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Prospect theory implementation</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-examples.html",
    "href": "prospect-theory/prospect-theory-examples.html",
    "title": "18  Prospect theory examples",
    "section": "",
    "text": "18.1 Mathematical examples",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Prospect theory examples</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-examples.html#mathematical-examples",
    "href": "prospect-theory/prospect-theory-examples.html#mathematical-examples",
    "title": "18  Prospect theory examples",
    "section": "",
    "text": "Summary\n\nIn the following mathematical examples, I demonstrate the operation of prospect theory through various scenarios, illustrating how individuals make decisions under uncertainty based on reference points, loss aversion, and diminishing sensitivity to gains and losses.\nThe 50:50 gamble demonstrates loss aversion, with losses weighted more heavily than equivalent gains.\nThe 60:40 gamble shows how diminishing sensitivity and loss aversion interact to influence decision-making.\nThe gamble in the gain domain illustrates the reflection effect, where individuals are risk-averse for gains but become risk-seeking for losses.\nChanges in wealth or reference points can significantly alter risk preferences, as shown in the examples of accepting or rejecting gambles after losses or wins.\n\n\n\nIn this section, I present a series of mathematical examples of prospect theory.\n\n\n18.1.1 A 50:50 gamble\nSuppose Alby has the following reference-dependent value function:\n\nv(x)=\\left\\{\\begin{matrix}\nx^\\frac{1}{2} \\qquad &\\textrm{where} \\space x \\geq 0\\\\[6pt]\n-2(-x)^\\frac{1}{2} \\quad &\\textrm{where} \\space x &lt; 0\n\\end{matrix}\\right.\n\nx is the realised outcome relative to the reference point.\nAssume that Alby’s reference point is the status quo and that he weights outcomes linearly.\nAlby is offered the gamble A:\n\n(0.5, \\$110; 0.5, −\\$100)\n\n\nAccept or reject?\nWill Alby want to play this gamble?\nTo determine this, we compare the weighted value of the gamble with the weighted value of rejecting the offer.\nThe weighted value of the gamble is:\n\\begin{align*}\nV(A)&=p_1v(x_1)+p_2v(x_2) \\\\[6pt]\n&=0.5\\times v(110)+0.5\\times v(-100) \\\\[6pt]\n&=0.5\\times (110)^\\frac{1}{2}-0.5\\times 2\\times (100)^\\frac{1}{2} \\\\[6pt]\n&=-4.76\n\\end{align*}\nAlby will not want to play this gamble as it has a negative value. He could receive a weighted value of 0 by simply not playing.\nThe reason for this negative value is that Alby is loss averse. The loss of $100 is given twice the weight of an equivalent gain.\nThe following chart illustrates. The horizontal axis is the outcome x relative to the reference point. The vertical axis is the value of each outcome. The S-shaped curve represents Alby’s value function, with a concave curve in the game domain and a convex curve in the loss domain. The curve is steeper in the loss domain, due to loss aversion.\nThe gain of $110 and the loss of $100 and their respective values are marked.\nI have drawn a straight line between the two outcomes. The weighted value of the two outcomes will be on this line.\nAs the probability of each outcome is 50 percent, the expected value of A, $5, is halfway between the two outcomes. If we project to the straight line from the expected value, we get V(A), a probability-weighted average of the two possible outcomes from the bet. V(A) is negative, indicating that the gamble has a lower weighted value than remaining at the status quo.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -2*(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-220, 220, 0.1),\n  y = u(seq(-220, 220, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1 &lt;- -200 #loss\nx2 &lt;- 220 #win\nev &lt;- 10 #expected value of gamble\nxc &lt;- 0 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-220, 220), ylim = c(-30, 15))+\n\n  #Add labels -100, v(-100) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"-100\", size = 4, hjust = 0.5, vjust = -0.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"v(-100)\", size = 4, hjust = -0.1, vjust = 0.45)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels 110, v(110) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"110\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"v(110)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels E[A], V(A) and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[A]\", size = 4, hjust = 0.3, vjust = -0.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"V(A)\", size = 4, hjust = 1.05, vjust = 0.45)\n\n\n\n\n\nFigure 18.1: A 50:50 gamble\n\n\n\n\n\n\n\n\n\n\nAccept or reject after loss?\nSuppose Alby loses his wallet containing $100. He feels bad about it and perceives it as a loss. His reference point is unchanged at the original status quo, but the amount of money he will have after any outcome is $100 less than otherwise. Would he be willing to take gamble A now?\nAfter losing $100 but not changing his reference point, he has two possible outcomes relative to his reference point: a gain of $10 (winning $110 minus the lost money in the wallet) and a loss of $200 (losing $100 and also losing his wallet).\n\nThe weighted value of gamble A is now:\n\\begin{align*}\nV(A)&=p_1v(x_1)+p_2v(x_2) \\\\[6pt]\n&=0.5\\times v(110-100)+0.5\\times v(-100-100) \\\\[6pt]\n&=0.5\\times (10)^\\frac{1}{2}-0.5\\times 2\\times (200)^\\frac{1}{2} \\\\[6pt]\n&=-12.56\n\\end{align*}\nThe value of not playing the gamble involves remaining with a loss of $100:\n\\begin{align*}\nV(\\neg A)&=v(-100) \\\\[6pt]\n&=-2\\times (100)^\\frac{1}{2} \\\\[6pt]\n&=-20\n\\end{align*}\nHe will now want to play the gamble as it has a greater value than staying with his current loss. The gamble becomes attractive as it allows recovery of the loss. Alby is risk seeking in the loss domain. (He would even accept a 50:50 gamble to win or lose $100 with an expected value of zero.)\nThe choice is illustrated in the following chart. The two possible outcomes, $200 below the reference point and $10 above the reference point, plus their values, are marked. The weighted value of those two possible outcomes is also marked, with the expected value, E of A, projected onto the line between the two outcomes to give V(A)\nIt is visually apparent that V(A) is above the value of a loss of $100, the outcome if Alby does not accept the gamble. As a result, Alby wants to accept the gamble.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -2*(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-220, 220, 0.1),\n  y = u(seq(-220, 220, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1 &lt;- -200 #loss\nx2 &lt;- 10 #win\nev &lt;- -95 #expected value of gamble\nxc &lt;- -100 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-220, 220), ylim = c(-30, 15))+\n\n  #Add labels -200, v(-200) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"-200\", size = 4, hjust = 0.5, vjust = -0.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"v(-200)\", size = 4, hjust = -0.2, vjust = 0.6)+\n\n  #Add labels -100, v(-100) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"-100\", size = 4, hjust = 0.9, vjust = -0.5)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"v(-100)\", size = 4, hjust = -0.2, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels 10, v(10) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"10\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"v(10)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels E[A], V(A) and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[A]\", size = 4, hjust = 0, vjust = -0.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"V(A)\", size = 4, hjust = -0.2, vjust = 0.45)\n\n\n\n\n\nFigure 18.2: A 50:50 gamble after a loss\n\n\n\n\n\n\n\n\n\n\nAccept or reject after adaptation to loss?\nAlby has now adapted to his loss of $100. The new reference point is the new wealth level incorporating the loss wallet. Would he take gamble A now?\nWe are now back to an identical situation as when he was first offered the gamble with his reference point as the status quo. He will not want to partake in the gamble.\n\n\nAccept or reject after a win?\nAlby wins $10,000 at the casino. He feels good about his win, so his reference point remains at his wealth excluding the win. Would he take gamble A now?\nWith the additional $10,000, the value of the gamble is:\n\\begin{align*}\nV(A)&=p_1v(x_1)+p_2v(x_2) \\\\[6pt]\n&=0.5\\times v(10000+110)+0.5\\times v(10000-100) \\\\[6pt]\n&=0.5\\times (10110)^\\frac{1}{2}+0.5\\times (9900)^\\frac{1}{2} \\\\[6pt]\n&=100.02\n\\end{align*}\nThe value of not playing the gamble is:\n\\begin{align*}\nV(\\neg A)&=v(10000) \\\\[6pt]\n&=10000^\\frac{1}{2} \\\\[6pt]\n&=100\n\\end{align*}\nThe gamble is now attractive. Alby is less risk averse at a higher wealth. Further, the gamble is entirely in the gain domain, meaning that loss aversion does not affect the decision.\nThe following chart, not drawn to scale, illustrates. Alby becomes increasingly risk neutral as we move further into the gain domain. You can see this through the value function curve becoming approximately straight. As a result, at a high enough wealth, the positive value bet becomes attractive. V(A) is above the value of the certain outcome, V(10000).\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -2*(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-220, 1000, 0.1),\n  y = u(seq(-220, 1000, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1 &lt;- 560 #loss\nx2 &lt;- 1000 #win\nev &lt;- 800 #expected value of gamble\nxc &lt;- 780 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-220, 1000), ylim = c(-30, 30))+\n\n  #Add labels 9,900, v(9,900) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"9,900\", size = 4, hjust = 0.5, vjust = 1.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"v(9,900)\", size = 4, hjust = 1.05, vjust = 0.6)+\n\n  #Add labels 10,000, v(10,000) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"10,000\", size = 4, hjust = 0.9, vjust = 1.5)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"v(10,000)\", size = 4, hjust = 1.05, vjust = 1.2)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels 10,110, v(10,110) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"10,110\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"v(10,110)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels E[A], V(A) and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[A]\", size = 4, hjust = 0, vjust = 1.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"V(A)\", size = 4, hjust = 1.05, vjust = 0)\n\n\n\n\n\nFigure 18.3: A 50:50 gamble after a win (not to scale)\n\n\n\n\n\n\n\n\n\n\n\n18.1.2 A 60:40 gamble\nPaddy makes decisions in accordance with prospect theory, has wealth $300 and value function:\n\nv(x)=\\left\\{\\begin{matrix}\nx^{\\frac{1}{2}} \\quad &\\textrm{where} \\quad x \\geq 0 \\\\[6pt]\n-2(-x)^{\\frac{1}{2}} \\quad &\\textrm{where} \\quad x &lt; 0\n\\end{matrix}\\right.\n\nAssume Paddy weights probabilities linearly.\nPaddy is offered the following bet A:\n\na 60% probability to win $150\na 40% probability to lose $100.\n\n\nAccept or reject\nDoes Paddy accept bet A?\nPaddy compares the value of taking versus not taking the bet:\n\\begin{align*}\nV(\\text{A})&=p_1v(x_1)+p_2v(x_2) \\\\[6pt]\n&=0.6\\times v(150)+0.4\\times v(-100) \\\\[6pt]\n&=0.6\\times (150)^{\\frac{1}{2}}-0.4\\times 2\\times (100)^{\\frac{1}{2}} \\\\[6pt]\n&=-0.652\n\\end{align*}\nThe value of not taking the bet is zero. Paddy would have no change from his reference point.\nPaddy rejects the bet as V(A) is less than the V(0)=0 that Paddy could get by simply rejecting the bet. He rejects the bet due to his loss aversion and diminishing sensitivity to gains. The loss is weighted double that of an equivalent gain, outweighing both the larger potential gain and 60% probability.\nThe following figure shows Paddy’s value function, the bets and the value of the bets. The figure illustrates that Paddy’s rejection is caused by both Paddy’s loss aversion and his diminishing sensitivity in the gain domain, which has a larger effect than the diminishing sensitivity in the loss domain due to the larger magnitude of the potential gain.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -2*(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-110, 160, 0.1),\n  y = u(seq(-110, 160, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1 &lt;- -100 #loss\nx2 &lt;- 150 #win\nev &lt;- 0.6*150-0.4*100 #expected value of gamble\nxc &lt;- 0 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-110, 160), ylim = c(-25, 15))+\n\n  #Add labels -100, v(-100) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"-100\", size = 4, hjust = 0.5, vjust = -0.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"v(-100)\", size = 4, hjust = -0.1, vjust = 0.45)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels 150, v(150) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"150\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"v(150)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels E[A], V(A) and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[A]\", size = 4, hjust = 0.4, vjust = -0.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"V(A)\", size = 4, hjust = 1.05, vjust = 0.45)\n\n\n\n\n\nFigure 18.4: A 60:40 gamble\n\n\n\n\n\n\n\n\n\n\nAccept or reject after a loss?\nFollowing some bad economic news, Paddy’s wealth declines to $150. Paddy cannot get over the loss, so his reference point remains his former wealth of $300.\nPaddy is offered bet A again. Does Paddy accept the bet?\nAs Paddy is now in the loss domain, the two potential outcomes from the bet are a gain of $0 and a loss of $250. His alternative is remaining at a point $150 below his reference point.\n\nPaddy compares the value of taking versus not taking the bet:\n\\begin{align*}\nV(\\text{A})&=p_1v(x_1)+p_2v(x_2) \\\\[6pt]\n&=0.6\\times v(-150+150)+0.4\\times v(-150-100) \\\\[6pt]\n&=0.6\\times (0)^{\\frac{1}{2}}-0.4\\times 2\\times (250)^{\\frac{1}{2}} \\\\[6pt]\n&=-12.649 \\\\\n\\\\\nV(\\neg\\text{A})&=v(-150) \\\\[6pt]\n&=-2\\times (150)^{\\frac{1}{2}} \\\\[6pt]\n&=-24.495\n\\end{align*}\nPaddy accepts the bet as V(A) is greater than the value of the certain loss of $150.\nThe following figure shows Paddy’s value function, the bets and the value of the bets. The figure shows that Paddy accepts the bet as he is risk seeking in the loss domain. The potential loss of another $100 results in a smaller incremental loss of value than an equivalent win of $100.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -2*(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-260, 100, 0.1),\n  y = u(seq(-260, 100, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1 &lt;- -250 #loss\nx2 &lt;- 0 #win\nev &lt;- -100 #expected value of gamble\nxc &lt;- -150 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-260, 100), ylim = c(-35, 5))+\n\n  #Add labels -250, v(-250) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"-250\", size = 4, hjust = 0.5, vjust = -0.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"v(-250)\", size = 4, hjust = -0.2, vjust = 0.6)+\n\n  #Add labels -150, v(-150) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"-150\", size = 4, hjust = 0.5, vjust = -0.5)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"v(-150)\", size = 4, hjust = -0.2, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels E[A]=-100, V(A) and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[A]=-100\", size = 4, hjust = 0.5, vjust = -0.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"V(A)\", size = 4, hjust = -0.2, vjust = 0.45)\n\n\n\n\n\nFigure 18.5: A 60:40 gamble after a loss\n\n\n\n\n\n\n\n\n\n\n\n18.1.3 A gamble in the gain domain\nSuppose Bill has the following reference-dependent value function:\n\nv(x)=\\left\\{\\begin{matrix}\nx^{1/2} \\qquad &\\textrm{where} &\\space x \\geq 0\\\\\n-2(-x)^{1/2} \\quad &\\textrm{where} &\\space x &lt; 0\n\\end{matrix}\\right.\n\nx is the change in Bill’s position relative to his reference point.\nWhat feature of Bill’s value function leads to the reflection effect?\nThe power of \\frac{1}{2} applied in both the gain and loss domain leads to diminishing sensitivity to gains and losses. The value function is concave in the gain domain and convex in the loss domain. This curvature leads to risk-averse behaviour in the gain domain and risk-seeking behaviour in the loss domain. This change in risk preference between the gain and loss domains is the reflection effect.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -2*(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-220, 220, 0.1),\n  y = u(seq(-220, 220, 0.1))\n)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-220, 220), ylim = c(-30, 15))\n\n\n\n\n\nFigure 18.6: Bill’s value function\n\n\n\n\n\n\n\n\n\nAccept or reject?\nBill considers a choice between $100 for certain and gamble A: (0.5, $250; 0.5, 0).\nWill Bill prefer the $100 or gamble A?\nThe weighted value of gamble A is:\n\\begin{align*}\nV(A)&=p_1v(x_1)+p_2v(x_2) \\\\[6pt]\n&=0.5\\times v(250)+0.5\\times v(0) \\\\[6pt]\n&=0.5 \\times 250^{0.5} + 0.5 \\times 0^{0.5} \\\\[6pt]\n&=7.91\n\\end{align*}\nThe value of the $100 for certain is:\n\\begin{align*}\nV(\\$100)&=v(100)\\\\[6pt]\n&=100^{0.5} \\\\[6pt]\n&=10\n\\end{align*}\nAs V(\\$100)&gt;V(A), Bill will prefer the $100 for certain to the gamble.\nThe possible outcomes from the gamble are zero and $250. The certain outcome on offer is $100. The expected value of the gamble is $125. The outcomes are in the gain domain.\nAs he is risk averse in the gain domain, the value of the $100 for certain exceeds the weighted value of the gamble. This can be seen through v(A) being less than v(\\$100). Bill will therefore choose the $100 for certain.\nThe following chart shows Bill’s choices. Bill rejects the gamble because of the diminishing sensitivity to gains. This leads him to be risk averse and reject the higher expected value option of the gamble.\nAs all possible outcomes under our assumed reference point are in the gain domain, loss aversion does not affect his decision. Note that we do not use the value function for x&lt;0 in determining Bill’s choice.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -2*(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-220, 220, 0.1),\n  y = u(seq(-220, 220, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;-0 #loss\nx2&lt;-200 #win\nev&lt;-100 #expected value of gamble\nxc&lt;-80 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-220, 220), ylim = c(-30, 15))+\n\n  #Add labels W+20, U(W+20) and line to curve indicating each\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n\n  #Add labels 100, U(100) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"100\", size = 4, hjust = 0.6, vjust = 1.5)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"v(100)\", size = 4, hjust = 1.05, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels 250, v(250) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"250\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"v(250)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels E[A], V(A) and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[A]=125\", size = 4, hjust = 0.12, vjust = 1.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"V(A)\", size = 4, hjust = 1.05, vjust = 0.45)\n\n\n\n\n\nFigure 18.7: Bill’s consideration of gamble A and the $100\n\n\n\n\n\n\n\n\n\n\nAccept or reject after a negative shock?\nSuppose Bill were to experience a large negative shock to his wealth that does not immediately change his reference point. Could this shock cause him to change his decision concerning the $100 and gamble A?\nA large negative shock to Bill’s wealth would cause him to change his decision concerning the $100 and gamble A. The shock would move the two possible outcomes into the loss domain, where Bill is risk seeking. (For this answer, I am assuming a shock of greater than $250. A smaller shock would change the analysis.)\nThe following diagram illustrates the outcomes relative to the reference point. Let L be a large negative number, the loss. The potential outcomes from the gamble are now L and L+250. The certain outcome of accepting the $100 is L+100.\n\nThe following diagram illustrates Bill’s decision after the shock. The outcomes L, L+100 and L+250, and their respective values, are marked. The expected value of the gamble is L+125. The weighted value of the gamble is V(L+A).\nDue to the convex curvature of the curve in the loss domain, Bill is risk seeking. As a result, the utility of the gamble is greater than the utility of the certain outcome. This can be seen in V(L+A) being greater than v(L+100).\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -2*(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-220, 220, 0.1),\n  y = u(seq(-220, 220, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;- -200 #loss\nx2&lt;- -20 #win\nev&lt;- -100 #expected value of gamble\nxc&lt;- -120 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-220, 220), ylim = c(-30, 15))+\n\n  #Add labels L, v(L) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"L\", size = 4, hjust = 0.5, vjust = -0.3)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"v(L)\", size = 4, hjust = -0.1, vjust = 0.6)+\n\n  #Add labels L+100, v(L+100) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"L+100\", size = 4, hjust = 0.8, vjust = -0.3)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"v(L+100)\", size = 4, hjust = -0.1, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels 250+L, U(250+L) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"L+250\", size = 4, hjust = 0.5, vjust = -0.3)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"v(L+250)\", size = 4, hjust = -0.1, vjust = 0.45)+\n\n  #Add labels L+E[A], v(A+L) and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"L+E[A]\", size = 4, hjust = 0.1, vjust = -0.3)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"V(L+A)\", size = 4, hjust = -0.1, vjust = 0.45)\n\n\n\n\n\nFigure 18.8: Bill’s consideration of gamble A and the $100 after the shock",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Prospect theory examples</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-examples.html#insurance",
    "href": "prospect-theory/prospect-theory-examples.html#insurance",
    "title": "18  Prospect theory examples",
    "section": "18.2 Insurance",
    "text": "18.2 Insurance\n\nSummary\n\nClassical economic theory explains insurance purchase through risk aversion, while prospect theory offers an alternative explanation involving risk-seeking behaviour in the loss domain and overweighting of small probabilities.\nA risk-neutral agent would not purchase insurance due to its negative expected value, but a risk-averse agent with a logarithmic utility function may buy insurance due to diminishing marginal utility.\nProspect theory’s reflection effect suggests people are risk-seeking in the loss domain, which alone would predict that people wouldn’t buy insurance, as it involves choosing between a certain loss (premium) and a potentially larger loss.\nProbability weighting in prospect theory suggests that people overweight small probabilities and underweight probabilities near certainty, which can make insurance attractive despite being in the loss domain.\nThe combination of a convex value function in the loss domain and overweighting of small probabilities can lead to insurance purchase under prospect theory, even when the reflection effect alone would suggest avoiding insurance.\n\n\n\n\n\n\n18.2.1 Introduction\nInsurance has a negative expected value due to the insurer’s profit and administrative costs. Why would a consumer purchase insurance?\nThe classical economic explanation for the purchase of insurance is based on diminishing marginal utility, which leads to risk aversion. Consumers are willing to buy insurance as the consumer prefers the certainty of the premium payment to the risk of suffering an uninsured loss.\nProspect theory provides an alternative explanation. The purchase of insurance involves a certain loss (the premium) or a gamble involving the possibility of either a large loss or the status quo. As prospect theory has people as risk seeking in the loss domain, we would not expect them to purchase insurance.\nHowever, under prospect theory, people also overweight small probabilities. This overweighting of small probabilities can make the purchase of insurance attractive even though it is in the loss domain.\nThis combination of the loss domain with a small probability is the bottom-right quadrant of the fourfold pattern to risk attitudes generated by prospect theory. People tend to be risk averse in this circumstance.\n\n\n\n\nGains\nLosses\n\n\n\n\nHigh probability\nRisk aversion\nRisk seeking\n\n\nLow probability\nRisk seeking\nRisk aversion\n\n\n\nThe following numerical example is an illustration.\nAn agent is considering insurance against bushfire for their house valued at H= $1 000 000. The house has a 1 in 1000 (p= 0.001) chance of burning down. An insurer is willing to offer full coverage for a premium (R) of $1100. (Note: $1000 is the actuarially fair price. The additional $100 might represent profit or administrative costs.)\n\n\n18.2.2 Expected value\nThe first question I will consider is whether a risk-neutral person would purchase the insurance. A risk-neutral utility function is:\n\nu(x)=x\n\nA risk-neutral agent will choose the option with the highest expected value.\nIf the agent purchases insurance, they pay the premium and do not suffer any loss regardless of whether there is a bushfire or not. Therefore, the expected value of purchasing insurance is the loss of the premium:\n\\begin{align*}\n\\mathbb{E}[\\text{I}]&=-R \\\\[6pt]\n&=-\\$1100\n\\end{align*}\nThe expected value of purchasing insurance is the guaranteed loss of the premium, $1100.\nIf the agent does not purchase insurance, they face the 1 in 1000 possibility of an uninsured loss. Therefore, the expected value of not purchasing insurance is the probability of loss times the value of the house:\n\\begin{align*}\n\\mathbb{E}[\\neg \\text{I}]&=p\\times(-H) \\\\[6pt]\n&=-0.001\\times 1\\,000\\,000 \\\\[6pt]\n&=-\\$1000\n\\end{align*}\nThe expected value of purchasing insurance is lower than the expected value of not purchasing insurance. Therefore, a risk-neutral agent would not purchase the insurance.\n\n\n18.2.3 Expected utility\nWould a risk-averse agent purchase the insurance? Suppose they have a logarithmic utility function (u(x)=\\ln(x)) and they have $10 000 in cash in addition to their house, giving them wealth (W) of $1 010 000.\nThe logarithmic utility function has diminishing marginal utility. Diminishing marginal utility is the principle that the marginal utility from each additional unit decreases. In the context of wealth, this means that each additional dollar provides less satisfaction than the previous one.\nDiminishing marginal utility means that the agent will be risk averse. They will prefer a certain outcome to a gamble with the same expected value.\nTo understand whether this risk-averse agent will purchase insurance in this instance, we need to compare the expected utility of purchasing insurance with the expected utility of not purchasing insurance.\nThe expected utility of purchasing insurance is the utility of the certain outcome, which is the utility of wealth after paying the premium:\n\\begin{align*}\n\\mathbb{E}[U(\\text{I})]&=u(W-R) \\\\[6pt]\n&=\\ln(1\\,010\\,000-1100) \\\\[6pt]\n&=13.8244\n\\end{align*}\nThe expected utility of not purchasing insurance is the probability-weighted sum of the utility of the two potential outcomes, the utility of wealth after losing the house and the utility of wealth if the house does not burn down:\n\\begin{align*}\n\\mathbb{E}[U(\\neg \\text{I})]&=p\\times u(W-H)+(1-p)\\times u(W) \\\\[6pt]\n&=0.001\\times \\ln(1\\,010\\,000-1\\,000\\,000)+0.999\\times \\ln(1\\,010\\,000) \\\\[6pt]\n&=13.8208\n\\end{align*}\nThe expected utility of purchasing insurance is greater than the expected utility of not purchasing insurance. This agent will purchase insurance.\nThe following diagrams illustrate. First I plot the agent’s utility function. The utility function is concave as the agent is risk averse. Each additional unit of wealth provides less utility than the previous unit.\n\n\nCode\nlibrary(ggplot2)\nlibrary(latex2exp)\n\nu &lt;- function(x){\n  log(x)\n}\n\ndf &lt;- data.frame(\n  x=seq(1,100,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;-3 #loss\nx2&lt;-90 #win\nev&lt;-77 #expected value of gamble\nxc&lt;-70 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\ninsurance_eu_1 &lt;- ggplot(mapping = aes(x, y)) +\n    geom_line(data = df) +\n    geom_vline(xintercept = 0, linewidth=0.25)+ \n    geom_hline(yintercept = 0, linewidth=0.25)+\n    labs(x = \"x\", y = \"U(x)\")+\n\n    # Set the theme\n    theme_minimal()+\n\n    #remove numbers on each axis\n    theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n    #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n    coord_cartesian(xlim = c(-8, 100), ylim = c(0, 5))\n\ninsurance_eu_1\n\n\n\n\n\nFigure 18.9: The utility function of a risk-averse agent\n\n\n\n\n\n\n\n\nI then mark each possible outcome from purchasing or not purchasing insurance on the horizontal axis and the utility of each of those outcomes on the vertical axis. These are: wealth after losing the house when uninsured (W-H), wealth after paying the insurance premium (W-R), and wealth if uninsured but the house does not burn down (W). I have not drawn this to scale.\n\n\nCode\nlibrary(ggplot2)\nlibrary(latex2exp)\n\nu &lt;- function(x){\n  log(x)\n}\n\ndf &lt;- data.frame(\n  x=seq(1,100,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;-3 #loss\nx2&lt;-90 #win\nev&lt;-77 #expected value of gamble\nxc&lt;-70 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\ninsurance_eu_2 &lt;- insurance_eu_1 +\n\n    #Add labels W, U(W) and line to curve indicating each\n    annotate(\"text\", x = x2, y = 0, label = \"W\", size = 4, hjust = 0.4, vjust = 1.5)+\n    annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n    annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n    annotate(\"text\", x = 0, y = u(x2), label = \"U(W)\", size = 4, hjust = 1.1, vjust = 0.4)+\n\n    #Add labels W-R, U(W_R) and line to curve indicating each\n    annotate(\"text\", x = xc, y = 0, label = \"W-R\", size = 4, hjust = 0.5, vjust = 1.5)+\n    annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n    annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n    annotate(\"text\", x = 0, y = u(xc), label = \"U(W-R)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n    #Add labels W-H, U(W-H) and line to curve indicating each\n    annotate(\"text\", x = x1, y = 0, label = \"W-H\", size = 4, hjust = 0.4, vjust = 1.5)+\n    annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n    annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n    annotate(\"text\", x = 0, y = u(x1), label = \"U(W-H)\", size = 4, hjust = 1.05, vjust = 0.45)\n\ninsurance_eu_2\n\n\n\n\n\nFigure 18.10: The utility of the outcomes of purchasing insurance and not purchasing insurance\n\n\n\n\n\n\n\n\nThe expected utility of not purchasing insurance is the probability-weighted sum of the utility of the two potential outcomes, the utility of wealth after losing the house and the utility of wealth if the house does not burn down. I can show this on the diagram by plotting a dash-dot line between U(W-H) and U(W). The expected utility of not purchasing insurance will be on this line.\n\n\nCode\nlibrary(ggplot2)\nlibrary(latex2exp)\n\nu &lt;- function(x){\n  log(x)\n}\n\ndf &lt;- data.frame(\n  x=seq(1,100,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;-3 #loss\nx2&lt;-90 #win\nev&lt;-77 #expected value of gamble\nxc&lt;-70 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\ninsurance_eu_3 &lt;- insurance_eu_2 +\n\n    #Add expected utility line\n    annotate(\"segment\", x = x2, xend = x1, y = u(x2), yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")\n\ninsurance_eu_3\n\n\n\n\n\nFigure 18.11: The expected utility line\n\n\n\n\n\n\n\n\nThe location of the expected utility is determined by the probability p of incurring a loss. This point lies at a distance of p from U(W) along the line (or equivalently, at a distance of 1-p from U(W-H)). This point aligns with the expected value of leaving the house uninsured \\mathbb{E}[\\neg \\text{I}].\nThe utility of purchasing insurance, U(W-R), is greater than the expected utility of not purchasing insurance, \\mathbb{E}[U(\\neg \\text{I})]. We can see this as U(W-R) is above \\mathbb{E}[U(\\neg \\text{I})] on the diagram. This risk-averse agent will purchase insurance.\n\n\nCode\nlibrary(ggplot2)\nlibrary(latex2exp)\n\nu &lt;- function(x){\n  log(x)\n}\n\ndf &lt;- data.frame(\n  x=seq(1,100,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;-3 #loss\nx2&lt;-90 #win\nev&lt;-77 #expected value of gamble\nxc&lt;-70 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\ninsurance_eu_4 &lt;- insurance_eu_3 +\n\n    #Add labels E[not I], E[U(not I)] and curve indicating each\n    annotate(\"text\", x = ev, y = 0, label = TeX(\"E[$\\\\neg$ I]\", output='character'), parse=TRUE, size = 4, hjust = 0.4, vjust = 1.4)+\n    annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n    annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n    annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = TeX(\"E[U($\\\\neg$ I)]\", output='character'), parse=TRUE, size = 4, hjust = 1.05, vjust = 0.45)\n\ninsurance_eu_4\n\n\n\n\n\nFigure 18.12: The expected utility of purchasing insurance and not purchasing insurance\n\n\n\n\n\n\n\n\n\n\n18.2.4 The reflection effect\nI will now move on to the elements of prospect theory, introducing them one at a time. The first element is the reflection effect.\nConsider an agent who is risk seeking in the domain of losses but weights probability linearly. Their value function is:\n\nv(x)=\\left\\{\\begin{matrix}\nx^{0.8} \\qquad &\\textrm{where} \\space x \\geq 0\\\\[6pt]\n-2(-x)^{0.8} \\quad &\\textrm{where} \\space x &lt; 0\n\\end{matrix}\\right.\n\nx is the realised outcome relative to the reference point.\nThe reflection effect occurs as this value function is concave in the gain domain and convex in the loss domain. This leads to risk averse and risk seeking behaviour, respectively.\nIn this analysis, we will take the reference point as current wealth before the purchase of the insurance. Determination of the reference point can be arbitrary. What if you pay insurance every year? Would the reference point then be wealth minus the insurance payment, meaning the insurance payment is in the gain domain? In that case, the analysis changes.\nWe can see the outcomes for an agent with a reference point of wealth before purchasing insurance on the following line (not drawn to scale). The outcomes are the premium payment -R and the value of the house after a bushfire -H. If uninsured and no fire, the agent will remain at their reference point of the status quo.\n\nWould this agent with the reflection effect and a reference point of wealth before purchasing the insurance make the purchase?\nWe need to compare the weighted value of purchasing insurance with the weighted value of not purchasing insurance. The agent will purchase insurance if the weighted value of purchasing insurance is greater.\nThe weighted value of purchasing insurance is the value of the certain outcome, which is the loss of the premium:\n\\begin{align*}\nV(\\text{I})&=v(-R) \\\\[6pt]\n&=-(1100)^{0.8} \\\\[6pt]\n&=-271.1\n\\end{align*}\nThe weighted value of not purchasing insurance is the probability-weighted sum of the value of the two potential outcomes, the value of wealth after losing the house and the value of wealth if the house does not burn down:\n\\begin{align*}\nV(\\neg\\text{I})&=\\sum_{i=1}^n p_iv(x_i) \\\\[6pt]\n&=p\\times v(-H)+(1-p)\\times v(0) \\\\[6pt]\n&=-0.001\\times (1 000 000)^{0.8}+0.999\\times 0 \\\\[6pt]\n&=-63.1\n\\end{align*}\nAs the value of purchasing insurance is less than the weighted value of not purchasing insurance, that is, V(\\text{I})&lt;V(\\neg\\text{I}), this agent does not purchase insurance. The diminishing feeling of loss leads to them weigh the certain loss of the premium relatively more heavily than the chance of losing the value of their house.\nIncluding loss aversion in the value function does not change the decision as all possible outcomes are in the loss domain.\nThe following diagrams illustrate. First I plot the agent’s value function. The value function is concave in the gain domain and convex in the loss domain, leading to risk averse and risk-seeking behaviour, respectively. Each additional gain or loss of a unit of wealth relative to the reference point results in a smaller change in value than the previous unit. There is diminishing sensitivity to both gains and losses.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -2*(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-220, 220, 0.1),\n  y = u(seq(-220, 220, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;- -200 #loss\nx2&lt;- 0 #win\nev&lt;- -30 #expected value of gamble\nxc&lt;- -60 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-220, 220), ylim = c(-30, 15))\n\n\n\n\n\nFigure 18.13: A value function with the reflection effect\n\n\n\n\n\n\n\n\nEach outcome and the value of that outcome from purchasing or not purchasing insurance is marked on the horizontal axis and the value of those outcomes on the vertical axis. These are: the premium payment -R and the outcome after a bushfire -H. If uninsured and no fire, the agent will remain at their reference point of the status quo.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -2*(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-220, 220, 0.1),\n  y = u(seq(-220, 220, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;- -200 #loss\nx2&lt;- 0 #win\nev&lt;- -30 #expected value of gamble\nxc&lt;- -60 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-220, 220), ylim = c(-30, 15))+\n\n  #Add labels -H, v(L) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"-H\", size = 4, hjust = 0.5, vjust = -0.3)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"v(-H)\", size = 4, hjust = -0.1, vjust = 0.6)+\n\n  #Add labels -R, v(-R) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"-R\", size = 4, hjust = 0.8, vjust = -0.3)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"v(-R)\", size = 4, hjust = -0.1, vjust = 0.3)\n\n\n\n\n\nFigure 18.14: The value of the outcomes of purchasing insurance and not purchasing insurance\n\n\n\n\n\n\n\n\nThe weighted value of not purchasing insurance is the probability-weighted sum of the value of the two potential outcomes, the value of wealth after losing the house and the reference point. I can show this on the diagram by plotting a dash-dot line between v(-H) and v(0). The weighted value of not purchasing insurance will be on this line.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -2*(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-220, 220, 0.1),\n  y = u(seq(-220, 220, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;- -200 #loss\nx2&lt;- 0 #win\nev&lt;- -30 #expected value of gamble\nxc&lt;- -60 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-220, 220), ylim = c(-30, 15))+\n\n  #Add labels -H, v(L) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"-H\", size = 4, hjust = 0.5, vjust = -0.3)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"v(-H)\", size = 4, hjust = -0.1, vjust = 0.6)+\n\n  #Add labels -R, v(-R) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"-R\", size = 4, hjust = 0.8, vjust = -0.3)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"v(-R)\", size = 4, hjust = -0.1, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")\n\n\n\n\n\nFigure 18.15: The weighted value line\n\n\n\n\n\n\n\n\nThe location of this point is determined by the probability p of incurring a loss. This point lies at a distance of p from v(0) along the line (or equivalently, at a distance of 1-p from v(-H)). This point aligns with the expected value of leaving the house uninsured \\mathbb{E}[\\neg I].\nThe value of purchasing insurance, v(-R), is less than the weighted value of not purchasing insurance, V(\\neg I). The agent will not purchase insurance. They are risk seeking in this loss domain.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -2*(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-220, 220, 0.1),\n  y = u(seq(-220, 220, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;- -200 #loss\nx2&lt;- 0 #win\nev&lt;- -30 #expected value of gamble\nxc&lt;- -60 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-220, 220), ylim = c(-30, 15))+\n\n  #Add labels -H, v(L) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"-H\", size = 4, hjust = 0.5, vjust = -0.3)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"v(-H)\", size = 4, hjust = -0.1, vjust = 0.6)+\n\n  #Add labels -R, v(-R) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"-R\", size = 4, hjust = 0.8, vjust = -0.3)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"v(-R)\", size = 4, hjust = -0.1, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels E[\\neg I], V(\\neg I) and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = as.character(TeX(\"E[$\\\\neg$ I]\")), size = 4, hjust = 0.5, vjust = -0.3, parse=TRUE)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = as.character(TeX(\"V($\\\\neg$ I)\")), size = 4, hjust = -0.1, vjust = 0.45, parse=TRUE)\n\n\n\n\n\nFigure 18.16: The reflection effect and insurance\n\n\n\n\n\n\n\n\n\n\n18.2.5 Probability weighting\nWould a person who is risk seeking in the domain of losses (that is, a person with a value function with reflection effect discussed earlier) who weights probability in accordance with prospect theory purchase the insurance?\nProspect theory proposes that people overweight small probabilities. They might weight probabilities as per the following table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbability (p)\n0.001\n0.01\n0.1\n0.25\n0.5\n0.75\n0.9\n0.99\n0.999\n\n\nWeight \\pi(p)\n0.01\n0.05\n0.15\n0.3\n0.5\n0.7\n0.85\n0.95\n0.99\n\n\n\nThat is, an outcome with a probability of p=0.001 is given a weight \\pi(p) of 0.01, ten times what its probability would suggest. An outcome with a probability of p=0.01 is given a weight \\pi(p) of 0.05, five times the weight.\nSimilarly, a probability of p=0.99 is given a weight \\pi(p) of 0.95 and a probability of p=0.999 is given a weight \\pi(p) of 0.99, implying that probabilities near certainty are underweighted relative to certainty itself.\nTo assess whether this person will purchase insurance, we need to compare the weighted value of purchasing insurance with the weighted value of not purchasing insurance. They will purchase insurance if the weighted value of purchasing insurance is greater.\nThe weighted value of purchasing insurance is the value of the certain outcome, which is the loss of the premium:\n\\begin{align*}\nV(\\text{I})&=v(-R) \\\\[6pt]\n&=-(1,100)^{0.8} \\\\[6pt]\n&=-271.1 \\\\\n\\end{align*}\nThe weighted value of not purchasing insurance is the weighted sum of the value of the two potential outcomes, with the weights from the table above:\n\\begin{align*}\nV(\\neg\\text{I})&=\\sum_{i=1}^n \\pi(p_i)v(x_i) \\\\[6pt]\n&=\\pi(p)\\times v(0)+\\pi(1-p)\\times v(-H) \\\\[6pt]\n&=\\pi(0.001)\\times v(-1\\,000\\,000)+\\pi(0.999)\\times v(0) \\\\[6pt]\n&=-0.01\\times (1\\,000\\,000)^{0.8}+0.99\\times 0 \\\\[6pt]\n&=-631\n\\end{align*}\nAs the value of purchasing insurance is greater than the value of not purchasing insurance, that is, V(\\text{I})&gt;V(\\neg\\text{I}), this person purchases insurance.\nAlthough the diminishing feeling of loss leads to them weigh the certain loss of the premium relatively more heavily than the chance of losing the value of their house, the overweighting of the probability of fire leads them to purchase insurance. Again, if we had included loss aversion, it would not have changed the decision, as all possible outcomes are in the loss domain.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Prospect theory examples</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-examples.html#a-multi-bet",
    "href": "prospect-theory/prospect-theory-examples.html#a-multi-bet",
    "title": "18  Prospect theory examples",
    "section": "18.3 A multi-bet",
    "text": "18.3 A multi-bet\nA multi-bet allows a gambler to combine a series of individual bets into a single wager, with the odds of all the single bets multiplied to achieve the final payoff. The gambler only wins the wager if all of the single bets are successful. Or in other words, if a single bet is lost, the entire multi-bet is lost. A multi-bet is also known as an “accumulator” bet or “parlay”.\nFor example, a multi-bet might combine the following bets:\n\nGWS Giants to defeat Adelaide Crows: $1.65 (that is, $1.65 is paid out for each $1 bet)\nFremantle Dockers to defeat Sydney Swans: $2.10\nEssendon Bombers to defeat Geelong Cats: $3.50\nNorth Melbourne Kangaroos to defeat Melbourne Demons: $4.00\nWest Coast Eagles to defeat Brisbane Lions: $6.00\n\nIf all five bets are successful, the gambler would win $291 for every $1 they have bet. (That is 1.65 x 2.10 x 3.50 x 4 x 6 = 291.06). If any of GWS, Fremantle, Essendon, North Melbourne, or the West Coast Eagles lose, the bet is lost.\nMany bookmakers also offer a “cash out” option for multi-bets. If the bet has been successful up to the date of the “cash out”, a gambler can “cash out” their bet before the remaining games are complete at a price offered by the bookmaker. The “cash out” offers are typically unattractive relative to the expected value of seeing out the rest of the multi-bet.\nFor example, Betty places a $20 multi-bet involving all nine games of Australian Rules Football one weekend. After eight games, she has picked all eight winners. If Geelong defeats North Melbourne in the ninth game she will win $10,000. Geelong is a heavy favourite, with a 95% probability of winning.\nBetty checks the cash out price for the multi-bet and sees that she can cash out the bet now for $7,000, a great return on her initial $20. That return, however, is much below the expected value of seeing the multi-bet through to the end ($9,500).\nBetty makes decisions according to prospect theory. That is, she judges gains and losses relative to a reference point, is loss averse, and has diminishing sensitivity to gains and losses in both directions. She also overweights certainty (which is equivalent to overweighting small probabilities).\nWhat elements of prospect theory might lead Betty to cash out the bet before the final game?\nWe can consider multiple potential reference points Betty might use to make her decision.\nOne potential reference point is Betty’s position before making the bet. In that case, Betty is comparing:\n\na certain gain of $6980 and\na gamble with a loss of $20 and a gain of $9,980.\n\nThe gamble is largely in the gain domain in which Betty is risk averse. Her risk aversion may lead her to cash out rather than take the gamble. The potential $20 loss may be overweighted due to loss aversion, but it is a relatively insignificant sum.\nAnother potential reference point is Betty’s position immediately after making the bet. She has adapted to the payment of $20. Here the analysis is similar. Betty is comparing:\n\na certain gain of $7000 and\na gamble with a gain of $10,000 or a payment of zero\n\nThe gamble is completely in the gain domain, where Betty is risk averse. Her risk aversion may lead her to cash out rather than gamble. Loss aversion is irrelevant in this instance.\nAnother potential reference point is that Betty is taking the $7000 to be locked in. This means she is comparing:\n\nstaying at the status quo with certainty and\na gamble involving a potential loss of $7000 and a gain of $3,000.\n\nIn this case, the combination of risk aversion reducing the value of the gain and loss aversion increasing the relative magnitude of the pain of loss could lead her to cash out. This would be counteracted by the convex curvature in the loss domain, but the loss aversion effect would likely dominate.\nFinally, Betty’s weighting of probabilities will also affect her decision. Overweighting certainty means overweighting small probabilities, such as the small probability of Geelong losing. This overweighting would push her towards cashing out as the loss would have greater weight in her calculation of the weighted value of each option.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Prospect theory examples</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-applications.html",
    "href": "prospect-theory/prospect-theory-applications.html",
    "title": "19  Prospect theory applications",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Prospect theory applications</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-applications.html#summary",
    "href": "prospect-theory/prospect-theory-applications.html#summary",
    "title": "19  Prospect theory applications",
    "section": "",
    "text": "Prospect theory can explain various real-world economic behaviours that deviate from traditional economic models, as illustrated by studies on taxi drivers, investors, and homeowners.\nSome studies on taxi driver behaviour on rainy days suggest that drivers may have a daily earnings target (reference point), and their decisions reflect loss aversion and diminishing sensitivity to gains, key elements of prospect theory.\nThe disposition effect in investing, where investors tend to sell winning stocks and hold losing ones, can be explained by prospect theory’s reflection effect.\nIn the housing market, owners subject to nominal losses tend to set higher asking prices, potentially due to loss aversion.\nHowever, follow-up studies and alternative explanations demonstrate that the application of prospect theory to these scenarios is not without controversy, and results can vary based on methodology and data interpretation.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Prospect theory applications</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-applications.html#introduction",
    "href": "prospect-theory/prospect-theory-applications.html#introduction",
    "title": "19  Prospect theory applications",
    "section": "19.1 Introduction",
    "text": "19.1 Introduction\nIn this part, I discuss some applied problems that have been analysed using prospect theory.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Prospect theory applications</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-applications.html#taxi-driver-behaviour-on-rainy-days",
    "href": "prospect-theory/prospect-theory-applications.html#taxi-driver-behaviour-on-rainy-days",
    "title": "19  Prospect theory applications",
    "section": "19.2 Taxi driver behaviour on rainy days",
    "text": "19.2 Taxi driver behaviour on rainy days\nWhy can’t you find a taxi on a rainy day?\nOne possible explanation comes from Colin Camerer et al. (1997), who studied the labour supply of New York City taxi drivers.\nThe taxi drivers rent a cab for a 12-hour period for a fixed fee, plus petrol. Within the 12 hours, a driver can choose how long they keep the taxi out.\nA taxi driver’s effective wage can vary for many reasons, such as weather, subway breakdowns, day of the week and conferences. When they are busier, they have a higher effective wage. That is, they earn more fares.\nIn two of the three samples they examined, Camerer et al. found that drivers drove less when their effective wages were higher. This was the case for inexperienced drivers in all three samples, and they drove significantly less than experienced drivers when wages were high.\nThis contrasts with the basic prediction of economic theory that supply increases with price. Supply curves slope upwards.\nCamerer et al. argue that this result is because taxi drivers have a daily earnings target, beyond which they derive little additional utility. This leads them to work until they reach their target, which occurs more quickly on days with a higher wage.\nThey argued that the drivers engage in “narrow bracketing” when they make decisions each day, isolating them as single decisions (how much should I work today?) rather than thinking about them as a stream (how much should I work each day this week?)\nAversion to falling below the reference point is consistent with loss aversion, with a result below the reference point causing stronger feelings than a result a similar amount above the reference point.\nThere have been numerous follow-up studies of taxi drivers. The results of these studies have varied.\n\nFarber (2005) studied New York cab drivers and found that the decision to stop work was primarily a function of how many hours had been worked up to that point in the day. He identified the difference between his and Camerer et al.’s result as being due to different empirical methods and measurement problems with the Camerer et al. data.\nFarber (2008) found that a labour supply model with reference-dependent targets better fits than a standard neoclassical model. However, there was substantial variation day-to-day in any given driver’s reference income level and most shifts ended before that reference income was reached.\nFarber (2015) used a much larger dataset on New York taxi driver behaviour and found that, as standard economic theory would predict, taxi drivers drive more when they can earn more. Farber also found that drivers did not earn more when it was raining.\nFinally, Martin (2017) examined taxi driver labour supply using the S-shaped reference dependence of prospect theory. That is, Martin used a model with the reflection effect, with risk-seeking behaviour in the loss domain and risk aversion in the gain domain. Martin found evidence that taxi driver behaviour was consistent with this full form of prospect theory. He differentiated from the other papers on the basis that they considered a narrower version of reference dependence focusing on loss aversion only.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Prospect theory applications</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-applications.html#the-disposition-effect",
    "href": "prospect-theory/prospect-theory-applications.html#the-disposition-effect",
    "title": "19  Prospect theory applications",
    "section": "19.3 The disposition effect",
    "text": "19.3 The disposition effect\nThe disposition effect is the tendency for investors to sell stocks that are in the gain domain relative to the purchase price and to hold stocks that are in the loss domain.\nWhile tax implications or portfolio rebalancing are both potential explanations for asymmetric behaviour relating to the sale of stocks, these factors are insufficient to explain the observed behaviour.\nMost behavioural explanations have turned to prospect theory.\nFor example, Shefrin and Statman (1985) argued that the disposition effect is driven by the reflection effect, whereby investors are risk seeking in the loss domain and risk averse in the gain domain. To demonstrate how it works, they present the following scenario:\n\n[C]onsider an investor who purchased a stock one month ago for $50 and who finds that the stock is now selling at $40. The investor must now decide whether to realize the loss or hold the stock for one more period. To simplify the discussion, assume that there are no taxes or transaction costs. In addition, suppose that one of two equiprobable outcomes will emerge during the coming period: either the stock will increase in price by $10 or decrease in price by $10. According to prospect theory, our investor frames his choice as a choice between the following two lotteries:\nA. Sell the stock now, thereby realizing what had been a $10 “paper loss”.\nB. Hold the stock for one more period, given 50-50 odds between losing an additional $10 or “breaking even.”\n\nFor an investor who is risk seeking in the loss domain, holding would be attractive. The following figure illustrates that the certain loss of $10 (from the reference point of $50) gives lower value than holding for a chance of eliminating the loss.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-25, 25, 0.1),\n  y = u(seq(-25, 25, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;- -20 #loss\nx2&lt;- 0 #win\nev&lt;- -10 #expected value of gamble\nxc&lt;- -10 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-25, 25), ylim = c(-5, 5))+\n\n  #Add labels -10, v(sell) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"-10\", size = 4, hjust = 0.6, vjust = -0.5)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"v(sell)\", size = 4, hjust = -0.1, vjust = 0.3)+\n\n  #Add labels -20, v(-20) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"-20\", size = 4, hjust = 0.5, vjust = -0.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"v(-20)\", size = 4, hjust = -0.1, vjust = 0.6)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels v(hold) and curve indicating position\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"v(hold)\", size = 4, hjust = -0.1, vjust = 0.45)\n\n\n\n\n\nFigure 19.1: The disposition effect in the loss domain\n\n\n\n\n\n\n\n\nIf we craft an alternative scenario where the stock is now selling at $60, selling would realise a $10 gain, while holding the stock would be a risky prospect with the same expected value. An investor who is risk averse in the gain domain will sell.\nThe following figure illustrates that the certain gain of $10 (from the reference point of $50) gives higher value than holding for a chance of a larger gain.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-25, 25, 0.1),\n  y = u(seq(-25, 25, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;-0 #loss\nx2&lt;-20 #win\nev&lt;-10 #expected value of gamble\nxc&lt;-10 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-25, 25), ylim = c(-5, 5))+\n\n  #Add labels 10, v(sell) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"10\", size = 4, hjust = 0.6, vjust = 1.5)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"v(sell)\", size = 4, hjust = 1.05, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels 20, v(20) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"20\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"v(20)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels v(hold) and curve indicating position\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"v(hold)\", size = 4, hjust = 1.05, vjust = 0.45)\n\n\n\n\n\nFigure 19.2: The disposition effect in the gain domain",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Prospect theory applications</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-applications.html#the-housing-market",
    "href": "prospect-theory/prospect-theory-applications.html#the-housing-market",
    "title": "19  Prospect theory applications",
    "section": "19.4 The housing market",
    "text": "19.4 The housing market\nGenesove and Mayer (2001) examined housing data from Boston. They found that owners subject to nominal losses set higher asking prices, with the increase in asking price being 25% to 35% of the difference between the expected selling price and their original purchase price.\nThey also found that these owners attain higher prices, covering around 3% to 18% of that difference.\nThis suggests sellers are averse to realising nominal losses. However, note that the aversion leads to a better outcome.\n\n\n\n\nCamerer, C., Babcock, L., Loewenstein, G., and Thaler, R. (1997). Labor supply of new york city cabdrivers: One day at a time*. The Quarterly Journal of Economics, 112(2), 407–441. https://doi.org/10.1162/003355397555244\n\n\nFarber, H. S. (2005). Is tomorrow another day? The labor supply of new york city cabdrivers. Journal of Political Economy, 113(1), 46–82. https://doi.org/10.1086/426040\n\n\nFarber, H. S. (2008). Reference-Dependent Preferences and Labor Supply: The Case of New York City Taxi Drivers. American Economic Review, 98(3), 1069–1082. https://doi.org/10.1257/aer.98.3.1069\n\n\nFarber, H. S. (2015). Why you can’t find a taxi in the rain and other labor supply lessons from cab drivers. The Quarterly Journal of Economics, 130(4), 1975–2026. https://doi.org/10.1093/qje/qjv026\n\n\nGenesove, D., and Mayer, C. (2001). Loss aversion and seller behavior: Evidence from the housing market. The Quarterly Journal of Economics, 116(4), 1233–1260. https://www.jstor.org/stable/2696458\n\n\nMartin, V. (2017). When to quit: Narrow bracketing and reference dependence in taxi drivers. Journal of Economic Behavior & Organization, 144, 166–187. https://doi.org/10.1016/j.jebo.2017.09.024\n\n\nShefrin, H., and Statman, M. (1985). The Disposition to Sell Winners Too Early and Ride Losers Too Long: Theory and Evidence. The Journal of Finance, 40(3), 777–790. https://doi.org/10.1111/j.1540-6261.1985.tb05002.x",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Prospect theory applications</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-exercises.html",
    "href": "prospect-theory/prospect-theory-exercises.html",
    "title": "20  Prospect theory exercises",
    "section": "",
    "text": "20.1 Changes in probability\nYou are in a draw for $1 million. Consider the following four scenarios where your chances of winning increases by 5%:\nMost people report that scenarios A) and D) represent better news. Why?",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Prospect theory exercises</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-exercises.html#changes-in-probability",
    "href": "prospect-theory/prospect-theory-exercises.html#changes-in-probability",
    "title": "20  Prospect theory exercises",
    "section": "",
    "text": "From 0% to 5%\nFrom 5% to 10%\nFrom 50% to 55%\nFrom 95% to 100%\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere is strong experimental evidence that we overweight certain events relative to near certain events. In this instance, we will tend to overweight the shift to a certain result (scenario D) relative to shifts involving intermediate probabilities (e.g. scenario B and C). This overweighting of certainty is effectively the same as overweighting low probability events. As a result, the probability shift that provides an initial chance at $1 million is also overweighted (scenario A).\nThe result is that scenarios A and D tend to be seen as better news than scenarios B and C.\nThe following diagram illustrates. On the horizontal axis is the probability (p). On the vertical axis is the decision weight applied to each probability (\\pi). If people applied probability weights linearly as they do in expected utility theory, the dashed line would represent how probabilities map to weights. Under prospect theory, people overweight small probabilities and underweight probabilities short of certainty. The solid line represents one functional mapping of these possibility and certainty effects.\nFrom this diagram, you can then see the change in decision weight from each change in probability. The changes from 0% to 5% and from 95% to 100% represent much larger changes in decision weight than the changes in intermediate probabilities.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Prospect theory exercises</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-exercises.html#bitcoin",
    "href": "prospect-theory/prospect-theory-exercises.html#bitcoin",
    "title": "20  Prospect theory exercises",
    "section": "20.2 Bitcoin",
    "text": "20.2 Bitcoin\nEdna, Ferdinand and Gretel each bought some Bitcoin at $50,000. The price rose to $80,000 and then dropped to $60,000, at which time they sold it.\nAll three are loss averse and have the following reference-dependent value function:\n\nv(x)=\\left\\{\\begin{matrix}\nx \\quad &\\textrm{where} \\quad x \\geq 0\\\\\n2x \\quad &\\textrm{where} \\quad x &lt; 0\n\\end{matrix}\\right.\n\nEdna uses the purchase price as her reference point. Ferdinand uses the peak price as his reference point. Gretel uses the sale price as her reference point.\nWhat is the change in value for each person? Who is happiest?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nValue for Edna:\n\\begin{align*}\nv(x)&=v(60-50) \\\\[6pt]\n&=10\n\\end{align*}\nValue for Ferdinand:\n\\begin{align*}\nv(x)&=v(60-80) \\\\[6pt]\n&=-2\\times 20 \\\\[6pt]\n&=-40\n\\end{align*}\nValue for Gretel:\n\\begin{align*}\nv(x)&=v(60-60) \\\\[6pt]\n&=0\n\\end{align*}\nEdna is happiest whereas Ferdinand is most disappointed. Both Edna and Gretel see the peak price as a foregone gain, whereas Ferdinand sees the failure to sell at the peak as a loss.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Prospect theory exercises</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-exercises.html#reference-points",
    "href": "prospect-theory/prospect-theory-exercises.html#reference-points",
    "title": "20  Prospect theory exercises",
    "section": "20.3 Reference points",
    "text": "20.3 Reference points\nMegan has the following reference-dependent value function:\n\nv(x)=\\left\\{\\begin{matrix}\nx \\quad &\\textrm{where} \\quad x \\geq 0\\\\\n2x \\quad &\\textrm{where} \\quad x &lt; 0\n\\end{matrix}\\right.\n\nwhere x is the realised outcome relative to the reference point.\na) If you look at v(x), we expect Megan to be:\n\nloss averse\nhave no decreased sensitivity to changes of greater magnitude.\n\nWhy?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMegan is loss averse as the slope of the value function in the loss domain is steeper than in the gain domain. One unit of loss leads to a greater change in value than one unit of gain.\nThere is no decreases sensitivity as the value function is linear in both domains. Sensitivity is constant. As the size of the loss or gain increases, the change in value remains constant despite the increasing magnitude.\n\n\n\nb) Assume Megan has received a birthday card from her aunt, which some years contains $25 and other years contains nothing.\nShe opens the card and it contains $10.\nConsider two alternative reference points: Megan is pessimistic and expects no money in the card, and Megan is optimistic and expects $25.\nCompute Megan’s value under each reference point. Which reference point yields higher value?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe value of the $10 from the reference point of expecting nothing is:\n\\begin{align*}\nv(x)&=v(10) \\\\[6pt]\n&=10\n\\end{align*}\nThe value of the $10 from the reference point of expecting $25 is:\n\\begin{align*}\nv(x)&=v(10-25) \\\\[6pt]\n&=2\\times (-15) \\\\[6pt]\n&=-30\n\\end{align*}\nMegan has higher value when she does not expect to receive any money. She gets the value of a gain of $10. If she expected the $25, she suffered the value of a loss of $15.\n\n\n\nc) Megan has received the $10 in the card and a piece of birthday cake. Her value function over money and pieces of birthday cake is:\n\nv(x)=v(m-r_m)+v(4c-4r_c)\n\nWhere m is the amount of money she receives, r_m is her reference point of how much money she expects, c is how many pieces of birthday cake she receives and r_c is how many pieces of birthday cake she expects.\nTo illustrate how this value function works, imagine Megan expects two pieces of cake and her dog jumps onto the table and eats one of them. Her change in the value function is:\n\\begin{align*}\nv(x)&=v(4c-4r_c) \\\\\n&=v(4\\times 1-4\\times 2) \\\\\n&=v(-4)\n\\end{align*}\nAs v(x)=2x when x&lt;0:\n\nv(-4)=-8\n\nFor this question, assume Megan does not believe that she will receive any money and she expects to eat two pieces of birthday cake. Her reference point is therefore r_m=0 and r_c=2. She receives $10 from her aunt.\nHer brother - who loves cake - offers to buy one of her pieces of birthday cake. What price p_s would make Megan indifferent between selling and keeping the piece of cake?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMegan will be indifferent when the value from each option is the same:\n\\begin{align*}\n\\underbrace{v(10-0+p_s)}_{\\substack{\\textrm{Value from} \\\\ \\textrm{unexpected} \\\\ \\textrm{money plus} \\\\  \\textrm{payment} \\\\ \\textrm{for cake}}}+\n\\underbrace{v(4\\times 1-4\\times 2)}_{\\substack{\\textrm{Value lost from} \\\\ \\textrm{giving up cake}}}\n&=\\underbrace{v(10-0)}_{\\substack{\\textrm{Value from} \\\\ \\textrm{unexpected} \\\\ \\textrm{money}}}+\nv\\underbrace{(4\\times 2-4\\times 2)}_{\\substack{\\textrm{Value of} \\\\ \\textrm{keeping cake}}} \\\\[12pt]\nv(10+p_s)+v(-4)&=v(10)+v(0) \\\\[6pt]\n10+p_s-8&=10\\\\[6pt]\np_s&=8\n\\end{align*}\n\n\n\nd) Assume that Megan expects to receive only one piece of birthday cake. Her brother then offers to sell her his piece of cake. For r_m=0 and r_c=1, what price p_b would make Megan indifferent between buying the cake and eating only her own piece?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMegan will be indifferent when the value from each option is the same:\n\\begin{align*}\n\\underbrace{v(10-0-p_b)}_{\\substack{\\textrm{Value from} \\\\ \\textrm{unexpected} \\\\ \\textrm{money minus} \\\\  \\textrm{payment} \\\\ \\textrm{for cake}}}+\n\\underbrace{v(4\\times 2-4\\times 1)}_{\\substack{\\textrm{Value gained from} \\\\ \\textrm{buying cake}}}\n&=\\underbrace{v(10-0)}_{\\substack{\\textrm{Value from} \\\\ \\textrm{unexpected} \\\\ \\textrm{money}}}+\nv\\underbrace{(4\\times 1-4\\times 1)}_{\\substack{\\textrm{Value of} \\\\ \\textrm{only one piece}}} \\\\[12pt]\nv(10-p_b)+v(4)&=v(10)+v(0) \\\\[6pt]\n10-p_b+4&=10\\\\[6pt]\np_b&=4\n\\end{align*}\n\n\n\ne) Why is there a difference between the price at which Megan was willing to sell cake in part c) compared to the price she was willing to pay in part d)?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe willingness to accept in part c) is higher than the willingness to pay in part d) as in part c) the foregone cake is coded as a loss. This loss reduces value at twice the rate of a gain in cake. The payment for the cake in both parts is in the gain domain due to the birthday present of $10, so the payment received or paid is given less weight than any loss.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Prospect theory exercises</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-exercises.html#saving-on-a-purchase",
    "href": "prospect-theory/prospect-theory-exercises.html#saving-on-a-purchase",
    "title": "20  Prospect theory exercises",
    "section": "20.4 Saving on a purchase",
    "text": "20.4 Saving on a purchase\nConsider the following two scenarios:\nA) You are considering buying a new type of coffee bean for your home coffee machine. It costs $50 at your local hipster cafe, but you discover that it is for sale for $40 at the supermarket 20 minutes drive from your home. Do you make the trip?\nB) You are considering buying a new laptop. It costs $1990 at your local computer store, but you discover that it is for sale for $1980 at another computer store 20 minutes drive from your home. Do you make the trip?\nWhen people are presented with scenarios such as this, they tend to report that they are less likely to make the trip in Scenario B for the more expensive product.\nExplain how an S-shaped value function with diminishing value in both gains and losses could result in this behaviour.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nDiminishing value means that the absolute difference between v(-40) and v(-50) is much larger than the absolute difference between v(-1980) and v(-1990). For example, suppose the value function was:\n\nv(x)=\\left\\{\\begin{matrix}\nx^\\frac{1}{2} \\quad &\\textrm{where} \\quad x \\geq 0\\\\\n-2(-x)^\\frac{1}{2} \\quad &\\textrm{where} \\quad x &lt; 0\n\\end{matrix}\\right.\n\nThis would mean that the difference between v(-40) and v(-50) is:\n\\begin{align*}\nv(-40)-v(-50)&=-2(40^\\frac{1}{2}-50^\\frac{1}{2}) \\\\\n&=1.49\n\\end{align*}\nThe difference between v(-1980) and v(-1990) is:\n\\begin{align*}\nv(-1980)-v(-1990)&=-2(1980^\\frac{1}{2}-1990^\\frac{1}{2}) \\\\\n&=0.22\n\\end{align*}\nMuch less value is gained by driving for the 20 minutes across town for the computer.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Prospect theory exercises</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-exercises.html#a-6040-gamble",
    "href": "prospect-theory/prospect-theory-exercises.html#a-6040-gamble",
    "title": "20  Prospect theory exercises",
    "section": "20.5 A 60:40 gamble",
    "text": "20.5 A 60:40 gamble\nSuppose an agent has the following reference-dependent value function:\n\nv(x)=\\left\\{\\begin{matrix}\nx^{3/4} \\qquad &\\textrm{where} \\space &x \\geq 0\\\\\n-2(-x)^{3/4} \\quad &\\textrm{where} \\space &x &lt; 0\n\\end{matrix}\\right.\n\nWhere x is the realised outcome relative to the reference point.\nAssume that the agent’s reference point is the status quo and the agent is offered the gamble A:\n(\\$100, 0.6; −\\$100, 0.4)\na) Will they want to play this gamble? Why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe utility from the gamble is:\n\\begin{align*}\nV(A)&=0.6v(100)-0.4v(-100) \\\\\n&=0.6\\times (100)^{0.75}-0.4\\times 2\\times (100)^{0.75} \\\\\n&=-6.32\n\\end{align*}\nThey will not want to play this gamble as it has a negative value for the agent. They could receive value of 0 by simply not playing.\nThe reason for this negative value is that the agent is loss averse. The loss of $100 is given twice the weight of an equivalent gain, meaning that they reject the bet despite a win of $100 being more probable.\n\n\n\nb) Suppose the agent takes this gamble and loses $100. They feel bad about it and perceive it as a loss. Their reference point is unchanged at the original status quo. They are offered gamble A again? Do they accept this second time? Why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAfter losing $100 but not changing their reference point, they have two possible outcomes relative to their reference point: recovery of their loss of $100 so they come out even and a loss of $200 (losing $100 twice).\n\\begin{align*}\nV(A)&=0.6v(-100+10)-0.4v(-100-100) \\\\\n&=0.6\\times (0)^{0.75}-0.4\\times 2\\times (200)^{0.75} \\\\\n&=-42.55\n\\end{align*}\nThe utility of not playing the gamble involves remaining with a loss of $100:\n\\begin{align*}\nV(\\neg A)&=v(-100) \\\\\n&=-2\\times (100)^{0.75} \\\\\n&=-63.25\n\\end{align*}\nThey will now want to play the gamble as it has a greater value than staying with their current loss. The reason the gamble becomes attractive is because it gives an opportunity to recover the loss. The agent is risk seeking over the loss domain.\n\n\n\nc) The agent is offered a new job for which they receive a $50,000 sign-on bonus. They adapt to their new wealth, so their reference point changes to accommodate their new situation. They are now offered gamble A again. Do they accept? Why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWith their new reference point, this question is effectively the same as part a). They will refuse the bet.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Prospect theory exercises</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-exercises.html#a-5050-gamble",
    "href": "prospect-theory/prospect-theory-exercises.html#a-5050-gamble",
    "title": "20  Prospect theory exercises",
    "section": "20.6 A 50:50 gamble",
    "text": "20.6 A 50:50 gamble\nSuppose Tim has the following reference-dependent value function:\n\nv(x)=\\left\\{\\begin{matrix}\nx^{1/2} \\qquad &\\textrm{where} &\\space x \\geq 0\\\\\n-2(-x)^{1/2} \\quad &\\textrm{where} &\\space x &lt; 0\n\\end{matrix}\\right.\n\nx is the change in Tim’s position relative to his reference point.\na) What feature of Tim’s value function leads to loss aversion? Explain.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe part of the value function that applies when x&lt;0 is increased by a factor of two relative to that part of the value function for when x&gt;0. This is done by multiplying the bottom portion by 2.\n\n\n\nb) Tim considers the gamble A: ($250, 0.5; -$100, 0.5). Will Tim want to play this gamble?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\begin{align*}\nV(A)&=p_1v(x_1)+p_2v(x_2) \\\\\n&=0.5v(\\$250)+0.5v(-\\$100) \\\\\n&=0.5\\times 250^{1/2}-0.5\\times 2\\times 100^{1/2} \\\\\n&=-2.09\n\\end{align*}\nTim has negative value from the gamble, when he could simply have zero value by declining. He rejects.\n\n\n\nc) Explain what features of the value function lead him to accept or reject the gamble.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTwo features of the value function lead him to reject:\n\nTim is loss averse (the -2 in the bottom equation), which leads him to give twice the weight to losses relative to an equal sized gain.\nTim has diminishing sensitivity to losses and gains. The larger gain is reduced proportionately more by this diminishing sensitivity.\n\n\n\n\nd) Suppose Tim were to experience a large positive or negative shock to his wealth that does not immediately change his reference point. Could either shock cause him to change his decision concerning gamble A? Explain.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBoth a positive and negative shock could lead Tim to change his decision.\nA large positive shock would place the entire bet into the gain domain. That would remove loss aversion as a factor in rejecting the bet. Given the high expected value, that would likely be sufficient for him to accept. However, a large shock would also place Tim further up the value function to a region where it is more linear (i.e. he is less risk averse). This will also increase the tendency to accept the bet.\nA large negative shock would place the entire bet into the loss domain. That would remove loss aversion as a factor in rejecting the bet as there is no gain against which the loss can be given relatively greater weight. Due to diminishing sensitivity to losses, Tim is also risk seeking in the loss domain. This would lead him to accept any bet with a positive expected value.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Prospect theory exercises</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-exercises.html#insurance-and-gambling",
    "href": "prospect-theory/prospect-theory-exercises.html#insurance-and-gambling",
    "title": "20  Prospect theory exercises",
    "section": "20.7 Insurance AND gambling",
    "text": "20.7 Insurance AND gambling\nExplain how probability weighting as proposed under Prospect Theory can lead a person to simultaneously gamble and purchase insurance.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nDecisions under Prospect Theory are the outcome of two factors:\n\nThe value function that gives a value to each outcome relative to a reference point\nThe probability weighting function that gives a decision weight to the probability of each outcome.\n\nThe Prospect Theory value function leads people to be risk averse in the domain of gains and risk seeking in the loss domain. This combination would tend to lead people to purchase neither insurance or lotteries. Their risk seeking behaviour could lead them to avoid the certain loss of the insurance premium. They would rather risk the loss of the insurable asset.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -2*(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-220, 220, 0.1),\n  y = u(seq(-220, 220, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;- -200 #loss\nx2&lt;- 0 #win\nev&lt;- -30 #expected value of gamble\nxc&lt;- -60 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-220, 220), ylim = c(-30, 15))+\n\n  #Add labels -V, v(L) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"-V\", size = 4, hjust = 0.5, vjust = -0.3)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"v(-V)\", size = 4, hjust = -0.1, vjust = 0.6)+\n\n  #Add labels -P, v(-P) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"-P\", size = 4, hjust = 0.8, vjust = -0.3)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"v(-P)\", size = 4, hjust = -0.1, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels E[don't], v(don't) and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[don't]\", size = 4, hjust = 0.5, vjust = -0.3)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"v(don't)\", size = 4, hjust = -0.1, vjust = 0.45)\n\n\n\n\n\nFigure 20.1: Purchasing insurance\n\n\n\n\n\n\n\n\nTheir risk averse behaviour in the domain of gains would make a lottery with a negative expected value unattractive, as the following diagram shows (not drawn to scale - the relative size of a win would typically dwarf the ticket price).\n\n\nCode\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -2*(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-110, 160, 0.1),\n  y = u(seq(-110, 160, 0.1))\n)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1 &lt;- -50 #loss\nx2 &lt;- 150 #win\nev &lt;- 0.2*x2+0.8*x1 #expected value of gamble\nxc &lt;- 0 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-80, 160), ylim = c(-15, 15))+\n\n  #Add labels -T, v(-T) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"-T\", size = 4, hjust = 0.5, vjust = -0.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"v(-T)\", size = 4, hjust = -0.1, vjust = 0.45)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels W-T, v(W-T) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"W-T\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"v(W-T)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels E[A], V(A) and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[X]\", size = 4, hjust = 0.4, vjust = -0.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"V(X)\", size = 4, hjust = -0.1, vjust = 0.45)\n\n\n\n\n\nFigure 20.2: Purchasing a lottery\n\n\n\n\n\n\n\n\nHowever, the probability weighting function can counteract that effect. By overweighting the small probability of an insurable event or a lottery win, the agent may decide to insure or purchase a lottery despite the risk attitudes inherent in the value function.\nAs an example, consider an agent who overweights a probability of 1 in a million lottery win by 1,000 times, acting as though they would win the $1 million prize once every 1000 lotteries. They also overweight the probability of a one in a thousand fire that would destroy their million dollar house by 100 times, acting as though it is a 1-in-10 chance. (These numbers are extreme, but I am creating a toy example.)\nSuppose the lottery ticket is $1 and their utility function is:\n\nv(x)=\\left\\{\\begin{matrix}\nx^{1/2} \\quad &\\textrm{where} \\space &x \\geq 0\\\\\n-(-x)^{1/2} \\quad &\\textrm{where} \\space &x &lt; 0\n\\end{matrix}\\right.\n\nValue of purchasing the lottery:\n\\begin{align*}\nv(x)&=\\sum_{i=1}^{n} \\pi(x_i)v(x_i) \\\\[6pt]\n&=0.001\\times (1000000-1)^{1/2}-0.999\\times (1)^{1/2} \\\\[6pt]\n&=0.000999\n\\end{align*}\nThe value of not purchasing the lottery is zero.\nThey will purchase the lottery as it has the higher value.\nValue of not purchasing insurance, which involves the potential loss of the house:\n\\begin{align*}\nv(x)&=\\sum_{i=1}^{n} \\pi(x_i)v(x_i) \\\\[6pt]\n&=-0.1\\times (1000000)^{1/2}+0.9\\times (0)^{1/2} \\\\[6pt]\n&=-100\n\\end{align*}\nValue of purchasing insurance, which is the certain loss of the premium:\n\\begin{align*}\nv(x)&=\\sum_{i=1}^{n} \\pi(x_i)v(x_i) \\\\[6pt]\n&=-(1000)^{1/2} \\\\[6pt]\n&=-31.6\n\\end{align*}\nThey purchase insurance as it has higher value than not purchasing it.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Prospect theory exercises</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-exercises.html#locking-in-a-win",
    "href": "prospect-theory/prospect-theory-exercises.html#locking-in-a-win",
    "title": "20  Prospect theory exercises",
    "section": "20.8 Locking in a win",
    "text": "20.8 Locking in a win\nAmber sued a tabloid newspaper for defamation. The trial has completed and the judge has retired to make her decision.\nAmber’s lawyer tells her that she has a 95% chance of winning and receiving $1,000,000 in damages, meaning she has a 5% chance of leaving with nothing. (Ignore any potential costs.) She then receives an offer of settlement from the newspaper for $800,000. Amber accepts.\nUse the fourfold pattern of attitudes to risk under prospect theory to explore why Amber accepted the settlement offer.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nRejecting the offer has a higher expected value than the value of the settlement:\n\\begin{align*}\nE[\\text{reject}]&=p_{\\text{win}} x_{\\text{win}} \\\\\n&=0.95\\times 1000000 \\\\\n&=950000\n\\end{align*}\nTwo forces under prospect theory would lead Amber to take the option with the lower expected value:\n\nPeople are risk averse in the gain domain. Amber would prefer certainty to a gamble with the same expected value, and depending on the level of risk aversion, would be willing to accept an amount for certain lower than the expected value of the bet. That is, the certainty equivalent of the gamble would be less than its expected value.\nPeople overweight small probabilities. The 5% probability of losing is likely overweighted by Amber.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Prospect theory exercises</span>"
    ]
  },
  {
    "objectID": "prospect-theory/prospect-theory-exercises.html#lotteries-as-incentives",
    "href": "prospect-theory/prospect-theory-exercises.html#lotteries-as-incentives",
    "title": "20  Prospect theory exercises",
    "section": "20.9 Lotteries as incentives",
    "text": "20.9 Lotteries as incentives\nA common intervention to encourage behaviour change is to offer a lottery ticket as an incentive. For example, a lottery ticket might be offered to people who complete a survey.\nThe government is considering whether it should incentivise vaccination with either:\n\na payment of $10 or\na lottery ticket with a 1 in a million chance of winning $10 million.\n\nUse concepts from prospect theory to explain why either option might be more successful.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere are two opposing forces that could lead to either option being preferred.\nBoth the lottery and payment of $10 are in the gain domain. Under prospect theory, people tend to be risk averse in the gain domain. This will make the payment, which has the same expected value as the lottery, more attractive.\nConversely, under prospect theory, people do not weight outcomes directly by their probability. They apply decision weights that tend to overweight small probabilities and underweight probabilities just short of certainty. This means that the small chance of $10 million will likely be overweighted. This could lead to the value of the lottery exceeding that of a certain payment.\nWhich effect dominates depends on how risk-averse people are and how much they overweight the probability.",
    "crumbs": [
      "Prospect theory",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Prospect theory exercises</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice.html",
    "href": "intertemporal-choice/intertemporal-choice.html",
    "title": "Intertemporal choice",
    "section": "",
    "text": "Summary\nIntertemporal choice refers to decisions involving costs and benefits occurring at different times.\nAlmost every decision is an intertemporal choice. Intertemporal choices can be important because:\nOne of the core principles of intertemporal choice is that people tend to discount future costs and benefits. They prefer to receive benefits earlier, rather than later, and prefer to incur costs later rather than earlier.",
    "crumbs": [
      "Intertemporal choice"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice.html#summary",
    "href": "intertemporal-choice/intertemporal-choice.html#summary",
    "title": "Intertemporal choice",
    "section": "",
    "text": "Intertemporal choice involves decisions with costs and benefits occurring at different times, which can be significant due to delayed feedback, irreversibility, and high stakes.\nA core principle is that people tend to discount future costs and benefits, preferring earlier benefits and later costs.\nIn this subject, discrete time is used, where time occurs in a series of steps, as opposed to continuous time.\nStreams of payoffs in discrete time can be represented using notation like S=(t_1,x_1;t_2,x_2;...;t_n,x_n), where t_i is the time period and x_i is the payoff in that period.\n\n\n\n\n\n\nFirst, feedback may not be immediate. For example, when will you realise that your retirement savings are inadequate?)\nSecond, your choices may be irreversible. What can you do if you reach retirement age with little savings?\nAnd finally, stakes can be large, affecting your health, wealth, family or career.",
    "crumbs": [
      "Intertemporal choice"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice.html#discrete-versus-continuous-time",
    "href": "intertemporal-choice/intertemporal-choice.html#discrete-versus-continuous-time",
    "title": "Intertemporal choice",
    "section": "Discrete versus continuous time",
    "text": "Discrete versus continuous time\nIn this subject, we will consider what is called “discrete time”. In discrete time, time occurs in a series of steps. For example, we might consider the following sequence of time periods:\n\nt_0,t_1,t_2,t_3,t_4,t_5,...\n\nAt each discrete moment in time, the agent might make a decision or receive a payoff. We assume that there is no moment between those two steps. For example, if t=0 is today and t=1 is in one week, we consider only those two moments, not any time between.\nDiscrete time contrasts with “continuous time”, where time is a continuous variable. Time is divisible into an infinite number of steps. For example, if t=0 is today and t=1 is in one week, there is an infinite number of other points in time between.",
    "crumbs": [
      "Intertemporal choice"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice.html#notation",
    "href": "intertemporal-choice/intertemporal-choice.html#notation",
    "title": "Intertemporal choice",
    "section": "Notation",
    "text": "Notation\nOne way of representing a stream of payoffs in discrete time is the following form:\n\nS=(t_1,x_1;t_2,x_2;...;t_n,x_n)\n\nt_i is the period in which the payoff is received. x_i is the payoff received in period t_i.\nConsider these two simple streams of payoffs.\nFor both streams, period t_1=0, which is now. Period t_2=1, which is one year from today.\nThe first stream is $100 now and nothing in a year. \nS_1=(0,\\$100;1,0)\n\nThe second stream is nothing today and $107 in one year. \nS_2=(0,0;1,\\$107)\n\nWould you prefer S_1 or S_2?",
    "crumbs": [
      "Intertemporal choice"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting.html",
    "href": "intertemporal-choice/exponential-discounting.html",
    "title": "21  Exponential discounting",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Exponential discounting</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting.html#summary",
    "href": "intertemporal-choice/exponential-discounting.html#summary",
    "title": "21  Exponential discounting",
    "section": "",
    "text": "Exponential discounting is a model where agents discount future costs and benefits at a consistent rate through time, with each additional period of delay resulting in a discount by a factor of \\delta.\nUnder this model, agents seek to maximise the discounted utility of future consumption, resulting in a smooth decline in the present value of future payoffs over time.\nOne implication of exponential discounting is time consistency, meaning an agent’s relative preference between two future options remains unchanged as time passes and the options draw closer.\nThe model assumes consumption independence, where utility in one period is independent of consumption in other periods, allowing goods to be split and moved across periods without changing their value beyond the discount effect.\nAdditional assumptions include stationary preferences (the utility function remains constant across periods) and utility independence (decision-makers only aim to maximise the sum of discounted utilities without preference for their distribution over time).",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Exponential discounting</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting.html#introduction",
    "href": "intertemporal-choice/exponential-discounting.html#introduction",
    "title": "21  Exponential discounting",
    "section": "21.1 Introduction",
    "text": "21.1 Introduction\nExponential discounting occurs when an agent discounts future costs and benefits at a consistent rate through time.\nUnder exponential discounting, each additional period of delay results in a discount of a future cost or benefit by a factor of \\delta. The discount factor \\delta is a number between 0 and 1. The higher the discount factor, the less the agent discounts future costs and benefits.\nYou will often see discussion of the ”discount rate”, r. In discrete time, the relationship between \\delta and r is as follows:\n\\delta=\\frac{1}{1+r}\nA larger discount factor implies less discounting. A larger discount rate implies more discounting.\nUnder the standard model of exponential discounting, an agent with a choice between alternative streams of payoffs will seek to maximize the discounted utility of the future path of consumption.\nThe following equation is an example of exponential discounting, with a stream of costs or benefits x_0 through to x_T incurred at periods 0 through to T. U_0 is utility of the stream of payoffs at time t=0. x_t is the payoff in period t.\n\\begin{align*}\nU_0&=u(x_0)+\\delta u(x_1)+\\delta^2u(x_2)+\\delta^3u(x_3)+...+\\delta^Tu(x_T) \\\\[6pt]\n&=\\sum_{t=0}^{t=T}\\delta^tu(x_t) \\\\[12pt]\n0&\\leq \\delta\\leq1\n\\end{align*}\nEach period of delay results in a discount of the future cost or benefit by a factor of \\delta. One period of delay results in a discount of \\delta. Two periods of delay results in a discount of \\delta^2. Three periods of delay results in a discount of \\delta^3 and so on.\nThe degree of discounting in this equation evolves each period as 1, \\delta, \\delta^2, \\delta^3, \\delta^4 and so on. This results in a smooth decline in present value of a future payoff over time.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Exponential discounting</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting.html#visualising-exponential-discounting",
    "href": "intertemporal-choice/exponential-discounting.html#visualising-exponential-discounting",
    "title": "21  Exponential discounting",
    "section": "21.2 Visualising exponential discounting",
    "text": "21.2 Visualising exponential discounting\nFigure 21.1 illustrates the effect of exponential discounting. The figure plots the size of the discount as a function of t for an exponential discounter with \\delta=0.9 and \\delta=0.75.\n\n\nCode\n#Plot of exponential discounting with two curves, one with delta=0.9 and one with delta=0.75\n\n##Load the ggplot2 package\nlibrary(ggplot2)\nlibrary(tidyr)\n\n#Define the discount factor\ndelta &lt;- c(0.75, 0.9)\n\n#Define the number of periods\nt &lt;- 0:10\n\n#Define the discount function\ndiscount &lt;- function(delta, t) {\n  delta^t\n}\n\n#data frame with three rows: t, discount(0.75, t) and discount(0.9, t)\ndiscounted &lt;- data.frame(t, discount(delta[1], t), discount(delta[2], t))\n\ncolnames(discounted) &lt;- c(\"t\",\"0.75\",\"0.9\")\n\ndiscounted &lt;- pivot_longer(discounted, cols = -t, names_to = \"delta\", values_to = \"discount\")\n\n#Plot the discount function with curves for each of the two values of delta using ggplot2\nggplot(discounted, aes(x=t, y=discount, group=delta, linetype=delta)) +\n    geom_line() +\n    labs(x=\"t\", y=\"Discount\") +\n    theme_minimal() +\n    scale_x_continuous(breaks=1:10) +\n    scale_y_continuous(breaks=seq(0, 1, 0.1)) +\n    geom_vline(xintercept = 0, linewidth=0.25)+ \n    geom_hline(yintercept = 0, linewidth=0.25)\n\n\n\n\n\nFigure 21.1: Exponential discount curves",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Exponential discounting</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting.html#time-consistency",
    "href": "intertemporal-choice/exponential-discounting.html#time-consistency",
    "title": "21  Exponential discounting",
    "section": "21.3 Time-consistency",
    "text": "21.3 Time-consistency\nOne implication of exponential discounting is time consistency.\nOnce the agent starts moving along the consumption path, they are time-consistent with their initial plan. For example, consider an agent facing the following two choices:\nWould you like $100 today or $110 next week?\nWould you like $100 next week or $110 in two weeks?\nAn exponential discounter will choose $100 in both choices or $110 in both choices. The reason is that after one week the second choice effectively becomes the same as the first choice. Time consistency implies that they will continue to want to make the same choice regardless of when they are making it.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Exponential discounting</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting.html#exponential-discounted-utility-model-assumptions",
    "href": "intertemporal-choice/exponential-discounting.html#exponential-discounted-utility-model-assumptions",
    "title": "21  Exponential discounting",
    "section": "21.4 Exponential discounted utility model assumptions",
    "text": "21.4 Exponential discounted utility model assumptions\nThe standard model of exponential discounting is underpinned by several assumptions.\n\n21.4.1 Consumption independence\nThe first assumption is consumption independence.\nConsumption independence means that utility in period t+k is independent of consumption in any other period. An outcome’s utility is unaffected by outcomes in prior or future periods.\nImagine a world where an exponential discounter intends to consume a behavioural economics subject.\nSuppose that exponential discounter wants to consume lecture 1 at t+3 and lecture 2 at t+4. Under consumption independence, if the agent does not attend lecture 1, they still expect to benefit from lecture 2 at t+4 consistent with the plan they decided at t.\nThis assumption allows us to write x=x_1+x_2+x_3+...+x_n. That is, good x can be split, allocated and moved across periods without changing the value of that good beyond the effect of the discount.\n\n\n21.4.2 Stationary preferences\nA second assumption is stationary preferences.\nThat is, U_t=U_{t=K}.\nThe utility function is stationary across periods. The functional form of U_t is the same as the functional form of U_{t+k}.\nThat means that if someone likes ice cream today, they will get the same utility from ice cream at a future time of consumption. Any preference for ice cream today versus tomorrow comes from the discounting of future consumption, not from changes in taste.\nSimilarly, with stationary preferences, you would not learn to appreciate the taste of wine over time.\n\n\n21.4.3 Utility independence\nA third assumption is utility independence.\nUnder utility independence, all that matters is maximizing the sum of discounted utilities. Decision makers have no preference for the distribution of utilities. They don’t seek to delay gratification or get unpleasant things out of the way.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Exponential discounting</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting-examples.html",
    "href": "intertemporal-choice/exponential-discounting-examples.html",
    "title": "22  Exponential discounting examples",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Exponential discounting examples</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting-examples.html#summary",
    "href": "intertemporal-choice/exponential-discounting-examples.html#summary",
    "title": "22  Exponential discounting examples",
    "section": "",
    "text": "Exponential discounters make decisions by comparing the discounted utility of different options, choosing the one with the highest value.\nThe discount factor \\delta determines how much future payoffs are discounted, with a higher \\delta resulting in less discounting of future outcomes.\nVisualisations, such as graphs showing discounted utility over time, can help illustrate how exponential discounters evaluate and compare different options.\nThe following examples illustrate that:\n\nTime consistency is demonstrated through consistent choices across different time frames.\nThe amount needed to compensate for a delay increases exponentially with time.\nDifferent discount factors can lead to different choices between the same options.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Exponential discounting examples</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting-examples.html#introduction",
    "href": "intertemporal-choice/exponential-discounting-examples.html#introduction",
    "title": "22  Exponential discounting examples",
    "section": "22.1 Introduction",
    "text": "22.1 Introduction\nIn this part, I will work through several numerical examples of decisions by an exponential discounter.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Exponential discounting examples</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting-examples.html#sec-exponential_example_1",
    "href": "intertemporal-choice/exponential-discounting-examples.html#sec-exponential_example_1",
    "title": "22  Exponential discounting examples",
    "section": "22.2 Example 1: $100 today or $110 next week",
    "text": "22.2 Example 1: $100 today or $110 next week\nAlison is an exponential discounter with discount factor \\delta=0.95 and utility each period of u(x_n)=x_n. She is offered two choices.\nChoice 1: Would she prefer $100 today (t=0) or $110 next week (t=1)?\nTo determine this, we calculate the discounted utility of each option. Alison will prefer the option with the highest discounted utility.\nWe write the discounted utility of the $100 today as U_0(0,\\$100). The subscript 0 indicates that the utility is calculated at time t=0. The first number in the brackets indicates the time the payment is received. In this case, the $100 is received at t=0, today. The second number in the brackets is the value of the payment.\nThe discounted utility of the $100 today, U_0(0,\\$100), is:\n\\begin{align*}\nU_0(0,\\$100)&=u(\\$100) \\\\[6pt]\n&=100\n\\end{align*}\nThere is no discount \\delta applied to the $100 as it is received immediately.\nWe write the discounted utility of the $110 next week as U_0(1,\\$110). The subscript 0 again indicates that the utility is calculated at time t=0. The first number in the brackets, 1, indicates the time the payment is received, t=1. The second number in the brackets is the value of the payment.\nThe discounted utility of the $110 next week is:\n\\begin{align*}\nU_0(1,\\$110)&=\\delta u(\\$110) \\\\[6pt]\n&=0.95\\times 110 \\\\[6pt]\n&=104.5\n\\end{align*}\nIn this case, a discount of \\delta=0.95 is applied to the $110 as it is received in one week.\nWe can now compare the discounted utility of each option. U_0(0,\\$100)=100&lt;104.5=U_0(1,\\$110). Alison would prefer to receive $110 next week as it leads to higher discounted utility.\nFigure 22.1 visualises the effect of discounting in Choice 1.\nThe two bars represent the options: $100 at t=0 and $110 at t=1. The line from the $110 option represents the discounted utility of that option at each time. At t=0 the discounted utility of the $110 received at t=1 is 104.5. At t=0 we can see that the $110 is preferred as the line indicating discounted utility is higher than the utility of the $100 received immediately.\n\n\nCode\n# Create a function to create the discounted bar chart\nlibrary(ggplot2)\n\n# Helper function to create discounted values\ncreate_discount_data &lt;- function(value, time, discount_rate, start) {\n  times &lt;- seq(start, time, by = 1)\n  data.frame(\n    t = times,\n    group = as.character(time),\n    value = value * discount_rate^(time - times)\n  )\n}\n\n# Main function to create the discounted bar chart\ncreate_discounted_bar_chart &lt;- function(smaller, t_s, larger, t_l, discount_rate, starting_at = 0, y_spacing = 20, x_spacing = 1) {\n  # Create the data\n  data &lt;- data.frame(\n    t = c(t_s, t_l),\n    U_t = c(smaller, larger)\n  )\n  \n  # Create the discounted values, starting from 'starting_at'\n  discounted_data &lt;- rbind(\n    create_discount_data(smaller, t_s, discount_rate, starting_at),\n    create_discount_data(larger, t_l, discount_rate, starting_at)\n  )\n  \n  # Shift t values based on starting_at\n  data$t_plot &lt;- data$t - starting_at\n  discounted_data$t_plot &lt;- discounted_data$t - starting_at\n  \n  # Filter out any data points before the starting point\n  data &lt;- data[data$t &gt;= starting_at, ]\n  discounted_data &lt;- discounted_data[discounted_data$t &gt;= starting_at, ]\n  \n  # Determine x-axis and y-axis limits\n  x_min &lt;- 0\n  x_max &lt;- max(max(data$t_plot), max(discounted_data$t_plot))\n  y_max &lt;- max(max(data$U_t), max(discounted_data$value)) * 1.1  # 10% buffer\n  \n  # Create the plot\n  ggplot() +\n    # Add the bars\n    geom_rect(data = data, aes(xmin = ifelse(t_plot == 0, 0, t_plot - 0.15),\n                               xmax = ifelse(t_plot == 0, 0.15, t_plot + 0.15),\n                               ymin = 0, ymax = U_t),\n              fill = \"white\", color = \"black\") +\n    \n    # Add the discount lines\n    geom_line(data = discounted_data, aes(x = t_plot, y = value, group = group), \n              color = \"black\", linewidth = 1) +\n    \n    # Customize the plot\n    scale_x_continuous(breaks = seq(x_min, x_max + 1, by = x_spacing), \n                       limits = c(x_min, x_max + 1),\n                       expand = c(0, 0),\n                       labels = function(x) x + starting_at) +\n    scale_y_continuous(breaks = seq(0, y_max, by = y_spacing), \n                       limits = c(0, y_max),\n                       expand = c(0, 0)) +\n    geom_vline(xintercept = 0, linewidth = 0.25) + \n    geom_hline(yintercept = 0, linewidth = 0.25) +\n    labs(x = \"t\",\n         y = expression(U[t])) +\n    theme_minimal() +\n    theme(\n      axis.title.y = element_text(angle = 0, vjust = 0.5),\n      panel.grid.major = element_blank(),\n      panel.grid.minor = element_blank()\n    )\n}\n\n\n\n\nCode\ncreate_discounted_bar_chart(100, 0, 110, 1, 0.95)\n\n\n\n\n\nFigure 22.1: Alison’s consideration of Choice 1\n\n\n\n\n\n\n\n\nChoice 2: Would Alison prefer $100 next week (t=1) or $110 in two weeks (t=2)?\nAgain, we calculate the discounted utility of each option. Alison will prefer the option with the highest discounted utility.\nThe discounted utility of the $100 next week is:\n\\begin{align*}\nU_0(1,\\$100)&=\\delta u(\\$100) \\\\[6pt]\n&=0.95\\times 100 \\\\[6pt]\n&=95\n\\end{align*}\nThe discounted utility of the $110 in two weeks is:\n\\begin{align*}\nU_0(2,\\$110)&=\\delta^2 u(\\$110) \\\\[6pt]\n&=0.95^2\\times 110 \\\\[6pt]\n&=99.275\n\\end{align*}\nWe can now compare the discounted utility of each option. U_0(1,\\$100)=95&lt;99.275=U_0(2,\\$110). Alison would prefer to receive $110 in two weeks.\nThe set of decisions across Choice 1 and Choice 2 are time consistent. If Alison selected $110 in two weeks for Choice 2 and was given a chance to change her choice after one week (which is effectively Choice 1), she would not change her decision.\nFigure 22.2 visualises the effect of discounting in Choice 2.\nThe two bars represent the options: $100 at t=1 and $110 at t=2. The line from each represents the discounted utility of that option at each time.\n\n\nCode\ncreate_discounted_bar_chart(100, 1, 110, 2, 0.95)\n\n\n\n\n\nFigure 22.2: Alison’s consideration of Choice 2\n\n\n\n\n\n\n\n\nFor example, at t=1 the discounted utility of the $100 received at t=1 is 100 and the discounted utility of the $110 received at t=2 is 104.50. We can read those values from the line. For any time t we can determine which option would be preferred by seeing which line is higher.\n\n\nCode\n# First, create the plot using the existing function\np &lt;- create_discounted_bar_chart(100, 1, 110, 2, 0.95)\n\n# Calculate the y-intercept for the dashed line\ny_intercept &lt;- 110 * 0.95  # 104.5\n\n# Add the dashed line and the label to the existing plot\np_with_line_and_label &lt;- p + \n  geom_segment(aes(x = 0, y = y_intercept, xend = 1, yend = y_intercept),\n               linetype = \"dashed\", color = \"black\") +\n  geom_text(aes(x = 0.2, y = y_intercept, label = sprintf(\"%.1f\", y_intercept)),\n            hjust = 1, vjust = -0.2, size = 3)\n\n# Display the modified plot\nprint(p_with_line_and_label)\n\n\n\n\n\nFigure 22.3: Alison’s consideration of Choice 2 - discounted utilities\n\n\n\n\n\n\n\n\nYou will note that the two lines do not cross. For an exponential discounter, if one line is higher at any particular time t, it is higher at all times.\nFigure 22.4 visualises Choice 2 reconsidered at t=1, which as noted earlier, is effectively Choice 1. The discounted utility of the $100 received immediately is less than the discounted utility of $110 in one week. The preference for the higher-value option remains.\n\n\nCode\ncreate_discounted_bar_chart(100, 1, 110, 2, 0.95, starting_at = 1)\n\n\n\n\n\nFigure 22.4: Alison’s reconsideration of Choice 2",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Exponential discounting examples</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting-examples.html#example-2-how-much-for-a-one-year-delay",
    "href": "intertemporal-choice/exponential-discounting-examples.html#example-2-how-much-for-a-one-year-delay",
    "title": "22  Exponential discounting examples",
    "section": "22.3 Example 2: How much for a one-year delay?",
    "text": "22.3 Example 2: How much for a one-year delay?\nBrenda is an exponential discounter with discount factor \\delta=0.95 per week and utility each period of u(x_n)=x_n\nShe is offered $100 today. What sum would she need to be offered in one year (52 weeks) to prefer that later payment to the $100 today?\nTo determine this, we calculate what sum received in one year would give Brenda the same discounted utility as receiving $100 today.\nThe discounted utility of the $100 today is:\n\\begin{align*}\nU_0(0,\\$100)&=u(\\$100) \\\\[6pt]\n&=100\n\\end{align*}\nThe discounted utility of the sum y received in 52 weeks is:\n\\begin{align*}\nU_0(52,\\$y)&=\\delta^{52} u(\\$y) \\\\[6pt]\n&=0.95^{52}\\times y\n\\end{align*}\nAs there is a 52-period delay, the discount factor \\delta is applied 52 times.\nShe will prefer $y in 52 weeks if U(52,\\$y) is greater than 100.\n\\begin{align*}\nU_0(52,\\$y)&&gt;100 \\\\[6pt]\n0.95^{52}\\times y&&gt;100 \\\\[6pt]\ny&&gt;\\frac{100}{0.95^{52}} \\\\[6pt]\ny&&gt;\\$1440.03\n\\end{align*}\nBrenda would be willing to wait a year for payment if she was paid more than $1440.03.\nFigure 22.5 visualises this problem. The bar at t=52 represents the $1440.03 Brenda would need to be paid (at minimum) to prefer that payment to $100 today. The line extended from that bar back to t=0 indicates the discounted utility of that payment at any time t. At t=0 the discounted utility of the $1440.03 is equal to the utility of $100.\n\n\nCode\ncreate_discounted_bar_chart(0, 0, 1440.03, 52, 0.95, y_spacing = 100, x_spacing = 4)\n\n\n\n\n\nFigure 22.5: Brenda’s choice",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Exponential discounting examples</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting-examples.html#example-3-10-in-five-days-or-20-in-10-days",
    "href": "intertemporal-choice/exponential-discounting-examples.html#example-3-10-in-five-days-or-20-in-10-days",
    "title": "22  Exponential discounting examples",
    "section": "22.4 Example 3: $10 in five days or $20 in 10 days?",
    "text": "22.4 Example 3: $10 in five days or $20 in 10 days?\nChelsea is an exponential discounter with discount factor \\delta=0.75 and utility each period of u(x_n)=x_n.\nWould Chelsea prefer $10 in five days (t=5) or $20 in 10 days (t=10)?\nWe calculate the discounted utility of each option. Chelsea will prefer the option with the highest discounted utility.\nThe discounted utility of the $10 in five days is:\n\\begin{align*}\nU_0(5,\\$10)&=\\delta^5u(\\$10) \\\\[6pt]\n&=0.75^5\\times 10 \\\\[6pt]\n&=2.37\n\\end{align*}\nThe discount factor \\delta is applied five times as the payment is received in five days.\nThe discounted utility of the $20 in 10 days is:\n\\begin{align*}\nU_0(10,\\$20)&=\\delta^{10} u(\\$20) \\\\[6pt]\n&=0.75^{10}\\times 20 \\\\[6pt]\n&=1.13\n\\end{align*}\nThe discount factor \\delta is applied 10 times as the payment is received in 10 days.\nWe can now compare the discounted utility of each option. U_0(5,\\$10)=2.37&gt;1.13=U_0(10,\\$20). The discounted utility is higher for the $10 in five days. As a result, Chelsea will prefer to receive $10 in five days.\nDorothy is an exponential discounter with discount factor \\delta=0.95 and utility each period of u(x_n)=x_n. Dorothy has a larger discount factor than Chelsea, meaning that she applies a smaller discount to future outcomes.\nWould Dorothy prefer $10 in five days (t=5) or $20 in 10 days (t=10)?\nThe discounted utility of the $10 in five days is:\n\\begin{align*}\nU_0(5,\\$10)&=\\delta^5u(\\$10) \\\\[6pt]\n&=0.95^5\\times 10 \\\\[6pt]\n&=7.74\n\\end{align*}\nThe discounted utility of the $20 in 10 days is:\n\\begin{align*}\nU_0(10,\\$20)&=\\delta^{10} u(\\$20) \\\\[6pt]\n&=0.95^{10}\\times 20 \\\\[6pt]\n&=11.97\n\\end{align*}\nThe discounted utility is higher for the $20 in 10 days. Dorothy will prefer to receive $20 in 10 days.\nFigure 22.6 visualises the choices and Chelsea and Dorothy’s discounting of the payoffs.\nIn both charts, vertical bars represent the $10 in five days and $20 in 10 days. The lines projecting back to t=0 represent the discounted utility of those payoffs at each time.\nWhen \\delta=0.75, the heavy discount to the more distant payoff means that it has a lower discounted utility than the smaller, sooner payment of $10. When \\delta=0.95, the discount is less severe and the $20 in 10 days has a higher discounted utility than the $10 in five days.\n\nCode\ncreate_discounted_bar_chart(10, 5, 20, 10, 0.75, y_spacing = 5)\ncreate_discounted_bar_chart(10, 5, 20, 10, 0.95, y_spacing = 5)\n\n\n\n\nFigure 22.6: Exponential discounting\n\n\n\n\n\n\n\n\n(a) Chelsea’s choice (\\delta=0.75)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Dorothy’s choice (\\delta=0.95)",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Exponential discounting examples</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting-anomalies.html",
    "href": "intertemporal-choice/exponential-discounting-anomalies.html",
    "title": "23  Exponential discounting anomalies",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Exponential discounting anomalies</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting-anomalies.html#summary",
    "href": "intertemporal-choice/exponential-discounting-anomalies.html#summary",
    "title": "23  Exponential discounting anomalies",
    "section": "",
    "text": "Empirical investigations have revealed several anomalies inconsistent with the exponential discounting model.\nEstimates of the discount factor \\delta show high variability across studies, with evidence suggesting it increases with the time horizon, contrary to the constant rate assumed in exponential discounting.\nPreference reversals have been observed in experiments, where subjects change their choices as the time to receive rewards draws closer, violating the time consistency assumption of exponential discounting.\nReal-world scenarios, such as choices between healthy and unhealthy snacks, provide further evidence of time inconsistency in decision-making, challenging the exponential discounting model’s assumptions.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Exponential discounting anomalies</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting-anomalies.html#introduction",
    "href": "intertemporal-choice/exponential-discounting-anomalies.html#introduction",
    "title": "23  Exponential discounting anomalies",
    "section": "23.1 Introduction",
    "text": "23.1 Introduction\nEmpirical investigation of people’s choices over time has revealed several anomalies that are inconsistent with the exponential discounting model.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Exponential discounting anomalies</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting-anomalies.html#estimation-of-delta",
    "href": "intertemporal-choice/exponential-discounting-anomalies.html#estimation-of-delta",
    "title": "23  Exponential discounting anomalies",
    "section": "23.2 Estimation of \\delta",
    "text": "23.2 Estimation of \\delta\nThe first anomaly is that estimates of the discount factor \\delta are highly variable.\nFrederick et al. (2002) plotted estimates of \\delta from a set of published papers. Figure 1a shows that the estimated discount factor increases with the time horizon. If studies with horizons of one year or less are excluded, there is no relationship between the discount factor and time horizon (Figure 1b).\n\nThis suggests that the discount factor may vary with time.\nSimilar evidence comes from Thaler (1981). He estimated the discount rate of experimental subjects by presenting them with a choice between a prize today or a larger prize later. In each case, the subjects were asked, given the size of the prize that could be received today, how large would the future prize would need to be such that waiting would be as attractive as receiving the money now.\nFor example, some subjects were asked how large a future prize would need to be such that they would be happy to wait three months, one year or three years rather than receiving $15 today. The median answers were $30, $60 and $100 respectively. If you use these answers to calculate an implied discount rate, the result is 277%, 139% and 63%. It can be seen that this discount rate is decreasing with the length of delay (which matches a pattern of an increasing discount factor with the length of delay).",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Exponential discounting anomalies</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/exponential-discounting-anomalies.html#preference-reversal",
    "href": "intertemporal-choice/exponential-discounting-anomalies.html#preference-reversal",
    "title": "23  Exponential discounting anomalies",
    "section": "23.3 Preference reversal",
    "text": "23.3 Preference reversal\nA second anomaly relates to the consistency of choices over time. An exponential discounter is time consistent in that if they prefer one of two future payoffs, they will continue to prefer that same payoff as they get closer to the time of receipt. They do not experience what is called a preference reversal.\nGreen et al. (1994) offered experimental subjects choices between a smaller reward and a delayed larger reward while varying the delay. For example, they offered the choice between:\n\nfirst, $20 now or $50 in three months\nsecond, $20 in one week or $50 in three months and one week.\n\nAcross the choices offered to the experimental subjects, there was a consistent effect whereby incrementing the delay for both rewards equally would result in a switch from the small sooner reward to the latter larger reward. Adding one week to both rewards in the first choice can result in people changing their preference between the sooner and later reward.\nA similar result was found in a study by Kirby and Herrnstein (1995). In that case, 34 of 36 experimental subjects reversed preference from a larger later reward to a smaller earlier reward as the delays to both decreased.\nHere is one intuitive set of choices from Thaler (1981).\nChoice A: Choose between one apple today and two apples tomorrow.\nChoice B: Choose between one apple in one year and two apples in one year plus one day.\nSome people might select one apple today in the first choice, but no-one would select one apple in one year in the second choice.\n\n23.3.1 Healthy choices\nWe can also see evidence for preference reversal when choosing between a healthy and unhealthy option.\nRead and Leeuwen (1998) asked 200 study participants to choose between healthy or unhealthy snacks that they would receive in one week. For example, for their snack next week, they might choose between a banana, apple, Mars bar or Snickers bar. 48% of men and 51% of women chose the healthy choice.\nAt the scheduled time one week later the experimenters asked the study participants to choose again. Although no reference was made to their previous choice, this effectively allowed them to change their mind. This time, only 25% of men and 11% of women chose the healthy snack. While many changed from the healthy to the unhealthy snack, almost no one changed from the unhealthy to the healthy snack.\nThis result is evidence of time inconsistency. The participants made different decisions depending upon when they made the decision.\n\n\n\n\nFrederick, S., Loewenstein, G., and O’Donoghue, T. (2002). Time discounting and time preference: A critical review. Journal of Economic Literature, 40(2), 351–401. https://www.jstor.org/stable/2698382\n\n\nGreen, L., Fristoe, N., and Myerson, J. (1994). Temporal discounting and preference reversals in choice between delayed outcomes. Psychonomic Bulletin & Review, 1(3), 383–389. https://doi.org/10.3758/BF03213979\n\n\nKirby, K. N., and Herrnstein, R. J. (1995). Preference Reversals Due to Myopic Discounting of Delayed Reward. Psychological Science, 6(2), 83–89. https://doi.org/10.1111/j.1467-9280.1995.tb00311.x\n\n\nRead, D., and Leeuwen, B. van. (1998). Predicting Hunger: The Effects of Appetite and Delay on Choice. Organizational Behavior and Human Decision Processes, 76(2), 189–205. https://doi.org/10.1006/obhd.1998.2803\n\n\nThaler, R. (1981). Some empirical evidence on dynamic inconsistency. Economics Letters, 8(3), 201–207. https://doi.org/10.1016/0165-1765(81)90067-7",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Exponential discounting anomalies</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/present-bias.html",
    "href": "intertemporal-choice/present-bias.html",
    "title": "24  Present bias",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Present bias</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/present-bias.html#summary",
    "href": "intertemporal-choice/present-bias.html#summary",
    "title": "24  Present bias",
    "section": "",
    "text": "Present bias is a concept developed to account for anomalies in the exponential discounting model, where people place additional weight on costs and benefits in the present.\nThe \\beta\\delta model, also known as quasi-hyperbolic discounting, uses two discount factors: \\beta for short-term discounting and \\delta for long-term discounting.\nIn the \\beta\\delta model, all future payoffs are discounted by \\beta\\delta once, and then by \\delta for each additional period of delay, resulting in a larger discount for the first period than subsequent periods.\nPresent bias can lead to time inconsistency, where decisions made at one point may be reversed later if given the opportunity to change.\nThe \\beta\\delta model maintains assumptions of consumption independence, stationary preferences, and utility independence from the exponential discounting model.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Present bias</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/present-bias.html#introduction",
    "href": "intertemporal-choice/present-bias.html#introduction",
    "title": "24  Present bias",
    "section": "24.1 Introduction",
    "text": "24.1 Introduction\nOne concept developed to account for anomalies in the exponential discounting model is present bias.\nPresent bias occurs when we place additional weight on costs and benefits at the present time.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Present bias</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/present-bias.html#the-betadelta-beta-delta-model",
    "href": "intertemporal-choice/present-bias.html#the-betadelta-beta-delta-model",
    "title": "24  Present bias",
    "section": "24.2 The \\beta\\delta (beta-delta) model",
    "text": "24.2 The \\beta\\delta (beta-delta) model\nOne simple model of present bias is the quasi-hyperbolic discounting model, otherwise known as the \\beta\\delta model. 1\nUnder the quasi-hyperbolic discounting model, two discount factors are applied to future costs and benefits.\nThe first is \\beta (beta), the short-term discount factor. All future payoffs are discounted by a single application of \\beta, a number between 0 and 1. The discount \\beta is applied simply because the payoff is not immediate. The higher the short-term discount factor, the less the agent discounts payoffs that are not received now.\nThe second is the discount factor \\delta that is also present in the exponential discounting model. Each additional period of delay results in a discount of a future cost or benefit by a factor of \\delta. The discount factor \\delta is also a number between 0 and 1. The higher the discount factor, the less the agent discounts future costs and benefits.\nAs for exponential discounting, an agent with a choice between alternative streams of payoffs under the \\beta\\delta model will seek to maximize the discounted utility of the future path of consumption.\nThe following equation provides a mathematical representation of the \\beta\\delta model, with a stream of costs or benefits x_0 through to x_T incurred at periods 0 through to T. U_0 is the discounted utility of the stream of payoffs at time t=0. x_t is the payoff in period t.\n\\begin{align*}\nU_0&=u(x_0)+\\beta \\delta u(x_1)+\\beta \\delta^2 u(x_2)+ ... + \\beta \\delta^T u(x_T) \\\\[6pt]\n&=u(x_0)+\\beta \\sum_{t=1}^{t=T}\\delta^t u(x_t) \\\\\n\\\\\n0&\\leq \\delta \\leq 1 \\\\\n\\\\\n0&\\leq \\beta \\leq 1\n\\end{align*}\nThe first period of delay results in a discount of the cost or benefit by a factor of \\beta\\delta. Each further period of delay results in a discount of \\delta.\nAs a result, the degree of discounting evolves over time as 1, \\beta\\delta, \\beta\\delta^2, \\beta\\delta^3, \\beta\\delta^4 and so on. This progression results in a larger discount for the first period of delay (\\beta\\delta) than the degree of discount for each subsequent period of delay (\\delta). There is a relative weighting toward the present.\nPresent bias of this nature can result in time inconsistency, with decisions at one point reversed at another if the agent is given the opportunity to change their mind.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Present bias</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/present-bias.html#visualising-present-bias",
    "href": "intertemporal-choice/present-bias.html#visualising-present-bias",
    "title": "24  Present bias",
    "section": "24.3 Visualising present bias",
    "text": "24.3 Visualising present bias\nThe following figures illustrate the effect of present bias.\nFigure 24.1 plots the size of the discount as a function of t for a present-biased agent with \\beta=0.75 and \\delta=0.9. The discount curve for an exponential discounter with \\delta=0.9 is also plotted. The curve for the present-biased agent has a large drop for the first period of delay. From then on, the discount is proportionally the same as for the exponential discounter.\nWe can read off the total discount factor at any time t from this chart. For example, the total discount factor for the exponential discounter is 0.9 at t=1, 0.81 at t=2 and 0.43 at t=8. The total discount factor for the present-biased agent is 0.675 at t=1, 0.61 at t=2 and 0.32 at t=8.\n\n\nCode\n##Load the ggplot2 package\nlibrary(ggplot2)\nlibrary(tidyr)\n\n#Define the agent's discount factors\nagents &lt;- data.frame(\n  agent_id = 1:2,\n  beta = c(1, 0.75),\n  delta = c(0.9, 0.9)\n)\n\n#Define the number of periods\nt &lt;- 0:10\n\n# Define the discount function using agents data frame\ndiscount &lt;- function(agent_id, t) {\n  beta &lt;- agents$beta[agent_id]\n  delta &lt;- agents$delta[agent_id]\n  ifelse(t==0, 1, beta * delta^t)\n}\n\n#data frame with three rows: t, discount(1, t) and discount(2, t)\ndiscounted &lt;- data.frame(t, discount(1, t), discount(2, t))\n\ncolnames(discounted) &lt;- c(\"t\",\"exponential\",\"present_bias\")\n\ndiscounted &lt;- pivot_longer(discounted, cols = -t, names_to = \"delta\", values_to = \"discount\")\n\n#Plot the discount function with curves for each of the two values of delta using ggplot2\nggplot(discounted, aes(x=t, y=discount, group=delta, linetype=delta)) +\n    geom_line() +\n    labs(x=\"t\", y=\"Discount\") +\n    theme_minimal() +\n    scale_x_continuous(breaks=1:10) +\n    scale_y_continuous(breaks=seq(0, 1, 0.1)) +\n    geom_vline(xintercept = 0, linewidth=0.25)+ \n    geom_hline(yintercept = 0, linewidth=0.25)+\n\n    #set vertical lines only at integer values of t\n    theme(panel.grid.minor = element_blank())+\n\n    # remove legend title, change legend item from \"present_bias\" to \"present bias\"\n    theme(legend.title=element_blank())+\n    scale_linetype_manual(values=c(\"solid\", \"dashed\"), labels=c(\"exponential\", \"present bias\"))\n\n\n\n\n\nFigure 24.1: Exponential versus present bias discount curves\n\n\n\n\n\n\n\n\nFigure 24.2 shows the discount curve for present-biased and exponential discounting agents with different parameters. The present-biased agent and exponential discounter have the same discount factor \\delta=0.75. The present-biased agent also has the short-term discount factor \\beta=0.75. Again, the present-biased agent discounts the first period of delay more than the exponential discounter.\n\n\nCode\n##Load the ggplot2 package\nlibrary(ggplot2)\nlibrary(tidyr)\n\n#Define the agent's discount factors\nagents &lt;- data.frame(\n  agent_id = 1:2,\n  beta = c(1, 0.75),\n  delta = c(0.75, 0.75)\n)\n\n#Define the number of periods\nt &lt;- 0:10\n\n# Define the discount function using agents data frame\ndiscount &lt;- function(agent_id, t) {\n  beta &lt;- agents$beta[agent_id]\n  delta &lt;- agents$delta[agent_id]\n  ifelse(t==0, 1, beta * delta^t)\n}\n\n#data frame with three rows: t, discount(1, t) and discount(2, t)\ndiscounted &lt;- data.frame(t, discount(1, t), discount(2, t))\n\ncolnames(discounted) &lt;- c(\"t\",\"exponential\",\"present_bias\")\n\ndiscounted &lt;- pivot_longer(discounted, cols = -t, names_to = \"delta\", values_to = \"discount\")\n\n#Plot the discount function with curves for each of the two values of delta using ggplot2\nggplot(discounted, aes(x=t, y=discount, group=delta, linetype=delta)) +\n    geom_line() +\n    labs(x=\"t\", y=\"Discount\") +\n    theme_minimal() +\n    scale_x_continuous(breaks=1:10) +\n    scale_y_continuous(breaks=seq(0, 1, 0.1)) +\n    geom_vline(xintercept = 0, linewidth=0.25)+ \n    geom_hline(yintercept = 0, linewidth=0.25)+\n\n    #set vertical lines only at integer values of t\n    theme(panel.grid.minor = element_blank())+\n\n    # remove legend title, change legend item from \"present_bias\" to \"present bias\"\n    theme(legend.title=element_blank())+\n    scale_linetype_manual(values=c(\"solid\", \"dashed\"), labels=c(\"exponential\", \"present bias\"))\n\n\n\n\n\nFigure 24.2: Exponential versus present bias discount curves - higher discount rate\n\n\n\n\n\n\n\n\nFigure 24.3 shows a scenario where the present-biased agent has a higher discount factor \\delta=0.9 than the exponential discounter with \\delta=0.75. The present-biased agent also has the short-term discount factor \\beta=0.75. The present-biased agent discounts the first period of delay more than the exponential discounter. However, due to their higher \\delta, the present-biased agent discounts additional periods of delay less than the exponential discounter and ultimately has a lower total discount for periods further in the future.\n\n\nCode\n##Load the ggplot2 package\nlibrary(ggplot2)\nlibrary(tidyr)\n\n#Define the agent's discount factors\nagents &lt;- data.frame(\n  agent_id = 1:2,\n  beta = c(1, 0.75),\n  delta = c(0.75, 0.9)\n)\n\n#Define the number of periods\nt &lt;- 0:10\n\n# Define the discount function using agents data frame\ndiscount &lt;- function(agent_id, t) {\n  beta &lt;- agents$beta[agent_id]\n  delta &lt;- agents$delta[agent_id]\n  ifelse(t==0, 1, beta * delta^t)\n}\n\n#data frame with three rows: t, discount(1, t) and discount(2, t)\ndiscounted &lt;- data.frame(t, discount(1, t), discount(2, t))\n\ncolnames(discounted) &lt;- c(\"t\",\"exponential\",\"present_bias\")\n\ndiscounted &lt;- pivot_longer(discounted, cols = -t, names_to = \"delta\", values_to = \"discount\")\n\n#Plot the discount function with curves for each of the two values of delta using ggplot2\nggplot(discounted, aes(x=t, y=discount, group=delta, linetype=delta)) +\n    geom_line() +\n    labs(x=\"t\", y=\"Discount\") +\n    theme_minimal() +\n    scale_x_continuous(breaks=1:10) +\n    scale_y_continuous(breaks=seq(0, 1, 0.1)) +\n    geom_vline(xintercept = 0, linewidth=0.25)+ \n    geom_hline(yintercept = 0, linewidth=0.25)+\n\n    #set vertical lines only at integer values of t\n    theme(panel.grid.minor = element_blank())+\n\n    # remove legend title, change legend item from \"present_bias\" to \"present bias\"\n    theme(legend.title=element_blank())+\n    scale_linetype_manual(values=c(\"solid\", \"dashed\"), labels=c(\"exponential\", \"present bias\"))\n\n\n\n\n\nFigure 24.3: Exponential versus present bias discount curves - different delta",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Present bias</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/present-bias.html#assumptions",
    "href": "intertemporal-choice/present-bias.html#assumptions",
    "title": "24  Present bias",
    "section": "24.4 Assumptions",
    "text": "24.4 Assumptions\nThe exponential discounting model is underpinned by many assumptions. These include:\n\nTime consistency, whereby once the agent starts moving along the consumption path, they are time-consistent with their initial plan.\nConsumption independence, whereby utility in period t+k is independent of consumption in any other period. An outcome’s utility is unaffected by outcomes in prior or future periods.\nStationary preferences, whereby U_t=U_{t+k}. The utility function is stationary across periods.\nUtility independence, whereby all that matters is maximising the sum of discounted utilities. Decision makers are assumed to have no preference for the distribution of utilities.\n\nUnder the \\beta\\delta model, we are loosening the assumption of time consistency. An agent may change their initial plan over time.\nHowever, we maintain the assumptions of consumption independence, stationary preferences and utility independence.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Present bias</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/present-bias.html#footnotes",
    "href": "intertemporal-choice/present-bias.html#footnotes",
    "title": "24  Present bias",
    "section": "",
    "text": "This model is a discrete-time version of hyperbolic discounting.↩︎",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Present bias</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/present-bias-examples.html",
    "href": "intertemporal-choice/present-bias-examples.html",
    "title": "25  Present bias examples",
    "section": "",
    "text": "25.1 Summary",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Present bias examples</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/present-bias-examples.html#summary",
    "href": "intertemporal-choice/present-bias-examples.html#summary",
    "title": "25  Present bias examples",
    "section": "",
    "text": "The following examples illustrate the contrast between exponential discounters’ time-consistent choices and present-biased agents’ time-inconsistent decisions when faced with immediate versus future rewards.\nThe use of graphical representations to visualise how present bias affects the relative attractiveness of rewards over time, particularly when the short-term discount factor no longer applies, can be used to illustrate choice and preference reversal.\nThe following examples illustrate that:\n\nThe \\beta\\delta model creates a “kink” in the discounting curve, with a steeper discount for the immediate future due to the short-term discount factor \\beta.\nPresent-biased agents may choose smaller-sooner rewards when available immediately, but larger-later rewards when both options are in the future.\nPresent bias has practical implications in financial decision-making, demonstrated through scenarios such as loan repayment choices.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Present bias examples</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/present-bias-examples.html#introduction",
    "href": "intertemporal-choice/present-bias-examples.html#introduction",
    "title": "25  Present bias examples",
    "section": "25.2 Introduction",
    "text": "25.2 Introduction\nIn the section, I provide some simple examples of the \\beta\\delta model.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Present bias examples</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/present-bias-examples.html#exponential-discounting-versus-present-bias",
    "href": "intertemporal-choice/present-bias-examples.html#exponential-discounting-versus-present-bias",
    "title": "25  Present bias examples",
    "section": "25.3 Exponential discounting versus present bias",
    "text": "25.3 Exponential discounting versus present bias\nFor the first example, we will consider the following pair of choices presented to an exponential discounting agent and a present-biased agent and contrast their decisions.\nChoice 1: Would you like $100 today or $110 next week?\nChoice 2: Would you like $100 next week or $110 in two weeks?\n\n25.3.1 The exponential discounter\nThe exponential discounter has \\delta=0.95 and utility each period of u(x_n)=x_n.\nWould the exponential discounter prefer $100 today (t=0) or $110 next week (t=1)?\nWhen we worked through this problem in Section 22.2, we calculated that:\n\nU_0(0,\\$100)=100&lt;104.5=U_0(1,\\$110)\n\nThe exponential discounter will prefer to receive $110 next week as it leads to higher discounted utility.\nChoice 2: Would the exponential discounter prefer $100 next week (t=1) or $110 in two weeks (t=2)?\nWhen we worked through this problem in Section 22.2, we calculated that:\n\nU_0(1,\\$100)=95&lt;99.275=U_0(2,\\$110)\n\nThe exponential discounter will prefer to receive $110 in two weeks.\nThe set of decisions across Choice 1 and Choice 2 are time consistent. If the exponential-discounting agent selected $110 in two weeks for Choice 2 and was given a chance to change their choice after one week (which is effectively an offer of Choice 1), they would not change their decision.\n\n\n25.3.2 The present-biased agent\nThe present biased agent has \\delta=0.95, \\beta=0.95 and utility each period of u(x_n)=x_n.\nChoice 1: Would this agent prefer $100 today (t=0) or $110 next week (t=1)?\nThe discounted utility of the $100 today is:\n\\begin{align*}\nU_0(0,\\$100)&=u(\\$100)\\\\[6pt]\n&=100\n\\end{align*}\nThe discounted utility of the $110 next week is:\n\\begin{align*}\nU_0(1,\\$110)&=u(x_0)+\\beta u(x_1) \\\\[6pt]\n&=\\beta\\delta u(\\$110) \\\\[6pt]\n&=0.95\\times 0.95\\times 110 \\\\[6pt]\n&=99.275\n\\end{align*}\nAs U_0(0,\\$100) &gt; U_0(1,\\$110), the present-biased agent will prefer to receive $100 this week.\nChoice 2: Would this present-biased agent prefer $100 next week (t=1) or $110 in two weeks (t=2)?\nThe discounted utility of the $100 next week is:\n\\begin{align*}\nU_0(1,\\$100)&=u(x_0)+\\beta u(x_1)+\\beta\\delta^2 u(x_2) \\\\[6pt]\n&=\\beta\\delta u(\\$100) \\\\[6pt]\n&=0.95\\times 0.95\\times 100 \\\\[6pt]\n&=90.25\n\\end{align*}\nThe discounted utility of the $110 in two weeks is:\n\\begin{align*}\nU_0(2,\\$110)&=u(x_0)+\\beta u(x_1)+\\beta\\delta^2 u(x_2) \\\\[6pt]\n&=\\beta\\delta^2 u(\\$110) \\\\[6pt]\n&=0.95\\times 0.95^2\\times 110 \\\\[6pt]\n&=94.31\n\\end{align*}\nAs U_0(1,\\$100)=90.25&lt;94.31=U_0(2,\\$110), the present-biased agent will prefer to receive $110 in two weeks.\nIf we consider those two choices by the present-biased agent together, we see the following pattern.\nFor choice 1, the present-biased agent will prefer $100 now to $110 in one week. Their preference for benefits now due to the short-term discount factor \\beta leads them to prefer the immediate payoff.\nFor choice 2, the present-biased agent will prefer $110 in two weeks to $100 in one week. They are willing to wait longer for a larger reward, with both outcomes in the future and subject to the short-term discount factor \\beta.\nConsider what would happen if this present-biased agent selected the $110 in two weeks in Choice 2, but after one week we asked if they would like to reconsider their choice. They are effectively being offered Choice 1. This would then lead them to change their mind and take the immediate $100.\nThis combination of decisions is time inconsistent. The present-biased agent’s actions are not consistent with their initial plan.\nWe can see this change in preference in the following diagram.\nThe vertical bars represent the payments of $100 and $110. The lines projecting back from the bars to the y-axis represent the discounted utility of each payment at each time.\nThere is a kink in the line projecting from the $110 in two weeks, representing the effect of the short-term discount factor \\beta. Between t=1 and t=2 both the short-term and usual discount factors are applied. This leads to that part of the curve having a steeper slope than between t=0 and t=1 where only the usual discount factor is applied.\nAt t=0 the discounted utility of the $110 at t=2 is higher and that payment is therefore preferred. At t=1 when the $100 is no longer discounted by the short-term discount factor \\beta, it suddenly becomes more attractive. If offered on that day, would be chosen in substitute of the $110 due in another week.\n\n\nCode\n# Create a function to create the discounted bar chart\nlibrary(ggplot2)\n\n# Helper function to create discounted values\ncreate_discount_data &lt;- function(value, t, beta, delta, start) {\n  times &lt;- seq(start, t, by = 1)\n  data.frame(\n    t = times,\n    group = as.character(t),\n    value = ifelse(t==times, value, value * beta * delta^(t - times))\n  )\n}\n\n# Main function to create the discounted bar chart\ncreate_discounted_bar_chart &lt;- function(smaller, t_s, larger, t_l, beta, delta, starting_at = 0, y_spacing = 20, x_spacing = 1) {\n  # Create the data\n  data &lt;- data.frame(\n    t = c(t_s, t_l),\n    U_t = c(smaller, larger)\n  )\n  \n  # Create the discounted values, starting from 'starting_at'\n  discounted_data &lt;- rbind(\n    create_discount_data(smaller, t_s, beta, delta, starting_at),\n    create_discount_data(larger, t_l, beta, delta, starting_at)\n  )\n  \n  # Shift t values based on starting_at\n  data$t_plot &lt;- data$t - starting_at\n  discounted_data$t_plot &lt;- discounted_data$t - starting_at\n  \n  # Filter out any data points before the starting point\n  data &lt;- data[data$t &gt;= starting_at, ]\n  discounted_data &lt;- discounted_data[discounted_data$t &gt;= starting_at, ]\n  \n  # Determine x-axis and y-axis limits\n  x_min &lt;- 0\n  x_max &lt;- max(max(data$t_plot), max(discounted_data$t_plot))\n  y_max &lt;- max(max(data$U_t), max(discounted_data$value)) * 1.1  # 10% buffer\n  \n  # Create the plot\n  ggplot() +\n    # Add the bars\n    geom_rect(data = data, aes(xmin = ifelse(t_plot == 0, 0, t_plot - 0.15),\n                               xmax = ifelse(t_plot == 0, 0.15, t_plot + 0.15),\n                               ymin = 0, ymax = U_t),\n              fill = \"white\", color = \"black\") +\n    \n    # Add the discount lines\n    geom_line(data = discounted_data, aes(x = t_plot, y = value, group = group, linetype = group), \n              color = \"black\", linewidth = 1) +\n    \n    # Customize the plot\n    scale_x_continuous(breaks = seq(x_min, x_max + 1, by = x_spacing), \n                       limits = c(x_min, x_max + 1),\n                       expand = c(0, 0),\n                       labels = function(x) x + starting_at) +\n    scale_y_continuous(breaks = seq(0, y_max, by = y_spacing), \n                       limits = c(0, y_max),\n                       expand = c(0, 0)) +\n    geom_vline(xintercept = 0, linewidth = 0.25) + \n    geom_hline(yintercept = 0, linewidth = 0.25) +\n    labs(x = \"t\",\n         y = expression(U[t])) +\n    theme_minimal() +\n    theme(\n      axis.title.y = element_text(angle = 0, vjust = 0.5),\n      panel.grid.major = element_blank(),\n      panel.grid.minor = element_blank(),\n      legend.position = \"none\"\n    )\n}\n\n\n\n\nCode\ncreate_discounted_bar_chart(100, 1, 110, 2, 0.95, 0.95)\n\n\n\n\n\nFigure 25.1: $100 next week or $110 in two weeks?",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Present bias examples</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/present-bias-examples.html#a-longer-delay",
    "href": "intertemporal-choice/present-bias-examples.html#a-longer-delay",
    "title": "25  Present bias examples",
    "section": "25.4 A longer delay",
    "text": "25.4 A longer delay\nAssume there is a present-biased agent with \\beta=0.75, \\delta=0.9 and utility each period of u(x_n)=x_n.\nWould this agent prefer $10 in five days (t=5) or $20 in 10 days (t=10)?\nThe discounted utility of the $10 in five days is:\n\\begin{align*}\nU_0(5,\\$10)&=\\beta\\delta^5u(\\$10) \\\\[6pt]\n&=0.75\\times 0.9^5\\times 10 \\\\[6pt]\n&=4.43\n\\end{align*}\nThe discounted utility of the $20 in 10 days is:\n\\begin{align*}\nU_0(10,\\$20)&=\\beta\\delta^{10} u(\\$20) \\\\[6pt]\n&=0.75\\times 0.9^{10}\\times 20 \\\\[6pt]\n&=5.23\n\\end{align*}\nAs U_0(5,\\$10)=4.43&lt;5.23=U_0(10,\\$20), this present-biased agent will prefer to receive $20 in 10 days.\nFive days pass so we are now at t=5. We ask the agent if they would like to change their mind.\nThe discounted utility of the $10 today is:\n\\begin{align*}\nU_5(5,\\$10)&=u(\\$10) \\\\[6pt]\n&=10\n\\end{align*}\nThe discounted utility of the $20 in five days is:\n\\begin{align*}\nU_5(10,\\$20)&=\\beta\\delta^5 u(\\$20) \\\\[6pt]\n&=0.75\\times 0.9^5\\times 20 \\\\[6pt]\n&=8.86\n\\end{align*}\nAs U_5(5,\\$10)=10&gt;8.86=U_5(10,\\$20), this present-biased agent will prefer to receive $10 today. They have changed their preference between the two payments relative to their decision at t=0.\nWe can see this change in preference in the following diagram.\nThe vertical bars represent the payments of $10 and $20. The lines projecting back from the bars to the y-axis represent the discounted utility of each payment at each time. There is a kink in the line in the period immediately before each payment, representing the effect of the short-term discount factor \\beta.\nAt t=0 (and through to t=4) the discounted utility of the $20 at t=10 is higher and that payment is therefore preferred. At t=5 when the $10 is no longer discounted by the short-term discount factor \\beta, it suddenly becomes more attractive. If offered on that day, would be chosen in substitute of the $20 due in another five days.\n\n\nCode\ncreate_discounted_bar_chart(10, 5, 20, 10, 0.75, 0.9, y_spacing = 5)\n\n\n\n\n\nFigure 25.2: $10 in five days or $20 in 10 days?",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Present bias examples</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/present-bias-examples.html#paying-a-loan",
    "href": "intertemporal-choice/present-bias-examples.html#paying-a-loan",
    "title": "25  Present bias examples",
    "section": "25.5 Paying a loan",
    "text": "25.5 Paying a loan\nCharlie is a naive present-biased agent with \\beta=0.5, \\delta=0.95 and u(x)=x.\nCharlie loaned $100 to Carol. Carol is due to pay Charlie back in 7 days (at t=7). Carol tells Charlie that she would prefer to pay him back later, and offers $200 in 14 days (at t=14) if he is willing to wait. Charlie is considering whether to accept Carol’s offer.\n(a) What does Charlie choose at t=0?\nTo determine what Charlie chooses at t=0, we need to compare the discounted utility of the two options.\nThe discounted utility of $100 at t=7 is:\n\\begin{align*}\nU_0(7,100)&=0.5\\times 0.95^7 \\times 100 \\\\\n&=34.92\n\\end{align*}\nThe discounted utility of $200 at t=14 is:\n\\begin{align*}\nU_0(14,200)&=0.5\\times 0.95^{14} \\times 200 \\\\\n&=48.77\n\\end{align*}\nCharlie chooses the option with the highest discounted utility, which is $200 at t=14.\n(b) At t=7 Charlie considers whether he should now demand payment of $100 at t=7 rather than wait for payment of $200 at t=14. What does Charlie choose at t=7?\nTo determine what Charlie chooses at t=7, we need to compare the discounted utility of the two options.\nThe discounted utility of $100 at t=7 is:\n\\begin{align*}\nU_7(7,100)&=0.95^0 \\times 100 \\\\\n&=100\n\\end{align*}\nThe discounted utility of $200 at t=14 is:\n\\begin{align*}\nU_7(14,200)&=0.5\\times 0.95^7 \\times 200 \\\\\n&=69.83\n\\end{align*}\nCharlie chooses the option with the highest discounted utility, which is $100 at t=7. He has changed his mind. This is because the sum at t=7 is no longer subject to the short-term discount factor \\beta.\n(c) Draw a graph illustrating Charlie’s choices.\nThe following chart shows each of the two options presented to Charlie, $100 at t=7 and $200 at t=14. The line extended from each back to t=0 represents the the discounted utility of each option at time t.\nIt can be seen that from t=0 to t=6, the discounted utility of $200 at t=14 is higher than the discounted utility of $100 at t=7. However, at t=7, the discounted utility of $100 at t=7 is higher than the discounted utility of $200 at t=14. Hence Charlie changes his mind.\n\n\nCode\ncreate_discounted_bar_chart(100, 7, 200, 14, 0.5, 0.95)\n\n\n\n\n\nFigure 25.3: Paying a loan",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Present bias examples</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/sophisticated-present-bias.html",
    "href": "intertemporal-choice/sophisticated-present-bias.html",
    "title": "26  Sophisticated present bias",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Sophisticated present bias</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/sophisticated-present-bias.html#summary",
    "href": "intertemporal-choice/sophisticated-present-bias.html#summary",
    "title": "26  Sophisticated present bias",
    "section": "",
    "text": "Present-biased agents can be categorised as naive or sophisticated, based on their awareness of future preference reversals.\nNaive agents incorrectly believe their future selves will discount rewards consistently, leading to time-inconsistent choices.\nSophisticated agents accurately predict their future preference reversals and plan accordingly.\nNaive agents use forward reasoning in decision-making, while sophisticated agents use backward reasoning.\nThe following examples show that the decision-making processes of naive and sophisticated agents can lead to different choices, even with identical discount factors.\nSophisticated agents may sometimes choose worse immediate outcomes to avoid even worse future outcomes due to anticipated preference reversals. They tend to take action earlier than naive agents, a behaviour known as “prepoperation”.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Sophisticated present bias</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/sophisticated-present-bias.html#introduction",
    "href": "intertemporal-choice/sophisticated-present-bias.html#introduction",
    "title": "26  Sophisticated present bias",
    "section": "26.1 Introduction",
    "text": "26.1 Introduction\nSuppose a present-biased agent considers whether they prefer a smaller, sooner payoff or a larger, later payoff. They decide they will wait for the larger, later payoff. Time passes until the smaller pay-off becomes immediately available. They change their mind and take the smaller payoff.\nWhy did the agent initially choose the larger payoff when they would take the smaller payoff? Were they aware of the likely outcome of their preferences? If they were aware, they might anticipate changing their mind and plan accordingly.\nFor many of us, we are aware that we make time-inconsistent decisions. We know that we often cave when faced with immediate temptation. Even if we don’t plan to eat a whole packet of cookies for dinner, have more than one beer, or stay up late watching just one more episode, we often do.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Sophisticated present bias</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/sophisticated-present-bias.html#naïve-and-sophisticated-present-biased-agents",
    "href": "intertemporal-choice/sophisticated-present-bias.html#naïve-and-sophisticated-present-biased-agents",
    "title": "26  Sophisticated present bias",
    "section": "26.2 Naïve and sophisticated present-biased agents",
    "text": "26.2 Naïve and sophisticated present-biased agents\nTo bring the idea that we are aware of our present bias into the analysis, I will distinguish between two types of present-biased agents: naive and sophisticated.\nConsider how a present-biased agent discounts a payoff for each successive period of delay under the \\beta\\delta model. The first period of delay results in the application of a total discount factor of \\beta\\delta. Each additional period of delay results in the application of an additional discount factor of \\delta. The discount factor applied for the first period of delay is relatively smaller - or the magnitude of the discount relatively greater - than the additional discount applied for any additional period of delay.\n\nA naive present-biased agent believes that the relative difference in discount between periods that they can see today will persist as time passes. That is, they believe that the discount factor of \\delta applied between, say, periods 2 and 3, will still be the relative discount when they reach period 2.\n\nHowever, when period 2 does arrive, the outcome in period 3 will be discounted by both the short-term discount factor \\beta and the usual discount factor \\delta, compared to no discount for the outcome in period 2. As a result, the relative discount of outcomes at different times will change when one of those outcomes becomes due today.\n\nA sophisticated present-biased agent correctly believes that they will apply both the short-term and usual discount factors in the future. As a result, they understand that the relative discount of different outcomes will change when one of those outcomes becomes due today. They understand that if faced with the temptation to take benefits or to delay costs, they will do so.\nA sophisticated and naive person can make different decisions despite having the same level of impatience, \\delta, and the same level of present bias, \\beta. Any difference emerges in the way that they reason through an intertemporal choice.\nThe naive agent makes their plans by forward reasoning, starting from today.\n\nFirst, they decide their preferred option for today, period 0, believing that they will stick to their plan in the future.\n\n\n\nWhen they move to the next period they recompute their plan, again believing they will stick to the plan once they move to the next period.\n\n\n\nThey repeat this process as they move through time.\n\n\nIn contrast, the sophisticated present-biased agent makes their plans by backward reasoning, starting from the final period.\n\nFor that final period, they solve for the preferred action.\n\n\n\nThey then consider one period earlier and solve for the preferred action, accounting for the previous decision. This means, that if they calculate that they will cave into temptation at a certain time, they will remove the option to resist from their choice set. Absent the ability to commit to an action, they will resign themselves to giving into temptation in advance.\n\n\n\nThey repeat this process as they move back to today.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Sophisticated present bias</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/sophisticated-present-bias.html#examples",
    "href": "intertemporal-choice/sophisticated-present-bias.html#examples",
    "title": "26  Sophisticated present bias",
    "section": "26.3 Examples",
    "text": "26.3 Examples\n\n\nThe difference between naive and sophisticated present-biased agents is best illustrated through examples.\n\n26.3.1 $100 next week or $110 in two weeks\nFor the first example, suppose we have a naive and a sophisticated present-biased agent, each with \\beta=0.95, \\delta=0.95 and utility each period of u(x_n)=x_n.\nWe offer them both the following choice.\n\nWould you like $100 next week or $110 in two weeks?\n\nWe also tell them that we will allow them to reconsider their decision next week.\nWhen the naive present-biased agent considers this problem, they simply compare the discounted utility of each payoff from the perspective of today.\nThe discounted utility of the $100 next week is:\n\\begin{align*}\nU_0(1,\\$100)&=\\beta u(x_1) \\\\[6pt]\n&=\\beta\\delta u(\\$100) \\\\[6pt]\n&=0.95\\times 0.95\\times 100 \\\\[6pt]\n&=90.25\n\\end{align*}\nThe discounted utility of the $110 in two weeks is:\n\\begin{align*}\nU_0(2,\\$110)&=\\beta\\delta^2 u(x_2) \\\\[6pt]\n&=\\beta\\delta^2 u(\\$110) \\\\[6pt]\n&=0.95\\times 0.95^2\\times 110 \\\\[6pt]\n&=94.31\n\\end{align*}\nAs U_0(1,\\$100)=90.25&lt;94.31=U_0(2,\\$110), at t=0 the present-biased agent will prefer to receive $110 in two weeks.\nBut this choice does accord with the naive agent’s preferences next week. Next week (at t=1) they will calculate utility of the $100 as:\n\\begin{align*}\nU_1(1,\\$100)&=u(x_1) \\\\[6pt]\n&=u(\\$100)\\\\[6pt]\n&=100\n\\end{align*}\nThe discounted utility of the $110 a week later is:\n\\begin{align*}\nU_1(2,\\$110)&=\\beta\\delta u(x_2) \\\\[6pt]\n&=\\beta\\delta u(\\$110) \\\\[6pt]\n&=0.95\\times 0.95\\times 110 \\\\[6pt]\n&=99.275\n\\end{align*}\nAs U_1(1,\\$100) &gt; U_1(2,\\$110), the present-biased agent will prefer to receive $100 immediately.\nAt t=0 their preference is inconsistent with what it will be next week at t=1.\nThe sophisticated present-biased agent will approach this decision differently. They consider it using backward induction.\nFirst, they will look at the choice they will face next week and calculate the discounted utility of each option as they will calculate it at that time.\nThat is, they calculate the discounted utility of the $100 at t=1 from the perspective of t=1.\n\\begin{align*}\nU_1(1,\\$100)&=u(x_1) \\\\[6pt]\n&=u(\\$100)\\\\[6pt]\n&=100\n\\end{align*}\nThey then calculate the discounted utility of the $110 at t=2 from the perspective of t=1.\n\\begin{align*}\nU_1(2,\\$110)&=\\beta\\delta u(x_2) \\\\[6pt]\n&=\\beta\\delta u(\\$110) \\\\[6pt]\n&=0.95\\times 0.95\\times 110 \\\\[6pt]\n&=99.275\n\\end{align*}\nAs U_1(1,\\$100) &gt; U_1(2,\\$110), the sophisticated agent sees that next week, at t=1 they will take the $100.\nThis is the same pair of calculations that the naive agent made at t=1. The difference is that the sophisticated agent makes this calculation at t=0 from the perspective of t=1. The naive agent does not consider this perspective until t=1.\nAfter considering their preference at t=1, the sophisticated agent then considers their choice at t=0. They see their future decision at t=1 and know that $110 in two weeks is not available to them. The only option they have is to choose $100 in one week. They effectively accept their future present bias now and choose the $100 in one week.\nIn this example, being naive or sophisticated does not change their final choice. It only changes their beliefs about their final decision over time. The sophisticated agent knows at t=0 what they will do at t=1. The naive agent is unaware that at t=1 they will make a decision inconsistent with their choice at t=0. We can summarise their decisions at each time as follows:\n\n\n\n\nNaive agent\nSophisticated agent\n\n\n\n\nt=0\n$110 at t=2\n$100 at t=1\n\n\nt=1\n$100 at t=1\n$100 at t=1\n\n\n\n\n\n26.3.2 Watching a movie\nSuppose we have a naive and a sophisticated present-biased agent, each with \\beta=0.5 and \\delta=1. They are present-biased, but beyond that present bias demonstrate no impatience.\nWe offer them the following choice.\n\nAn OK movie today (t=0) that gives utility of 6\nA good movie next week (t=1) that gives utility of 10\nA great movie in two weeks (t=2) that gives utility of 16\n\nWe also tell the agents that next week they will be offered an opportunity to change their minds.\nFirst, we consider the naive agent. They calculate utility from the perspective of today.\n\\begin{align*}\nU_0(0,\\text{OK})&=u(\\text{OK}) \\\\[6pt]\n&=6 \\\\\n\\\\\nU_0(1,\\text{good})&=\\beta\\delta u(\\text{good}) \\\\[6pt]\n&=0.5\\times 1\\times 10 \\\\[6pt]\n&=5 \\\\\n\\\\\nU_0(2,\\text{great})&=\\beta\\delta^2 u(\\text{great}) \\\\[6pt]\n&=0.5\\times 1^2\\times 16 \\\\[6pt]\n&=8\n\\end{align*}\nAs U_0(2,\\text{great})&gt;U_0(0,\\text{OK})&gt;U_0(1,\\text{good}), the naive agent will choose the great movie in two weeks.\nBut what then happens when the naive agent is given the chance to change their mind after one week?\n\\begin{align*}\nU_1(1,\\text{good})&=u(\\text{good}) \\\\[6pt]\n&=10 \\\\\n\\\\\nU_1(2,\\text{great})&=\\beta\\delta u(\\text{great}) \\\\[6pt]\n&=0.5\\times 1\\times 16 \\\\[6pt]\n&=8\n\\end{align*}\nAs U_1(1,\\text{good})&gt;U_1(2,\\text{great}), the naive agent will change their mind and watch the good movie immediately.\nWhat of our sophisticated agent?\nThey will make their decision today based on correct beliefs about their future preferences. To do this, they solve by backward induction. First, what will their decision be next week?\n\\begin{align*}\nU_1(1,\\text{good})&=u(\\text{good}) \\\\[6pt]\n&=10 \\\\\n\\\\\nU_1(2,\\text{great})&=\\beta\\delta u(\\text{great}) \\\\[6pt]\n&=0.5\\times 1\\times 16 \\\\[6pt]\n&=8\n\\end{align*}\nAs U_1(1,\\text{good})&gt;U_1(2,\\text{great}), the sophisticated agent can see that they will choose to watch the good movie immediately.\nKnowing this is the case, the sophisticated agent now decides whether they prefer the OK movie today or the good movie next week.\n\\begin{align*}\nU_0(0,\\text{OK})&=u(\\text{OK}) \\\\[6pt]\n&=6 \\\\\n\\\\\nU_0(1,\\text{good})&=\\beta\\delta u(\\text{good}) \\\\[6pt]\n&=0.5\\times 1\\times 10 \\\\[6pt]\n&=5 \\\\\n\\end{align*}\nAs U_0(0,\\text{OK})&gt;U_0(1,\\text{good}), the sophisticated agent prefers the OK movie today.\nFrom today’s perspective, the sophisticated agent would prefer the great movie in two weeks, but as they know they will cave in to their present bias next week and watch the good movie, they make today’s decision on that basis. They know that if they select the great movie today they won’t watch it.\n\n\n26.3.3 A library fine\nA naive present-biased agent has failed to return their library books and is fined at t=0. They can select one of the following payment schemes:\n(0,-\\$10), (1,-\\$15) or (2,-\\$25)\nThat is, they can pay $10 today, $15 at t=1 or $25 at t=2.\nThey are free to change the scheme over time as they see fit.\nThe agent’s utility is linear in money - that is, u(x_n)=x_n - with discount factors \\beta=0.5 and \\delta=1.\nThe naive agent calculates the utility of each option today.\n\\begin{align*}\nU_0(0,-\\$10)&=u(-\\$10) \\\\[6pt]\n&=-10 \\\\\n\\\\\nU_0(1,-\\$15)&=\\beta\\delta u(-\\$15) \\\\[6pt]\n&=0.5\\times 1\\times (-15) \\\\[6pt]\n&=-7.5 \\\\\n\\\\\nU_0(2,-\\$25)&=\\beta\\delta^2 u(-\\$25) \\\\[6pt]\n&=0.5\\times 1^2\\times (-25) \\\\[6pt]\n&=-12.5\n\\end{align*}\nAs U_0(1,-\\$15)&gt;U_0(0,-\\$10)&gt;U_0(2,-\\$25), the naive agent will choose to pay $15 at t=1.\nA week passes and the naive agent is now at t=1, the time when they were planning to pay the fine. The naive agent reconsiders their decision.\n\\begin{align*}\nU_1(1,-\\$15)&=u(-\\$15) \\\\[6pt]\n&=-15 \\\\\n\\\\\nU_1(2,-\\$25)&=\\beta\\delta u(-\\$25) \\\\[6pt]\n&=0.5\\times 1\\times (-25) \\\\[6pt]\n&=-12.5\n\\end{align*}\nAs U_1(2,-\\$25)=-12.5&gt;=-15=U_1(1,-\\$15), the naive agent changes their decision and further delays their payment. They now choose to pay $25 at t=2.\nWhen they reach t=2, they have no choice but to pay the $25.\nA sophisticated present-biased agent has also failed to return their library books and is fined at t=0. They can select one of the following payment schemes:\n(0,-\\$10), (1,-\\$15) or (2,-\\$25)\nThey are free to change the scheme over time as they see fit.\nThe sophisticated agent’s utility is linear in money u(x_n)=x_n, with discount factors \\beta=0.5 and \\delta=1.\nFor the sophisticated agent, we start calculating utility from the final period.\nAt t=2, they have no choice but to pay the $25.\nWhat of t=1?\n\\begin{align*}\nU_1(1,-\\$15)&=u(-\\$15) \\\\[6pt]\n&=-15 \\\\\n\\\\\nU_1(2,-\\$25)&=\\beta\\delta u(-\\$25) \\\\[6pt]\n&=0.5\\times 1\\times (-25) \\\\[6pt]\n&=-12.5\n\\end{align*}\nThe sophisticated agent can see that if they choose at t=1, they will choose to pay $25 at t=2.\nNow we iterate at t=0. The sophisticated agent only compares $10 at t=0 with $25 at t=2 because they know that at t=1 they will select $25 at t=2. They know that if they delay once they will delay again and end up paying the largest fine. Hence they limit their comparison to those outcomes that might occur:\n\\begin{align*}\nU_0(0,-\\$10)&=u(-\\$10) \\\\[6pt]\n&=-10 \\\\\n\\\\\nU_0(2,-\\$25)&=\\beta\\delta^2 u(-\\$25) \\\\[6pt]\n&=0.5\\times 1^2\\times (-25) \\\\[6pt]\n&=-12.5\n\\end{align*}\nAs U_0(0,-\\$10)&gt;U_0(2,-\\$25), the sophisticated agent will choose to pay $10 at t=0.\nIn the examples, we have seen two contrasting outcomes for the sophisticated agent.\nIn the movie example, they watch an OK movie today, rather than a good movie in one week or a great movie in two, because they knew that they would watch the good movie in one week if they delayed to watch the great movie. As a result, they watched an earlier, worse movie than the naive agent.\nIn the library fine example, they paid the lowest possible fine as they saw they would further delay paying the fine in the future, leading it to increase even more.\nThe sophisticated agent’s behaviour arises from two tensions:\n\nThey understand that they will not be able to wait for the optimal time.\nThey are present-biased so they prefer benefits today and costs delayed to the future.\n\nIn combination, these imply a sophisticated agent will generally take action earlier than the naive agent. They can “prepoperate”, which is doing something now when it would be better to wait.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Sophisticated present bias</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/commitment.html",
    "href": "intertemporal-choice/commitment.html",
    "title": "27  Commitment",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Commitment</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/commitment.html#summary",
    "href": "intertemporal-choice/commitment.html#summary",
    "title": "27  Commitment",
    "section": "",
    "text": "Sophisticated present-biased agents can foresee their future actions. This foresight allows them to use commitment devices - mechanisms that lock them into a course of action by changing the value or availability of future options.\nCommitment devices can work through three main channels:\n\nForcing the agent to maintain the optimal course of action.\nDepressing the value of the undesired action\nIncreasing the value of the optimal action\n\nThe following examples illustrate how these commitment devices work in practice:\n\nForcing optimal action: Buying a non-refundable movie ticket, Odysseus tying himself to the mast, and using lay-by schemes.\nDepressing the value of bad actions: Using platforms like stickK to impose penalties for failing to meet goals.\nIncreasing the value of optimal actions: Temptation bundling, such as pairing exercise with audiobooks or massages.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Commitment</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/commitment.html#introduction",
    "href": "intertemporal-choice/commitment.html#introduction",
    "title": "27  Commitment",
    "section": "27.1 Introduction",
    "text": "27.1 Introduction\nA sophisticated present-biased agent can foresee their future actions and adjust their decisions today based on their foresight.\nThis foresight provides an opportunity. By seeing their future selves fail, they can commit themselves to a course of action today that they would not otherwise be able to choose.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Commitment</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/commitment.html#commitment-device",
    "href": "intertemporal-choice/commitment.html#commitment-device",
    "title": "27  Commitment",
    "section": "27.2 Commitment device",
    "text": "27.2 Commitment device\nPeople often implement the opportunity to commit themselves to a course of action by using a commitment device.\nA commitment device is a mechanism that locks you into a course of action by changing the value or availability of future options.\nCommitment devices may work through the following channels:\n\nThey may depress the value of the bad course of action.\nThey may increase the value of the optimal course of action\nThey may force the agent to maintain the optimal course of action.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Commitment</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/commitment.html#commitment-examples",
    "href": "intertemporal-choice/commitment.html#commitment-examples",
    "title": "27  Commitment",
    "section": "27.3 Commitment examples",
    "text": "27.3 Commitment examples\nI will now illustrate those channels with examples.\n\n27.3.1 Forcing the optimal course of action\nA sophisticated present-biased agent with \\beta=0.5 and \\delta=1 is choosing between three movies, an OK movie, a good movie, and a great movie. The OK movie would give utility of 6, the good movie would give utility of 10, and the great movie would give utility of 16.\nThe problem is that only the OK movie is showing today (t=0). The good movie is showing next week (t=1), and the great movie is showing in two weeks (t=2).\nThe agent has enough money and time to watch only one movie. Should they watch the OK movie today or wait for the good or great movie?\nTo determine their action, they solve by backward induction.\nFirst, what will their decision be next week?\n\\begin{align*}\nU_1(1,\\text{good})&=u(\\text{good}) \\\\[6pt]\n&=10 \\\\[6pt]\n\\\\[6pt]\nU_1(2,\\text{great})&=\\beta\\delta u(\\text{great}) \\\\[6pt]\n&=0.5\\times 1\\times 16 \\\\[6pt]\n&=8\n\\end{align*}\nAs U_1(1,\\text{good})&gt;U_1(2,\\text{great}), the sophisticated agent can see that they will choose to watch the good movie immediately.\nKnowing this is the case, the sophisticated agent now decides whether they prefer the OK movie today or the good movie next week.\n\\begin{align*}\nU_0(0,\\text{OK})&=u(\\text{OK}) \\\\[6pt]\n&=6 \\\\[6pt]\n\\\\[6pt]\nU_0(1,\\text{good})&=\\beta\\delta u(\\text{good}) \\\\[6pt]\n&=0.5\\times 1\\times 10 \\\\[6pt]\n&=5\n\\end{align*}\nAs U_0(0,\\text{OK})&gt;U_0(1,\\text{good}), the sophisticated agent prefers the OK movie today.\nBut when they compare all three options at t=0, they would prefer the great movie in two weeks.\n\\begin{align*}\nU_0(2,\\text{great})&=\\beta\\delta^2 u(\\text{great}) \\\\[6pt]\n&=0.5\\times 1^2\\times 16 \\\\[6pt]\n&=8 \\\\[6pt]\n&\\geq 6=U_0(0,\\text{OK})\n\\end{align*}\nIt is only because they can foresee their future failing after one week that they don’t wait for the great movie.\nBut what if they could commit themselves today? For example, suppose they could purchase a non-refundable, non-resalable ticket to the great movie in two weeks. The result is that a sophisticated present-biased agent would buy a ticket to the great movie in two weeks and prevent their future self from changing their action.\n\n\n27.3.2 Forcing the optimal course of action: Odysseus\nAnother example of forcing the agent to maintain the optimal course of action is the story of Odysseus.\nOdysseus was required to sail past the sirens at t=1. At that time he can either jump off his ship to join the sirens (and die) or sail on past and live, having a great life at t=2.\nAs Odysseus is a sophisticated present-biased agent, he considers what he is likely to do at t=1. He realises that he will jump off the ship for the immediate benefit of joining the sirens at the loss of the longer-term discounted benefit of living.\nBut from the perspective of Odysseus today, at t=0, with both the benefits of the sirens and living in the future and therefore discounted, Odysseus would prefer to live. As a result, he decides to commit himself to that course of action by instructing his crew to tie him to the mast (plus leaving his ears unplugged so that he also gets some benefits from the siren song).\n\n\n27.3.3 Forcing the optimal course of action: lay-by\nSuppose a quasi-hyperbolic discounting agent with discount factors \\beta=1/2 and \\delta=1 wants a new jacket for work. They need to save for three months to purchase the jacket. But each month they save they forgo consumption that would boost their utility.\nThey receive the following payoffs for each action:\n\n\n\n\nt=0\nt=1\nt=2\n\n\n\n\nSave\n0\n0\n45\n\n\nSpend\n10\n10\n10\n\n\n\nFirst, consider what a naive quasi-hyperbolic discounting agent chooses.\nAt t=0, they calculate the discounted utility of each option.\n\\begin{align*}\nU_0(\\text{Save})&=0+\\beta\\delta \\times 0+\\beta\\delta^2\\times 45 \\\\[6pt]\n&=0.5\\times 45 \\\\[6pt]\n&=22.5 \\\\[6pt]\n\\\\[6pt]\nU_0(\\text{Spend})&=10+\\beta\\delta \\times 10+\\beta\\delta^2\\times 10 \\\\[6pt]\n&=10+0.5\\times 10+0.5\\times 10 \\\\[6pt]\n&=20\n\\end{align*}\nAt t=0, U_0(\\text{Save})&gt;U_0(\\text{Spend}). The agent plans to save for the jacket.\nOne month now passes. The agent has saved for a month. They could now spend their savings from last month and this month, giving a short-term boost, or keep saving for their jacket. The payoffs for each action are:\n\n\n\n\nt=1\nt=2\n\n\n\n\nSave\n0\n45\n\n\nStart spending at t=1\n20\n10\n\n\n\nAgain, the naive agent calculates the discounted utility of each option.\n\\begin{align*}\nU_1(\\text{Save})&=0+\\beta\\delta\\times 45 \\\\[6pt]\n&=0.5\\times 45 \\\\[6pt]\n&=22.5 \\\\[6pt]\n\\\\[6pt]\nU_1(\\text{Start spending at t=1})&=20+\\beta\\delta \\times 10 \\\\[6pt]\n&=20+0.5\\times 10 \\\\[6pt]\n&=25\n\\end{align*}\nAt t=1 spending now has the highest discounted utility. After saving for the first period, the agent spends despite initially wanting to save.\nNow let’s consider this problem from the point of view of a sophisticated present-biased agent. They see their full choice set as:\n\n\n\n\nt=0\nt=1\nt=2\n\n\n\n\nSave\n0\n0\n45\n\n\nStart spending at t=1\n0\n20\n10\n\n\nSpend\n10\n10\n10\n\n\n\nThe sophisticated agent works backward through time. At t=2, if they have saved, the agent will buy the jacket. Otherwise, the agent will spend.\nThe discounted utility of the options at t=1 is as follows:\n\\begin{align*}\nU_1(\\text{Save})&=0+\\beta\\delta\\times 45 \\\\[6pt]\n&=0.5\\times 45 \\\\[6pt]\n&=22.5 \\\\[6pt]\n\\\\[6pt]\nU_1(\\text{Start spending at }t=1)&=20+\\beta\\delta \\times 10 \\\\[6pt]\n&=20+0.5\\times 10 \\\\[6pt]\n&=25\n\\end{align*}\nAs U_1(\\text{Start spending at }t=1)&gt;U_1(\\text{Save}), the sophisticated agent would spend.\nThe sophisticated agent now knows that saving for the jacket is not available to them as they will spend at t=1 regardless of their initial action. There was no need to consider the option to start spending at t=0 as if they had spent then there is no other choice at t=1.\nThe sophisticated agent now chooses between the two feasible options at t=0:\n\\begin{align*}\nU_0(\\text{Start spending at }t=1)&=0+\\beta\\delta \\times 20+\\beta\\delta^2\\times 10 \\\\[6pt]\n&=0.5\\times 20+0.5\\times 10 \\\\[6pt]\n&=15 \\\\[6pt]\n\\\\[6pt]\nU_0(\\text{Spend})&=10+\\beta\\delta \\times 10+\\beta\\delta^2\\times 10 \\\\[6pt]\n&=10+0.5\\times 10+0.5\\times 10 \\\\[6pt]\n&=20\n\\end{align*}\nAs U_0(\\text{Spend})&lt;U_0(\\text{Start spending at }t=1), they start to spend at t=0. Contrast this with the naïve agent who chooses Save at t=0.\nNow consider what the sophisticated agent may do in the presence of lay-by. Lay-by involves paying a deposit and administrative fee toward the purchase of a product. You receive your purchase when you make payment in full later.\nFor payment of an administrative fee equivalent to 1 unit of utility and an initial deposit (the agent’s savings in t=0), the agent can reserve the jacket, preventing them from spending that money at t=2. The new set of options is:\n\n\n\n\nt=0\nt=1\nt=2\n\n\n\n\nSave\n0\n0\n45\n\n\nStart spending at t=1\n0\n20\n10\n\n\nSpend\n10\n10\n10\n\n\nLay-by\n-1\n0\n45\n\n\n\nThe lay-by option is strictly worse than Save. But what happens if lay-by is available to the sophisticated present-biased agent?\nAgain, working backward, at t=2, the agent buys the jacket if they have saved and otherwise spends.\nAt t=1, by the same logic we looked at previously, they spend if they can do so. That eliminates Save from their choice set.\nAt t=0, they now compare the feasible options:\n\\begin{align*}\nU_0(\\text{Start spending at }t=1)&=0+\\beta\\delta \\times 20+\\beta\\delta^2\\times 10 \\\\[6pt]\n&=0.5\\times 20+0.5\\times 10 \\\\[6pt]\n&=15 \\\\[6pt]\n\\\\[6pt]\nU_0(\\text{Spend})&=10+\\beta\\delta \\times 10+\\beta\\delta^2\\times 10 \\\\[6pt]\n&=10+0.5\\times 10+0.5\\times 10 \\\\[6pt]\n&=20 \\\\[6pt]\n\\\\[6pt]\nU_0(\\text{Lay-by})&=-1+\\beta\\delta \\times 0+\\beta\\delta^2\\times 45 \\\\[6pt]\n&=-1+0.5\\times 0+0.5\\times 45 \\\\[6pt]\n&=21.5\n\\end{align*}\nAs U_0(\\text{Lay-by})&gt;U_0(\\text{Spend})&gt;U_0(\\text{Start spending at }t=1), lay-by is the preferred option at t=0. As it binds the agent in the future, they can stick to this plan.\nNote that lay-by is strictly worse than Save as the agent must pay the administrative fee. But the sophisticated quasi-hyperbolic discounting agent chooses it as the only feasible way to get their jacket. Without lay-by they know they will start spending at t=1 and end up with lower utility from the perspective of their t=0 self.\n\n\n27.3.4 Depressing the value of the bad course of action\nstickK is a online platform that enables people to commit to future courses of action. stickK works as follows:\nFirst, you state a time-based goal, such as not smoking during the next month, losing 5kg over the next 90 days, or writing the next chapter of your PhD thesis by Christmas.\nSecond, you commit a stake that will be paid to a charity (or an anti-charity) if you fail to meet your goal.\nAt the stated time, you then report (or a referee appointed by you reports) whether you have met your goal. If you fail to report or report that you failed to meet your goal, your credit card is debited by the staked amount.\n\nI used stickK during my PhD. I regularly set deadlines for tasks and staked, say, a payment of $500 to the National Rifle Association. If I didn’t complete the task, I lost the money. Throughout the PhD, I met my benchmarks every time except for one.\nTo understand how stickK works in the context of the \\beta\\delta model, consider a sophisticated present-biased agent who is weighing the enjoyment they get from smoking versus the long-term health effects.\nThis sophisticated present-biased agent has \\beta=1/2 and \\delta=1. They enjoy smoking, which gives them utility of 5. However, the agent also likes being healthy. Higher health gives utility of 8.\nAt t=0 the agent is deciding whether to smoke over the next month (t=1). If the agent doesn’t smoke, they will have better health at t=2.\nThe sophisticated agent works backward through time. At t=1 its payoffs are:\n\\begin{align*}\nU_1(\\text{smoking})&=5 \\\\\n\\\\\nU_1(\\text{healthy})&=\\beta\\delta\\times 8 \\\\\n&=4\n\\end{align*}\nThe agent decides to smoke.\nAs a result, at t=0, knowing that it will cave at t=1, the agent doesn’t bother committing to not smoking, even though from the perspective of t=0 refraining from smoking is the better option:\n\\begin{align*}\nU_0(\\text{smoking})&=\\beta\\delta\\times 5 \\\\[6pt]\n&=2.5 \\\\[6pt]\n\\\\[6pt]\nU_0(\\text{healthy})&=\\beta\\delta^2\\times 8 \\\\[6pt]\n&=4\n\\end{align*}\nBut now suppose the agent learns about stickK. The agent has the option of staking a sum at t=0 to prevent it from smoking. The agent decides to stake an amount equivalent to utility 5 that would be incurred at t=2.\nWorking backward through time, the agent knows that at t=1 if it has not staked any money with stickK, it will smoke. But what if it has?\n\\begin{align*}\nU_1(\\text{stickK+smoking})&=u(\\text{smoking})+\\beta\\delta\\times u(\\text{lost stake}) \\\\[6pt]\n&=5+\\beta\\delta\\times (-5) \\\\[6pt]\n&=2.5 \\\\[6pt]\n\\\\[6pt]\nU_1(\\text{stickK+healthy})&=\\beta\\delta\\times u(\\text{healthy}) \\\\[6pt]\n&=\\beta\\delta\\times 8 \\\\[6pt]\n&=4\n\\end{align*}\nThe agent would refrain from smoking at t=1 due to the penalty they would have to pay.\nThis means the agent’s options at t=0 are effectively a comparison between smoking and using stickK to commit to not smoking. The discounted utility of each option is as follows.\n\\begin{align*}\nU_0(\\text{smoking})&=\\beta\\delta\\times u(\\text{smoking}) \\\\[6pt]\n&=\\beta\\delta\\times 5 \\\\[6pt]\n&=2.5 \\\\[6pt]\n\\\\[6pt]\nU_0(\\text{stickK+healthy})&=\\beta\\delta^2\\times u(\\text{healthy}) \\\\[6pt]\n&=\\beta\\delta^2\\times 8 \\\\[6pt]\n&=4\n\\end{align*}\nAs U_0(\\text{stickK+healthy})&gt;U_0(\\text{smoking}), the agent chooses to commit using stickK.\nOne interesting feature of these two options at t=0 is that the penalty does not appear in either calculation of the discounted utility. We have already calculated that if the penalty is present at t=1, the agent will not smoke. So when they consider their options at t=1, there is no cost to committing.\nFor any problem of this form, the agent could always successfully use stickK to commit to any action. The agent just needs to make the stake high enough.\n\n\n27.3.5 Increasing the value of the optimal action: temptation bundling\n“Temptation bundling” involves increasing the value of the optimal course of action by adding a temptation to that course.\nConsider the following example.\nBeth has the choice between exercising and watching television today at t=0.\n\nBeth does not enjoy exercise, which gives utility of 0. However, exercise leads her to be healthy, giving utility of 12 in the future at t=1.\nBeth enjoys watching television, which gives utility of 6. However, watching television leads her to be unhealthy with utility of 0 in the future at t=1.\n\nBeth is sophisticated and discounts the future quasi-hyperbolically. Beth’s \\beta=1/2 and her \\delta=2/3. Does Beth exercise?\nBeth works through the options by backward induction. At t=1 there is no choice to be made, as Beth simply enjoys the utility of the action she chose at t=0.\nFor t=0 she calculates the discounted utility of each option as follows:\n\\begin{align*}\nU_0(\\text{exercise})&=u(\\text{exercise})+\\beta\\delta u(\\text{healthy}) \\\\[6pt]\n&=0+\\frac{1}{2}\\times \\frac{2}{3}\\times 12 \\\\[6pt]\n&=4 \\\\[6pt]\n\\\\[6pt]\nU_0(\\text{television})&=u(\\text{television})+\\beta\\delta u(\\text{unhealthy}) \\\\[6pt]\n&=6+\\frac{1}{2}\\times \\frac{2}{3}\\times 0 \\\\[6pt]\n&=6\n\\end{align*}\nBeth chooses to watch television.\nBut what if Beth loved massages and remembers she has a massage voucher she has been saving? What if she decides that if she exercises today, she will go for a massage straight after? Let us assume that the utility of a massage is 3.\nThe discounted utility of exercising is now:\n\\begin{align*}\nU_0(\\text{exercise+massage})&=u(\\text{exercise})+u(\\text{massage})\\\\[6pt]\n&\\qquad+\\beta\\delta u(\\text{healthy}) \\\\[6pt]\n&=3+\\frac{1}{2}\\times \\frac{2}{3}\\times 12 \\\\[6pt]\n&=7\n\\end{align*}\nU_0(\\text{exercise+massage})&gt;U_0(\\text{television}), so Beth now chooses to exercise.\nThis example is not strictly a commitment device as Beth could cheat. Beth could watch television and get the massage. But people are often good at creating “mental accounts” by which they make certain money or activities out-of-bounds unless certain conditions are met.\n\n\n27.3.6 Gym attendance\nOne empirical illustration of temptation bundling comes from an experiment to increase gym attendance.\nKirgios et al. (2020) found that teaching gym-goers how to temptation bundle with a free audiobook boosts gym visits. Simply receiving a free audiobook with no explicit instruction boosts exercise, implying that people who are given audiobooks by gyms can infer they should temptation bundle. However, teaching temptation bundling modestly outperforms simply giving gym-goers free audiobooks.\n\n\n\n\nKirgios, E. L., Mandel, G. H., Park, Y., Milkman, K. L., Gromet, D. M., Kay, J. S., and Duckworth, A. L. (2020). Teaching temptation bundling to boost exercise: A field experiment. Organizational Behavior and Human Decision Processes, 161, 20–35. https://doi.org/10.1016/j.obhdp.2020.09.003",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Commitment</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/preference-over-profiles.html",
    "href": "intertemporal-choice/preference-over-profiles.html",
    "title": "28  Delayed gratification, spread and variation",
    "section": "",
    "text": "28.1 Delayed gratification\nRecall the assumption of utility independence:\nHowever, there is evidence that people care about the shape of the utility stream over time. There is evidence that people delay gratification, and prefer spread and variation. They don’t care solely about maximising discounted utility.\nThis evidence suggests that the assumption of utility independence does not hold. I will now discuss these three bodies of evidence.\nThe first concerns delayed gratification.\nConsider the following example:\nWhat would an exponential discounter with \\delta=0.8 do?\nWhat would a present-biased agent with \\beta=0.5 and \\delta=0.8 do?\nBoth agents would go to the beach today and study tomorrow. They will always schedule pleasant tasks before unpleasant tasks.\nDoes this match people’s observed behaviour?\nThere is considerable evidence that people will schedule unpleasant tasks first and pleasant ones later. This might be thought of as a preference for an increasing utility profile.\nHow could this be possible for someone who discounts the future?\nOne way is to ease the requirement that \\delta be less than one. This provides a solution to the weekend problem but also leads to the potential of endlessly postponing pleasant experiences.\nEasing this requirement also clashes with other evidence that people often postpone unpleasant tasks and that people have a \\delta much less than one for many decisions.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Delayed gratification, spread and variation</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/preference-over-profiles.html#delayed-gratification",
    "href": "intertemporal-choice/preference-over-profiles.html#delayed-gratification",
    "title": "28  Delayed gratification, spread and variation",
    "section": "",
    "text": "It is a sunny weekend. You can either study today and go to the beach tomorrow, or you can go to the beach today and study tomorrow.\nStudying gives you a utility of 10. Going to the beach gives you a utility of 20.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Delayed gratification, spread and variation</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/preference-over-profiles.html#spread-of-utility",
    "href": "intertemporal-choice/preference-over-profiles.html#spread-of-utility",
    "title": "28  Delayed gratification, spread and variation",
    "section": "28.2 Spread of utility",
    "text": "28.2 Spread of utility\nAnother body of evidence suggests that we prefer a spread of utility. We like to distribute pleasant experiences over time.\nIn part, this emerges from diminishing marginal utility. Additional units of a good or service on a day when we already have ample will provide less utility than on a day when we have little.\nHowever, some of the evidence cannot be accounted for by diminishing marginal utility.\nFor example, suppose someone plans to catch up with one friend over lunch and another at dinner. Some people prefer these two events on different days, giving them a spread of utility over time.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Delayed gratification, spread and variation</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/preference-over-profiles.html#variation",
    "href": "intertemporal-choice/preference-over-profiles.html#variation",
    "title": "28  Delayed gratification, spread and variation",
    "section": "28.3 Variation",
    "text": "28.3 Variation\nWe also have a preference for variation. Consider the following:\n\nYour favourite meal is lasagna. Your second favourite meal is spaghetti bolognese. Your third favourite is fish and chips.\nYou are offered the following two options:\n\nLasagna every night for the next week.\nAlternating meals of lasagna, spaghetti and fish and chips.\n\n\nWe don’t choose to have the same good or service over and over.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Delayed gratification, spread and variation</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-applications.html",
    "href": "intertemporal-choice/intertemporal-choice-applications.html",
    "title": "29  Intertemporal choice applications",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Intertemporal choice applications</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-applications.html#summary",
    "href": "intertemporal-choice/intertemporal-choice-applications.html#summary",
    "title": "29  Intertemporal choice applications",
    "section": "",
    "text": "The following examples demonstrate how understanding intertemporal choice can inform policy design and product development to help individuals overcome present bias and achieve long-term goals.\nPeople willingly choose illiquid savings accounts with equal or lower interest rates, suggesting demand for commitment devices among sophisticated, present-biased agents.\nA voluntary commitment product involving forfeitable deposits increased the likelihood of quitting smoking, demonstrating the effectiveness of commitment devices in behaviour change.\nDefault effects significantly influence organ donor registration rates, potentially due to present bias or rational cost-benefit calculations.\nThe Save More Tomorrow program successfully increases retirement savings by mitigating loss aversion and present bias.\nANZ Bank’s Progress Saver and Term Deposit accounts illustrate how present bias and the demand for commitment devices influence consumer financial decisions.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Intertemporal choice applications</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-applications.html#introduction",
    "href": "intertemporal-choice/intertemporal-choice-applications.html#introduction",
    "title": "29  Intertemporal choice applications",
    "section": "29.1 Introduction",
    "text": "29.1 Introduction\nIn this part, I discuss several applications of the intertemporal choice concepts we have covered.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Intertemporal choice applications</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-applications.html#savings",
    "href": "intertemporal-choice/intertemporal-choice-applications.html#savings",
    "title": "29  Intertemporal choice applications",
    "section": "29.2 Savings",
    "text": "29.2 Savings\nThe first example relates to the use of commitment devices to increase savings.\nBeshears et al. (2020) offered experimental participants the opportunity to save in two accounts, one liquid and the other with liquidity constraints such as withdrawal penalties. They found that the experimental participants put nearly half of their money in the illiquid account even though it paid the same interest rate. This behaviour contrasts with the standard economic prediction that all money should go to the liquid account, which dominates the illiquid account’s features. Even when the interest rate on the illiquid account was lower, it still attracted around a quarter of the money.\nThis extract from Table 3 in the paper shows the proportion of funds allocated to each type of “commitment account” when experimental participants had a choice between an account with no liquidity constraints paying 22% interest and the commitment account.\n\nYou can see that where the interest rates between the liquid and illiquid accounts were equal, the accounts with harsher constraints attracted more money. The account with a higher withdrawal penalty (20% compared to 10%) attracted more money, and the account that barred withdrawals attracted even more.\nThis result suggests a demand among sophisticated, present-biased agents for products that will enable them to control their future behaviours.\nThis behaviour has also been observed outside the lab.\nAshraf et al. (2006) offered a commitment savings product called SEED (Save, Earn, Enjoy Deposits) to randomly chosen clients of a Philippine bank. SEED restricted access to savings for one year.\nOther than providing a possible commitment savings device, no further benefit accrued to individuals with this account.\nDespite this, 28% of participants took up a commitment savings product. The average savings balance increased by 42% after six months and 82% after one year.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Intertemporal choice applications</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-applications.html#smoking",
    "href": "intertemporal-choice/intertemporal-choice-applications.html#smoking",
    "title": "29  Intertemporal choice applications",
    "section": "29.3 Smoking",
    "text": "29.3 Smoking\nThe following example relates to quitting smoking.\nGiné et al. (2010) tested a voluntary commitment product for smoking cessation.\nSmokers were offered a product that comprised a savings account in which they deposit funds. After six months, they took urine tests for nicotine and cotinine.\nIf they passed, the money was returned. Otherwise, it was forfeited.\nThe result was that 11% of smokers offered the product took it up. Smokers offered the product were 3 percentage points more likely to pass the 6-month test than the control group\nThe effect persisted in a surprise test at 12 months.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Intertemporal choice applications</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-applications.html#organ-donation",
    "href": "intertemporal-choice/intertemporal-choice-applications.html#organ-donation",
    "title": "29  Intertemporal choice applications",
    "section": "29.4 Organ donation",
    "text": "29.4 Organ donation\nThe next example concerns organ donation.\nIn European countries there are registers of people who will donate their organs in case of death. There is a considerable gap in the percentage of registered organ donors between countries. Why?\n Figure from Johnson and Goldstein (2003).\nYellow countries have an opt-in policy. People are required to register as an organ donor.\nGreen countries have an opt-out policy known as presumed consent. Citizens are presumed to consent unless they opt out (often through submission of a form).\nThis outcome is a classic example of a default effect. Defaults are sticky. The stickiness of defaults is typically assumed to come from loss aversion or present bias.\nPresent bias might influence the decision as follows. There is an immediate cost of changing from the default, be that time, effort or money. That cost is not discounted. In contrast, the future benefit of their action is discounted.\nIf you asked these people about their future plans, they might say they intend to change their organ donation registration. In the hypothetical, both the costs and benefits and in the future. They believe they will switch later.\nHowever, it is possible to argue that the stickiness of the defaults is due to a rational cost-benefit calculation rather than loss aversion or present bias. The cost of opting out is real, and people may not have a strong preference about whether they are an organ donor.\nFurther, registration does not mean that your organs will be donated. Other factors, such as family preference, affect donation. Among other things, the absence of any active consent in situations of presumed consent means that the family cannot take the organ donation register as an indication of the deceased’s wishes. There is little benefit in changing the registration if it will have little effect on the outcome you care about (actual organ donation).\nJohnson and Goldstein (2003) argued that there is a positive relationship between an opt-out policy and organ donations. But, it is much weaker than the registration numbers would suggest and based on a simple regression that likely does not capture all relevant variables.\nThere are alternatives to presumed consent that may increase organ donation rates.\nOne alternative is using defaults more transparently with easy opt out. For example, when obtaining your driver’s licence, there could be a section stating: “Please tick this box if you do not wish to be registered as an organ donor”. This measure would likely increase registration over the alternative of asking people to tick the box if they wish to be an organ donor.\nAnother alternative is “active choice”, where citizens are required to indicate whether or not they wish to be registered. This choice could also be built into a form such as a driver’s licence application or renewal.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Intertemporal choice applications</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-applications.html#save-more-tomorrow",
    "href": "intertemporal-choice/intertemporal-choice-applications.html#save-more-tomorrow",
    "title": "29  Intertemporal choice applications",
    "section": "29.5 Save More Tomorrow",
    "text": "29.5 Save More Tomorrow\nThe next example of intertemporal choice relates to retirement savings.\nThe Save More Tomorrow program, designed by Thaler and Benartzi (2004), combines prospect theory and time preference principles to increase retirement savings.\nUnder Save More Tomorrow, customers are asked to commit in advance to allocating a fraction of their future salary increases toward their retirement savings accounts.\nSave More Tomorrow is designed to reduce loss aversion when deciding contribution amounts. A commitment of a proportion of a pay rise means that the contribution can increase over time, but pay never decreases.\nThe program is designed to reduce the effect of present bias. The cost of the savings is in the future, meaning that the costs are subject to the short-term discount factor and not disproportionately overweighted relative to the benefits.\nThe program capitalises on participants’ propensity to stick with the status quo, as people are unlikely to unwind their future commitments despite being able to opt out at any time.\nThat ability to opt out also reduces regret and disappointment aversion.\nThe first tests of the Save More Tomorrow program by Thaler and Benartzi (2004) resulted in 78 per cent of those offered the plan joining, 80 per cent of those remaining in the plan through the fourth pay rise, and average savings rates increasing from 3.5 per cent to 13.6 per cent over 40 months. This compares to much lower savings rates by those who declined advice, accepted a recommended savings rate or took advice but declined to enrol in Save More Tomorrow.\nFigure 29.1 illustrates the results. Along the horizontal axis are the four groups: those who declined to enrol in the program, those who declined to receive advice, those who accepted a recommended savings rate, and those who accepted the Save More Tomorrow program. The vertical axis shows the percentage of income saved at each of five measurement points; before they received advice and after the following four raises.\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\n\ndf &lt;- data.frame( \"Raise\" = c(\"Pre-advice\", \"First\", \"Second\", \"Third\", \"Fourth\"),\n                  \"Declined-advice\"=c(6.6, 6.5, 6.8, 6.6, 6.2),\n                  \"Recommended\"=c(4.4, 9.1, 8.9, 8.7, 8.8),\n                  \"SMarT\"= c(3.5, 6.5, 9.4, 11.6, 13.6),\n                  \"Declined\"= c(6.1, 6.3, 6.2, 6.1, 5.9)\n                  )\n\ndf2 &lt;- df |&gt;\n  pivot_longer(!Raise, names_to = \"group\", values_to =\"percentage\") |&gt;\n  arrange(group) |&gt;\n  mutate(Raise=factor(Raise, levels=c(\"Pre-advice\", \"First\", \"Second\", \"Third\", \"Fourth\")))\n\ndf2 &lt;- df2[,c(2,1,3)]\n\ndf2 &lt;- df2 |&gt;\n  mutate(group = replace(group, group == \"No.advice\", \"Declined advice\")) |&gt;\n  mutate(group = replace(group, group == \"Declined\", \"Declined SMarT\"))\n\nggplot(df2, aes(group, percentage)) +\n  geom_col(aes(group = Raise, fill=Raise), colour = \"grey50\", position = \"dodge\")+ \n  labs(x = \"\", y = \"Percentage of income saved\") +\n  scale_fill_brewer(palette=\"RdBu\")+\n  #change Declined.advice to Declined advice\n  scale_x_discrete(labels = function(x) gsub(\"Declined.advice\", \"Declined advice\", x))+\n\n  # Set the theme\n  theme_minimal()\n\n\n\n\n\nFigure 29.1: Savings rates for SMarT\n\n\n\n\n\n\n\n\nNote the savings rate is higher than the default rate in Australia. Could the default in Australia create a low anchor for some people?",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Intertemporal choice applications</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-applications.html#the-progress-saver-account",
    "href": "intertemporal-choice/intertemporal-choice-applications.html#the-progress-saver-account",
    "title": "29  Intertemporal choice applications",
    "section": "29.6 The Progress Saver Account",
    "text": "29.6 The Progress Saver Account\nAnother applied example of how we can use intertemporal choice in an applied setting concerns ANZ bank’s progress saver account.\nANZ bank’s progress saver account pays bonus monthly interest on the condition that a customer deposits at least $10 into the account and makes no withdrawals. The bonus interest was 3.74% per year at the time of writing. If you fail to make the minimum deposit or withdraw from the account, you are paid a nominal interest rate of 0.01% per year on your savings for the month.\n\nMany account holders do not receive bonus interest each month. Most notably, while they often make deposits, they later withdraw funds, leading to the loss of the bonus interest.\nThis behaviour may be evidence of a preference reversal due to present bias. Today, the customer may have a preference for saving money for a long-term goal rather than short-term spending at a closer date. But when that opportunity for spending arrives, they prefer withdrawing from the account and spending the money now. That spending is no longer subject to the short-term discount factor \\beta, whereas the long-term savings goal and any interest toward achieving it are.\nFor example, suppose a customer is deciding whether to save money for their house deposit far in the future or spend the money on a new pair of shoes when they go shopping next week. Both are in the future and are subject to a short-term discount factor. In that circumstance, saving for the deposit might be preferred. However, when the shopping day comes, the shoes can be bought now. The shoes are not subject to the short-term discount factor and may give higher discounted utility than the long-term savings goal. The customer then withdraws the funds for the shoes, having changed their mind.\nThe behaviour could also be for rational reasons, such as a change in circumstances.\nThe bank has another product, a term deposit savings account, that pays, at the time of writing, 0.15% interest if you commit your money for 12 months. Many customers still use the term deposit despite paying much lower interest than the progress saver account and constraining access to funds.\n\nWhy do people use this apparently sub-optimal product?\nSome customers are what we call “sophisticated” present-biased agents. They are present biased, but they know they are present biased. They can see their future failings as they think through problems using backward induction. As a result, they can implement strategies to restrain their future self, such as a commitment device. A commitment device is a mechanism that locks you into a course of action by changing the value or availability of future options.\nIf they foresaw spending their money on shoes, they would know that depositing in the progress saver account would not lead to them saving for their house deposit long term. As a result, that person may decide to forgo the possibility of higher interest (that they won’t receive) to constrain their future self from buying shoes when shopping. The term deposit provides that constraint, acting as a commitment device.\n\n\n\n\nAshraf, N., Karlan, D., and Yin, W. (2006). Tying odysseus to the mast: Evidence from a commitment savings product in the philippines*. The Quarterly Journal of Economics, 121(2), 635–672. https://doi.org/10.1162/qjec.2006.121.2.635\n\n\nBeshears, J., Choi, J. J., Harris, C., Laibson, D., Madrian, B. C., and Sakong, J. (2020). Which early withdrawal penalty attracts the most deposits to a commitment savings account? Journal of Public Economics, 183, 104144. https://doi.org/10.1016/j.jpubeco.2020.104144\n\n\nGiné, X., Karlan, D., and Zinman, J. (2010). Put Your Money Where Your Butt Is: A Commitment Contract for Smoking Cessation. American Economic Journal: Applied Economics, 2(4), 213–235. https://doi.org/10.1257/app.2.4.213\n\n\nJohnson, E. J., and Goldstein, D. (2003). Do Defaults Save Lives? Science, 302(5649), 1338–1339. https://doi.org/10.1126/science.1091721\n\n\nThaler, Richard H., and Benartzi, S. (2004). Save More Tomorrow: Using Behavioral Economics to Increase Employee Saving. Journal of Political Economy, 112(S1), S164–S187. https://doi.org/10.1086/380085",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Intertemporal choice applications</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-exercises.html",
    "href": "intertemporal-choice/intertemporal-choice-exercises.html",
    "title": "30  Intertemporal choice exercises",
    "section": "",
    "text": "30.1 Exercise or television?\nOlga and Paul can choose one of the following options:\na) Olga discounts the future exponentially with \\delta=2/3. At t=0, what is Olga’s utility of exercising and watching television? What does Olga do?\nb) Paul discounts the future quasi-hyperbolically with \\beta=3/4 and \\delta=2/3. At t=0, what is Paul’s utility of exercising and watching television? What does Paul do?",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Intertemporal choice exercises</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-exercises.html#exercise-or-television",
    "href": "intertemporal-choice/intertemporal-choice-exercises.html#exercise-or-television",
    "title": "30  Intertemporal choice exercises",
    "section": "",
    "text": "Exercising at t=0 (utility = 0) and being healthy at t=1 (utility = 30).\nWatching television at t=0 (utility = 15) and being unhealthy at t=1 (utility = 0).\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\begin{align*}\nU_0(exercise)&=u(x_0)+\\delta u(x_1) \\\\\n&=0+\\frac{2}{3}\\times 30 \\\\\n&=20 \\\\\n\\\\\nU_0(television)&=u(x_0)+\\delta u(x_1) \\\\\n&=15+\\frac{2}{3}\\times 0 \\\\\n&=15\n\\end{align*}\nOlga gets higher discounted utility from exercising, so chooses to exercise.\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\begin{align*}\nU_0(exercise)&=u(x_0)+\\beta\\delta u(x_1) \\\\\n&=0+\\frac{3}{4}\\times \\frac{2}{3}\\times 30 \\\\\n&=15 \\\\\n\\\\\nU_0(television)&=u(x_0)+\\beta\\delta u(x_1) \\\\\n&=6+\\frac{3}{4}\\times \\frac{2}{3}\\times 0 \\\\\n&=15\n\\end{align*}\nPaul is indifferent between the two options, so could choose either.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Intertemporal choice exercises</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-exercises.html#today-or-tomorrow",
    "href": "intertemporal-choice/intertemporal-choice-exercises.html#today-or-tomorrow",
    "title": "30  Intertemporal choice exercises",
    "section": "30.2 Today or tomorrow?",
    "text": "30.2 Today or tomorrow?\nTerry and Andy are given the choice between the following three options:\n\nA (utility of 3 at t=0)\nB (utility of 4 at t=1)\nC (utility of 5 at t=2).\n\na) Suppose that Terry discounts the future exponentially with 0&lt;\\delta&lt;1. He is indifferent between A and B at t=0. What does this tell you about Terry’s \\delta?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe utility of A and B must be equal.\n\\begin{align*}\nU_0(A)&=U_0(B) \\\\[6pt]\n3&=\\delta 4 \\\\[6pt]\n\\delta&=\\frac{3}{4}\n\\end{align*}\n\n\n\nb) Andy discounts the future quasi-hyperbolically with 0&lt;\\beta&lt;1 and 0&lt;\\delta&lt;1. At t=0, Andy is indifferent between A and B. What does this tell you about Andy’s \\beta and \\delta?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe utility of A and B must be equal.\n\\begin{align*}\nU_0(A)&=U_0(B) \\\\[6pt]\n3&=\\beta\\delta 4 \\\\[6pt]\n\\beta\\delta&=\\frac{3}{4}\n\\end{align*}\nWe cannot determine anything else about the two as the discounting between t=0 and t=1 is a function of both the short-term and exponential discount factor.\n\n\n\nc) At t=0, Andy is indifferent between B and C. What does this tell you about Andy’s \\beta and \\delta?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe utility of B and C must be equal.\n\\begin{align*}\nU_0(B)&=U_0(C) \\\\[6pt]\n\\beta\\delta 4&=\\beta\\delta^2 5 \\\\[6pt]\n4&=\\delta 5 \\\\\n\\delta&=\\frac{4}{5}\n\\end{align*}\n\n\n\nd) Combining the results of (b) and (c), compute Andy’s \\beta and \\delta?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe have already computed:\n\n\\delta=\\frac{4}{5}.\n\nWe also know:\n\n\\beta\\delta=\\frac{3}{4}\n\nAccordingly, substituting (1) into (2):\n\\begin{align*}\n\\beta\\frac{4}{5}=\\frac{3}{4} \\\\\n\\beta=\\frac{15}{16}\n\\end{align*}",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Intertemporal choice exercises</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-exercises.html#sec-Q3",
    "href": "intertemporal-choice/intertemporal-choice-exercises.html#sec-Q3",
    "title": "30  Intertemporal choice exercises",
    "section": "30.3 Today or tonight?",
    "text": "30.3 Today or tonight?\nKate and Jack have utility function u(x)=x and can choose one of $3 now (t=0), $4 this afternoon (at t=1), or $7 tonight (t=2).\na) Kate is an exponential discounter with \\delta=\\frac{1}{2}. What does she choose?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe calculate discounted utility of each option and choose the highest.\n\\begin{align*}\nU_0(\\$3)&=3 \\\\[6pt]\nU_0(\\$4)&=\\delta\\times 4 \\\\\n&=2 \\\\[6pt]\nU_0(\\$7)&=\\delta^2\\times 7 \\\\\n&=\\frac{7}{4}\n\\end{align*}\nKate chooses the $3 now.\n\n\n\nb) Jack is a hyperbolic discounter with \\beta=\\frac{1}{2} and delta=1 what does Jack choose?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYou calculate discounted utility of each option and choose the highest.\n\\begin{align*}\nU_0(\\$3)&=3 \\\\[6pt]\nU_0(\\$4)&=\\beta\\delta\\times 4 \\\\\n&=\\frac{1}{2}\\times 1 \\times 4 \\\\\n&=2 \\\\[6pt]\nU_0(\\$7)&=\\beta\\delta^2\\times 7 \\\\\n&=\\frac{1}{2}\\times 1^2 \\times 7 \\\\\n&=3.5\n\\end{align*}\nJack chooses the $7 tonight.\nAlthough Jack is a hyperbolic discounter, the short-term discount factor is only applied once.\n\n\n\nc) This afternoon (t=1) comes and Jack reconsiders his decision. Should he take $4 this afternoon (t=1), or $7 tonight (t=2). What does Jack decide?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe calculate discounted utility of each option and choose the highest.\n\\begin{align*}\nU_1(\\$4)&=4 \\\\[6pt]\nU_1(\\$7)&=\\beta\\delta\\times 7 \\\\\n&=\\frac{1}{2}\\times 1 \\times 7 \\\\\n&=3.5\n\\end{align*}\nJack changes his mind and takes the $4 immediately.\n\n\n\nd) Why did or did not Jack change his mind?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAt t=0 the difference in discount between the $4 at t=1 and $7 at t=2 is \\delta. Both are discounted by \\beta as neither is immediately available. However, at t=1 the difference in discount between the $4 and $7 is \\beta\\delta. The $4 is no longer subject to the immediate discount of \\beta, making it relatively more attractive.\n\n\n\ne) Show the answers to parts a) to d) using a diagram.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe below figure shows the each of the payoffs that Kate could receive at t=0,1,2. The lines represent the discounted utility of each option at each time.\nAt t=0 we can see that the $3 immediately gives higher discounter utility than both of the larger, later options.\n\nThe below figure shows the each of the payoffs that Jack could receive at t=0,1,2. The lines represent the discounted utility of each option at each time.\nAt t=0 we can see that the $4 paid at t=1 gives higher discounter utility. We can also see that the lines represented the discounted utility at each time cross, giving the potential for a time inconsistent decision.\n\nIn the next figure we move forward to t=1. Jack’s preferred option changes. He now prefers the $4 immediately. It is no longer discounted by \\beta.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Intertemporal choice exercises</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-exercises.html#small-reward-now-or-large-reward-later",
    "href": "intertemporal-choice/intertemporal-choice-exercises.html#small-reward-now-or-large-reward-later",
    "title": "30  Intertemporal choice exercises",
    "section": "30.4 Small reward now or large reward later?",
    "text": "30.4 Small reward now or large reward later?\nAlfred and Blake are exponential discounters. They can choose between a small reward now or a larger reward later. Alfred discounts the future heavily (low \\delta). Blake does not (\\delta close to one).\na) How might Alfred and Blake’s choices be affected by their discount factor?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nEach will discount the two rewards, with the size of the discount for the larger reward reflecting the size of the delay relative to the delay for the small reward.\nAlfred and Blake will prefer to wait if the discounted utility of the larger reward is higher than that of the small reward.\nAs Alfred has a higher discount rate, Alfred is more likely than Blake to prefer the small reward as Alfred will discount the larger reward by more.\n\n\n\nb) Catherine is a quasi-hyperbolic discounter. She can choose between the same two rewards. Before either award is available, she prefers the large reward. However, she changes her mind and chooses when the small reward at the time it becomes available.\nWhy did Catherine change her mind?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIf Catherine prefers the large reward, this means the discounted utility of the larger reward is higher than that for the small reward. As both rewards are experienced with delay, the small and large reward are discounted by the short-term discount factor, plus the exponential discount factor proportional to the delay.\nWhen the small reward becomes available, Catherine no longer applies any discount to the small reward. The exponential discount factor applied to the larger reward also decreases for the time that has passed. Despite the size of the exponential discount being applied to each reward decreasing by the same amount, the removal of the short-term discount factor from the small reward must have been of sufficient that it now has the larger expected utility.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Intertemporal choice exercises</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-exercises.html#credit-score",
    "href": "intertemporal-choice/intertemporal-choice-exercises.html#credit-score",
    "title": "30  Intertemporal choice exercises",
    "section": "30.5 Credit score",
    "text": "30.5 Credit score\nA credit score is a score developed by credit agencies and lenders as a measure of how risky a borrower is. The score is derived using data on past behaviour. A person with a higher credit score is considered more likely to repay a loan on time.\nResearchers found a correlation between people’s discount factors, \\beta and \\delta, and their credit score.\nWhat would this correlation be? Explain why you might see this relationship.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nYou would expect to see a positive correlation between the credit score and the discount factors.\n\\beta relates to present-bias, which results in greater weight being given to any costs or benefits today relative to costs and benefits experienced with delay.\n\\delta relates to impatience, with each successive period of delay being subject to a discount relative to the previous.\nBoth discount factors could affect the credit score.\nTo the extent the future is discounted due to either discount rate, this makes borrowing more attractive provided the interest costs are not too high.\nIf either discount factor were low enough, an agent might be willing to borrow more than they could feasibly pay off in the future (or at extortionate interest rates). The benefits of consumption today might exceed the costs of failure to repay, with those costs sufficiently discounted that them agent is willing to incur them. An agent with low \\beta might be particularly vulnerable to this as an impulsive purchase today might be attractive even though the debt (e.g. credit card) might be payable soon. Failure to pay would hurt their credit score.\nUnintended payment problems are more likely to be caused by low \\beta.\nIf someone with low \\delta borrowed money with the intention to pay it off in the future, they would stick to that plan. They are time consistent.\nSomeone with low \\beta may borrow with the intention to pay it off. However, when the day of payment arrives, they may change their mind and prefer not to incur the immediate cost of payment as that exceeds the discounted costs in the future (such as penalty interest and a low credit score). This would also hurt their credit score.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Intertemporal choice exercises</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-exercises.html#time-inconsistent-preferences",
    "href": "intertemporal-choice/intertemporal-choice-exercises.html#time-inconsistent-preferences",
    "title": "30  Intertemporal choice exercises",
    "section": "30.6 Time inconsistent preferences",
    "text": "30.6 Time inconsistent preferences\nRecall the question in Section 30.3.\nWe found that at t=0 Jack planned to wait until tonight (t=2) for the $7, but in the afternoon (t=1) he changed his mind and took the $4 that was available immediately.\nJack’s friend Allan is a sophisticated quasi-hyperbolic discounter with \\beta=\\frac{1}{2} and \\delta=1.\nDoes your answer change for Allan? Why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe behaviour of Jack that we observed in Tutorial 5 was that of a naive hyperbolic discounter. In each period he calculated his preferred option and acted as though he would stick to that decision in the future. He did not anticipate changing his mind at t=1.\nAllan considers the choice by using backward induction from the final period.\nIf Allan waits until tonight, he takes the $7 with certainty.\nNow considering his choice at t=1.\n\\begin{align*}\nU_1(\\$4\\text{ at }t=1)&=4 \\\\[6pt]\nU_1(\\$7\\text{ at }t=2)&=\\beta\\delta\\times 7 \\\\[6pt]\n&=3.5\n\\end{align*}\nAt t=1 Allan can see that he will cave in take the $4.\nAllan now considers t=0 with the knowledge he will take the $4 at t=1. He knows that he will not make it to the $7 at t=2, so he removes it from his choice set.\n\\begin{align*}\nU_0(\\$3\\text{ at }t=0)&=3 \\\\[6pt]\nU_0(\\$4\\text{ at }t=1)&=\\beta\\delta\\times 4 \\\\[6pt]\n&=2\n\\end{align*}\nAt t=0 Allan chooses the $3. His sophistication leads him to preproperate. He takes a lower amount earlier than the naive Jack.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Intertemporal choice exercises</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-exercises.html#eating-cake",
    "href": "intertemporal-choice/intertemporal-choice-exercises.html#eating-cake",
    "title": "30  Intertemporal choice exercises",
    "section": "30.7 Eating cake",
    "text": "30.7 Eating cake\nKelvin and Linda both like chocolate cake. There are two periods in which they can eat cake, t=1,2. They receive an immediate benefit of 12 for eating cake at t=1 and 6 for eating cake at t=2\nAt t=3 they incur the costs of their diet and pay a cost of 8. The total cost depends on how much cake they eat.\nKelvin and Linda have preferences of \\beta=0.5 and \\delta=1.\nTo illustrate, if Kelvin or Linda eat at t=1 they receive a benefit of 12 at t=1 and a cost of 8 at t=3. If Kelvin or Linda eat at both at t=1 and at t=2, they receive a benefit of 12 at t=1 and 6 at t=2 and a cost of 16 at t=3.\nKelvin is naive, Linda is sophisticated.\na) When will Kelvin eat?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe can calculate utility of eating in each round separately as the utilities are additive.\nAt t=0:\n\\begin{align*}\nU_0(\\text{eat at }t=1)&=\\beta\\delta\\times 12-\\beta\\delta^3\\times 8 \\\\\n&=0.5\\times 1\\times 12-0.5\\times 1^3 \\times 8 \\\\\n&=2 \\\\\n\\\\\nU_0(\\text{eat at } t=2)&=\\beta\\delta^2\\times 6-\\beta\\delta^3\\times 8 \\\\\n&=0.5\\times 1^2\\times 6-0.5\\times 1^3 \\times 8 \\\\\n&=-1\n\\end{align*}\nKelvin plans to eat at t=1 but not t=2.\nAt t=1:\n\\begin{align*}\nU_1(\\text{eat at } t=1)&=12-\\beta\\delta^2\\times 8 \\\\\n&=12-0.5\\times 1^2 \\times 8 \\\\\n&=8 \\\\\n\\\\\nU_1(\\text{eat at } t=2)&=\\beta\\delta\\times 6-\\beta\\delta^2\\times 8 \\\\\n&=0.5\\times 1\\times 6-0.5\\times 1 \\times 8 \\\\\n&=-1\n\\end{align*}\nKelvin eats at t=1 but does not plan to eat at t=2.\nAt t=2:\n\\begin{align*}\nU_2(\\text{eat at } t=2)&=6-\\beta\\delta^2\\times 8 \\\\\n&=6-0.5\\times 1^2 \\times 8 \\\\\n&=2\n\\end{align*}\nKelvin eats at t=2.\nKelvin, being naive, thinks he will stick to his initial plan of eating at t=1 but not at t=2, but ends up eating in both periods.\n\n\n\nb) When will Linda eat?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nLinda is sophisticated and solves their problem backward.\nThere is no decision to make at t=3. She simply incurs the cost of their past behaviour.\nAt t=2:\n\\begin{align*}\nU_2(\\text{eat at } t=2)&=6-\\beta\\delta^2\\times 8 \\\\\n&=6-0.5\\times 1^2 \\times 8 \\\\\n&=2\n\\end{align*}\nLinda anticipates that she will eat at t=2.\nLinda knows she will eat at t=2, so she don’t need to reconsider her plan for then at t=1.\nAt t=1:\n\\begin{align*}\nU_1(\\text{eat at } t=1)&=12-\\beta\\delta^2\\times 8 \\\\\n&=12-0.5\\times 1^2 \\times 8 \\\\\n&=8\n\\end{align*}\nLinda also anticipates that she will eat at t=1.\nAt t=0, Linda can now see that she will eat at t=1 and t=2 no matter what she decides now. She simply accepts her future course of action.\n\n\n\nc) Assume that Kelvin and Linda can pay price p at t=0 for a binding commitment device that prevents them from eating more than they initially plan. Assuming costs and benefits are measured in dollars, what is the maximum price p that Linda would pay to use the commitment device?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFrom the perspective of period t=0 all costs and benefits are discounted. At t=0:\n\\begin{align*}\nU_0(\\text{eat at } t=1)&=\\beta\\delta\\times 12-\\beta\\delta^3\\times 8 \\\\\n&=0.5\\times 1\\times 12-0.5\\times 1^3 \\times 8 \\\\\n&=2 \\\\\n\\\\\nU_0(\\text{eat at } t=2)&=\\beta\\delta^2\\times 12-\\beta\\delta^3\\times 8 \\\\\n&=0.5\\times 1^2\\times 6-0.5\\times 1^3 \\times 8 \\\\\n&=-1\n\\end{align*}\nFrom the perspective of t=0, eating at t=2 has negative discounted utility. As a result, if a commitment device available, Linda would use it to commit to not eating at t=2. The commitment device would prevent a loss of 1. Therefore, Linda would pay up to p=\\$1.\n\n\n\nd) What happens to Kelvin, a naive agent, in the presence of the commitment device?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBeing naive, Kelvin does not perceive the necessity of using a commitment device as he trusts he will comply with his plans.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Intertemporal choice exercises</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-exercises.html#completing-an-assignment",
    "href": "intertemporal-choice/intertemporal-choice-exercises.html#completing-an-assignment",
    "title": "30  Intertemporal choice exercises",
    "section": "30.8 Completing an assignment",
    "text": "30.8 Completing an assignment\nYour assignment is due today at t=0.\nYou can complete the assignment within a day, but on that day you will incur a utility cost of 10.\nFor every day you submit late, you lose one mark. You experience a utility cost of 1 for every mark lost on the day it is lost. If handed in more than 6 days late, you will fail and experience utility cost of 1000. (In other words, if you haven’t yet submitted, you will definitely submit at t=6).\nThis leaves you with a decision to hand in at t = 0, t = 1, t = 2, ... , t = 5, or t=6.\nFor instance:\n\nIf you submit today, at t=0, you experience utility cost of 10.\nIf you submit tomorrow, at t=1, you will experience utility cost of 10 plus a utility cost of 1 for the mark lost on that day.\nIf you submit at t=2, you will experience a utility cost of 1 at t=1 for the mark lost, a utility cost of 1 at t=2 for another mark lost, and a utility cost of 10 for completing the assignment.\nIf you submit at t=6, you will experience a utility cost of 1 on each day from t=1 to t=6 for the marks lost, plus a utility cost of 10 at t=6 for completing the assignment.\n\nYou are a hyperbolic discounter with \\beta=0.75 and \\delta=1.\na) When do you finish if you are naive?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAt t=0 you have 7 possible plans to consider: finishing your assignment at t=0 through to t=6. You compare the discounted utilities from the various plans as follows.\nAt t=0:\n\nFinish today (t=0): -10\nFinish tomorrow (t=1): 0.75(-10-1)=-8.50\nFinish at t=2: 0.75(-10-2)=-9.25\nFinish at t=3: 0.75(-10-3)=-10\n…\nFinish at t=6: 0.75(-10-6)=-12\n\nAt t=0, you plan to finish at t=1 as that yields the highest discounted utility. You put off finishing the assignment until tomorrow.\nAt t=1 you then reconsider your decision. The penalty received at t=1 is now sunk and won’t affect the decision:\n\nFinish today (t=1): -10=-10\nFinish tomorrow (t=2): 0.75(-10-1)=-8.25\nFinish at t=3: 0.75(-10-2)=-9\n…\nFinish at t=6: 0.75(-10-5)=-11.25\n\nAt t=1, you change your plan and now intend to finish at t=2, which yields the highest discounted utility.\nThis pattern continues day after day, always intending to complete tomorrow, until t=6, with an ultimate outcome of -10 utility cost on that day, plus -1 utility cost each day for the last 6 days.\n\nFinish at t=5: -10\nFinish at t=6: 0.75(-10-1)=-8.25\n\n\n\n\nb) When do you finish if you are sophisticated?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIf you are sophisticated, you will start at the end and work backwards.\nAt t=6, you know that if you haven’t finished the assignment you must, with -10 utility.\nAt t=5, you choose between:\n\nFinish at t=5: -10\nFinish at t=6: 0.75(-10-1)=-8.25\n\nYou do not plan to do the assignment at t=5 and you remove t=5 from your plans.\nAt t=4, you choose between:\n\nFinish at t=4: -10\nFinish at t=6: 0.75(-10-2)=-9\n\nYou do not plan to do the assignment at t=4 and you remove t=4 from your plans.\nAt t=3, you choose between:\n\nFinish at t=3: -10\nFinish at t=6: 0.75(-10-3)=-9.75\n\nYou do not plan to do the assignment at t=3 and you remove t=3 from your plans.\nAt t=2, you choose between:\n\nFinish at t=2: -10\nFinish at t=6: 0.75(-10-4)=-10.5\n\nUtility is higher completing the assignment earlier. You plan to do the assignment at t=2 and you remove t=6 from your plans.\nAt t=1, you choose between:\n\nFinish at t=1: -10\nFinish at t=2: 0.75(-10-1)=-8.25\n\nYou plan to do the assignment at t=2 and you remove t=1 from your plans.\nAt t=0, you choose between:\n\nFinish at t=0: -10\nFinish at t=2: 0.75(-10-2)=-9\n\nYou will not change your intentions further and will complete the assignment at t=2.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Intertemporal choice exercises</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-exercises.html#saving-for-retirement",
    "href": "intertemporal-choice/intertemporal-choice-exercises.html#saving-for-retirement",
    "title": "30  Intertemporal choice exercises",
    "section": "30.9 Saving for retirement",
    "text": "30.9 Saving for retirement\nCitizens of Perthia have the choice between the following options:\n\nSaving for retirement at t=1 (u_1=0) and having a comfortable retirement at t=2 (u_2=20)\nSpending at t=1 (u_1=10) and having a difficult retirement at t=2 (u_2=0).\n\na) Ellie is an exponential discounter with \\delta=3/4. What does Ellie choose at t=0 and t=1? Why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\begin{align*}\nU_0(save)&=\\delta u_1+\\delta^2 u_2 \\\\\n&=0+\\bigg(\\frac{3}{4}\\bigg)^2\\times 20 \\\\\n&=11.25 \\\\\n\\\\\nU_0(spend)&=\\delta u_1+\\delta^2 u_2 \\\\\n&=\\frac{3}{4}\\times 10+0 \\\\\n&=7.5 \\\\\n\\\\\nU_1(save)&=u_1+\\delta u_2 \\\\\n&=0+\\frac{3}{4}\\times 20 \\\\\n&=15 \\\\\n\\\\\nU_1(spend)&=u_1+\\delta u_2 \\\\\n&=10+0\\\\\n&=10\n\\end{align*}\nEllie intends to save in both periods and does so. Ellie is time consistent. Knowing that Ellie is an exponential discounter, we did not need to calculate her decision at both t=0 and t=1. As exponential discounters are time consistent, we could have simply determined her decision for one period and known that would also be her decision at other times.\n\n\n\nb) Freddie is a naive quasi-hyperbolic discounter with \\beta=1/4 and \\delta=1. What does Freddie choose at t=0 and t=1? Why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\begin{align*}\nU_0(save)&=\\beta\\delta u_1+\\beta\\delta^2 u_2 \\\\\n&=0+\\frac{1}{4}\\times (1)^2\\times 20 \\\\\n&=5 \\\\\n\\\\\nU_0(spend)&=\\beta\\delta u_1+\\beta\\delta^2 u_2 \\\\\n&=\\frac{1}{4}\\times 1\\times 10+0 \\\\\n&=2.5 \\\\\n\\end{align*}\nAt t=0 Freddie plans to save.\n\\begin{align*}\nU_1(save)&=u_1+\\beta\\delta u_2 \\\\\n&=0+\\frac{1}{4}\\times 1\\times 20 \\\\\n&=5 \\\\\n\\\\\nU_1(spend)&=u_1+\\beta\\delta u_2 \\\\\n&=10+0 \\\\\n&=10\n\\end{align*}\nAt t=1 Freddie chooses to spend Freddie has changed his mind. He is time inconsistent. At t=0 both saving and spending are subject to the short-term discount factor \\beta, with the relative discount between saving and spending being only \\delta. However, at t=1 the benefit of spending is available immediately and no longer discounted by \\beta.\n\n\n\nc) Grant is a sophisticated quasi-hyperbolic discounter with \\beta=1/4 and \\delta=1. What does Grant do? Why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nGrant works through his options using backward induction.\nAt t=2 Grant has no decision to make.\nAt t=1:\n\\begin{align*}\nU_1(save)&=u_1+\\beta\\delta u_2 \\\\\n&=0+\\frac{1}{4}\\times 1\\times 20 \\\\\n&=5 \\\\\n\\\\\nU_1(spend)&=u_1+\\beta\\delta u_2 \\\\\n&=10+0\\\\\n&=10\n\\end{align*}\nAt t=1 Grant will spend. (This is the same calculation we made for Freddie at t=1.)\nAs Grant knows he will spend at t=1, that is the only feasible option available at t=0. Grant will choose to spend.\nUltimately, Grant takes the same action as Freddie. However, he can see his future decisions and is aware of that coming failure to stick with what would be his preferences at t=0.\n\n\n\nd) Grant is offered the opportunity to bind himself to a course of action at t=0 at the cost of 1 point of utility at t=2. What does Grant do?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn the presence of the commitment device, Grant now has two feasible options to consider at t=0.\n\\begin{align*}\nU_0(commit)&=\\beta\\delta u_1+\\beta\\delta^2 u_2 \\\\\n&=0+\\frac{1}{4}\\times (1)^2\\times (20-1) \\\\\n&=4.75 \\\\\n\\\\\nU_0(spend)&=\\beta\\delta u_1+\\beta\\delta^2 u_2 \\\\\n&=\\frac{1}{4}\\times 1\\times 10+0 \\\\\n&=2.5 \\\\\n\\end{align*}\nGrant now chooses to commit at a price of one unit of utility at t=2.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Intertemporal choice exercises</span>"
    ]
  },
  {
    "objectID": "intertemporal-choice/intertemporal-choice-exercises.html#buy-now-pay-later",
    "href": "intertemporal-choice/intertemporal-choice-exercises.html#buy-now-pay-later",
    "title": "30  Intertemporal choice exercises",
    "section": "30.10 Buy-now pay-later",
    "text": "30.10 Buy-now pay-later\nBuy-now pay-later works as follows: a person purchases an item with an initial payment of one-quarter of the purchase price. They get access to the purchased item immediately. They then pay three equal instalments each fortnight until they have paid for the purchase in full. If they fail to make a payment on time, they are required to pay a fee of $10 and are barred from using the buy-now pay-later facility in the future.\nVernon used a buy-now pay-later provider to purchase a new jacket for $200. He paid $50 on the day of the purchase and is now required to pay the next $50 instalment in two weeks. That is, Vernon’s schedule of costs and benefits is:\n\nPurchase date: Gains jacket and pays $50\nIn two weeks: Pays $50\nIn four weeks: Pays $50\nIn six weeks: Pays $50\n\nAt that time of the purchase Vernon intends to pay for the jacket as required by the buy-now pay-later provider in two, four and six weeks.\nTwo weeks after the purchase when his payment became due Vernon changed his mind and did not make the payment. He purchased a carton of beer for a party that night with the money instead. Vernon’s options and the cost and benefits of those options had not changed since the purchase date.\nIs Vernon an exponential discounter or present-biased? Why? Explain why Vernon changed his mind.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAs Vernon has exhibited time inconsistent behaviour, he must be present-biased. An exponential discounter would be time consistent.\nA present-based person subjects costs and benefits experienced with any delay to a short-term discount factor.\nWhen Vernon purchased the jacket, the benefit of the jacket and the cost of $50 would not have been subject to any discount. The cost of the three future payments (or the benefit of alternative uses of that money such as purchasing beer) would be subject to the short-term discount. Any fee for failing to make a payment and the loss of the buy-now pay-later facility for that failure would also be subject to that short-term discount factor.\nWhen the next payment is due, the cost of that payment (or the benefit of the beer) is no longer subject to the short-term discount factor, whereas any fee from failing to make the payment and the loss of the facility are still subject to that short-term discount factor. As a result, cost of the payment / benefit of the beer now has relatively greater weight than the future costs, leading Vernon to change his mind.",
    "crumbs": [
      "Intertemporal choice",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Intertemporal choice exercises</span>"
    ]
  },
  {
    "objectID": "probability-foundations/probability-foundations.html",
    "href": "probability-foundations/probability-foundations.html",
    "title": "Probability foundations",
    "section": "",
    "text": "Imagine you’re a surgeon deciding whether to operate on a patient. The procedure could save their life, but it also carries risks. Or picture yourself as an investor choosing between stocks for your retirement savings. Each investment offers different potential returns, but also different chances of loss. Or envision yourself at a poker table, trying to judge whether your friend is bluffing with a weak hand or sitting on a royal flush. Calling their hand could have markedly different outcomes.\nThese decisions share a common thread: we must make choices without perfect information. Sometimes we know the probabilities, like the odds of rolling a six on a fair die. We call this risk. Other times we can only make educated guesses without knowing the probabilities, like whether an investment will pay off. We call this uncertainty. And to analyse decision-making under risk and uncertainty, we need to consider how people form beliefs and compute probabilities.\nConsider that poker game. Your friend just raised the stakes significantly. Are they bluffing? You might consider how often they’ve bluffed before (your prior belief), combine it with how they’re acting now (new evidence), and update your assessment of their hand. This process of updating beliefs based on new evidence - which we’ll explore as Bayes’ Rule - lies at the heart of probability theory.\nIn this part, we’ll proceed in three steps. First, I will lay out the foundations of probability theory - the basic rules and principles that underpin all probabilistic thinking. Then I will discuss Bayes’ Rule, a powerful tool that shows us how to update our beliefs when we get new information. Finally, I will extend these ideas into subjective expected utility theory, which helps us understand how people make decisions when probabilities aren’t known.",
    "crumbs": [
      "Probability foundations"
    ]
  },
  {
    "objectID": "probability-foundations/probability-theory.html",
    "href": "probability-foundations/probability-theory.html",
    "title": "31  Probability theory",
    "section": "",
    "text": "Summary\nP(A \\cup B) = P(A) + P(B)\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B)\nP(A \\cap B) = P(A)P(B)\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Probability theory</span>"
    ]
  },
  {
    "objectID": "probability-foundations/probability-theory.html#summary",
    "href": "probability-foundations/probability-theory.html#summary",
    "title": "31  Probability theory",
    "section": "",
    "text": "The probability function P(\\cdot) assigns a real number between 0 and 1 to each event, with \\sum P(\\cdot) = 1 for all possible outcomes.\nFor mutually exclusive events A and B, the probability of either event occurring is:\n\n\n\nFor non-mutually exclusive events A and B, the probability of either event occurring is:\n\n\n\nFor independent events, the probability of both events occurring is the product of their individual probabilities:\n\n\n\nConditional probability P(A|B) is the probability of A given that B has occurred. It’s calculated as:\n\n\n\nThe Monty Hall problem illustrates conditional probability: given the host opens a specific door, what is the probability of the car being behind the unopened door?",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Probability theory</span>"
    ]
  },
  {
    "objectID": "probability-foundations/probability-theory.html#introduction",
    "href": "probability-foundations/probability-theory.html#introduction",
    "title": "31  Probability theory",
    "section": "31.1 Introduction",
    "text": "31.1 Introduction\nIn this part, I introduce some basic concepts in probability theory.",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Probability theory</span>"
    ]
  },
  {
    "objectID": "probability-foundations/probability-theory.html#the-probability-function",
    "href": "probability-foundations/probability-theory.html#the-probability-function",
    "title": "31  Probability theory",
    "section": "31.2 The probability function",
    "text": "31.2 The probability function\nThe probability of an outcome is the chance with which it occurs. We denote the probability of outcome A as P(A), where P(\\cdot) represents a probability function that assigns a real number to each event.\nThe probability function has the following features.\nFirst, the probability of outcome A lies between 0 and 1. That is:\n\n0 \\leq P(A) \\leq 1\n\nFor example, the probability of drawing the Ace of Spades from a full deck of 52 cards is 1 in 52 or ~0.02.\nThe probability of flipping a head with a fair coin is 1 in 2 or 0.5.\nSecond, the probability of the entire outcome space equals 1.\nFor example, suppose we have 52 possible cards we can draw from the deck, each with 1 in 52 probability. If we draw a single card, the probability that we draw one of those cards is:\n\\begin{align*}\n\\frac{1}{52}+\\frac{1}{52}+\\frac{1}{52}+...+\\frac{1}{52}&=\\sum_{n=1}^{n=52}\\frac{1}{52} \\\\[12pt]\n&=1\n\\end{align*}\nThird, suppose outcomes A and B are mutually exclusive. In that case, the probability of A or B is the sum of the probability of A and the probability of B. That is:\n\\begin{align*}\nP(A \\text{ or } B)&=P(A \\cup B) \\\\[6pt]\n&=P(A)+P(B)\n\\end{align*}\nFor example, if we have a deck with 52 cards, the probability of pulling out an Ace with a single draw is as follows.\n\\begin{align*}\nP(A\\spadesuit \\cup A\\heartsuit \\cup A\\diamondsuit \\cup A\\clubsuit)&=P(A\\spadesuit)+P(A\\heartsuit)+P(A\\diamondsuit)+P(A\\clubsuit) \\\\[6pt]\n&=\\frac{1}{52}+\\frac{1}{52}+\\frac{1}{52}+\\frac{1}{52} \\\\[6pt]\n&=\\frac{4}{52}\n\\end{align*}\nAlternatively, suppose outcomes A and B are not mutually exclusive. In that case, the probability of one or the other is the sum of the probability of A and the probability of B minus the probability of both occurring. That is:\n\nP(A \\cup B)=P(A)+P(B)-P(A\\cap B)\n\nwhere P(A \\cap B) is the probability of both outcome A and B.\nFor example, if we have a deck with 52 cards, the probability of pulling out an Ace or a Diamond with a single draw is as follows.\n\\begin{align*}\nP(A \\cup \\diamondsuit)&=P(A)+P(\\diamondsuit)-P(A \\cap \\diamondsuit) \\\\[6pt]\n&=\\frac{4}{52}+\\frac{1}{4}-\\frac{1}{52} \\\\[6pt]\n&=\\frac{16}{52}\n\\end{align*}\nFinally, if outcomes A and B are independent, the conjunction of the two independent outcomes is the product of their probabilities. That is\n\nP(A \\cap B)=P(A)P(B)\n\nFor example, suppose we draw a single card from a deck of cards, place that card back in the deck, and then make another draw. The probability of drawing the Ace of Spades in either draw is 1⁄52. The probability of drawing the Ace of Spades twice is:\n\\begin{align*}\nP(A\\spadesuit \\cap A\\spadesuit)&=P(A\\spadesuit)\\times P(A\\spadesuit) \\\\[6pt]\n&=\\frac{1}{52}\\times \\frac{1}{52} \\\\[12pt]\n&=\\frac{1}{2704}\n\\end{align*}\nNote that if A and B are mutually exclusive, they are not independent and P(A \\cap B)=0.",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Probability theory</span>"
    ]
  },
  {
    "objectID": "probability-foundations/probability-theory.html#conditional-probability",
    "href": "probability-foundations/probability-theory.html#conditional-probability",
    "title": "31  Probability theory",
    "section": "31.3 Conditional probability",
    "text": "31.3 Conditional probability\nConditional probability concerns the probability of an outcome given another outcome.\nFor example, drawing a card from a deck of cards with replacement - that is, putting back each card after it is drawn - means that whatever card was drawn in the first draw does not affect the probability of the outcome of the second draw. Each draw is independent of the other.\nBut what if you draw two cards from the same deck without replacement?\nIn that case, the two draws are not independent of each other. For instance, if you pull out the Ace of Spades first, the second card cannot be the Ace of Spades.\nWe say here that the probability of drawing an Ace of Spades on the second draw is conditional on the result of the first draw.\nWhen one outcome is conditional on another, such as the probability of outcome A conditional on outcome B occurring, we write this conditional probability as P(A|B).\nSuppose I draw two cards from a deck without replacement. What is the probability of drawing an Ace for both draws?\nWe know that the first draw affects the probability of drawing an Ace on the second draw. If the first card is an Ace, one less Ace is in the deck for the second draw.\nThe probability of drawing an Ace on the first draw is 4 in 52. If I draw an Ace in the first draw, the probability of drawing an Ace on the second is 3 in 51. There is one less Ace and one less card than for the first draw. By multiplying the probability of these two events together, we can get the probability of an Ace on both draws.\n\\begin{align*}\nP(\\text{Ace 1st}\\cap\\text{Ace 2nd})&=P(\\text{Ace 1st})\\times P(\\text{Ace 2nd}|\\text{Ace 1st}) \\\\[6pt]\n&=\\frac{4}{52}\\times \\frac{3}{51} \\\\[12pt]\n&=\\frac{1}{221}\n\\end{align*}\n\n31.3.1 Formula for conditional probability\nWe can see that the solution to this problem has taken the form:\n\nP(A\\cap B)=P(A|B)P(B)\n\nThe joint probability of two outcomes equals the probability of A conditional on B multiplied by the probability of B.\nWe can rearrange this formula to determine the probability of A given outcome B.\n\nP(A|B)=\\frac{P(A\\cap B)}{P(B)}\n\nIf A and B are independent, P(A|B)=P(A). In that case, the formula simplifies to that for calculating the probability of the conjunction of independent outcomes we saw earlier, P(A \\cap B)=P(A)P(B). The equation P(A\\cap B)=P(A|B)P(B) is a more general version of how to calculate the conjunction of two events.\nDue to symmetry, we can also write the conditional probability as:\n\nP(A\\cap B)=P(A|B)P(B)=P(B|A)P(A)\n\n\n\n31.3.2 Example\nAs a test of this formula, let’s take our previous example of drawing two Aces from the same deck. What is the probability of drawing an Ace on the second draw if you drew an Ace on the first?\n\\begin{align*}\nP(\\text{Ace 2nd}|\\text{Ace 1st})&=\\frac{P(\\text{Ace 1st}\\cap\\text{Ace 2nd})}{P(\\text{Ace 1st})} \\\\[12pt]\n&=\\cfrac{\\cfrac{1}{221}}{\\cfrac{4}{52}} \\\\[24pt]\n&=\\frac{3}{51}\n\\end{align*}\n\n\n31.3.3 The Monty Hall problem\nConsider the following problem as answered by Marilyn vos Savant in her column Ask Marilyn in Parade magazine (Savant, 1990):\n\nSuppose you’re on a game show and you’re given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what’s behind the doors, opens another door, say No. 3, which has a goat. He then says to you, “Do you want to pick door No. 2?” Is it to your advantage to switch your choice?\n\nThis problem is known as the Monty Hall problem as it is loosely based on the American game show Let’s Make a Deal. Monty Hall was the original host of the show.\nAssume that the rules of this game show are that:\n\nThe host must always open a door that you did not choose.\nThe host must always open a door to reveal a goat and never the car.\nThe host must always offer you the choice to switch between the chosen door and the remaining closed door.\n\nFor this question, you are effectively being asked: what is the probability that the car is behind Door 2 conditional on the host opening door 3.\nTo help us think about this problem, consider the following tree that maps the possible outcomes after you select Door 1. The first split of the tree represents the 1/3 probability that the car is behind each of the three doors. Given the car’s location, the next split represents the probability that the host opens each door. The final column indicates the probability of each combination of car location and door opened.\n\nIf the car is behind Door 1, which you have selected, the host could open either Door 2 or Door 3 with equal probability. If the car is behind Door 2, the host must open Door 3. If the car is behind Door 3, the host must open Door 2.\nGiven the host opened Door 3, we can calculate the conditional probability that the car is behind door 2 as follows:\n\\begin{align*}\nP(C2|D3)&=\\frac{P(C2\\cap D3)}{P(D3)} \\\\[12pt]\n&=\\frac{\\frac{1}{3}}{\\frac{1}{3}+\\frac{1}{6}} \\\\[12pt]\n&=\\frac{2}{3}\n\\end{align*}\nYou should switch to door 2.\n\n\n\n\nSavant, M. vos. (1990). Game show problem. PARADE Magazine, 16. https://web.archive.org/web/20130121183432/http://marilynvossavant.com/game-show-problem/",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Probability theory</span>"
    ]
  },
  {
    "objectID": "probability-foundations/bayes-rule.html",
    "href": "probability-foundations/bayes-rule.html",
    "title": "32  Bayes’ rule",
    "section": "",
    "text": "Summary\nP(A|B)=\\frac{P(B|A)P(A)}{P(B)}\nP(B) = P(B|A)P(A) + P(B|\\neg A)P(\\neg A)\nP(H|E) = \\frac{P(E|H)P(H)}{P(E)}",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Bayes' rule</span>"
    ]
  },
  {
    "objectID": "probability-foundations/bayes-rule.html#summary",
    "href": "probability-foundations/bayes-rule.html#summary",
    "title": "32  Bayes’ rule",
    "section": "",
    "text": "Bayes’ rule is a method for calculating the conditional probability of an event.\nBayes’ rule gives the probability of outcome A given B, P(A|B), using the unconditional probability of outcome A, the probability of observing B given A and the total probability of outcome B:\n\n\n\nThe total probability P(B) can be calculated as:\n\n\n\nBayes’ rule can be thought of as a way to update beliefs about a hypothesis H given evidence E:",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Bayes' rule</span>"
    ]
  },
  {
    "objectID": "probability-foundations/bayes-rule.html#introduction",
    "href": "probability-foundations/bayes-rule.html#introduction",
    "title": "32  Bayes’ rule",
    "section": "32.1 Introduction",
    "text": "32.1 Introduction\nBayes’ rule is a method for estimating the conditional probability of an event.\nSpecifically, Bayes’ rule allows us to use the following information to estimate the conditional probability of outcome A given outcome B:\n\nThe unconditional probability of outcome A\nThe probability of observing outcome B given outcome A\nThe total probability of outcome B.\n\nThe formula for Bayes’ rule is:\n\\begin{align*}\nP(A|B)&=\\frac{P(A\\cap B)}{P(B)} \\\\[12pt]\n&=\\frac{P(B|A)P(A)}{P(B)}\n\\end{align*}\nThe denominator P(B) is the total probability of event B. If the total probability of event B is not directly available, we can often calculate it with information concerning the conditional probabilities of B given the occurrence (or not) of A.\n\nP(B)=P(B|A)P(A)+P(B|\\neg A)P(\\neg A)\n\nThe symbol \\neg represents “not”.\nWe can therefore write Bayes’ rule as follows:\n\\begin{align*}\nP(A|B)&=\\frac{P(B|A)P(A)}{P(B)} \\\\[12pt]\n&=\\frac{P(B|A)P(A)}{P(B|A)P(A)+P(B|\\neg A)P(\\neg A)}\n\\end{align*}",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Bayes' rule</span>"
    ]
  },
  {
    "objectID": "probability-foundations/bayes-rule.html#updating-beliefs",
    "href": "probability-foundations/bayes-rule.html#updating-beliefs",
    "title": "32  Bayes’ rule",
    "section": "32.2 Updating beliefs",
    "text": "32.2 Updating beliefs\nWe can think of Bayes’ rule as how we should update our beliefs in light of a new event.\nRational agents should update their beliefs using Bayes’ rule.\nIn this case, the following elements are involved:\n\nA hypothesis, H. For example, “the coin is fair” or “the coin is rigged”.\nThe prior probability of the hypothesis H being true, P(H). For example, “the coin is fair” has a prior probability of 0.5.\nThe probability of observing event E given a hypothesis H, P(E|H). For example, “the coin shows a head” has a probability of 0.5 given that the coin is fair.\nThe posterior probability of the belief H given the event E, P(H|E). For example, we would have an updated probability in our hypothesis that “the coin is fair” based on the coin showing a head.\n\nUnder this framing, Bayes’ rule is formulated as follows:\n\\begin{align*}\n\\underbrace{P(H|E)}_\\text{Posterior belief}&=\\frac{P(E|H)\\overbrace{P(H)}^\\text{Prior belief}}{P(E)} \\\\[12pt]\n&=\\frac{P(E|H)P(H)}{P(E|H)P(H)+P(E|\\neg H)P(\\neg H)}\n\\end{align*}",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Bayes' rule</span>"
    ]
  },
  {
    "objectID": "probability-foundations/bayes-rule.html#a-rigged-coin",
    "href": "probability-foundations/bayes-rule.html#a-rigged-coin",
    "title": "32  Bayes’ rule",
    "section": "32.3 A rigged coin",
    "text": "32.3 A rigged coin\nSuppose your friend has two coins. One is a fair coin with a head on one side and a tail on the other. The second coin is a rigged coin with a head on both sides.\nYour friend takes one of the coins and flips it. The coin shows a head. What is the probability that this coin is the rigged coin?\nWe will assume that he randomly selected either coin with a probability of 50%. We take that as our prior belief:\n\nP(\\text{rigged})=0.5\n\nThe probability of a head if it is the rigged coin is 1.\n\nP(\\text{head}|\\text{rigged})=1\n\nTo use Bayes’ rule, we need the total probability that a head comes up, P(\\text{head}).\nHere we will use the formula for total probability.\n\\begin{align*}\nP(\\text{head})&=P(\\text{head}|\\text{rigged})P(\\text{rigged})+P(\\text{head}|\\text{fair})P(\\text{fair}) \\\\[6pt]\n&=1\\times 0.5+0.5\\times 0.5 \\\\[6pt]\n&=0.75\n\\end{align*}\nPutting this into Bayes’ rule:\n\\begin{align*}\nP(\\text{rigged}|\\text{head})&=\\frac{P(\\text{head}|\\text{rigged})P(\\text{rigged})}{P(\\text{head})} \\\\[12pt]\n&=\\frac{1\\times 0.5}{0.75} \\\\[6pt]\n&=\\frac{2}{3}\n\\end{align*}\nYour friend flips the coin again and gets another head. What is the updated probability that the coin is rigged?\nThe prior belief is now P(\\text{rigged})=\\frac{2}{3}.\nThe total probability of flipping a head is:\n\\begin{align*}\nP(\\text{head})&=P(\\text{head}|\\text{rigged})P(\\text{rigged})+P(\\text{head}|\\text{fair})P(\\text{fair}) \\\\[6pt]\n&=1\\times \\frac{2}{3}+0.5\\times \\frac{1}{3} \\\\[6pt]\n&=\\frac{5}{6}\n\\end{align*}\nPutting this into Bayes rule:\n\\begin{align*}\nP(\\text{rigged}|\\text{head})&=\\frac{P(\\text{head}|\\text{rigged})P(\\text{rigged})}{P(\\text{head})} \\\\[12pt]\n&=\\frac{1\\times \\frac{2}{3}}{\\frac{5}{6}} \\\\[6pt]\n&=\\frac{4}{5}\n\\end{align*}\nYour belief that the coin is rigged has now increased to 80%.\nYour friend flips the coin 10 more times and gets 10 more heads. What is the updated probability that the coin is rigged?\nWe use our prior belief of P(\\text{rigged})=\\frac{4}{5}.\nThe total probability of flipping 10 heads is:\n\\begin{align*}\nP(\\text{10 heads})&=P(\\text{10 heads}|\\text{rigged})P(\\text{rigged})+P(\\text{10 heads}|\\text{fair})P(\\text{fair}) \\\\[6pt]\n&=1\\times \\frac{4}{5}+\\bigg(\\frac{1}{2}\\bigg)^{10}\\times \\frac{1}{5} \\\\[6pt]\n&=0.8002\n\\end{align*}\nPutting this into Bayes’ rule:\n\\begin{align*}\nP(\\text{rigged}|\\text{10 heads})&=\\frac{P(\\text{10 heads}|\\text{rigged})P(\\text{rigged})}{P(\\text{10 heads})} \\\\[12pt]\n&=\\frac{1\\times \\frac{4}{5}}{0.8002} \\\\[12pt]\n&=0.99976\n\\end{align*}\nWe now believe the coin is rigged with greater than 99.9% probability.",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Bayes' rule</span>"
    ]
  },
  {
    "objectID": "probability-foundations/bayes-rule.html#balls-from-an-urn",
    "href": "probability-foundations/bayes-rule.html#balls-from-an-urn",
    "title": "32  Bayes’ rule",
    "section": "32.4 Balls from an urn",
    "text": "32.4 Balls from an urn\nYou have two urns filled with balls. Urn 1 has 30% black balls and 70% yellow balls. Urn 2 has 70% black balls and 30% yellow balls. The labels have fallen off the urns, so you do not know which urn is which.\nYou reach into one of the urns and pull out a yellow ball. What is the probability that you have drawn the ball from urn 1?\nThe Bayes’ rule formula to solve this problem is:\n\\begin{align*}\nP(\\text{urn 1}|\\text{yellow})=\\frac{P(\\text{yellow}|\\text{urn 1})P(\\text{urn 1})}{P(\\text{yellow})}\n\\end{align*}\nWe take the prior probability of the ball coming from urn 1 to be 50%. The probability of drawing a yellow ball from urn 1 is 70%.\nThe total probability of drawing a yellow ball is:\n\\begin{align*}\nP(\\text{yellow})&=P(\\text{yellow}|\\text{urn 1})P(\\text{urn 1})+P(\\text{yellow}|\\text{urn 2})P(\\text{urn 2}) \\\\[6pt]\n&=0.3\\times 0.5+0.7\\times 0.5 \\\\[6pt]\n&=0.5\n\\end{align*}\nPutting this into Bayes’ rule:\n\\begin{align*}\nP(\\text{urn 1}|\\text{yellow})&=\\frac{P(\\text{yellow}|\\text{urn 1})P(\\text{urn 1})}{P(\\text{yellow})} \\\\[12pt]\n&=\\frac{P(\\text{yellow}|\\text{urn 1})P(\\text{urn 1})}{P(\\text{yellow}|\\text{urn 1})P(\\text{urn 1})+P(\\text{yellow}|\\text{urn 2})P(\\text{urn 2})} \\\\[12pt]\n&=\\frac{0.7\\times 0.5}{0.7\\times 0.5+0.3\\times 0.5} \\\\[12pt]\n&=0.7\n\\end{align*}\nYou put the first ball back in the urn, reach in again and pull out a black ball. What is the probability that you have drawn the ball from urn 1?\nGiven we have already drawn one ball and updated our probability, we will use the prior probability of P(\\text{urn 1})=0.7.\nThe total probability of drawing a black ball is:\n\\begin{align*}\nP(\\text{black})&=P(\\text{black}|\\text{urn 1})P(\\text{urn 1})+P(\\text{black}|\\text{urn 2})P(\\text{urn 2}) \\\\[6pt]\n&=0.3\\times 0.7+0.7\\times 0.3 \\\\[6pt]\n&=0.42\n\\end{align*}\nPutting this into Bayes rule:\n\\begin{align*}\nP(\\text{urn 1}|\\text{black})&=\\frac{P(\\text{black}|\\text{urn 1})P(\\text{urn 1})}{P(\\text{black})} \\\\[12pt]\n&=\\frac{0.3\\times 0.7}{0.42} \\\\[12pt]\n&=0.5\n\\end{align*}\nThe answer of 0.5 should seem intuitive. We have now drawn one black and one yellow ball. In combination, this is uninformative and we are back at our initial prior of 0.5.",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Bayes' rule</span>"
    ]
  },
  {
    "objectID": "probability-foundations/bayes-rule.html#the-monty-hall-problem",
    "href": "probability-foundations/bayes-rule.html#the-monty-hall-problem",
    "title": "32  Bayes’ rule",
    "section": "32.5 The Monty Hall problem",
    "text": "32.5 The Monty Hall problem\nRecall the Monty Hall problem:\n\nSuppose you’re on a game show and you’re given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what’s behind the doors, opens another door, say No. 3, which has a goat. He then says to you, “Do you want to pick door No. 2?” Is it to your advantage to switch your choice?\n\nAssume that the rules of this game show are that:\n\nThe host must always open a door that you did not choose.\nThe host must always open a door to reveal a goat and never the car.\nThe host must always offer you the choice to switch between the chosen door and the remaining closed door.\n\nWe want to know the probability that the car is behind Door 2 given the host opened Door 3. We want to know P(C2|D3). 1\nTo determine this using Bayes’ rule, we would use the following formula:\n\\begin{align*}\nP(C2|D3)&=\\frac{P(D3|C2)P(C2)}{P(D3)}\n\\end{align*}\nP(D3) is the probability that the host opens Door 3. It is calculated using the formula for total probability:\n\\begin{align*}\nP(D3)&=P(D3|C1)P(C1)+P(D3|C2)P(C2)+P(D3|C3)P(C3)\n\\end{align*}\nEach of those elements are as follows.\nP(C1), P(C2) and P(C3) are our prior probability of the car being behind each door, which is \\frac{1}{3}.\nP(D3|C1) is the probability that the host opens door 3, given the car is behind door 1. The host could open either of Door 2 or Door 3 as neither has the car behind it, so the probability of Door 3 is \\frac{1}{2}.\nP(D3|C2) is the probability that the host opens Door 3, given the car is behind Door 2. The host must open that door, so the probability is one. They cannot open the door you have chosen or the door that the car is behind.\nP(D3|C3) is the probability that the host opens door 3, given the car is behind door 3. The host cannot open a door to show the car, so the probability is zero.\nReturning to our equations, the total probability of the host opening Door 3 is:\n\\begin{align*}\nP(D3)&=P(D3|C1)P(C1)+P(D3|C2)P(C2)+P(D3|C3)P(C3) \\\\[6pt]\n&=\\frac{1}{2}\\times\\frac{1}{3}+1\\times\\frac{1}{3}+0\\times\\frac{1}{3} \\\\[6pt]\n&=\\frac{1}{2}\n\\end{align*}\nNow we can calculate the probability that the car is behind Door 2, given the host opened Door 3:\n\\begin{align*}\nP(C2|D3)&=\\frac{P(D3|C2)P(C2)}{P(D3)} \\\\[12pt]\n&=\\frac{1\\times\\frac{1}{3}}{\\frac{1}{2}} \\\\[12pt]\n&=\\frac{2}{3}\n\\end{align*}\nThe contestant should switch doors.",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Bayes' rule</span>"
    ]
  },
  {
    "objectID": "probability-foundations/bayes-rule.html#footnotes",
    "href": "probability-foundations/bayes-rule.html#footnotes",
    "title": "32  Bayes’ rule",
    "section": "",
    "text": "Technically, we want P(C2|D3\\cap X1) where X1 is our selection of Door 1. However, adding this complication to the calculation does not change the answer.↩︎",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Bayes' rule</span>"
    ]
  },
  {
    "objectID": "probability-foundations/probability-theory-exercises.html",
    "href": "probability-foundations/probability-theory-exercises.html",
    "title": "33  Probability theory exercises",
    "section": "",
    "text": "33.1 Judging a fund manager\nYou want to know if a fund manager is skilled as you believe skilled management can lead to outperformance. The following is known:\nYou observe an outperforming fund manager. What is the probability that the fund manager is skilled?",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probability theory exercises</span>"
    ]
  },
  {
    "objectID": "probability-foundations/probability-theory-exercises.html#judging-a-fund-manager",
    "href": "probability-foundations/probability-theory-exercises.html#judging-a-fund-manager",
    "title": "33  Probability theory exercises",
    "section": "",
    "text": "20% of fund managers are skilled.\nIf a fund manager is skilled, the probability that they outperform the market is 80%.\nIf a fund manager is unskilled, the probability that they outperform the market is 40%.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe calculate the solution using Bayes’ rule.\n\nP(\\text{skilled}|\\text{outperform})=\\frac{P(\\text{outperform}|\\text{skilled})P(\\text{skilled})}{P(\\text{outperform})}\n\nWe can calculate P(outperform) using the law of total probability.\n\\begin{align*}\nP(\\text{outperform})&=P(\\text{outperform}|\\text{skilled})P(\\text{skilled})+P(\\text{outperform}|\\text{unskilled})P(\\text{unskilled}) \\\\[6pt]\n&=0.8\\times 0.2+0.4\\times 0.8 \\\\[6pt]\n&=0.48\n\\end{align*}\nInputting this into Bayes’ rule, we get:\n\\begin{align*}\nP(\\text{skilled}|\\text{outperform})&=\\frac{P(\\text{outperform}|\\text{skilled})P(\\text{skilled})}{P(\\text{outperform})} \\\\[6pt]\n&=\\frac{0.8\\times 0.2}{0.48} \\\\[6pt]\n&=0.333\n\\end{align*}\nA fund manager who outperforms is skilled with 0.333 probability. You cannot neglect that low base rate of skilled managers.",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probability theory exercises</span>"
    ]
  },
  {
    "objectID": "probability-foundations/probability-theory-exercises.html#detecting-a-terrorist",
    "href": "probability-foundations/probability-theory-exercises.html#detecting-a-terrorist",
    "title": "33  Probability theory exercises",
    "section": "33.2 Detecting a terrorist",
    "text": "33.2 Detecting a terrorist\nEvery month 100 million people fly on commercial airlines. Imagine 10 of them are terrorists.\nAirport security are able to correctly identify that a person is a terrorist in 99% of cases and a non-terrorist in 99.9% of cases.\nA person is identified by airport security as a terrorist. Using Bayes’ rule, what is the probability that they are a terrorist?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe can use Bayes’ Theorem to calculate the conditional probability:\n\n\\begin{aligned}\nP(\\text{terrorist | identified}) &= \\dfrac{P(\\text{identified | terrorist})P(\\text{terrorist})}{P(\\text{identified})} \\\\[12 pt]\n&= \\dfrac{0.99\\times 0.0000001}{0.99\\times 0.0000001+0.001\\times 0.999999} \\\\[12 pt]\n&= 0.000099\n\\end{aligned}\n\nOr approximately 1 in 10,000.",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probability theory exercises</span>"
    ]
  },
  {
    "objectID": "probability-foundations/probability-theory-exercises.html#rolling-a-die",
    "href": "probability-foundations/probability-theory-exercises.html#rolling-a-die",
    "title": "33  Probability theory exercises",
    "section": "33.3 Rolling a die",
    "text": "33.3 Rolling a die\nYou have two six-sided dice:\n\none die is fair with the numbers 1 through to 6 occurring with equal probability\nthe other die is loaded and always rolls a 5 or a 6 with equal probability.\n\nYou pull one die out of your pocket and roll it. You did not check which die it was before you rolled. (Assume you could have pulled either die out of your pocket with equal probability.)\na) The die shows a six. What is the probability that it is the loaded die?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe are asked to calculate P(\\text{D1 loaded}|6). To calculate this, I will use Bayes’ rule.\n\\begin{align*}\nP(\\text{D1 loaded}|6)&=\\frac{P(6|\\text{D1 loaded})P(\\text{D1 loaded})}{P(6)} \\\\[12pt]\n&=\\frac{P(6|\\text{D1 loaded})P(\\text{D1 loaded})}{P(6|\\text{D1 loaded})P(\\text{D1 loaded})+P(6|\\text{D1 fair})P(\\text{D1 fair})} \\\\[12pt]\n&=\\frac{0.5\\times 0.5}{0.5\\times 0.5+\\frac{1}{6}\\times 0.5} \\\\[12pt]\n&=0.75\n\\end{align*}\nThe first die is the loaded die with 75% probability.\n\n\n\nb) You pull the other die out of your pocket and roll it. It shows a 5. What is the updated probability that the first die is the loaded die?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe are asked to calculate P(\\text{D1 loaded}|\\text{D2 } 5). We have a prior probability of the first die being loaded of 0.75, which comes from the answer in the previous question.\nPutting this into Bayes’ rule:\n\\begin{align*}\nP(\\text{D1 loaded}|\\text{D2 } 5)&=\\frac{P(\\text{D2 } 5|\\text{D1 loaded})P(\\text{D1 loaded})}{P(\\text{D2 } 5)} \\\\[12pt]\n&=\\frac{P(\\text{D2 } 5|\\text{D1 loaded})P(\\text{D1 loaded})}{P(\\text{D2 } 5|\\text{D1 loaded})P(\\text{D1 loaded})+P(\\text{D2 } 5|\\text{D1 fair})P(\\text{D1 fair})} \\\\[12pt]\n&=\\frac{\\frac{1}{6}\\times 0.75}{\\frac{1}{6}\\times 0.75+0.5\\times 0.25} \\\\[12pt]\n&=0.5\n\\end{align*}\nEach die is loaded with a 50% probability.\nYou could reach the same result by calculating the probability that the second die is fair given a 5. This is the same as the probability that the first die is loaded given a 5 on the second die. This approach gives the same result as the above calculation, but you need only think about one die.\n\\begin{align*}\nP(\\text{D2 fair}|5)&=\\frac{P(5|\\text{D2 fair})P(\\text{D2 fair})}{P(5)} \\\\[12pt]\n&=\\frac{P(5|\\text{D2 fair})P(\\text{D2 fair})}{P(5|\\text{D2 fair})P(\\text{D2 fair})+P(5|\\text{D2 loaded})P(\\text{D2 loaded})} \\\\[12pt]\n&=\\frac{\\frac{1}{6}\\times 0.75}{\\frac{1}{6}\\times 0.75+0.5\\times 0.25} \\\\[12pt]\n&=0.5\n\\end{align*}",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probability theory exercises</span>"
    ]
  },
  {
    "objectID": "probability-foundations/probability-theory-exercises.html#male-or-female",
    "href": "probability-foundations/probability-theory-exercises.html#male-or-female",
    "title": "33  Probability theory exercises",
    "section": "33.4 Male or female",
    "text": "33.4 Male or female\nThese two related questions come from magazine columnist Marilyn vos Savant.\na) A shopkeeper says she has two new baby beagles to show you, but she doesn’t know whether they’re male, female, or a pair. You tell her that you want only a male, and she telephones the fellow who’s giving them a bath. “Is at least one a male?” she asks him. “Yes!” she informs you with a smile. What is the probability that the other one is a male?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe prior probabilities are:\n\\begin{align*}\nP(MM)&=0.25 \\\\[6pt]\nP(MF)&=P(FM)=0.25 \\\\[6pt]\nP(FF)&=0.25\n\\end{align*}\nUsing Bayes’ rule:\n\\begin{align*}\nP(MM|M)&=\\frac{P(M|MM)P(MM)}{P(M)} \\\\[6pt]\n&=\\frac{P(M|MM)P(MM)}{\\begin{aligned}P(&M|MM)P(MM)+P(M|MF)P(MF)\\\\&+P(M|FM)P(FM)+P(M|FF)P(FF)\\end{aligned}} \\\\[6pt]\n&=\\frac{1\\times\\frac{1}{4}}{1\\times\\frac{1}{4}+1\\times\\frac{1}{4}+1\\times\\frac{1}{4}+0\\times\\frac{1}{4}} \\\\[6pt]\n&=\\frac{\\frac{1}{4}}{\\frac{3}{4}} \\\\[6pt]\n&=\\frac{1}{3}\n\\end{align*}\n\n\n\nb) Say that a woman and a man (who are unrelated) each have two children. We know that at least one of the woman’s children is a boy and that the man’s oldest child is a boy. Can you explain why the chances that the woman has two boys do not equal the chances that the man has two boys?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFor the woman, the prior probabilities before learning she has a boy are:\n\\begin{align*}\nP(BB)&=0.25 \\\\[6pt]\nP(BG)&=P(GB)=0.25 \\\\[6pt]\nP(GG)&=0.25\n\\end{align*}\nUsing Bayes’ rule:\n\\begin{align*}\nP(BB|B)&=\\frac{P(B|BB)P(BB)}{P(B)} \\\\[12pt]\n&=\\frac{P(B|BB)P(BB)}{\\begin{aligned}P(&B|BB)P(BB)+P(B|BG)P(BG)\\\\&+P(B|GB)P(GB)+P(B|GG)P(GG)\\end{aligned}} \\\\[12pt]\n&=\\frac{1\\times\\frac{1}{4}}{1\\times\\frac{1}{4}+1\\times\\frac{1}{4}+1\\times\\frac{1}{4}+0\\times\\frac{1}{4}} \\\\[12pt]\n&=\\frac{\\frac{1}{4}}{\\frac{3}{4}} \\\\[12pt]\n&=\\frac{1}{3}\n\\end{align*}\nFor the man, the prior probabilities before learning his eldest is a boy are:\n\\begin{align*}\nP(BB)&=0.25 \\\\[6pt]\nP(BG)&=0.25 \\\\[6pt]\nP(GB)&=0.25 \\\\[6pt]\nP(GG)&=0.25\n\\end{align*}\nUsing Bayes’ rule:\n\\begin{align*}\nP(BB|B)&=\\frac{P(B|BB)P(BB)}{P(B)} \\\\[12pt]\n&=\\frac{P(B|BB)P(BB)}{\\begin{aligned}P(&B|BB)P(BB)+P(B|BG)P(BG)\\\\&+P(B|GB)P(GB)+P(B|GG)P(GG)\\end{aligned}} \\\\[12pt]\n&=\\frac{1\\times\\frac{1}{4}}{1\\times\\frac{1}{4}+1\\times\\frac{1}{4}+0\\times\\frac{1}{4}+0\\times\\frac{1}{4}} \\\\[12pt]\n&=\\frac{\\frac{1}{4}}{\\frac{2}{4}} \\\\[12pt]\n&=\\frac{1}{2}\n\\end{align*}\nNote: questions such are these are typically sensitive to unstated assumptions, particularly around the procedure used to elicit the information around the sex of the child. Due to this, part a) is probably less vulnerable to alternative assumptions than b) as it contains information about the elicitation procedure in the question.",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probability theory exercises</span>"
    ]
  },
  {
    "objectID": "probability-foundations/probability-theory-exercises.html#luggage",
    "href": "probability-foundations/probability-theory-exercises.html#luggage",
    "title": "33  Probability theory exercises",
    "section": "33.5 Luggage",
    "text": "33.5 Luggage\nYou have taken a flight and are worried that your luggage will not be on the flight. You know that 20% of bags have not been arriving with the passenger.\nThe following table of conditional probabilities (from Pearl & Mackenzie (2018)) gives the probability that your bag will be on the luggage carousel conditional on the bag being on the flight and how long you have been waiting at the carousel.\n\n\n\nBag on plane\nTime elapsed\nCarousel=true\n\n\n\n\nFalse\n0\n0\n\n\nFalse\n1\n0\n\n\nFalse\n2\n0\n\n\nFalse\n3\n0\n\n\nFalse\n4\n0\n\n\nFalse\n5\n0\n\n\nFalse\n6\n0\n\n\nFalse\n7\n0\n\n\nFalse\n8\n0\n\n\nFalse\n9\n0\n\n\nFalse\n10\n0\n\n\nTrue\n0\n0\n\n\nTrue\n1\n10\n\n\nTrue\n2\n20\n\n\nTrue\n3\n30\n\n\nTrue\n4\n40\n\n\nTrue\n5\n50\n\n\nTrue\n6\n60\n\n\nTrue\n7\n70\n\n\nTrue\n8\n80\n\n\nTrue\n9\n90\n\n\nTrue\n10\n100\n\n\n\na) You have been waiting 5 minutes for your bag and it has not arrived. What is the probability that your bag was not on the flight?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\begin{align*}\nP(\\text{false}|\\text{not arrived after 5})&=\\frac{P(\\text{not arrived after 5}|\\text{false})P(\\text{false})}{P(\\text{not arrived after 5})} \\\\[12pt]\n&=\\frac{P(\\text{not arrived after 5}|\\text{false})P(\\text{false})}{\\begin{aligned}P(&\\text{not arrived after 5}|\\text{false})P(\\text{false})\\\\&+P(\\text{not arrived after 5}|\\text{true})P(\\text{true})\\end{aligned}} \\\\[12pt]\n&=\\frac{1\\times 0.2}{1\\times 0.2+0.5\\times 0.8} \\\\[12pt]\n&=0.333\n\\end{align*}\nThe probability that the bag was not on the flight is 33%.\n\n\n\nb) You have been waiting 9 minutes for your bag and it has not arrived. What is the probability that your bag was not on the flight?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\begin{align*}\nP(\\text{false}|\\text{not arrived after 9})&=\\frac{P(\\text{not arrived after 9}|\\text{false})P(\\text{false})}{P(\\text{not arrived after 9})} \\\\[12pt]\n&=\\frac{P(\\text{not arrived after 9}|\\text{false})P(\\text{false})}{\\begin{aligned}P(&\\text{not arrived after 9}|\\text{false})P(\\text{false})\\\\&+P(\\text{not arrived after 9}|\\text{true})P(\\text{true})\\end{aligned}} \\\\[12pt]\n&=\\frac{1\\times 0.2}{1\\times 0.2+0.1\\times 0.8} \\\\[12pt]\n&=0.714\n\\end{align*}\nThe probability that the bag was not on the flight is 71%.\n\n\n\nc) You have been waiting 10 minutes for your bag and it has not arrived. What is the probability that your bag was not on the flight?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\begin{align*}\nP(\\text{false}|\\text{not arrived after 10})&=\\frac{P(\\text{not arrived after 10}|\\text{false})P(\\text{false})}{P(\\text{not arrived after 10})} \\\\[12pt]\n&=\\frac{P(\\text{not arrived after 10}|\\text{false})P(\\text{false})}{\\begin{aligned}P(&\\text{not arrived after 10}|\\text{false})P(\\text{false})\\\\&+P(\\text{not arrived after 10}|\\text{true})P(\\text{true})\\end{aligned}} \\\\[12pt]\n&=\\frac{1\\times 0.2}{1\\times 0.2+0\\times 0.8} \\\\[12pt]\n&=1\n\\end{align*}\nThe probability that the bag was not on the flight is 100%.",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probability theory exercises</span>"
    ]
  },
  {
    "objectID": "probability-foundations/probability-theory-exercises.html#murder",
    "href": "probability-foundations/probability-theory-exercises.html#murder",
    "title": "33  Probability theory exercises",
    "section": "33.6 Murder?",
    "text": "33.6 Murder?\nIn a now famous case, Sally Clark was convicted of murder after the death of her two sons. The defence argued both children had died of sudden infant death syndrome. The prosecution called statistical evidence that the chance of a SIDS death was 1 in 8543, so the chance of two children dying of SIDS was 1 in 73 million (8543\\times 8543).\nThe conviction was overturned on a second appeal. For what reasons could the following simple calculation be misleading?\n\\begin{align*}\nP(\\text{SIDS death}\\land\\text{SIDS death})&=P(\\text{SIDS death})\\times P(\\text{SIDS death}) \\\\[12pt]\n&=\\frac{1}{8543}\\times\\frac{1}{8543} \\\\[12pt]\n&=\\frac{1}{7.3\\times 10^{7}}\n\\end{align*}\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nReason 1: The probability of a 2nd SIDS death given first SIDS death is not independent. e.g. SIDS deaths are related due to genetics, family environment. That is, the relevant probability is:\n\nP(\\text{SIDS death}|\\text{genetics, family environment, etc})\n\nThis would mean that:\n\nP(\\text{2 SIDS deaths in same family})&gt;(P(\\text{1 SIDS death}))^2\n\nThe appropriate calculation is:\n\nP(\\text{SIDS death}\\land\\text{SIDS death})=P(1^{st}\\text{ SIDS death})\\times P(2^{nd}\\text{ SIDS death}|1^{st}\\text{ SIDS death})\n\nReason 2: We also need to consider the probability of alternative possibility - i.e. murder. We want calculate:\n\nP(\\text{murder}|{2\\text{ deaths}})=\\frac{P(2\\text{ deaths}|\\text{murder})P(\\text{murder})}{P(2\\text{ deaths})}\n\nIf murder itself is also unlikely, then it is not correct to simply attribute the alternative to SIDS the residual probability.",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probability theory exercises</span>"
    ]
  },
  {
    "objectID": "probability-foundations/probability-theory-exercises.html#a-fire-alarm",
    "href": "probability-foundations/probability-theory-exercises.html#a-fire-alarm",
    "title": "33  Probability theory exercises",
    "section": "33.7 A fire alarm",
    "text": "33.7 A fire alarm\nYou know the following statistics about fire:\n\nThe probability of your house catching fire on any particular day is 1 in 10,000\nYour fire alarm correctly detects a house fire 95% of the time\nThe probability that your fire alarm sounds on a day when there is no fire (a false alarm) is 1 in 100.\n\nYour alarm goes off. What is the probability that your house is on fire?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\begin{align*}\nP(\\text{fire}|\\text{alarm})&=\\frac{P(\\text{alarm}|\\text{fire})P(\\text{fire})}{P(\\text{alarm})} \\\\[12pt]\n&=\\frac{P(\\text{alarm}|\\text{fire})P(\\text{fire})}{P(\\text{alarm}|\\text{fire})P(\\text{fire})+P(\\text{alarm}|\\neg\\text{fire})P(\\neg\\text{fire})} \\\\[12pt]\n&=\\frac{0.95\\times 0.0001}{0.95\\times 0.0001+0.01\\times 0.9999} \\\\[12pt]\n&=0.0094\n\\end{align*}\nThe probability of a fire if the alarm goes off is 0.94%.",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>Probability theory exercises</span>"
    ]
  },
  {
    "objectID": "probability-foundations/subjective-expected-utility.html",
    "href": "probability-foundations/subjective-expected-utility.html",
    "title": "34  Subjective expected utility theory",
    "section": "",
    "text": "Summary\n\\mathbb{E}[U(x)] = \\sum_{i=1}^n \\pi(x_i)u(x_i)",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Subjective expected utility theory</span>"
    ]
  },
  {
    "objectID": "probability-foundations/subjective-expected-utility.html#summary",
    "href": "probability-foundations/subjective-expected-utility.html#summary",
    "title": "34  Subjective expected utility theory",
    "section": "",
    "text": "Subjective expected utility theory applies to situations of uncertainty where probabilities are unknown.\nAgents maximise subjective expected utility using subjective probabilities. Subjective expected utility is defined as:\n\n\n\nWe assume that decision-makers maintain coherent subjective probabilities consistent with Bayesian probability theory.\nProbabilistic coherence protects decision-makers from exploitation through Dutch Books.\nAn anomaly in subjective expected utility theory is the Ellsberg paradox, where people’s preference for known over unknown probabilities violates the theory’s predictions.",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Subjective expected utility theory</span>"
    ]
  },
  {
    "objectID": "probability-foundations/subjective-expected-utility.html#introduction",
    "href": "probability-foundations/subjective-expected-utility.html#introduction",
    "title": "34  Subjective expected utility theory",
    "section": "34.1 Introduction",
    "text": "34.1 Introduction\nWhen deciding whether to invest in an untested technology or choose between conflicting medical treatments, we rarely have access to exact well-defined probabilities. Subjective expected utility theory provides us with a framework for examining decisions in such circumstances, where probabilities are unknown.\nIn standard expected utility theory, probabilities are derived from known frequencies or distributions. In contrast, subjective expected utility theory uses subjective probabilities based on personal judgment.\nThis subjective approach maintains the mathematical framework of expected utility theory. Agents maximise subjective expected utility, \\mathbb{E}[U(X)], by assigning subjective probabilities, \\pi(x_i), to outcomes x_i. The equation for subjective expected utility theory is the same as that for expected utility theory, except for these subjective probabilities. Subjective expected utility equals the subjective probability weighted sum of the utilities of each outcome x_i:\n\\begin{align*}\n\\mathbb{E}[U(X)]&=\\pi(x_1)u(x_1)+\\pi(x_2)u(x_2)+...+\\pi(x_n)u(x_n)\\\\[6pt]\n&=\\sum_{i=1}^n \\pi(x_i)u(x_i)\n\\end{align*}\nThis process involves:\n\nDefining utility u(x_i) over final outcomes x_1,\\ldots,x_n.\nDefining subjective probabilities \\pi(x_i) for each outcome.\nWeighting each outcome’s utility by its subjective probability.\nSumming the weighted utilities.",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Subjective expected utility theory</span>"
    ]
  },
  {
    "objectID": "probability-foundations/subjective-expected-utility.html#axioms-for-subjective-expected-utility",
    "href": "probability-foundations/subjective-expected-utility.html#axioms-for-subjective-expected-utility",
    "title": "34  Subjective expected utility theory",
    "section": "34.2 Axioms for subjective expected utility",
    "text": "34.2 Axioms for subjective expected utility\nThe axioms for subjective expected utility theory were first set out by Leonard Savage in 1954. These axioms have a close alignment with the axioms for standard expected utility theory, although they are adapted to the subjective nature of the probabilities.\nOne of these axioms is the sure-thing principle. Informally, we could state it as follows:\n\nSuppose there are two possible states of the world. If you prefer one option (A) over another (B) in one possible state, and you also prefer A over B under the alternative state, then you should prefer A over B even if you do not know which state will occur.",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Subjective expected utility theory</span>"
    ]
  },
  {
    "objectID": "probability-foundations/subjective-expected-utility.html#coherent-probabilities",
    "href": "probability-foundations/subjective-expected-utility.html#coherent-probabilities",
    "title": "34  Subjective expected utility theory",
    "section": "34.3 Coherent probabilities",
    "text": "34.3 Coherent probabilities\nThe Sure-Thing Principle, in combination with other axioms such as continuity, effectively forces subjective probabilities to be coherent.\nEach potential event must have a subjective probability of between 0 and 1 (non-negativity). Formally:\n\n0 \\leq \\pi(A) \\leq 1\n\nSubjective probabilities must be additive. That is, for mutually exclusive events A and B, the subjective probability of either event occurring is:\n\n\\pi(A \\cup B) = \\pi(A) + \\pi(B)\n\nFurther, the sum of the subjective probabilities of all all mutually exclusive, exhaustive events events is one (normalisation):\n\n\\sum \\pi(\\cdot) = 1\n\nOnce subjective probabilities satisfy the usual rules of probability, Bayes’ Rule becomes the only way to revise these probabilities consistently when new information arrives. If you learn some event B has happened, you must update the probability of A using:\n\n\\pi(A \\mid B) = \\frac{\\pi(A \\cap B)}{\\pi(B)},\n\nOtherwise, you could violate the Sure-Thing Principle by preferring one option over another in each conditional scenario (“if B” vs. “if not B”) yet reversing that preference when you do not know whether B has occurred. Thus, coherent subjective probabilities naturally imply Bayesian updating.\n\n34.3.1 Why coherence matters\nCoherence ensures that subjective probabilities avoids paradoxes and do not cause errors in decision-making.\nFor example, coherent subjective probabilities can allow someone to avoid a Dutch Book. A Dutch book is a set of bets that guarantees a loss to one party regardless of the outcome. If probabilities violate coherence requirements, such a set of bets can be constructed against the decision-maker.\nFor example, consider someone who assigns probabilities that violate additivity:\n\nProbability of rain tomorrow: 60%\nProbability of no rain tomorrow: 50%\n\nThese probabilities sum to 110%, violating normalisation. A bookmaker could:\n\nSell a $60 bet paying $100 if it rains\nSell a $50 bet paying $100 if it doesn’t rain\n\nThe decision-maker pays $110 in total. If it rains, they win $100 from bet 1 and nothing from bet 2. If it doesn’t rain, they win $100 from bet 2 and nothing from bet 1. The decision-maker pays $110 in total but can only win $100, guaranteeing a loss of $10.\nThe Dutch Book argument thus demonstrates that incoherent probabilities lead to exploitable inconsistencies. Decision-makers who follow the coherence requirements are protected from such guaranteed losses.",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Subjective expected utility theory</span>"
    ]
  },
  {
    "objectID": "probability-foundations/subjective-expected-utility.html#an-anomaly-the-ellsberg-paradox",
    "href": "probability-foundations/subjective-expected-utility.html#an-anomaly-the-ellsberg-paradox",
    "title": "34  Subjective expected utility theory",
    "section": "34.4 An anomaly: the Ellsberg Paradox",
    "text": "34.4 An anomaly: the Ellsberg Paradox\nThe Ellsberg paradox demonstrates that many people’s choices violate subjective expected utility theory.\nConsider two urns, each containing 100 balls. In the “risky” urn, there are 50 red and 50 black balls. In the “ambiguous” urn is a mix of red and black balls of unknown proportions. You are offered the following two gambles:\n\nThe first, which we will call gamble A, will involve a draw from the risky urn. If you correctly predict the colour that is drawn, you will win $100.\nThe second, gamble B, involves a draw from the ambiguous urn. Again, if you correctly predict the colour that is drawn, you will win $100.\n\n\n\n\n\n\nMost people strictly prefer gamble A to gamble B. However, this robust pattern violates subjective expected utility theory and the sure-thing principle.\nTo understand why, consider the probability of drawing a ball from the risky urn. The probability of drawing a red ball equals the probability of drawing a black ball which equals 0.5. Whatever colour you predict for gamble A, the expected utility of the draw from the risky urn is 0.5 times the utility of $100.\n\n\\mathbb{E}[U(A)] = 0.5u(\\$100)\n\nIf you draw from the ambiguous urn, we need to know the subjective probabilities you give for each ball colour. These don’t have to be 50%. Maybe the experimenter likes red.\nWhatever those subjective probabilities, we can calculate subjective expected utility. Let the subjective probability that the ball is red be \\pi(r), with the subjective probability of the ball being black being \\pi(b)=1-\\pi(r) (by normalisation).\nThe subjective expected utility of predicting red for gamble B is the subjective probability of the ball being red times the utility of winning $100:\n\n\\mathbb{E}[U(B_r)] = \\pi(r)u(\\$100)\n\nThe subjective expected utility of predicting black for gamble B is the subjective probability of the ball being black times the utility of winning $100:\n\n\\mathbb{E}[U(B_b)] = (1-\\pi(r))u(\\$100)\n\nAs you get to predict the colour, choosing gamble B will deliver you the higher of the subjective expected utility of red or black. Your subjective expected utility is the higher of the probability of red or black times the utility of winning $100.\n\\begin{align*}\n\\mathbb{E}[U(B)]&=\\max\\{\\pi(r)u(\\$100), (1-\\pi(r))u(\\$100\\} \\\\[12pt]\n&=\\max\\{\\pi(r), 1-\\pi(r)\\}u(\\$100)\n\\end{align*}\nIf \\pi(r)=0.5, then gambles A and B give the same subjective expected utility. But for any \\pi(r)\\neq 0.5, gamble B should be strictly preferred. This is because when your subjective probability differs from 0.5, you can increase your subjective expected utility by betting on whichever colour you believe is more likely in the ambiguous urn. Therefore, no matter what your subjective belief, gamble B should be at least weakly preferred to gamble A.\nTo put this into the language of the sure-thing principle, there are 101 possible states of the world (no red balls in the ambiguous urn, one red ball in the ambiguous urn, etc.). For 100 of those states - whenever there are not 50 of each colour in the urn - you should strictly prefer gamble B. In the case of equal numbers of each ball, you should weakly prefer gamble B (indifference). Therefore, given you should prefer gamble B to gamble A whatever the state, you should prefer gamble B not knowing precisely how many balls of each colour are in the ambiguous urn.\nThis paradox suggests people distinguish between risk (known probabilities) and ambiguity (unknown probabilities) in ways that subjective expected utility theory cannot capture. This result - known as the Ellsberg paradox - illustrates “ambiguity aversion”. People tend to prefer gambles with known probabilities over gambles with ambiguous probabilities.",
    "crumbs": [
      "Probability foundations",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Subjective expected utility theory</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics-and-biases.html",
    "href": "heuristics-and-biases/heuristics-and-biases.html",
    "title": "Heuristics and biases",
    "section": "",
    "text": "Imagine you are trying to catch a ball.\nOne strategy would be to calculate the ball’s trajectory - that is, it’s speed, angle, and spin - make some adjustments for wind resistance. You then move to the spot where the ball will land.\nAnother would be to use a simple rule: keep your eye on the ball and maintain a constant angle of gaze as you move. This mental shortcut - known as the gaze heuristic - works remarkably well. Yet this same strategy can lead you to run in a curved path rather than straight to where the ball will land. It might lead to first run away and then run toward the landing point.\n\nThis approach to catching a ball is an example of a heuristic - a mental shortcut. Heuristics are essential tools that help us navigate a complex world with constrained cognitive bandwidth. But heuristics can also lead to systematic biases.\nIn this part, I will explore how we use heuristics to form judgments and make decisions under uncertainty. I will examine how these mental shortcuts can lead to biases and errors in our reasoning.\nFirst, I’ll examine fundamental heuristics that people commonly use when assessing probabilities and making predictions. I’ll cover the representativeness heuristic (judging probability by similarity to prototypes), the availability heuristic (estimating frequency based on how easily examples come to mind), and anchoring and adjustment (using initial values as reference points for estimates).\nBuilding on this foundation, I’ll then analyse specific biases that emerge in probability judgments. We’ll explore the conjunction fallacy (judging combinations of events as more likely than individual events) and base-rate neglect (failing to consider background probabilities). We will also consider two famous biases that we encounter in the world of sports and gambling: the hot-hand fallacy and the gambler’s fallacy.\nWe will then look at how heuristics can actually serve as effective decision-making tools rather than just sources of error. Through the lens of the bias-variance trade-off, we’ll see how simpler heuristic approaches can sometimes outperform more complex strategies.\nFinally, I’ll examine overconfidence, an inability to calibrate the accuracy of our judgments. I will look at three dimensions of overconfidence, being overprecision, overestimation, and overplacement. We’ll explore how these manifest in real-world decision-making contexts.\nThis exploration will give us a richer understanding of how people actually make probabilistic judgments, rather than just how they theoretically should. This provides crucial insights for analysing decision-making under uncertainty.",
    "crumbs": [
      "Heuristics and biases"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics.html",
    "href": "heuristics-and-biases/heuristics.html",
    "title": "35  Heuristics",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Heuristics</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics.html#summary",
    "href": "heuristics-and-biases/heuristics.html#summary",
    "title": "35  Heuristics",
    "section": "",
    "text": "Heuristics are mental shortcuts or rules of thumb people use to make decisions. They often involve limited information and simpler computation than full optimization.\nThe representativeness heuristic involves judging the probability of an event or category membership based on how similar it is to a prototype or stereotype, often neglecting relevant base rates.\nThe availability heuristic leads people to estimate frequency or probability based on how easily examples come to mind, which can be influenced by factors like recency or vividness.\nAnchoring and adjustment is a process where people start with an initial value (anchor) and adjust insufficiently from it, even when the anchor is arbitrary or irrelevant, leading to biased estimates.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Heuristics</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics.html#introduction",
    "href": "heuristics-and-biases/heuristics.html#introduction",
    "title": "35  Heuristics",
    "section": "35.1 Introduction",
    "text": "35.1 Introduction\nHeuristics are mental shortcuts or rules of thumb that people use to make decisions. They differ from optimisation in that they typically involve a limited information set and a more computationally tractable decision method.\nAn example of a heuristic is the recognition heuristic. Under this heuristic, if one of two objects is recognised, infer that the recognised object is more likely to be the target object. For example, if you want to predict which of two players will win a tennis match, and you know of only one of the two players, infer that the player you know will win. Similarly, if judging the relative size of two cities, of which you have heard of only one, infer that the city you have heard of is larger.\nThere is substantial evidence that people use heuristics. People don’t normally calculate conditional probabilities using Bayes’ rule. Instead, the heuristics might approximate Bayes rule under certain conditions.\nHeuristics are often accurate and tractable, but in some environments can lead to error.\nTversky and Kahneman (1974) defined three now classic heuristics: representativeness, availability and anchoring.\nI will illustrate these three and then discuss a series of biases in probability judgment for which these heuristics may provide an explanation.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Heuristics</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics.html#representativeness-heuristic",
    "href": "heuristics-and-biases/heuristics.html#representativeness-heuristic",
    "title": "35  Heuristics",
    "section": "35.2 Representativeness heuristic",
    "text": "35.2 Representativeness heuristic\nSuppose you wish to estimate the probability that an event or person belongs to a certain class.\n\n“What is the probability that event A belongs to class B?”\n“What is the probability that process B will generate event A?”\n\nUnder the representativeness heuristic, people evaluate probabilities by the degree to which A is representative of (similar to) B.\nTversky and Kahneman (1974) provide the following example:\n\n[C]onsider an individual who has been described by a former neighbor as follows:\n“Steve is very shy and withdrawn, invariably helpful, but with little interest in people, or in the world of reality. A meek and tidy soul, he has a need for order and structure, and a passion for detail.”\nHow do people assess the probability that Steve is engaged in a particular occupation from a list of possibilities (for example, farmer, salesman, airline pilot, librarian, or physician)? How do people order these occupations from most to least likely? In the representativeness heuristic, the probability that Steve is a Iibrarian, for example, is assessed by the degree to which he is representative of, or similar to, the stereotype of a librarian. Indeed, research with problems of this type has shown that people order the occupations by probability and by similarity in exactly the same way.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Heuristics</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics.html#availability-heuristic",
    "href": "heuristics-and-biases/heuristics.html#availability-heuristic",
    "title": "35  Heuristics",
    "section": "35.3 Availability heuristic",
    "text": "35.3 Availability heuristic\nUnder the availability heuristic, people assess the frequency of a class or the probability of an event by the ease with which they can recall instances or occurrences. If an event is more “available”, it is judged to have a higher frequency or probability.\nFor example, if assessing the probability of a heart attack, you might recall occurrences among people you know. If you are assessing the probability of shark attack, you might recall how often you hear of attacks on the news.\nIn one experiment, Tversky and Kahneman (1974) gave experimental subjects lists of names. In some lists, the men were more famous than the women, and in other lists, vice versa. After viewing the list, they were asked whether the list had more men or women.\nFor each list, the subjects judged that the sex with more famous names was more common. Those names were more available in their minds.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Heuristics</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics.html#anchoring-and-adjustment",
    "href": "heuristics-and-biases/heuristics.html#anchoring-and-adjustment",
    "title": "35  Heuristics",
    "section": "35.4 Anchoring and adjustment",
    "text": "35.4 Anchoring and adjustment\nWhen using anchoring and adjustment, people estimate by starting from an initial value and adjust from that value to obtain the final estimate.\nSuppose you know the odds of outcome A, and want to estimate the odds of outcome B. Anchoring and adjustment implies that you will start with the odds of outcome A and adjust to obtain the odds of outcome B.\nThe accuracy of anchoring and adjustment depends on the anchor’s quality and the size of the adjustment from the anchor.\nThe quality of the anchor relates to the strength of the correlation between the anchor and the quantity being estimated. Empirically, people tend to use weak or irrelevant anchors.\nThe size of the adjustment then needs to account for the relationship between the anchor and the quantity being estimated. Empirically, observed adjustments from the anchor are too small.\nAs an example, Tversky and Kahneman (1974) asked subjects to estimate the percentage of African countries in the United Nations.\nA number between 0 and 100 was determined by spinning a wheel in the subjects’ presence. The subjects were instructed to indicate first whether that number was higher or lower than the estimated percentage, and then to estimate the value of the quantity by moving upward or downward from the given number.\nDifferent groups were given different numbers from the wheel. These arbitrary numbers had a marked effect on estimates. The median estimates of the percentage of African countries in the United Nations were 25 and 45 for groups that received numbers 10 and 65 from the wheel, respectively.\nPayoffs for accuracy did not reduce the effect of the anchor.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Heuristics</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics.html#heuristics-examples",
    "href": "heuristics-and-biases/heuristics.html#heuristics-examples",
    "title": "35  Heuristics",
    "section": "35.5 Heuristics examples",
    "text": "35.5 Heuristics examples\n\n35.5.1 A used car\nYou are shopping for a used car. You see a car you like and ask the salesperson how much it costs.\nShe says “one hundred thousand dollars”. You know this number is too high, and after some negotiation, purchase the car for $20,000. You feel pleased with your negotiation skills.\nYou later see a similar car for sale for $15,000.\nWhat heuristic could lead to your pattern of behaviour?\nThis pattern of behaviour could be caused by anchoring and adjustment.\nWhen using anchoring and adjustment, people estimate by starting from an initial value and adjust from that value to obtain the final estimate. Empirically, people tend to use weak or irrelevant anchors and make insufficient adjustments from the anchor.\nWhen the car dealer stated the high price, this acted as an anchor, even though you knew it was too high. You used a weak anchor.\nThat you ultimately purchased the car for too much suggests you insufficiently adjusted for that weak anchor.\n\n\n35.5.2 A wealthy person\nYou see a person who drives a luxury car and wears designer clothes. You decide they must be wealthy, even though you have no other information about this person. \na) What heuristic could lead to this belief?\nThe representativeness heuristic could cause this belief.\nUnder the representativeness heuristic, people evaluate probabilities by the degree to which A is representative of (similar to) B.\nIn this case, a person driving a luxury car and wearing designer clothes is highly representative of a wealthy person. You place a high probability on them being wealthy.\nb) Explain how using this heuristic would differ from using Bayes’ rule in this situation.\nUnder Bayes’ rule, the probability that someone is wealthy is a function of:\n\nthe probability that any particular person in the population is wealthy (the base rate that forms your prior probability)\nthe probability that a wealthy person will drive a luxury car and wear designer clothes\nthe probability that a non-wealthy person will drive a luxury car and wear designer clothes.\n\nThey take that prior probability and update it based on the evidence they have observed.\nBayes’ rule differs from that under the representativeness heuristic in that it considers the population’s base rate. What proportion of people are wealthy? The representativeness heuristic does not. The representativeness heuristic is largely based on the probability that a wealthy person will drive a luxury car and wear designer clothes relative to a non-wealthy person - that is, how representative clothing and cars are of wealth.\n\n\n\n\nTversky, A., and Kahneman, D. (1974). Judgment under Uncertainty: Heuristics and Biases. Science, 185(4157), 1124–1131. https://doi.org/10.1126/science.185.4157.1124",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>Heuristics</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/biases-in-probability-judgment.html",
    "href": "heuristics-and-biases/biases-in-probability-judgment.html",
    "title": "36  Biases in probability judgment",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Biases in probability judgment</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/biases-in-probability-judgment.html#summary",
    "href": "heuristics-and-biases/biases-in-probability-judgment.html#summary",
    "title": "36  Biases in probability judgment",
    "section": "",
    "text": "The conjunction fallacy occurs when people judge the probability of two events occurring together as higher than the probability of one of those events occurring alone, violating basic probability rules.\nBase-rate neglect is the tendency to ignore general probabilities (base rates) when making judgments about specific cases, often leading to errors in conditional probability calculations.\nProbability matching is a suboptimal strategy where people predict outcomes in proportion to their observed frequencies, rather than always choosing the most likely outcome.\nThe gambler’s fallacy is the mistaken belief that if an event occurs more frequently than normal during a given period, it will occur less frequently in the future (or vice versa).\nThe hot hand fallacy is the belief that a person who has experienced success with a random event has a greater chance of further success in additional attempts. Analysing this belief can be complicated by statistical biases in measurement and the potential existence of genuine “hot hands” in some contexts.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Biases in probability judgment</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/biases-in-probability-judgment.html#introduction",
    "href": "heuristics-and-biases/biases-in-probability-judgment.html#introduction",
    "title": "36  Biases in probability judgment",
    "section": "36.1 Introduction",
    "text": "36.1 Introduction\nIn this part, I introduce several biases in probability judgment:\n\nThe conjunction fallacy\nBase-rate neglect\nProbability matching\nThe gambler’s fallacy\nThe hot hand fallacy",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Biases in probability judgment</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/biases-in-probability-judgment.html#the-conjunction-fallacy",
    "href": "heuristics-and-biases/biases-in-probability-judgment.html#the-conjunction-fallacy",
    "title": "36  Biases in probability judgment",
    "section": "36.2 The conjunction fallacy",
    "text": "36.2 The conjunction fallacy\n\n\nThe conjunction fallacy occurs when someone judges the probability of the conjunction of two events to be greater than the probability of one or both events.\nFor example, if we have two outcomes, A and B, the probability of both A and B occurring - that is, the conjunction of A and B - should be less than or equal to each of the individual probabilities.\n\n\nCode\n# create a Venn diagram using ggvenn showing P(A), P(B) and P(A and B)\n\n# Import required package\nlibrary(\"ggvenn\")\n  \n# Create Data\nvenn &lt;- list(A = sort(sample(1:500, 50)),\n                  B = sort(sample(1:500, 50)))\n  \n# Create venn diagram Pairwise\nggvenn(venn, show_percentage = FALSE, show_elements=FALSE, fill_color=c(\"white\", \"white\"), set_name_color=\"white\",text_color=\"white\")+\n  annotate(\"text\",\n           x =  c(-.75, 0.75, 0),\n           y =   c(0,0,0),\n           label =  c('P(A)', 'P(B)', 'P(A and B)'),\n           size = 6)\n\n\n\n\n\nFigure 36.1: The conjunction of P(A) and P(B)\n\n\n\n\n\n\n\n\nThe most famous example of the conjunction fallacy comes from Tversky and Kahneman (1983). They asked students to read the following statement:\n\nLinda is 31 years old, single, outspoken, and very bright. She majored in philosophy. As a student, she was deeply concerned with issues of discrimination and social justice, and also participated in anti-nuclear demonstrations.\n\nTversky and Kahneman asked the students to rank the following statements from most to least probable:\n\nLinda is a teacher in elementary school.\nLinda works in a bookstore and takes Yoga classes.\nLinda is active in the feminist movement.\nLinda is a psychiatric social worker.\nLinda is a member of the League of Women Voters.\nLinda is a bank teller.\nLinda is an insurance salesperson.\nLinda is a bank teller and is active in the feminist movement.\n\nNote that “8. Linda is a bank teller and is active in the feminist movement” is a conjunction of “3. Linda is active in the feminist movement” and “6. Linda is a bank teller”.\nTversky and Kahneman found in a sample of students that 88% ranked 3 before 8 before 6. “6. Linda is a bank teller” was rated less probable than “8. Linda is a bank teller and is active in the feminist movement”.\nTo understand why this is an error, recall that the probability of the conjunction of two outcomes is as follows:\n\nP(A\\cap B)=P(A|B)P(B)=P(B|A)P(A)\n\nIf P(A|B)&lt;1 and P(B|A)&lt;1, P(A\\cap B) must be less than P(A) or P(B).\nOne explanation for why people make this error relates to the representativeness heuristic.\nTversky and Kahneman constructed the description of Linda to be representative of a feminist and unrepresentative of a bank teller. If people use the representativeness heuristic to order the statements, they will likely rank 8 above 6.\nThe Linda Problem is one of the most heavily debated experiments in the social sciences.\nFor example, Hertwig and Gigerenzer (1999) argue that people infer non-mathematical meaning to the word “probability”, taking it to mean “plausible” or “credible”.\nWhile this is possibly a fair critique of the Linda problem, other illustrations of the conjunction fallacy appear more robust.\nFor example, Tversky and Kahneman (1983) created this example involving rolls of a die:\n\nConsider a regular six-sided die with four green faces and two red faces. The die will be rolled 20 times and the sequence of greens (G) and reds (R) will be recorded. You are asked to select one sequence, from a set of three, and you will win $25 if the sequence you chose appears on successive rolls of the die. Please check the sequence of greens and reds on which you prefer to bet.\n\nRGRRR\nGRGRRR\nGRRRRR\n\n\n65% of experimental subjects chose sequence 2. It appears more “representative” of a die with four green faces and two red faces. But note that 1 is contained within 2 and is strictly more likely. The fact subjects are betting on the outcome should remove doubt about interpretation.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Biases in probability judgment</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/biases-in-probability-judgment.html#base-rate-neglect",
    "href": "heuristics-and-biases/biases-in-probability-judgment.html#base-rate-neglect",
    "title": "36  Biases in probability judgment",
    "section": "36.3 Base-rate neglect",
    "text": "36.3 Base-rate neglect\n\n\nThe base rate is the probability of an outcome unconditional on any evidence.\nFor example, if 1% of the population has COVID-19 and the remainder doesn’t, the base rate of COVID-19 is 1%. If you were to obtain evidence that someone has COVID-19, such as a positive COVID-19 test, you would use that base rate in determining the conditional probability that they have the disease.\nBase rate neglect is the failure to consider an event’s base rate when making a judgment.\n\n36.3.1 The cab problem\nOne illustration of base-rate neglect comes from the cab problem by Tversky and Kahneman (1982). It involves the following story:\n\nA cab was involved in a hit and run accident at night. Two cab companies, the Green and the Blue, operate in the city. Participants are given the following data:\n\n85% of the cabs in the city are Green, 15% are Blue.\nA witness identified the cab as Blue. The court tested the reliability of the witness under the same circumstances that existed on the night of the accident and concluded that the witness correctly identified each one of the two colours 80% of the time.\n\nWhat is the probability that the cab involved in the accident was Blue rather than Green?\n\nIn the experiment, the median and modal answer was 80%.\nThe correct answer is 41%.\nThe experimental result indicates confusion between conditional probabilities. The experimental participants were confusing the probability of the witness identifying a blue cab given that the cab was blue, with the probability of the cab being blue given that the witness identified it as blue. However, we need to use Bayes’ rule to calculate the probability of the cab being blue, given that the witness identified it as blue.\n\n\\underbrace{P(\\text{claim blue}|\\text{blue})}_{80\\%}\\neq \\underbrace{P(\\text{blue}|\\text{claim blue})}_{\\text{Requires Bayes' rule}}\n\nThe experimental subjects effectively neglected the rarity of blue cabs. A witness seeing a blue cab is representative of what would occur if the cab were blue.\nThe correct answer is as follows:\n\\begin{align*}\nP(\\text{blue}|\\text{claim blue})&=\\frac{P(\\text{claim blue}|\\text{blue})P(\\text{blue})}{P(\\text{claim blue})} \\\\[12pt]\n&=\\frac{P(\\text{claim blue}|\\text{blue})P(\\text{blue})}{\\Bigg(\\begin{aligned}P(&\\text{claim blue}|\\text{blue})P(\\text{blue})\\\\&+P(\\text{claim blue}|\\neg\\text{blue})P(\\neg\\text{blue})\\end{aligned}\\Bigg)} \\\\[30pt]\n&=\\frac{0.8\\times 0.15}{0.8\\times 0.15+0.2\\times 0.85} \\\\[12pt]\n&=0.41\n\\end{align*}\n\n\n36.3.2 Medical diagnosis\nWe can also see base rate neglect in the context of diagnosing a rare disease.\nConsider the following problem:\n\nYou test yourself for COVID-19. The following information is known:\n\nThe probability that a person has COVID-19 is 1% (the prevalence).\nIf a person has COVID-19, the probability that they test positive is 90% (the sensitivity).\nIf a person does not have COVID-19, the probability that they nevertheless test positive is 9% (the false positive rate).\n\nYou test positive. What is the chance that you have COVID-19?\n\nWhen problems of this nature are given to physicians, around 10 to 20% reason using Bayes’ rule (for example, see Hoffrage et al. (2015)). The most common answers approximate the sensitivity, 90% for this example.\nAs for the cab problem, there is confusion between the conditional probabilities.\n\nP(\\text{COVID}|\\text{+ve})\\neq P(\\text{+ve}|\\text{COVID})\n\nOne hypothesis for this error is that a positive test is “representative” of someone with COVID-19. As a result, the test is given greater weight than the more general information about the base rate.\nThe correct answer is:\n\\begin{align*}\nP(\\text{COVID}|\\text{+ve})&=\\frac{P(\\text{+ve}|\\text{COVID})P(\\text{COVID})}{P(\\text{+ve})} \\\\[12pt]\n&=\\frac{P(\\text{+ve}|\\text{COVID})P(\\text{COVID})}{\\Bigg(\\begin{aligned}P(&\\text{+ve}|\\text{COVID})P(\\text{COVID})\\\\&+P(\\text{+ve}|\\neg\\text{COVID})P(\\neg\\text{COVID})\\end{aligned}\\Bigg)} \\\\[30pt]\n&=\\frac{0.9\\times 0.01}{0.9\\times 0.01 + 0.09\\times 0.99} \\\\[12pt]\n&=0.092\n\\end{align*}\n\n\n36.3.3 Natural frequencies\nLet us reconsider this medical problem with an alternative representation. This representation uses “natural frequencies”.\n\nYou test yourself for COVID-19. The following information is known:\n\nTen in every 1000 people have COVID-19 (the prevalence).\nOf these 10 people with COVID-19, nine will test positive (the sensitivity).\nOf the 990 people without COVID-19, about 89 nevertheless test positive (the false positive rate).\n\nYou test positive. What is the chance that you have COVID-19?\n\nSeeing a representation in this manner makes the base rate (and the rate of false positives) much more salient, and leads to more accurate estimates of the conditional probabilities. We can see that the probability that we have COVID-19, given we tested positive for COVID-19, equals the number of people who have COVID-19 who have tested positive, divided by the total number of positive tests:\n\\begin{align*}\nP(\\text{COVID}|\\text{+ve})&=\\frac{n(\\text{+ve }\\cap \\text{COVID})}{n(\\text{+ve})} \\\\[12pt]\n&=\\frac{9}{9+89} \\\\[12pt]\n&=0.092\n\\end{align*}\nCosmides and Tooby (1996) first proposed using natural frequencies in this way. We derive natural frequencies by observing cases representatively sampled from a population.\nHoffrage and Gigerenzer (1998) reported that this change in representation increased the proportion of correct answers among physicians from 10% to 46%.\nThere is evidence that you can get further gains through a frequency tree representation (e.g. Spiegelhalter and Gage (2015)). Below is one such tree from Gigerenzer (2011), which they compare with a tree using conditional probabilities.\n\nThe numbers at the bottom of the conditional probability tree do not contain the base rate information. You can’t simply compare them to calculate conditional probabilities. You need to refer to the middle layer. Conversely, the natural frequency tree contains all you need to calculate the conditional probability in the bottom row.\nTo illustrate this point, consider what happens if we convert the numbers at the bottom of the conditional probability tree into frequencies: 900 in 1000, 10 in 1000, 90 in 1000 and 910 in 1000. Gigerenzer calls these simple frequencies. While simple frequencies can make a problem more tractable, they do not allow us to calculate conditional probabilities. Simple frequencies are just a restatement of the probabilities. In contrast, natural frequencies are joint frequencies, such as the number of people who test positive and who have COVID-19.\n\n36.3.3.1 Identifying a finch\nThe following example provides another illustration of the use of Bayes’ rule and natural frequencies.\nYou are trying to spot a rare type of bird, the Darwin finch. It looks very similar to the Wallace finch, except for a slight difference in the shape of its beak. You know the following about the finches in your area:\n\n99% of the finches are Wallace finches. The remaining 1% are Darwin finches.\nIf you spot a Darwin finch, you will correctly identify it as a Darwin finch 95% of the time. The other 5% of the time, you identify it as a Wallace finch.\nIf you spot a Wallace finch, you will correctly identify it as a Wallace finch 95% of the time. The other 5% of the time, you identify it as a Darwin finch.\n\nYou spot a finch and identify it as a Darwin finch.\nWhat is the probability that the finch is a Darwin finch?\nFirst, I use Bayes’ rule to calculate the probability.\n\\begin{align*}\nP(D|I)&=\\frac{P(I|D)P(D)}{P(I)} \\\\[6pt]\n&=\\frac{P(I|D)P(D)}{P(I|D)P(D)+P(I|\\neg D)P(\\neg D)} \\\\[6pt]\n&=\\frac{0.95\\times 0.01}{0.95\\times 0.01 + 0.05\\times 0.99} \\\\[6pt]\n&=0.16\n\\end{align*}\nThe probability that it is a Darwin finch is 16%.\nNext, I use natural frequencies to calculate that same conditional probability.\nSuppose there are 10,000 finches.\nThat would mean there are 100 Darwin finches and 9,900 Wallace finches.\nIf I spotted these 100 Darwin finches, I would identify 95 as Darwin finches.\nIf I spotted a Wallace Finch, I would identify 0.05\\times 9900=495 as Darwin Finches.\nThat means 95 of the 95+495=590 birds I identify as Darwin finches would be Darwin finches.\nTherefore:\n\\begin{align*}\nP(D|I)&=\\frac{95}{590} \\\\[6pt]\n&=0.16 \\\\\n\\end{align*}\nNote that in this example, I have started with a number of finches, 10,000, which allows me to avoid fractions and small decimals. If I started with only 100 finches, I would later be talking about an unintuitive 4.95 finches. If you are using natural frequencies to solve a problem of conditional probability, you should choose a large enough number to avoid complicated fractions and decimals. Alternatively (or in conjunction), round any unintuitive numbers to the nearest whole number, giving you an approximate answer in your final calculation.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Biases in probability judgment</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/biases-in-probability-judgment.html#probability-matching",
    "href": "heuristics-and-biases/biases-in-probability-judgment.html#probability-matching",
    "title": "36  Biases in probability judgment",
    "section": "36.4 Probability matching",
    "text": "36.4 Probability matching\n\n\nProbability matching is the tendency of people to mirror the probability distributions they observe in their predictions of events. For example, if asked to predict whether a die will show a six or not, they will predict six around one in six rolls.\nThe strategy of probability matching is not optimal for minimising prediction error.\nConsider the following experimental setup:\n\nA red lamp that turns on with probability p=0.70\nA green lamp that turns on with probability q=0.30\n\nParticipants predict which light will turn on after observing a series of flashes.\nWhat do participants do?\nThe predictions tend to reflect the actual probabilities of the two light bulbs being turned on. People tend to predict 70% of the time that the red lamp will come on and 30% of the time that the green lamp will come on.\nWith probability matching, the probability of a successful guess is:\n\\begin{align*}\np(\\text{success})&=0.7\\times 0.7+0.3\\times0.3 \\\\[6pt]\n&=0.58\n\\end{align*}\nA better strategy is always to select the event with the highest probability. In this example, participants should always predict that the red light will be turned on, giving them a 70% probability of a successful guess.\nSimilarly, for my earlier example of a die roll, the option with lowest error is always to predict that the die will not show a six.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Biases in probability judgment</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/biases-in-probability-judgment.html#the-gamblers-fallacy",
    "href": "heuristics-and-biases/biases-in-probability-judgment.html#the-gamblers-fallacy",
    "title": "36  Biases in probability judgment",
    "section": "36.5 The gambler’s fallacy",
    "text": "36.5 The gambler’s fallacy\n\n\nThe gambler’s fallacy is the false belief that an outcome not recently realised in a sequence of independent draws is more likely to occur on the next draw.\nFor example, following three flips of a coin that all come up heads, a person experiencing the gambler’s fallacy would believe that a tail is more likely on the next flip.\nUsing data from Rapoport and Budescu (1997), Rabin and Vayanos (2010) derived the probability of heads predicted by experimental subjects, given the last three flips being heads or tails. Following a sequence of three heads, they predict heads on the next flip with only 30% probability. But after three tails, they predict heads on the next flip with 70% probability.\n\nOne explanation for the gambler’s fallacy is representativeness. For example, people do not see the sequence of coin flips HHHHHH as representative of flipping a fair coin six times. They see HHTTHH as more representative, even though both sequences have the same probability of occurring.\n\n36.5.1 The law of small numbers\nAn alternative explanation is that people believe in the “law of small numbers” (Rabin, 2002). They overestimate the degree to which a small sample will resemble the population from which it is drawn. For example, if a fair coin is flipped six times, they will overestimate the likelihood the result will be three heads and three tails.\nImagine an urn filled with red balls and black balls. You draw balls from the urn with replacement. The red balls are drawn with probability p and the black balls are drawn with probability 1−p.\nAssume Freddy knows the probabilities p and 1−p but (wrongly) assumes balls are drawn from the urn without replacement. If he believes there are N balls in the urn, he expects a sample of N balls to match p and 1−p exactly.\nUnder Freddy’s beliefs, outcomes are correlated. Under the actual process, where balls are replaced, the outcomes are uncorrelated.\nImagine Freddy plays roulette. The roulette wheel contains 36 slots, 18 black and 18 red. Assume that Freddy believes there are 18 red and 18 black “balls in the urn”.\nFreddy observes four spins of the wheel before betting. He observes a sequence of four reds.\nAn unbiased belief would be that the sequence of reds tells him nothing about future draws because the outcomes are uncorrelated.\nHowever, Freddy believes that, after four reds, black is more likely on the next spin. He is wrongly computing the probability based on a belief that only 14 reds remain along with 18 blacks.\n\\begin{align*}\n\\hat P(RRRRR|RRRR)&=\\frac{\\text{reds}}{\\text{reds}+\\text{blacks}} \\\\[12pt]\n&=\\frac{18-4}{18-4+18} \\\\[12pt]\n&=0.438\n\\end{align*}\nIn reality, P(RRRRR|RRRR)=0.5. Freddy is suffering from the gambler’s fallacy.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Biases in probability judgment</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/biases-in-probability-judgment.html#the-hot-hand-fallacy",
    "href": "heuristics-and-biases/biases-in-probability-judgment.html#the-hot-hand-fallacy",
    "title": "36  Biases in probability judgment",
    "section": "36.6 The hot hand fallacy",
    "text": "36.6 The hot hand fallacy\n\n\nA person subject to the hot hand fallacy believes a streak will persist despite each outcome being independent of the last.\nFor example, suppose a spectator observes a basketball player taking a series of shots during a game. The spectator then makes predictions based on the observed shots, with good shots predicted to be more likely following a streak of successful shots. After a series of good shots, they believe the player has a “hot hand”.\nLet’s look at this example in more detail.\nSuppose a person takes ten shots in a basketball game. In this image, a ball is a hit, an X is a miss.\nTo assess whether this person has a hot hand, we can look at their shots following a previous hit. For instance, in this sequence of shots, there are six occasions where we have a shot following a hit. Five successful shots, such as the highlighted seventh shot, are followed by another hit.\n\nWe can then compare the player’s average shooting percentage with the proportion of shots they hit if the shot immediately before was a hit. If their hit rate after a hit is higher than their normal shot probability, we might say they get a hot hand.\nUsing this methodology, Gilovich et al. (1985) took shot data from various sources, including the Philadelphia 76ers and Boston Celtics, and examined the data for evidence of a hot hand. They also looked at whether there was a hit or miss after streaks of hits or misses.\nFrom this data, they argued that the hot hand was an illusion. There was no evidence that a player was more likely to make a shot following a series of successful shots.\n\n36.6.1 A bias in sequences\nGilovich et al. (1985) was the first of many examinations of whether there is a hot hand in sports (see Bar-Eli et al. (2006)). Through this research, there has been many methodological debates and arguments about whether there might be bias in the data, such as teams adjusting their defence in response to a player with a hot hand. However, the general trend in the literature was a finding of no evidence of a hot hand.\nMiller and Sanjurjo (2018) provided a compelling critique of this position. They found a statistical bias in the analysis by Gilovich et al. (1985) and many others. The intuition behind the statistical bias is as follows.\nSuppose you flip a coin three times. There are eight possible sequences of heads and tails. Each sequence has an equal probability of occurring.\nConsidering these sequences, if you were to flip a coin three times, and there is a head followed by another flip in that sequence, what is the expected probability that another head will follow that head?\nTable 36.1 shows the proportion of heads following a previous flip of heads for each sequence. In the table’s first row, HHH, the first flip is a head. Another head follows that first flip. After the second flip, a head, we also have a head. There is no flip after the third head. 100% of the heads in that sequence followed by another flip are followed by a head.\nIn the second row of the table, HHT, a head follows 50% of the heads.\nIn the third row, there is one head followed by another flip, which is a tail. None of the heads in that sequence are followed by a head.\nAnd so on until the last two rows, where there are no heads followed by another flip.\nNow, back to our question. If you were to flip a coin three times, and there is a head followed by another flip in that sequence, what is the expected probability that another head will follow that head? It turns out the answer to this question is 42%. I get this number by calculating the expected probability of a head given any particular sequence. This is equal to the average of the probabilities in each sequence.\n\n\n\nTable 36.1: Eight possible combinations of heads and tales across three flips\n\n\n\n\n\nFlips\np(H_{t+1}|H_t)\n\n\n\n\nHHH\n100%\n\n\nHHT\n50%\n\n\nHTH\n0%\n\n\nHTT\n0%\n\n\nTHH\n100%\n\n\nTHT\n0%\n\n\nTTH\n-\n\n\nTTT\n-\n\n\nExpected probability\n41.7%\n\n\n\n\n\n\nThat calculation contrasts with what we get we count across all of the sequences, where we see eight flips of head followed by another flip. Of the subsequent flips, four are heads and four are tails, which is the 50% you expect.\nWhy do we find that difference? By looking at these short sequences, we are introducing a bias. The cases of heads following heads tend to cluster together, such as in the first sequence, which has two cases of a head following a head. Yet the sequence THT, which has only one flip occurring after a head, is equally likely to occur as HHH. A tail appears more likely to follow a heads because of this bias, whereby the streaks tend to cluster together. The expected probability I get when taking a series of three flips is 42%, when in fact the actual probability of a head following a head is 50%. As the sequence of flips gets longer, the bias reduces in size, although it increases if we examine longer streaks, such as the probability of a head after three previous heads.\nThe net effect of this bias is that the measure of the proportion of heads following another head is biased downwards.\nThis bias is relevant to the analysis of the hot hand as it is present in the methodology of the papers that purportedly demonstrated that there was no hot hand in basketball, such as that by Gilovich et al. (1985). They effectively took short streaks of shots and calculated the proportion of hits followed by another hit. Their measure of the proportion of hits following a hit or sequence of hits is biased downwards. Like our calculation using coins, a calculation using that method results in a number lower than the actual probability of hitting a shot.\nConversely, the hot hand pushes the probability of hitting a shot after a previous hit up. If there is a hot hand, we should see more hits following a previous hit.\nNow consider the net effect of these two forces. If there is a hot hand, the probability of hitting a shot after a previous hit should be higher than the average hit rate. The biased methodology pushes the measure in the other direction. Together, the downward bias and the hot hand counteract each other. In the case of Gilovich et al. (1985), these two countervailing forces led to the conclusion by researchers that each shot is independent of the last.\nHowever, if you use a methodology not subject to this bias, you get a true measure of the hot hand. And in the case of the Gilovich et al. data, removing the bias reveals a hot hand. Miller and Sanjurjo (2018) found that in the Gilovich et al. data the probability of hitting a shot following a sequence of three previous hits is 13 percentage points higher than after a sequence of three misses.\n\n\n36.6.2 Alternative intuition\nHere is another way of showing that there is a bias in this sequence.\nTo do this, we will use Bayes’ rule with more than two variables. This operates in a similar manner to our previous use of Bayes’ rule.\nTo understand this, suppose we have three possible outcomes, A, B and C. For these outcomes we can write the following probabilities:\n\\begin{align*}\nP(A\\cap B\\cap C)&=P(A\\cap B|C)P(C)=P(A|B\\cap C)P(B\\cap C) \\\\[6pt]\n&=P(B|A\\cap C)P(A\\cap C)=P(C|A\\cap B)P(A\\cap B)\n\\end{align*}\nAnd so on. We can write the joint probability of these events as varying combinations of the conditional probabilities.\nTypically we derive Bayes’ rule by equating any two of these equations. For instance, as P(A|B\\cap C)P(B\\cap C)=P(B|A\\cap C)P(A\\cap C) we can rearrange this to write:\n\nP(A|B\\cap C)=\\frac{P(B|A\\cap C)P(A\\cap C)}{P(B\\cap C)}\n\nWe will use this equation in our example.\nNow, suppose we flip three coins and select at random one of the flips that follows a heads. This means that if we select a flip that follows a head we will select either flip 2 or flip 3.\nIf we select flip 2, we know that flip 1 was a head. The first two flips in the sequence are either HT or HH.\nHowever, we can also say that if we select flip 2, HT is twice as likely as HH. Why? Because if the first two coins were HH we could also have chosen flip 3.\nThat is, if the first two flips are HT, we can only select flip 2. We select flip 2 with 100% probability. If the first two flips are HH, we select flip 2 with 50% probability and flip 3 with 50% probability.\nWe are twice as likely to observe HT as HH, given we selected flip 2.\nUsing H_i or T_i to represent a head or tail on the i-th flip and X_i to represent selection of flip i, we can show the probability of a tail given we have selected flip 2 using Bayes’ rule. Using the equation we derived earlier involving three potential outcomes:\n\\begin{align*}\nP(T_2|H_1\\cap X_2)&=\\frac{P(X_2|H_1\\cap T_2)P(H_1\\cap T_2)}{P(H_1\\cap X_2)} \\\\[12pt]\n&=\\underbrace{\n  \\frac{\n    P(X_2|H_1\\cap T_2)P(H_1\\cap T_2)\n    }{\n      \\Bigg(\\begin{aligned}P(&X_2|H_1\\cap T_2)P(H_1\\cap T_2)\\\\&+P(X_2|H_1\\cap H_2)P(H_1\\cap H_2)\\end{aligned}\\Bigg)\n      }\n  }_{\\text{Expand denominator using formula for total probability}} \\\\[48pt]\n&=\\frac{1\\times 0.25}{1\\times 0.25+0.5\\times 0.25} \\\\[12pt]\n&=\\frac{2}{3} \\\\[6pt]\n\\\\\nP(H_2|H_1\\cap X_2 )&=\\frac{P(X_2|H_1\\cap H_2)P(H_1\\cap H_2)}{P(H_1\\cap X_2)} \\\\[12pt]\n&=\\underbrace{\n  \\frac{\n    P(X_2|H_1\\cap H_2)P(H_1\\cap H_2)\n    }{\n      \\Bigg(\\begin{aligned}P(&X_2|H_1\\cap T_2)P(H_1\\cap T_2)\\\\&+P(X_2|H_1\\cap H_2)P(H_1\\cap H_2)\\end{aligned}\\Bigg)\n      }\n  }_{\\text{Expand denominator using formula for total probability}} \\\\[48pt]\n&=\\frac{0.5\\times 0.25}{1\\times 0.25+0.5\\times 0.25} \\\\[12pt]\n&=\\frac{1}{3}\n\\end{align*}\nAs you can only select flip 2 if flip 1 is a head, we can also say that P(T_2|H_1\\cap X_2)=P(T_2|X_2)=\\frac{2}{3} and P(H_2|H_1\\cap X_2 )=P(H_2|X_2)=\\frac{1}{3}. That is, the probability of a tail given we have selected flip 2 is 2/3. The probability of a head given we have selected flip 2 is 1/3. We are twice as likely to observe T_2 as H_2, given we have selected flip 2.\nWe don’t see the same bias if we select flip 3.\nIf we select flip 3, we know that flip 2 was a head. But the fact we select flip 3 does not tell us anything about what flip 3 is, as flip 3 itself does not influence the choice of flip. Whether flip 3 is a head or tail is independent of the choice of flip 3 or the outcome of flip 2.\nAccordingly:\n\\begin{align*}\nP(T_3|H_2\\cap X_3)&=P(T_3)=0.5 \\\\\n\\\\\nP(H_3|H_2\\cap X_3)&=P(H_3)=0.5\n\\end{align*}\nWe now combine the results of our examination of the second and third flip.\nWe are equally likely to select flip 2 or flip 3 as flips 1 and 2 will each be heads with 50% probability. If both are heads, we select one randomly. Given we have selected a flip, what is the probability that the following flip is a head?\n\\begin{align*}\nP(H)&=P(X_2)\\times P(H_2|X_2)+P(X_3)\\times P(H_3|X_3) \\\\[6pt]\n&=0.5\\times 0.33+0.5\\times 0.5 \\\\[6pt]\n&=0.417\n\\end{align*}\nWhat does this mean for measurement of the hot hand?\nAs for before, if I take a sequence of three flips and I look at a flip after a head, if there is at least one head, the probability that flip is a head is 0.42. This is despite the coin flips being independent. It appears I have a cold hand.\nUse that same methodology in a scenario where there is a hot hand, the bias will counteract the hot hand and make it harder to detect, if it can be detected at all.\n\n\n36.6.3 The hot hand fallacy for truly random sequences\nDespite the evidence that there is a hot hand in some sports, there is strong evidence that there still exists a “hot hand fallacy”. People see streaks in truly random processes, with each outcome independent of the last.\nFor example, Ayton and Fischer (2004) found that when people predict the results of a roulette wheel’s spins, they increase their confidence in their predictions after a series of successes. Their confidence increases despite the outcome being random. Interestingly, they also exhibit the gambler’s fallacy in what they predict.\n\n\n\n\nAyton, P., and Fischer, I. (2004). The hot hand fallacy and the gambler’s fallacy: Two faces of subjective randomness? Memory & Cognition, 32(8), 1369–1378. https://doi.org/10.3758/BF03206327\n\n\nBar-Eli, M., Avugos, S., and Raab, M. (2006). Twenty years of “hot hand” research: Review and critique. Psychology of Sport and Exercise, 7(6), 525–553. https://doi.org/10.1016/j.psychsport.2006.03.001\n\n\nCosmides, L., and Tooby, J. (1996). Are humans good intuitive statisticians after all? Rethinking some conclusions from the literature on judgment under uncertainty. Cognition, 58(1), 1–73. https://doi.org/10.1016/0010-0277(95)00664-8\n\n\nGigerenzer, G. (2011). What are natural frequencies? BMJ, 343, d6386. https://doi.org/10.1136/bmj.d6386\n\n\nGilovich, T., Vallone, R., and Tversky, A. (1985). The hot hand in basketball: On the misperception of random sequences. Cognitive Psychology, 17(3), 295–314. https://doi.org/10.1016/0010-0285(85)90010-6\n\n\nHertwig, R., and Gigerenzer, G. (1999). The ‘conjunction fallacy’ revisited: how intelligent inferences look like reasoning errors. Journal of Behavioral Decision Making, 12(4), 275–305. https://doi.org/10.1002/(SICI)1099-0771(199912)12:4&lt;275::AID-BDM323&gt;3.0.CO;2-M\n\n\nHoffrage, U., and Gigerenzer, G. (1998). Using natural frequencies to improve diagnostic inferences. Academic Medicine, 73(5), 53840. https://doi.org/10.1097/00001888-199805000-00024\n\n\nHoffrage, U., Krauss, S., Martignon, L., and Gigerenzer, G. (2015). Natural frequencies improve bayesian reasoning in simple and complex inference tasks. Frontiers in Psychology, 6, 1473. https://doi.org/10.3389/fpsyg.2015.01473\n\n\nMiller, J. B., and Sanjurjo, A. (2018). Surprised by the Hot Hand Fallacy? A Truth in the Law of Small Numbers. Econometrica, 86(6), 2019–2047. https://doi.org/10.3982/ECTA14943\n\n\nRabin, M. (2002). Inference by believers in the law of small numbers. The Quarterly Journal of Economics, 117(3), 775–816. https://doi.org/10.1162/003355302760193896\n\n\nRabin, M., and Vayanos, D. (2010). The gambler’s and hot-hand fallacies: Theory and applications. The Review of Economic Studies, 77(2), 730–778. https://doi.org/10.1111/j.1467-937X.2009.00582.x\n\n\nRapoport, A., and Budescu, D. V. (1997). Randomization in individual choice behavior. Psychological Review, 104, 603–617. https://doi.org/10.1037/0033-295X.104.3.603\n\n\nSpiegelhalter, D., and Gage, J. (2015). What can education learn from real-world communication of risk and uncertainty? The Mathematics Enthusiast, 12(1), 4–10. https://doi.org/10.54870/1551-3440.1329\n\n\nTversky, A., and Kahneman, D. (1982). Evidential impact of base rates. In A. Tversky, D. Kahneman, and P. Slovic (Eds.), Judgment under uncertainty: Heuristics and biases (pp. 153–160). Cambridge University Press. https://www.cambridge.org/core/books/judgment-under-uncertainty/evidential-impact-of-base-rates/CC35C9E390727085713C4E6D0D1D4633\n\n\nTversky, A., and Kahneman, D. (1983). Extensional versus intuitive reasoning: The conjunction fallacy in probability judgment. Psychological Review, 90(4), 293–315. https://doi.org/10.1037/0033-295X.90.4.293",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>Biases in probability judgment</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics-and-the-bias-variance-trade-off.html",
    "href": "heuristics-and-biases/heuristics-and-the-bias-variance-trade-off.html",
    "title": "37  Heuristics and the bias-variance trade-off",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Heuristics and the bias-variance trade-off</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics-and-the-bias-variance-trade-off.html#summary",
    "href": "heuristics-and-biases/heuristics-and-the-bias-variance-trade-off.html#summary",
    "title": "37  Heuristics and the bias-variance trade-off",
    "section": "",
    "text": "Heuristics, while often associated with errors, can be powerful and effective decision-making tools due to the bias-variance trade-off.\nThe bias-variance trade-off suggests that as model complexity increases, bias tends to decrease, but variance (sensitivity to data fluctuations) increases. There’s an optimal level of complexity that balances these two factors.\nSimple heuristics can sometimes outperform more complex decision-making strategies by finding a better bias-variance trade-off, leading to lower overall error despite using less information.\nThe “Take the Best” heuristic, which uses cues in order of validity to make predictions, has been shown to perform as well as or better than multiple regression across various environments.\nThe gaze heuristic, used for catching balls, demonstrates how a simple rule (maintaining a constant angle of gaze) can effectively solve a complex problem without requiring complex calculations, even if it results in a seemingly biased movement pattern.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Heuristics and the bias-variance trade-off</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics-and-the-bias-variance-trade-off.html#introduction",
    "href": "heuristics-and-biases/heuristics-and-the-bias-variance-trade-off.html#introduction",
    "title": "37  Heuristics and the bias-variance trade-off",
    "section": "37.1 Introduction",
    "text": "37.1 Introduction\nMuch of the heuristics and biases literature of Kahneman, Tversky and those who followed in their footsteps focuses on the errors that can be caused by using heuristics. However, there are also powerful reasons why we use heuristics in decision making.\nOne of the strongest arguments for the use of heuristics relates to what is called the bias-variance trade-off.\nSuppose you are trying to make a prediction or develop an estimate based on historical data. There is a true underlying process that is generating the data. You plan to build a predictive model that should approximate the underlying process. You have a noisy data sample with which to develop it and you are trying to decide which predictors to include.\nFor example, you want to predict the level of dropout in a school. You have possible predictors such as attendance rates, family socio-economic status, the school’s average SAT score, and the degree of parental involvement in the child’s schooling. Which of those should you include in your model?\nBias is the degree to which there are erroneous assumptions in your model. The classic case of bias is when you have failed to include a relevant predictor. If you exclude relevant predictors, your predictive model will not include relevant relations between the predictors and the target output you are trying to predict. In the school example, to the extent any of these factors are linked to dropout rates, excluding them can bias your prediction.\nHowever, the inclusion of too many predictors can lead to what is called variance, which is an error that arises because of the sensitivity of the model to fluctuations in the data you use to develop the model. It ultimately involves giving too much weight to irrelevant or marginally relevant information.\nFor example, if you included the school colours in your model, it may appear to give you a better model due to noise. But as soon as you used that model to make a new prediction, the inclusion of the irrelevant variable would likely backfire.\nThe following image gives one conception of bias and variance. An unbiased predictor will tend to centre on the target. A low variance predictor will tend to cluster. A low variance, low bias estimate is the best outcome.\n\nHowever, as the term bias-variance trade-off suggests, you typically can’t choose the minimum bias, minimum variance option. There is a trade-off between the two. As model complexity increases, bias tends to decrease, but variance tends to go up. There is an optimal level of complexity.\n\nThe result of this bias-variance trade-off means that heuristics can sometimes be better than more complex decision making strategies. This is not just because they are tractable for the human mind - unlike, say prospect theory calculations or Bayesian updating - but also because they find a better bias-variance trade-off. Despite our focus on how heuristics can cause biases decisions, they can also lead to lower error.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Heuristics and the bias-variance trade-off</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics-and-the-bias-variance-trade-off.html#simple-heuristics",
    "href": "heuristics-and-biases/heuristics-and-the-bias-variance-trade-off.html#simple-heuristics",
    "title": "37  Heuristics and the bias-variance trade-off",
    "section": "37.2 Simple heuristics",
    "text": "37.2 Simple heuristics\nIn a chapter in Simple Heuristics That Make Us Smart, Czerlinski et al. (1999) describe a competition between some simple heuristics and multiple regression. Both were used to predict outcomes across 20 environments, such as school dropout rates and fish fertility.\nOne simple heuristic in their competitions was “Take the Best”. This heuristic operates by working through variables in order of validity in predicting the outcome. For example, if you want to know which of two schools has the highest dropout rate, you ask which of the many possible predictive cues has the highest validity. If student attendance rate has the highest validity, and one school has lower attendance than the other, infer that that school with the lower attendance has the higher dropout rate. If the attendance rate is the same, look at the next cue.\nDepending on the precise specifications, the result of the competition across the 20 environments was either a victory for Take the Best or at least equal performance with multiple regression. This is impressive for something that is less computationally expensive and ignores much of the data (or in other words, is biased).\nThe reason for this success was that the simpler models had lower variance. This enabled lower or similar total error to the more complex models that included all variables.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Heuristics and the bias-variance trade-off</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics-and-the-bias-variance-trade-off.html#example-the-gaze-heuristic",
    "href": "heuristics-and-biases/heuristics-and-the-bias-variance-trade-off.html#example-the-gaze-heuristic",
    "title": "37  Heuristics and the bias-variance trade-off",
    "section": "37.3 Example: The gaze heuristic",
    "text": "37.3 Example: The gaze heuristic\nAs another example of a heuristic in operation, consider the gaze heuristic.\nThe gaze heuristic is a tool that people - and dogs - use to catch balls. The heuristic is simply this: maintain the ball at a constant angle of gaze. If you move to keep this angle constant, you will end up where the ball lands. Obviously, this is easier than calculating where you should be from the velocity of the ball, the angle of flight, the effect of wind resistance and so on.\n\n\nSource: Gigerenzer (2021)\n\n\n\nBut it results in a strange pattern of movement. Suppose you are close to the point where the ball is first hit into the air. As it rises you will tend to back away from the ball. As it then starts to fall, you will move back in. If it is hit up to the side of you, you will move to the ball in a curve. If you examine the path you took to catch the ball, you might call the curve a bias. However, it is actually the result of a very effective decision-making tool.\nThere are also some circumstances where the gaze heuristic works better than others. It tends to work best when the ball is already high in the air. If you catch sight of a ball hit straight up before it has risen far, using the heuristic for its entire flight could require first running away from the ball and then toward it.\nUnderstanding this is a much richer understanding than saying that the catcher is biased because they did not run straight to where the ball was going to land. It also points to the power of heuristics. Try to train someone to run straight to where a ball will land and watch them fail. Don’t see heuristics as poor cousins of “more rational” approaches.\n\n\n\n\nCzerlinski, J., Gigerenzer, G., and Goldstein, D. G. (1999). How good are simple heuristics. In G. Gigerenzer, P. Todd, and The ABC Research Group (Eds.), Simple heuristics that make us smart. Oxford University Press.\n\n\nGigerenzer, G. (2021). Embodied heuristics. Frontiers in Psychology, 12. https://www.frontiersin.org/articles/10.3389/fpsyg.2021.711289",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Heuristics and the bias-variance trade-off</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/overconfidence.html",
    "href": "heuristics-and-biases/overconfidence.html",
    "title": "38  Overconfidence",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Overconfidence</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/overconfidence.html#summary",
    "href": "heuristics-and-biases/overconfidence.html#summary",
    "title": "38  Overconfidence",
    "section": "",
    "text": "Overconfidence is a robust finding in judgment and decision-making research, but it actually encompasses three distinct phenomena: overprecision, overestimation, and overplacement.\nOverprecision is the tendency to believe our predictions or estimates are more accurate than they are, often demonstrated in confidence interval tasks.\nOverestimation is the belief that we can perform better than we realistically can, typically occurring for difficult tasks but not for easy ones.\nOverplacement is the erroneous judgment that we are better than others, which varies with task difficulty. People tend to overplace on easy tasks and underplace on difficult ones.\nOverconfidence has been linked to real-world phenomena such as excessive firm entry in markets and over-trading in financial markets, with experiments and studies demonstrating how it can lead to suboptimal outcomes in these domains.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Overconfidence</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/overconfidence.html#introduction",
    "href": "heuristics-and-biases/overconfidence.html#introduction",
    "title": "38  Overconfidence",
    "section": "38.1 Introduction",
    "text": "38.1 Introduction\nDe Bondt and Thaler (1995) wrote “Perhaps the most robust finding in the psychology of judgment and choice is that people are overconfident.”\nTake the following examples:\n\nA person is asked to estimate the length of the Nile by providing a range that the respondent is 90% sure contains the correct answer. For example, they might answer that there is a 90% probability that the Nile is between 2500km and 5000km long. However, when people answer this question, the estimate typically contains the correct answer only 50% of the time.\nPGA golfers typically believe they sink around 75% of 6-foot putts – some even believe they sink as many as 85% – when the average is closer to 55%.\n93% of American drivers rate themselves as better than average. 25% of high school seniors believe they are in the top 1% in their ability to get along with others.\n\nThere are many similar examples, all making the case that people are generally overconfident.\nBut despite each being labelled as overconfidence, note that these examples are three different phenomena.\nOverprecision is the tendency to believe that our predictions or estimates are more accurate than they are. The typical study seeking to show overprecision asks for someone to give confidence ranges for their estimates, such as estimating the length of the Nile.\nOverestimation is the belief that we can perform at a level beyond that which we realistically can. The evidence here is mixed. We typically overestimate when attempting a difficult task, such as a six-foot putt. But on easy tasks, the opposite is often the case – we tend to underestimate our performance. Whether over or underestimation occurs depends upon the domain.\nOverplacement is the erroneous relative judgement that we are better than others. Obviously, we cannot all be better than average. But this relative judgement, like overestimation, tends to vary with task difficulty. For easy tasks, such as driving a car, we overplace and consider ourselves better than most. But, people will rate themselves below average for a skill such as drawing or identifying plants from the Amazon. People don’t suffer from pervasive overplacement. Whether they overplace depends on what the situation is.\nYou might note that we tend to both underestimate and overplace our performance on easy tasks. We can also overestimate but underplace our performance on difficult tasks.\nSo, are we both underconfident and overconfident at the same time? The blanket term of overconfidence does little justice to what is occurring.\nThe conflation of these different effects under the umbrella of overconfidence often plays out in stories of how overconfidence (rarely assessed before the fact) led to someone’s fall. For instance, evidence that people tend to believe they are better drivers than average (overplacement) is not evidence that overconfidence led someone to pursue a disastrous corporate merger (overestimation).",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Overconfidence</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/overconfidence.html#firm-entry",
    "href": "heuristics-and-biases/overconfidence.html#firm-entry",
    "title": "38  Overconfidence",
    "section": "38.2 Firm entry",
    "text": "38.2 Firm entry\nAn example of overconfidence in action can be seen in firm entry.\nMost new businesses fail within a few years. For example, one study of US manufacturers found over 60% of entrants had exited within five years and almost 80% within 10 years.\nCamerer and Lovallo (1999) ran an experiment to test whether business failure may be due to optimism about their relative skill.\nThe lab experiment involved a set of markets. Those who chose to participate in a market were paid a set amount according to their rank within the market. Those ranked within the “market capacity” would share a payment of $50. Those beyond the market capacity would be penalised $10. Accordingly, if there are 5 entrants above market capacity, the expected payoff of all entrants is zero. More than that and it is negative.\nThe rank in the market was determined by either luck, through a random draw, or a test of skill involving logic puzzles or trivia questions about sports or current events.\nIn each round of the experiment, the market capacity was announced to the players, along with whether the payoffs in the market were based on luck or skill. The participants were then asked to forecast the expected number of entrants (for which they earn a payment if correct) and decide simultaneously and without communicating whether to enter into the market. Subjects were then told how many participants had entered.\nAfter all of the rounds, students solved puzzles or took the trivia quiz to determine their skill rank.\n\nThe results of the experiment showed that more participants entered the market when the ranking was based on skill than if based on random draw. This indicates a belief that their skill level will rank them higher than a random draw: they are above average.\nAn interesting element to this experiment was that for some of the markets the participants were recruited by being asked if they would like to volunteer for an experiment in which performance would depend on their performance on sports or current event trivia questions. Hence the pool in those markets would be stronger than typical.\nIn those markets with self-selected participants, market entry was even higher, and payoffs were negative in most rounds. This suggests the self-selected entrants were overconfident in their skill due to what Camerer and Lovallo call “reference group neglect”. The participants seem to neglect that the others in the reference group also self-selected in to the experiment and think they are skilled too.\nMoore et al. (2007) also ran an experiment on firm entry and found, like Camerer and Lovallo, that entrepreneurs overweight personal factors and underweight competitors when making entry decisions. However, when they varied the task difficulty, they found excess entry only when the industry appeared an easy one in which to compete. When it appeared difficult, too few entered. People overplaced in easy markets and underplaced in hard ones.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Overconfidence</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/overconfidence.html#trading",
    "href": "heuristics-and-biases/overconfidence.html#trading",
    "title": "38  Overconfidence",
    "section": "38.3 Trading",
    "text": "38.3 Trading\nAnother domain where overconfidence has been argued to play a role is related to trading.\nA consistent finding in the analysis of trading behaviour is that more trading leads to poorer outcomes. The higher transaction costs are not compensated through higher returns.\nTo test whether over-trading may be linked to overconfidence, Barber and Odean (2001) examined investors by gender. Men tend to be more overconfident than women - a point they support with evidence of overprecision, overplacement and overestimation. If overconfidence leads to more trading, you would predict that men would trade more than women.\nBarber and Odean (2001) examined trading account data from over 35,000 households for the period from February 1991 to January 1997. They found that men traded 45 percent more than women, reducing their net returns by 2.65 percentage points a year as opposed to 1.72 percentage points for women.\n\n\n\n\nBarber, B. M., and Odean, T. (2001). Boys will be boys: Gender, overconfidence, and common stock investment*. The Quarterly Journal of Economics, 116(1), 261–292. https://doi.org/10.1162/003355301556400\n\n\nCamerer, C., and Lovallo, D. (1999). Overconfidence and Excess Entry: An Experimental Approach. The American Economic Review, 89(1), 13.\n\n\nDe Bondt, W. F. M., and Thaler, R. H. (1995). Chapter 13 Financial decision-making in markets and firms: A behavioral perspective. In R. A. Jarrow, V. Maksimovic, and W. T. Ziemba (Eds.), Handbooks in Operations Research and Management Science (Vol. 9, pp. 385–410). Elsevier. https://www.sciencedirect.com/science/article/pii/S092705070580057X\n\n\nMoore, D. A., Oesch, J. M., and Zietsma, C. (2007). What Competition? Myopic Self-Focus in Market-Entry Decisions. Organization Science, 18(3), 440–454. https://doi.org/10.1287/orsc.1060.0243",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Overconfidence</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics-and-biases-exercises.html",
    "href": "heuristics-and-biases/heuristics-and-biases-exercises.html",
    "title": "39  Heuristics and biases exercises",
    "section": "",
    "text": "39.1 Detecting a terrorist\nEvery month 100 million people fly on commercial airlines. Imagine 10 of them are terrorists.\nAirport security are able to correctly identify that a person is a terrorist in 99% of cases and a non-terrorist in 99.9% of cases.\na) Intuitive responses to questions of this type tend to involve much higher probabilities. Discuss how intuitive responses could err due to confusion of conditional probabilities.\nb) State and solve the question in part a) in terms of natural frequencies.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Heuristics and biases exercises</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics-and-biases-exercises.html#detecting-a-terrorist",
    "href": "heuristics-and-biases/heuristics-and-biases-exercises.html#detecting-a-terrorist",
    "title": "39  Heuristics and biases exercises",
    "section": "",
    "text": "Answer\n\n\n\n\n\nIf a person confuses P(\\text{terrorist | identified}) with P(\\text{identified | terrorist}) they will wrongly assume the probability that someone identified as a terrorist is a terrorist is 99%. This is a common explanation for mistakes of this nature: e.g. identification of cabs problem discussed in Section 36.3.1.\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nNumber of passengers: 100,000,000\nNumber of terrorists: 10\nNumber of terrorists identified as terrorists: 10\\times 0.999 \\approx 10\nNumber of non-terrorists identified as terrorists: 0.001\\times 100,000,000=100,000\nProportion of people identified as terrorists who are terrorists = 10/(10+100000) \\approx 1 \\text{ in } 10000",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Heuristics and biases exercises</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics-and-biases-exercises.html#a-fire-alarm",
    "href": "heuristics-and-biases/heuristics-and-biases-exercises.html#a-fire-alarm",
    "title": "39  Heuristics and biases exercises",
    "section": "39.2 A fire alarm",
    "text": "39.2 A fire alarm\nYou know the following statistics about fire:\n\nThe probability of your house catching fire on any particular day is 1 in 10,000\nYour fire alarm correctly detects a house fire 95% of the time\nThe probability that your fire alarm sounds on a day when there is no fire (a false alarm) is 1 in 100.\n\na) Your alarm goes off. What is the probability that your house is on fire?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\begin{align*}\nP(\\text{fire}|\\text{alarm})&=\\frac{P(\\text{alarm}|\\text{fire})P(\\text{fire})}{P(\\text{alarm})} \\\\[12pt]\n&=\\frac{P(\\text{alarm}|\\text{fire})P(\\text{fire})}{P(\\text{alarm}|\\text{fire})P(\\text{fire})+P(\\text{alarm}|\\neg\\text{fire})P(\\neg\\text{fire})} \\\\[12pt]\n&=\\frac{0.95\\times 0.0001}{0.95\\times 0.0001+0.01\\times 0.9999} \\\\[12pt]\n&=0.0094\n\\end{align*}\nThe probability of a fire if the alarm goes off is 0.94%.\n\n\n\nb) Many people given this problem estimate the probability of the house being on fire as close to 95%. Provide one possible explanation for this error.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nPeople often confuse P(A|B) with P(B|A). In this case, such confusion would lead them to conclude that P(\\text{fire}|\\text{alarm})=P(\\text{alarm}|\\text{fire})=95\\%. You might also think of this as anchoring on the 95% and insufficiently adjusting from there.\nAlternatively, people sometimes act as though they have assumed uniform priors: e.g. 50:50 as to whether a fire or not.\nIn that case:\n\\begin{align*}\nP(\\text{fire}|\\text{alarm})&=\\frac{P(\\text{alarm}|\\text{fire})P(\\text{fire})}{P(\\text{alarm})} \\\\[12pt]\n&=\\frac{P(\\text{alarm}|\\text{fire})P(\\text{fire})}{P(\\text{alarm}|\\text{fire})P(\\text{fire})+P(\\text{alarm}|\\neg\\text{fire})P(\\neg\\text{fire})} \\\\[12pt]\n&=\\frac{0.95\\times 0.5}{0.95\\times 0.5+0.01\\times 0.5} \\\\[12pt]\n&=0.9896\n\\end{align*}\n\n\n\nc) Express and solve this problem using natural frequencies.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nYour house will catch fire on 100 out of 1,000,000 days. (You could choose any base number of days - I chose 1 million as gives round numbers for the following items.)\nYour fire alarm will correctly detect a house fire on 95 of those days.\nYou will have a false alarm on 9,999 out of the 999,900 days without fire.\n\n\\begin{align*}\nP(\\text{fire}|\\text{alarm})&=\\frac{95}{95+9999} \\\\[12pt]\n&=0.0094\n\\end{align*}",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Heuristics and biases exercises</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics-and-biases-exercises.html#the-law-of-small-numbers",
    "href": "heuristics-and-biases/heuristics-and-biases-exercises.html#the-law-of-small-numbers",
    "title": "39  Heuristics and biases exercises",
    "section": "39.3 The law of small numbers",
    "text": "39.3 The law of small numbers\nLincoln observes performance by fund manager Neville. Neville may be a skilled, mediocre or unskilled manager:\n\nA skilled fund manager has a 75% chance of beating the market each quarter.\nA mediocre fund manager has a 50% chance of beating the market each quarter.\nAn unskilled fund manager has a 25% chance of beating the market each quarter.\n\nLincoln knows these odds.\nThe performance of a fund manager is independent from quarter to quarter.\nConsider the model we used to examine behaviour involving a belief in the law of small numbers whereby the decision maker acts as though the process has the character of balls being drawn out of an urn without replacement. Lincoln develops his beliefs using this model with N = 12.\na) Lincoln thinks Neville is mediocre. What does Lincoln believe is the probability that Neville beats the market in the first quarter?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nLincoln thinks the realisation of Neville’s performance is like drawing from an urn with N=12 balls. Because he believes Neville is mediocre, he thinks half (6) of the balls are good-performance balls and half (6) are bad-performance balls. The likelihood of drawing a good ball (G) the first quarter is 6/12.\n\\begin{align*}\n\\hat P(G)&=\\frac{G}{N} \\\\[12pt]\n&=\\frac{6}{12} \\\\[12pt]\n&=0.5\n\\end{align*}\n\n\n\nb) Neville beats the market in the first quarter. What does Lincoln believe is the probability he does it again in the second quarter?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn Lincoln’s mind, the balls are not replaced once drawn. If Neville has a good first quarter, Lincoln believes that only five good balls remain. Therefore, Lincoln believes that the probability of Neville having a good second quarter is 5/11.\n\\begin{align*}\n\\hat P(GG|G)&=\\frac{G-1}{N-1} \\\\[12pt]\n&=\\frac{5}{11}\n\\end{align*}\n\n\n\nc) Neville beats the market again. What does Lincoln believe is the probability that he will do so in the third quarter?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAfter two good quarters, Lincoln believes only four good balls remain. Therefore, the probability of Neville having another good quarter is 4/10.\n\\begin{align*}\n\\hat P(GGG|GG)&=\\frac{G-2}{N-2} \\\\[12pt]\n&=\\frac{4}{10}\n\\end{align*}\n\n\n\nd) Lincoln observes Jill, who he believes is a skilled fund manager. What does Lincoln believe is the probability of her having 10 consecutive periods of out-performance?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nLincoln believes that in 12 quarters Jill will have nine quarters of out-performance. As a result, he does not believe it is possible for her to have ten consecutive periods of out-performance. After nine periods, only three balls are left in the urn. None of those balls are good.\n\\begin{align*}\n\\hat P(GGGGGGGGGG|GGGGGGGGG)&=\\frac{G-9}{N-9} \\\\[12pt]\n&=\\frac{0}{3} \\\\[12pt]\n&=0\n\\end{align*}\n\n\n\ne) What psychological bias does Lincoln’s behaviour reflect? Explain.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nEach time Neville has a good quarter, Lincoln thinks it is less likely that Neville will have another. This is an example of gambler’s fallacy. Lincoln thinks that Neville’s sequence of performances should be the typical sequence of a mediocre fund manager, with the same number of good and bad quarters. This leads Lincoln to expect bad quarters to be more likely after a sequence of good quarters.\nSimilarly for Jill, Lincoln expects a string of success to correct itself and her record to revert to the average for a skilled manager.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Heuristics and biases exercises</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics-and-biases-exercises.html#heuristics",
    "href": "heuristics-and-biases/heuristics-and-biases-exercises.html#heuristics",
    "title": "39  Heuristics and biases exercises",
    "section": "39.4 Heuristics",
    "text": "39.4 Heuristics\nFor each of the following experiments from Tverksy and Kahneman (1974), explain what heuristic may be leading to the belief or decision.\na) Tverksy and Kahneman (1974) write:\n\nSubjects were shown brief personality descriptions of several individuals, allegedly sampled at random from a group of 100 professionals-engineers and lawyers. The subjects were asked to assess, for each description, the probability that it belonged to an engineer rather than to a lawyer. In one experimental condition, subjects were told that the group from which the descriptions had been drawn consisted of 70 engineers and 30 lawyers. In another condition, subjects were told that the group consisted of 30 engineers and 70 lawyers. The odds that any particular description belongs to an engineer rather than to a lawyer should be higher in the first condition, where there is a majority of engineers, than in the second condition, where there is a majority of lawyers. Specifically, it can be shown by applying Bayes’ rule that the ratio of these odds should be (.7/.3^2), or 5.44, for each description. In a sharp violation of Bayes’ rule, the subjects in the two conditions produced essentially the same probability judgments.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThis behaviour might be explained by representativeness. Tverksy and Kahneman (1974) write:\n\n[S]ubjects evaluated the likelihood that a particular description belonged to an engineer rather than to a lawyer, by the degree to which this description was representative of the two stereotypes, with little or no regard for the prior probabilities of the categories.\nThe subjects used prior probabilities correctly when they had no other information. In the absence of a personality sketch, they judged the probability that an unknown individual is an engineer to be .7 and .3, respectively, in the two base-rate conditions. However, prior probabilities were effectively ignored when a description was introduced, even when this description was totally uninformative.\n\n\n\n\nb) Tverksy and Kahneman (1974) write:\n\nSuppose one samples a word (of three letters or more) at random from an English text. Is it more likely that the word starts with r or that r is the third letter? … [M]ost people judge words that begin with a given consonant to be more numerous than words in which the same consonant appears in the third position. They do so even for consonants, such as r or k, that are more frequent in the third position than in the first.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThis behaviour might be explained by availability. Tverksy and Kahneman (1974) write:\n\nPeople approach this problem by recalling words that begin with r (road) and words that have r in the third position (car) and assess the relative frequency by the ease with which words of the two types come to mind. Because it is much easier to search for words by their first letter than by their third letter, most people judge words that begin with a given consonant to be more numerous than words in which the same consonant appears in the third position.\n\n\n\n\nc) Tverksy and Kahneman (1974) write:\n\nTwo groups of high school students estimated, within 5 seconds, a numerical expression that was written on the blackboard. One group estimated the product\n8\\times 7\\times 6\\times 5\\times 4\\times 3\\times 2\\times 1\nwhile another group estimated the product\n1\\times 2\\times 3\\times 4\\times 5\\times 6\\times 7\\times 8\n…\nThe median estimate for the ascending sequence was 512, while the median estimate for the descending sequence was 2,250. The correct answer is 40,320.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThis behaviour might be explained by anchoring and adjustment. Tverksy and Kahneman (1974) write:\n\nTo rapidly answer such questions, people may perform a few steps of computation and estimate the product by extrapolation or adjustment. Because adjustments are typically insufficient, this procedure should lead to underestimation. Furthermore, because the result of the first few steps of multiplication (performed from left to right) is higher in the descending sequence than in the ascending sequence, the former expression should be judged larger than the latter.\n\n\n\n\nd) Tverksy and Kahneman (1974) write:\n\nIn considering tosses of a coin for heads or tails … people regard the sequence H-T-H-T-T-H to be more likely than the sequence H-H-H-T-T-T … [or] … the sequence H-H-H-H-T-H.\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThis behaviour might be explained by representativeness. Tverksy and Kahneman (1974) write:\n\nPeople expect that a sequence of events generated by a random process will represent the essential characteristics of that process even when the sequence is short. …\n[P]eople expect that the essential characteristics of the process will be represented, not only globally in the entire sequence, but also locally in each of its parts. A locally representative sequence, however, deviates systematically from chance expectation: it contains too many alternations and too few runs. Another consequence of the belief in local representativeness is the well-known gambler’s fallacy. After observing a long run of red on the roulette wheel. for example, most people erroneously believe that black is now due, presumably because the occurrence of black will result in a more representative sequence than the occurrence of an additional red.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Heuristics and biases exercises</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics-and-biases-exercises.html#overconfidence",
    "href": "heuristics-and-biases/heuristics-and-biases-exercises.html#overconfidence",
    "title": "39  Heuristics and biases exercises",
    "section": "39.5 Overconfidence",
    "text": "39.5 Overconfidence\nConsider the following three statements. Suppose that each statement is an instance of overconfidence. For each statement name and define the form of overconfidence that provides the best explanation for the students’ beliefs.\na) 90% of students believe they will score above the class average in the final exam.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nOverplacement.\nOverplacement is the erroneous relative judgement that we are better than others.\n\n\n\nb) 90% of students believe they will receive a high distinction.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nOverestimation.\nOverestimation is the belief that we can perform at a level beyond that which we realistically can.\n\n\n\nc) Arthur believes with 90% probability that he will score between 74% and 76% in the final exam.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nOverprecision.\nOverprecision is the tendency to believe that our predictions or estimates are more accurate than they actually are.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Heuristics and biases exercises</span>"
    ]
  },
  {
    "objectID": "heuristics-and-biases/heuristics-and-biases-exercises.html#lethal-events",
    "href": "heuristics-and-biases/heuristics-and-biases-exercises.html#lethal-events",
    "title": "39  Heuristics and biases exercises",
    "section": "39.6 Lethal events",
    "text": "39.6 Lethal events\nWhen people are asked the frequency of lethal events, they are often inaccurate. The following table lists those events most subject to under- or over-estimation of the frequency.\n\n\n\n\n\n\n\nMost overestimated\nMost underestimated\n\n\n\n\nAll accidents\nMotor vehicle accidents\nTornadoes\nFlood\nAll cancer\nFire and flames\nVenomous bite or sting\nHomicide\nDiabetes\nStomach cancer\nStroke\nTuberculosis\nAsthma\nEmphysema\n\n\n\nWhat heuristic could lead to this pattern of overestimation and underestimation? Why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe most overestimated events tend to be vivid events that are often the subject of news. The most underestimated are much less vivid and likely receive less coverage.\nThis pattern could be driven by the availability heuristic. When using the availability heuristic, people judge the frequency of events by the ease with which instances of those events come to mind.\nWhen asked to estimate the frequency of vivid events often in the news, instances of those events will easily come to mind. The availability heuristic will lead these events to be judged more probable.\nConversely, people will find it harder to call to mind those events which are less vivid and newsworthy, leading them to judge those events as being less frequent.",
    "crumbs": [
      "Heuristics and biases",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Heuristics and biases exercises</span>"
    ]
  },
  {
    "objectID": "game-theory/game-theory.html",
    "href": "game-theory/game-theory.html",
    "title": "Game theory",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Game theory"
    ]
  },
  {
    "objectID": "game-theory/game-theory.html#summary",
    "href": "game-theory/game-theory.html#summary",
    "title": "Game theory",
    "section": "",
    "text": "Game theory studies strategic interaction between players, where outcomes depend on others’ behaviour and beliefs about strategies.\nComponents of a game include players, actions, strategies, information available, and payoffs.\nPlayers are typically assumed to be rational optimisers who understand the game and assume the same of other players.\nGames can be categorised as cooperative vs non-cooperative based on the ability to negotiate binding contracts.\nGames can also be categorised as simultaneous vs sequential, based on the timing of decisions and knowledge of others’ actions.",
    "crumbs": [
      "Game theory"
    ]
  },
  {
    "objectID": "game-theory/game-theory.html#introduction",
    "href": "game-theory/game-theory.html#introduction",
    "title": "Game theory",
    "section": "Introduction",
    "text": "Introduction\nIn many situations, your outcome depends on others’ behaviour. Their outcome depends on your behaviour.\nSimilarly, your strategy will depend on your belief about others’ strategy. Their strategy depends on their beliefs about your strategy.\nGame theory studies this strategic interaction between players. We can solve strategic problems using the tools of game theory.",
    "crumbs": [
      "Game theory"
    ]
  },
  {
    "objectID": "game-theory/game-theory.html#components-of-a-game",
    "href": "game-theory/game-theory.html#components-of-a-game",
    "title": "Game theory",
    "section": "Components of a game",
    "text": "Components of a game\nA game has the following components:\n\nFirst, the players of the game. Most of the games we examine in these notes involve two players.\nSecond, the actions that each player can take; for example to contribute to a common pool or to defect.\nThird, the strategies that comprise a complete contingent plan of action. That is, for any given scenario or action by another player, a strategy specifies the action to be taken by the player.\nFourth, the information available to players. In these notes, we generally assume perfect information.\nAnd finally, the payoffs. This comprises a complete summary of the value to each player of each set of actions.",
    "crumbs": [
      "Game theory"
    ]
  },
  {
    "objectID": "game-theory/game-theory.html#the-players",
    "href": "game-theory/game-theory.html#the-players",
    "title": "Game theory",
    "section": "The players",
    "text": "The players\nIn game theoretical analysis, we typically assume that the players are rational optimisers who understand the game that they are playing. By rational, we mean that the player is aware of their alternatives, forms expectations about any unknowns, has preferences that conform to the axioms of completeness and transitivity and they choose the best option using some optimisation algorithm.\nWe also assume that the players assume other players are also rational optimisers who understand the game.\nWe weaken this assumption when we analyse behavioural game theory.",
    "crumbs": [
      "Game theory"
    ]
  },
  {
    "objectID": "game-theory/game-theory.html#types-of-games",
    "href": "game-theory/game-theory.html#types-of-games",
    "title": "Game theory",
    "section": "Types of games",
    "text": "Types of games\nThere are many different types of games analysed in game theory. Some of the delineations between these games are as follows.\n\nCooperative versus non-cooperative games\nFirst, games are often divided into cooperative and non-cooperative games.\nIn non-cooperative games, players are not allowed to negotiate binding contracts. In cooperative games, players can negotiate binding contracts that allow them to implement joint strategies.\nIn these notes, I will focus on non-cooperative games.\n\n\nSimultaneous or sequential games\nSecond, games can involve simultaneous or sequential moves.\nIn a simultaneous move game, you make decisions without knowing the action of your rival.\nIn sequential games, players make sequential decisions knowing the other player’s action. We will examine both of these types of game in these notes.",
    "crumbs": [
      "Game theory"
    ]
  },
  {
    "objectID": "game-theory/simultaneous-move-one-shot-games.html",
    "href": "game-theory/simultaneous-move-one-shot-games.html",
    "title": "40  Simultaneous-move one-shot games",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Simultaneous-move one-shot games</span>"
    ]
  },
  {
    "objectID": "game-theory/simultaneous-move-one-shot-games.html#summary",
    "href": "game-theory/simultaneous-move-one-shot-games.html#summary",
    "title": "40  Simultaneous-move one-shot games",
    "section": "",
    "text": "Simultaneous-move one-shot games involve players making decisions without knowing their rival’s actions. These games are typically represented in a “normal” or “strategic” form using a matrix.\nThe prisoner’s dilemma is a classic example of such a game, where two prisoners must decide whether to confess or remain silent.\nIn game theory, a dominant strategy is one that yields the highest payoff regardless of the opponent’s actions. In the prisoner’s dilemma, confessing is the dominant strategy for both players.\nA Nash equilibrium occurs when each player’s strategy is the best response to the other’s strategy. In the prisoner’s dilemma, the Nash equilibrium is (Confess, Confess), despite this not being the optimal outcome for either player.\nThe examples showcase different types of simultaneous-move one-shot games, demonstrating concepts such as multiple equilibria, coordination problems, and the tension between individual and collective outcomes.\n\nThe driving game demonstrates a coordination game with two Nash equilibria: (Left, Left) and (Right, Right).\nMatching pennies is a zero-sum game with no pure-strategy Nash equilibria.\nThe stag hunt game shows a coordination game with two Nash equilibria: (Stag, Stag) and (Hare, Hare), highlighting the tension between cooperation and individual safety.\nThe public goods game illustrates the conflict between individual and collective interests, with the Nash equilibrium being no contribution, despite full contribution being Pareto optimal.",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Simultaneous-move one-shot games</span>"
    ]
  },
  {
    "objectID": "game-theory/simultaneous-move-one-shot-games.html#introduction",
    "href": "game-theory/simultaneous-move-one-shot-games.html#introduction",
    "title": "40  Simultaneous-move one-shot games",
    "section": "40.1 Introduction",
    "text": "40.1 Introduction\nIn a simultaneous-move one-shot game, you make decisions without knowing the action of your rival. This can be interpreted as either players making decisions at the same time or players making decisions before knowing the decisions of their rivals.",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Simultaneous-move one-shot games</span>"
    ]
  },
  {
    "objectID": "game-theory/simultaneous-move-one-shot-games.html#the-normal-form",
    "href": "game-theory/simultaneous-move-one-shot-games.html#the-normal-form",
    "title": "40  Simultaneous-move one-shot games",
    "section": "40.2 The normal form",
    "text": "40.2 The normal form\nWe usually write simultaneous move one-shot games in the “strategic” or “normal” form. In this form, all of the monetary or non-monetary outcomes are represented in a matrix.\nI will now illustrate the normal form of the game with a game called the prisoner’s dilemma.\n\n40.2.1 The prisoner’s dilemma\nThe prisoner’s dilemma is a classic simultaneous-move one-shot game. A pair of criminals have been captured following a crime. The police have sufficient evidence to convict them of a minor crime (e.g. trespass), but insufficient evidence to convict them of the major crime that has occurred (e.g. theft of the crown jewels).\nThe police place each prisoner in a separate cell where they cannot communicate with each other. The police then offer both prisoners a deal: confess and they will let them go free despite the minor crime, but they will then have the evidence required to give their criminal partner a massive sentence for the serious crime.\nIf neither confesses, the police will have insufficient evidence to get a conviction for the major crime, so they will both receive a short sentence for the minor crime. If both confess, they will both get a longer sentence, but with some reduction in sentence relative to if they didn’t confess.\nThe normal form of the game is as follows:\n\n\n\nFigure 40.1: The prisoner’s dilemma\n\n\n\n\n\n\nPrisoners A and B have two actions available: to confess and to stay silent. The numbers in the matrix represent the payoffs from each combination of actions, in this case, the number of years they will serve in prison. A higher number is therefore a worse outcome. The left number in each cell of the matrix represents the payoff to the row player, Prisoner A. The number on the right of each matrix cell is the payoff to the column player, Prisoner B.\nFor example, if both Prisoner A and Prisoner B choose to confess, they each receive a prison sentence of five years. If Prisoner A confesses and Prisoner B remains silent, Prisoner A gets off without a prison sentence, whereas Prisoner B gets twenty years.\nEquipped with the normal form of the game, we can determine what each player wants to do in response to each action of the other player.\nFor example, we can see that if Prisoner B confesses, Prisoner A can either confess and receive five years in prison, or remain silent and receive 20 years in prison. They would choose to confess.\nWe indicate the preferred action in response to another player’s action by circling the relevant payoff. For example:\n\n\n\nFigure 40.2: The prisoner’s dilemma: representing preferred actions\n\n\n\n\n\n\nIf Prisoner B remains silent, Prisoner A could either confess and escape without a sentence, or remain silent and receive a sentence of one year in prison. They would prefer to confess.\nWe can then work through the same process for Prisoner B’s actions.\nIf Prisoner A confesses, Prisoner B can either confess and receive five years in prison, or remain silent and receive 20 years in prison. They would choose to confess.\nIf Prisoner A remains silent, Prisoner B could either confess, and escape without a sentence, or remain silent, and receive a sentence of one year in prison. They would prefer to confess.\nIndicating this set of preferred actions in response to that of the other player gives us this completed matrix.\n\n\n\nFigure 40.3: The prisoner’s dilemma solved",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Simultaneous-move one-shot games</span>"
    ]
  },
  {
    "objectID": "game-theory/simultaneous-move-one-shot-games.html#dominant-strategies",
    "href": "game-theory/simultaneous-move-one-shot-games.html#dominant-strategies",
    "title": "40  Simultaneous-move one-shot games",
    "section": "40.3 Dominant strategies",
    "text": "40.3 Dominant strategies\nBefore examining this matrix further, I will now introduce the concept of the dominant strategy.\nA strategy is dominant if it gives a higher payoff than every other strategy, for every strategy that your rivals play.\nA strategy is strictly dominant if it gives a strictly higher payoff than every other strategy, for every strategy that your rivals play.\nIf you have a strictly dominant strategy, you should play it for sure.\nIn a dominant strategy equilibrium, all players choose a dominant strategy.\nIn the prisoner’s dilemma, both players have a dominant strategy to confess. No matter what the other player does, confessing is better than remaining silent.",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Simultaneous-move one-shot games</span>"
    ]
  },
  {
    "objectID": "game-theory/simultaneous-move-one-shot-games.html#nash-equilibrium",
    "href": "game-theory/simultaneous-move-one-shot-games.html#nash-equilibrium",
    "title": "40  Simultaneous-move one-shot games",
    "section": "40.4 Nash equilibrium",
    "text": "40.4 Nash equilibrium\nAnother important concept is the Nash equilibrium.\nA set of strategies is a Nash equilibrium if every player is playing a best response to their rivals’ strategies. No one has an incentive to change strategy.\nA Nash equilibrium is self-enforcing and stable. If the players agree to play a certain way, they’ll both do it. Unilateral deviations are not worthwhile.\nThe prisoner’s dilemma has a single Nash equilibrium: (Confess, Confess). Visually, where the preferred response of both players to the other player’s action falls within the same cell, this indicates a Nash equilibrium.",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Simultaneous-move one-shot games</span>"
    ]
  },
  {
    "objectID": "game-theory/simultaneous-move-one-shot-games.html#simultaneous-move-one-shot-game-examples",
    "href": "game-theory/simultaneous-move-one-shot-games.html#simultaneous-move-one-shot-game-examples",
    "title": "40  Simultaneous-move one-shot games",
    "section": "40.5 Simultaneous-move one-shot game examples",
    "text": "40.5 Simultaneous-move one-shot game examples\n\n\nIn this part, I will show some examples of simultaneous-move one-shot games.\n\n40.5.1 The driving game\nConsider the following game between two players deciding what side of the road to drive on. They can drive on the left or the right. If they both drive on the left or right when they approach each other, they will successfully pass. If one drives on the left and the other on the right, they will crash.\n\n\n\nFigure 40.4: The driving game\n\n\n\n\n\n\nWhat are the Nash equilibria?\nIf Driver 2 drives on the left, Driver 1 can either successfully drive on the left, or drive on the right and crash. They would choose to drive on the left. If Driver 2 drives on the right, Driver 1 can either successfully drive on the right, or drive on the left and crash. They would choose to drive on the right.\nSimilarly, if Driver 1 drives on the left, Driver 2 can either successfully drive on the left, or drive on the right and crash. They would choose to drive on the left. If Driver 1 drives on the right, Driver 2 can either successfully drive on the right, or drive on the left and crash. They would choose to drive on the right.\nWe can see from the matrix that there are two Nash equilibria. The Nash equilibria are (Left, Left) and (Right, Right). If both drivers are driving on the left, neither has an incentive to change their strategy. If both drivers are driving on the right, again, neither has an incentive to change.\n\n\n\nFigure 40.5: The driving game solved\n\n\n\n\n\n\n\n\n40.5.2 Matching pennies\nThe next game, called matching pennies, involves two players, Even and Odd, who each have a penny. Each player must select one side of the penny and simultaneously show the penny to the other player. If the pennies match, Even wins. If they don’t match, Odd wins.\n\n\n\nFigure 40.6: Matching pennies\n\n\n\n\n\n\nWhat are the Nash equilibria?\nTo determine this, we work through the matrix as we did in the previous example.\nIf Odd shows heads, Even can either show heads and win, or show tails and lose. They would choose to show heads. If Odd shows tails, Even can either show tails and win, or show heads and lose. They would choose to show tails.\nSimilarly, if Even shows heads, Odd can either show tails and win, or show heads and lose. They would choose to show tails. If Even shows tails, Odd can either show heads and win, or show tails and lose. They would choose to show tails.\n\n\n\nFigure 40.7: Matching pennies solved\n\n\n\n\n\n\nThere are no pure-strategy Nash equilibria for this game. For any combination of heads and tails, one of the players would want to change their choice.\nThere are what are called “mixed-strategy Nash equilibria” in this game, but mixed-strategy equilibria are beyond the scope of this subject.\n\n\n40.5.3 The stag hunt\nConsider the “stag hunt game” between two players deciding what animal they will hunt. Both hunters need to cooperate to catch the stag. They can catch a hare by themselves, but it provides less meat.\n\n\n\nFigure 40.8: The stag hunt game\n\n\n\n\n\n\nWhat are the Nash equilibria?\nIf Hunter 2 hunts the stag, Hunter 1 can either hunt the stag and catch it, or hunt the hare and catch it. They would choose to hunt the stag as it gives a payoff of 3 compared to 1. If Hunter 2 hunts the hare, Hunter 1 can either hunt the stag and not catch it, or hunt the hare and catch it. They would choose to hunt the hare as it gives a payoff of 1 compared to 0.\nSimilarly, if Hunter 1 hunts the stag, Hunter 2 can either hunt the stag and catch it, or hunt the hare and catch it. They would choose to hunt the stag as it gives a payoff of 3 compared to 1. If Hunter 1 hunts the hare, Hunter 2 can either hunt the stag and not catch it, or hunt the hare and catch it. They would choose to hunt the hare as it gives a payoff of 1 compared to 0.\n\n\n\nFigure 40.9: The stag hunt game solved\n\n\n\n\n\n\nThe Nash equilibria are (Stag, Stag) and (Hare, Hare). On either pair of strategies, neither player has incentive to change. It is an open question, however, as to which Nash equilibrium might emerge if they were to play the game.\n\n\n40.5.4 The public goods game\nThe final game I will consider in this part is the public goods game.\nIn this game, each participant is given an initial endowment.\nEach participant secretly and simultaneously chooses how much of their endowment they wish to contribute to a public pot.\nThe money in the public pot is multiplied by some amount and split evenly between the players. Typically, the multiple applied to the pot is greater than 1, but less than the number of players.\nFor example, five players might each be given $10, with the pot doubled. Suppose they each contribute $5 of their $10 endowment to the pot. The $25 contributed to the pot is multiplied by 2 to a total of $50. Each player then receives $10 from the pot, giving them $15 in total.\n\n\n\nFigure 40.10: The public goods game\n\n\n\n\n\n\nIn Nash equilibrium in the public goods game, nobody transfers anything to the pot. Any contributions are split between all players, so if there are more players than the multiple, which is normally the case by design, contributions result in a loss to that individual player.\nConsider the previous game, but this time Player E contributes nothing. There is then $20 in the pot, which is doubled to $40. The pot is then split equally between the players, each receiving $8 from the pot. The result is that Player E is better off having not contributed, ending with $18, compared to the $15 they would have received had they contributed $5 like the other players.\n\n\n\nFigure 40.11: The public goods game with defection\n\n\n\n\n\n\nThe Pareto optimal result, however, is for all players to contribute their full endowment and each receives back their multiplied contribution. However, the Pareto optimal result is not stable, as each player has an incentive to defect and contribute nothing.\n\n\n\nFigure 40.12: The public goods game with cooperation",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Simultaneous-move one-shot games</span>"
    ]
  },
  {
    "objectID": "game-theory/sequential-games.html",
    "href": "game-theory/sequential-games.html",
    "title": "41  Sequential games",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Sequential games</span>"
    ]
  },
  {
    "objectID": "game-theory/sequential-games.html#summary",
    "href": "game-theory/sequential-games.html#summary",
    "title": "41  Sequential games",
    "section": "",
    "text": "Sequential games involve players making decisions in order, with knowledge of previous actions. These games are typically represented in “extensive form” using a game tree.\nThe centipede game is an example of a sequential game where players take turns deciding to “take” (end the game) or “pass” (continue), with increasing payoffs at each step.\nA subgame perfect Nash equilibrium is a solution concept where players’ strategies constitute a Nash equilibrium in every subgame of the original game.\nThe centipede game is solved using backward induction, resulting in a subgame perfect Nash equilibrium where the first player “takes” at the very first opportunity, despite this leading to a lower payoff than if players cooperated by passing.\nThe other examples illustrate sequential games and their subgame perfect Nash equilibria, demonstrating concepts like backward induction and the importance of credible threats.\nThe ultimatum game shows that rational play leads to minimal offers being accepted, with subgame perfect Nash equilibria of offering $1 (or $0) and accepting.\nThe dictator game, with no strategic interaction, predicts the dictator will keep the entire endowment.\nThe trust game demonstrates how lack of trust can lead to suboptimal outcomes, with the subgame perfect Nash equilibrium being no investment and no return.",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Sequential games</span>"
    ]
  },
  {
    "objectID": "game-theory/sequential-games.html#introduction",
    "href": "game-theory/sequential-games.html#introduction",
    "title": "41  Sequential games",
    "section": "41.1 Introduction",
    "text": "41.1 Introduction\nIn sequential games, players make sequential decisions knowing the action of the other player.",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Sequential games</span>"
    ]
  },
  {
    "objectID": "game-theory/sequential-games.html#the-extensive-form",
    "href": "game-theory/sequential-games.html#the-extensive-form",
    "title": "41  Sequential games",
    "section": "41.2 The extensive form",
    "text": "41.2 The extensive form\nSequential games can be shown in what is called the “extensive form” representation. The extensive form representation explicitly shows the timing of play.\nPayoffs are represented in a game tree.\nI will now illustrate the extensive form with a game called the centipede game.\n\n41.2.1 The centipede game\nThis centipede game has six decision nodes. At each node, a player can “take”, and end the game, or they can “pass”, increasing the total payoff. The other player then has a move.\nThe numbers 1 and 2 along the top of the centipede represent the decision nodes for two players. At the first node, player 1 has the choice to take or pass. If player 1 passes, player 2 has the choice to take or pass, and so on. At the final node, the game ends regardless of what player 2 chooses.\n\nThe payoff when a player takes and ends the game is represented by the numbers in the brackets. The first number is the payoff for player 1 and the second number is the payoff for player 2. For example, if player 1 takes at the first node, they receive a payoff of 1 and player 2 receives a payoff of 0. At the final node, if player 2 passes they receive a payoff of 5 and Player 1 receives a payoff of 6. If player 2 takes at that final node, they receive a payoff of 6 and Player 1 receives a payoff of 4.",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Sequential games</span>"
    ]
  },
  {
    "objectID": "game-theory/sequential-games.html#subgame-perfect-nash-equilibrium",
    "href": "game-theory/sequential-games.html#subgame-perfect-nash-equilibrium",
    "title": "41  Sequential games",
    "section": "41.3 Subgame perfect Nash equilibrium",
    "text": "41.3 Subgame perfect Nash equilibrium\nBefore examining this game, I will introduce the concept of a subgame perfect Nash equilibrium.\nA subgame is a part of a game that can be played as a game itself. It begins at a single node and contains every successor node.\n\n41.3.1 Solving the centipede game\nFor example, this final stage of the centipede game is a subgame.\n\nAs is this subset of the game.\n\nA Nash Equilibrium is subgame perfect if every player plays the Nash Equilibrium in every subgame\nWe can solve for the subgame perfect Nash equilibrium of sequential games by backward induction. To do that we solve for the decision nodes at the end of the game first and then work our way back to the beginning of the game.\nIn our centipede game, using backward induction, player 2 at the final node will “take” for a payoff of 6 instead of passing for a payoff of 5. When marking choices in a sequential game, it is often useful to mark the option taken by the player, or that not taken, in addition to indicating the payoff they would receive.\n\nAt the node immediately before, player 1 will “take” for a payoff of 5 instead of passing, given player 2 will then take, giving player 1 a payoff of 4.\n\nTherefore, at the node before, player 2 will take for a payoff of 4 instead of passing for a payoff of 3.\nTherefore, at the node before, player 1 will take for a payoff of 3 instead of passing for a payoff of 2.\nTherefore, player 2 at the node before will take for a payoff of 2 instead of passing for a payoff of 1.\nAnd therefore, player 1 at the first node will take for a payoff of 1 instead of passing for a payoff of 0.\n\nThere is a unique subgame perfect equilibrium for the centipede game: S_1=(\\text{take, take, take}) and S_2=(\\text{take, take, take}), where S_1 and S_2 are the set of strategies for player 1 and player 2 respectively.\nIn the subgame perfect Nash equilibrium of the centipede game, player 1 takes at the first node.",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Sequential games</span>"
    ]
  },
  {
    "objectID": "game-theory/sequential-games.html#sequential-game-examples",
    "href": "game-theory/sequential-games.html#sequential-game-examples",
    "title": "41  Sequential games",
    "section": "41.4 Sequential game examples",
    "text": "41.4 Sequential game examples\n\n\nIn this part, I will discuss some sequential games and their subgame perfect Nash equilibria.\n\n41.4.1 The ultimatum game\nThe first example is the ultimatum game.\nThe ultimatum game involves two players: the proposer and the responder.\nThe proposer is given a fixed amount of money m. They then offer a portion x of the sum m to the responder.\nThe responder can either accept or reject the offer. They make this decision knowing the fixed amount m held by the proposer and the offer x.\nIf the responder accepts, the responder receives the offer x and the proposer gets the remainder m-x. If the responder rejects, both players receive nothing.\n\n\nThe ultimatum game\n\n\n\nBelow is the extensive form of the ultimatum game with m=\\$10 and an assumption that the offer must be a whole dollar amount. At the first node is the proposer. They can choose to offer any dollar sum between $0 and $10. Whatever the choice, the responder is at the next node. They can choose to accept or reject the offer. The payoffs of each set of actions is indicated in the brackets at the bottom of the game tree, with the first number being the proposer’s payoff and the second number being the responder’s payoff.\n\n\nUltimatum game tree\n\n\n\nIf we work through this game by backward induction, we can see that for any non-zero amount, the responder will accept the offer. The only time they might not accept is where the offer is 0, but they still might.\nGiven this, the proposer will offer $0 or $1 only.\n\n\nThe ultimatum game Nash equilibrium\n\n\n\nWe can say that there are two subgame perfect Nash equilibria. The first is for the proposer to offer $1 and the responder to accept if offered $1 and reject if offered $0. The other (weak) subgame perfect Nash equilibrium is an offer of $0 and acceptance.\nMore generally, game theory makes a clear prediction on the outcome of the ultimatum game. If the players have monotonic preferences - that is, more is better - the responder accepts any x&gt;0 (and possibly even if x=0) and the the proposer offers the smallest amount the proposer can offer.\nWhere the strategy space is continuous (that is the offer could always be made smaller) the only subgame perfect Nash equilibrium is for the proposer to offer $0 and the receiver to accept.\n\n\n41.4.2 The dictator game\nThe next example is the dictator game.\nIn the dictator game, the dictator is given a fixed amount of money m. They then offer a portion x of the sum m to the receiver. The game then ends.\nExchange is unilateral. Receivers have an empty strategy set.\n\n\nThe dictator game\n\n\n\nThe standard game theory prediction is no interaction whatsoever. The dictator maximises their payoff by keeping all of the endowment themselves, receiving payoff m (which is bolded).\n\n\nThe dictator game solved\n\n\n\n\n\n41.4.3 The trust game\nThe final example is the trust game.\nThe trust game involves two players: a sender and a receiver\nBoth the sender and receiver are given an initial sum m.\nThe sender sends a share x of their m to the receiver. This amount x is often called the investment.\nBefore the investment is received by the receiver, it is multiplied by some factor k.\nTherefore, the receiver receives kx.\nThe receiver then returns to the sender some share y of their total allocation m+kx.\nThe final outcome is the sender has m-x+y and the receiver has m+kx-y. We can represent these payoffs as:\n\n(m-x+y, m+kx-y)\n\nThe extensive form of the game is as follows.\n\n\nThe trust game\n\n\n\nHere is a numerical example.\nSuppose the sender and receiver are given an initial sum of $10.\nThe sender decides to send $5 of their $10 to the receiver.\nThis is multiplied by a factor of 3. Therefore, the receiver receives $15 and now has $25.\nThe receiver then returns to the sender $7.50 of their $25.\nThe final outcome is (10−5+7.50,  10+15−7.50)=(12.50, 17.50).\n\n\nThe trust game example\n\n\n\nIf both receivers have utility function u(x)=x the only subgame-perfect equilibrium is that the receiver will keep all their money, so the sender sends nothing.\nWe can see this by backward induction. The receiver can either return y for a payoff of 10+3x-y or return 0 for a payoff of 10+3x. The receiver will return 0.\nOne way to think about this problem is that the receiver is effectively playing a dictator game.\nWorking backwards, the sender therefore has a choice between sending x for a payoff of 10-x or sending 0 for a payoff of 10. The sender will send 0.\n\n\nThe trust game solved\n\n\n\nRelative to the Pareto optimal outcome whereby the sender’s full endowment is tripled and they receive a positive return on their investment, both players are worse off under the equilibrium outcome.",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Sequential games</span>"
    ]
  },
  {
    "objectID": "game-theory/asymmetric-information.html",
    "href": "game-theory/asymmetric-information.html",
    "title": "42  Asymmetric information",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Asymmetric information</span>"
    ]
  },
  {
    "objectID": "game-theory/asymmetric-information.html#summary",
    "href": "game-theory/asymmetric-information.html#summary",
    "title": "42  Asymmetric information",
    "section": "",
    "text": "Information asymmetry in markets can lead to market failures, even with rational agents. This is illustrated by the “market for lemons” example, where buyers’ inability to observe product quality before purchase can result in only low-quality goods being sold.\nThe winner’s curse is a phenomenon in common-value auctions where the winning bidder tends to overpay. This occurs because winning implies that other bidders valued the item lower, suggesting the winner’s estimate may be too high.\nThe Nash equilibrium strategy in such auctions is to bid more conservatively than your private estimate of the value.",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Asymmetric information</span>"
    ]
  },
  {
    "objectID": "game-theory/asymmetric-information.html#introduction",
    "href": "game-theory/asymmetric-information.html#introduction",
    "title": "42  Asymmetric information",
    "section": "42.1 Introduction",
    "text": "42.1 Introduction\nTo date in this section on game theory, I have assumed perfect information. That is, all players know the rules of the game, the available actions and the payoffs from each set of actions.\nI will now explore two examples where we relax this assumption and allow the parties to have different information. However, we will retain the assumption of rational behaviour.",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Asymmetric information</span>"
    ]
  },
  {
    "objectID": "game-theory/asymmetric-information.html#sec-market-for-lemons",
    "href": "game-theory/asymmetric-information.html#sec-market-for-lemons",
    "title": "42  Asymmetric information",
    "section": "42.2 The market for lemons",
    "text": "42.2 The market for lemons\nThis example draws on the work of Akerlof (1970).\nAn agent decides to buy a used car. Price p is fixed and quality is unobservable.\nSuppose there are two types of cars: good cars and lemons. A car is good with probability q and a lemon with probability 1−q.\nThe seller knows the type. To the seller, good cars are worth $10,000 and lemons $5,000.\nTo potential buyers, good cars are worth $15,000 and lemons $7,500.\nBefore the purchase, the buyer knows the types of cars in the market and the frequency of each. They only discover the type of car, however, after the purchase.\nGiven both car types are worth more to buyers than sellers, there should exist advantageous trades for both parties for both types of car. Selling is an efficient solution.\nBut what happens?\nLet \\mu be the probability that a car that is sold is good. If sellers are willing to sell their good cars, \\mu=q. If not, \\mu=0.\nTherefore, the expected value of a car to a buyer is:\n\nE=\\mu 15000+(1−\\mu)7500=7500+7500\\mu\n\nHence, the buyer will be willing to pay up to p=7500+7500\\mu.\nGiven the value of each type of cars to sellers, they will sell a lemon if p\\geq 5000 and a good car if p\\leq 10000.\nCombining the conditions for the buyer and seller, a lemon will be sold if the price lies between the minimum required by the seller for the lemon and the maximum the buyer is willing to pay for the lemon. That is:\n\n5000\\leq p\\leq 7500+7500\\mu\n\nThis relationship holds regardless of the value of \\mu, so the seller will always be willing and able to sell the lemon.\nThey will be able to sell the good car if:\n\n10000\\leq p\\leq 7500+\\mu7500\n\nThis relation can only hold if \\mu\\geq 1/3.\nAssuming risk neutral buyers, we are left with two possible equilibria.\nIf q\\geq 1/3, sellers sell both types of cars:\n\n\\mu=q\\leq 1/3→10000\\leq p^∗\\leq 7500+\\mu7500\n\nIf q&lt;1/3, sellers sell only lemons:\n\n\\mu=0→5000\\leq p^∗\\leq 7500\n\nGeneralising what is happening here:\n\nWhen buyers cannot observe product quality, sellers have an incentive to pass off lemons as good cars.\nRational buyers expect this seller behaviour and they lower their willingness to pay.\nSellers cannot sell good cars at high prices even though buyers would be willing to pay high prices for good cars.\nAt the lower prices, sellers only offer to sell lemons.\n\nInformation asymmetry is sufficient to result in a market failure even if the agents are rational.",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Asymmetric information</span>"
    ]
  },
  {
    "objectID": "game-theory/asymmetric-information.html#sec-winners-curse",
    "href": "game-theory/asymmetric-information.html#sec-winners-curse",
    "title": "42  Asymmetric information",
    "section": "42.3 The winner’s curse",
    "text": "42.3 The winner’s curse\nThe second example involves a phenomenon called the winner’s curse.\nThe winner’s curse occurs in the context of common-value auctions.\nA common-value auction is an auction in which the item for sale has the same value to all the bidders.\nExamples include stocks, which all have one value, and oil, where the amount of oil in a tract is the same for all oil companies.\nCommon-value auctions contrast with private-value auctions in which bidders have different valuations for the item for sale. This typically occurs where the item’s valuation reflects bidder tastes, such as art.\nThe winner’s curse is a phenomenon in common value auctions whereby the winner tends to experience a loss.\nPetroleum engineers invented the term in discussing why oil companies in the Gulf of Mexico had poor results in the 1950s through 1970s. Oil companies in the Gulf acquired drilling rights through auctions. Their rights tended to lead to losses or less in profits than expected. In hindsight, the winning bids were unreasonably high.\nThe winner’s curse is widely documented in experimental settings and has been observed in corporate environments.\n\n42.3.1 Winner’s curse example\nI will now walk through a numerical example of the winner’s curse.\nCompany 1 and company 2 hire a geologist to estimate the value of an oil field. The honest geologist of each company privately reports their estimated valuation to the company. Company 1 learns v_1 and company 2 learns v_2.\nv_1 and v_2 are uniformly distributed between $0 and $100 and independent.\nAssume the true value of the oil field is the mean of v_1 and v_2:\n\nV=\\frac{v_1+v_2}{2}\n\nThe two companies simultaneously bid for the field in a first-price auction. The highest bid wins and pays their bid.\nWhat should a company bid in this auction?\nSuppose both companies bid the private valuation they receive. Company 1 receives v_1=50, bids $50 and wins.\nIf they win, v_1=\\$50&gt;v_2.\nOn average, in this state of the world company 2’s signal is $25 (due to the uniform distribution). The average value of the tract is therefore:\n\n\\bar V=(50+25)/2=\\$37.50\n\nThe result is that company 1 has, on average, profit of \\$37.50-\\$50=-\\$12.50. That is, a loss of $12.50.\nCompany 1 now decides to change strategy and bid less than the valuation they receive. What if v_1=50 and company 1 bids $37.50 instead. We will assume that company 2 continues to bid v_2 and company 1 wins.\nIf company 1 wins, \\$37.50&gt;v_2.\nOn average, in this state of the world, company 2’s signal is $18.75 (due to the uniform distribution). The average value of the tract is therefore:\n\n(50 + 18.75)/2=\\$34.37\n\nCompany 1’s profit is, on average, \\$34.37-\\$37.50=-\\$3.13.\nCompany 1 now decides to bid only half the valuation. What if v_1=\\$50 and company 1 bids $25. We again assume company 2 bids v_2 and company 1 wins.\nIf company 1 wins, 25&gt;v_2.\nOn average, in this state of the world company 2’s signal is $12.50 (due to the uniform distribution), so the average value of the tract is (50 +12.50)/2=\\$31.25.\nCompany 1’s profit is \\$31.25 − \\$25 = \\$6.25 on average. However, they will win only 25% of the time.\nThis analysis also has a complication in that it does not account for the fact that company 2 is also a strategic player. We assumed company 2 bids v_2, but as for company 1, this strategy would lead to an expected loss for company 2.\nSo what does each firm do at equilibrium?\nAs each firm will have the same strategy at equilibrium, we can solve for company 1 assuming company 2 does the same strategy in response. At equilibrium, we can also assume that each company will have an expected profit of zero as each company would otherwise have an incentive to change their bid to gain a share of the positive profit.\nCompany 1 will win if \\delta v_1&gt;\\delta v_2; in other words, if v_1&gt;v_2. On average, in this state of the world company 2’s signal is 0.5v_1 (due to the uniform distribution), so that the average value of the tract is (v_1+0.5v_1)/2=0.75v_1.\nCompany 1’s profit is:\n\n\\pi_1=0.75v_1-\\delta v_1=(0.75-\\delta)v_1\n\nProfit is zero when \\delta=0.75. The Nash equilibrium is that both parties bid 75% of their private valuation.\nIn summary, bidding based purely on your own valuation fails to take into account that you only win if the other player’s signal is low.\nAlternatively, we may say that winning the auction is bad news regarding the value of the field. This is the winner’s curse.\nBecause of the winner’s curse, the Nash equilibrium is to bid more conservatively.\nThe mistake that oil companies make is ignoring or underestimating the winner’s curse. If an oil company wins an auction, it’s likely because its geologists have the highest estimates of the field’s value. But if all other geologists have lower estimates of the value, the company’s geologists have probably overestimated it.\n\n\n\n\nAkerlof, G. A. (1970). The market for “lemons”: Quality uncertainty and the market mechanism*. The Quarterly Journal of Economics, 84(3), 488–500. https://doi.org/10.2307/1879431",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Asymmetric information</span>"
    ]
  },
  {
    "objectID": "game-theory/strategic-moves-and-commitment.html",
    "href": "game-theory/strategic-moves-and-commitment.html",
    "title": "43  Strategic moves and commitment",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Strategic moves and commitment</span>"
    ]
  },
  {
    "objectID": "game-theory/strategic-moves-and-commitment.html#summary",
    "href": "game-theory/strategic-moves-and-commitment.html#summary",
    "title": "43  Strategic moves and commitment",
    "section": "",
    "text": "Strategic moves are actions that change the game being played, typically from a single-stage to a two-stage game. They come in two forms: unconditional (commitments) and conditional (threats and promises).\nFor commitments to be effective, they must be observable and irreversible.\nConditional strategic moves must be credible. If carrying out a threat or promise is too costly for the player making it, the threat or promise won’t influence the other player’s actions.\nThe game of “chicken” illustrates how strategic moves can change outcomes. Originally, this game has two pure-strategy Nash equilibria: (Straight, Swerve) and (Swerve, Straight). However, if one player commits to going straight (e.g., by removing their steering wheel), it changes the Nash equilibrium to favour that player.",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Strategic moves and commitment</span>"
    ]
  },
  {
    "objectID": "game-theory/strategic-moves-and-commitment.html#chicken",
    "href": "game-theory/strategic-moves-and-commitment.html#chicken",
    "title": "43  Strategic moves and commitment",
    "section": "43.1 Chicken",
    "text": "43.1 Chicken\nConsider the following game of chicken. Two players are driving toward each other. Whoever swerves first loses. If neither swerves, they crash and die.\n\nThere are two pure-strategy Nash equilibria: (Straight, Swerve) and (Swerve, Straight). If the other player swerves, they want to go straight. If the other player goes straight, they want to swerve.\n\nNow consider a new scenario.\nAs they are driving toward each other, Player A rips the steering wheel out of their car and throws it out the window. They will now drive straight no matter what Player B does.\n\nThis is effectively a new game. What is the Nash equilibrium?\nThe Nash equilibrium is (Straight, Swerve). Player A wins the game of chicken.",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Strategic moves and commitment</span>"
    ]
  },
  {
    "objectID": "game-theory/strategic-moves-and-commitment.html#strategic-moves",
    "href": "game-theory/strategic-moves-and-commitment.html#strategic-moves",
    "title": "43  Strategic moves and commitment",
    "section": "43.2 Strategic moves",
    "text": "43.2 Strategic moves\nThe option to commit to a course of action, as in this game of chicken, is an example of a strategic move.\nA strategic move changes the game you are playing from a single-stage game to a two-stage game. In the first stage, you make your strategic move. In the second you play the original game.\nStrategic moves come in two forms:\n\nUnconditional strategic moves, which we call commitments\nAnd conditional strategic moves, which we call threats and promises\n\n\n43.2.1 Unconditional strategic moves\nAn unconditional strategic move is a commitment. For example, removing your steering wheel in chicken is a commitment.\nThe commitment needs to be observable and irreversible.\nIf your opponent cannot observe your commitment, you can claim to have made the commitment when you have not.\nIf your commitment is reversible, the game remains as if you had never made it.\n\n\n43.2.2 Conditional strategic moves\nA conditional strategic move involves specifying to your opponent how you will respond to each move.\nA threat involves specifying negative consequences to the other player if they do not play as you wish. ”If you don’t clean your room, you won’t get dessert.”\nA promise involves specifying positive consequences to the other player if they play as you wish. “If you clean your room, you can have dessert.”\nThreats and promises only achieve their objective if they are credible. That is, they only work if the other player believes they will be carried out as stated.\nSticking to a commitment and carrying out a threat or a promise typically reduces the possible actions of the player. If the proposer loses too much from carrying out a threat or promise, they will not carry it out.\n\n\n43.2.3 Example: Complaining is costly\nHere is an example.\nYou threaten to complain about poor service by a company. Complaining is costly.\n\nWe work through this problem by backward induction. At the final node for the customer, they can complain for a payoff of -1 or not complain for a payoff of 1. They will not complain.\nThe company, therefore, has a choice between providing good service for a payoff of 1 or bad service for a payoff of 2. They will provide bad service. The company has the same payoff for bad service regardless of the presence of the threat to complain as the threat is not credible.\nFor the customer’s initial choice of whether to threaten to complain, it does not matter either way. Regardless of their threat, they receive bad service.\nThe result is two sub-game perfect Nash equilibria: (Threatens to complain, Bad service, Does not complain) and (No threat, Bad service).",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Strategic moves and commitment</span>"
    ]
  },
  {
    "objectID": "game-theory/game-theory-exercises.html",
    "href": "game-theory/game-theory-exercises.html",
    "title": "44  Game theory exercises",
    "section": "",
    "text": "44.1 The cold war\nThe year is 1964 and the Soviet Union and the United States are in the midst of the cold war.\nSuppose each player is considering whether they should act aggressively (hawk) or peacefully (dove). If one plays hawk while the other plays dove, they win the cold war. If both play hawk, there is a nuclear armageddon.\nThe payoffs (x,y) of each option for the Soviet Union and United States is as follows:\na) What is the Nash equilibrium of this game? What other game does this resemble?\nb) In the movie Dr Strangelove, the Soviet Union created a doomsday machine that would detonate automatically if there was a nuclear strike. The fallout would render the earth uninhabitable. The doomsday machine could not be deactivated and would explode if any attempt was made.\nExplain how the doomsday device could act as a commitment device?\nc) In the movie, the Soviet Union failed to inform the United States of the existence of the device. How could this failure to inform undermine its effectiveness as a commitment device?",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Game theory exercises</span>"
    ]
  },
  {
    "objectID": "game-theory/game-theory-exercises.html#the-cold-war",
    "href": "game-theory/game-theory-exercises.html#the-cold-war",
    "title": "44  Game theory exercises",
    "section": "",
    "text": "Answer\n\n\n\n\n\nThe preferred action in response to the action of the other player are indicated in the below diagram.\n\nThe two Nash equilibria are (Hawk, Dove) and (Dove, Hawk).\nThis game resembles chicken. Each player wants to win, but if neither swerve, there is a catastrophic outcome for both.\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBy removing dove as a response to hawk, the game effectively changes to the following:\n\nThe Soviet Union can now credibly signal that it will respond to hawk with hawk. This leads to a single Nash equilibrium: (Hawk, Dove).\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nA commitment will only be effective if it is both observable and irreversible. While the doomsday machine is irreversible, by not being observable it will not change the response of the United States. The United States will think they are playing the game analysed in part a), not that in part b).",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Game theory exercises</span>"
    ]
  },
  {
    "objectID": "game-theory/game-theory-exercises.html#hiring",
    "href": "game-theory/game-theory-exercises.html#hiring",
    "title": "44  Game theory exercises",
    "section": "44.2 Hiring",
    "text": "44.2 Hiring\nRobyn is hunting for a new employee. Robyn’s company uses highly-technical equipment and needs to invest heavily in training the new employee. If the new employee leaves straight after training, Robyn’s company will suffer a net loss from the employee. If the employee stays long-term, they will have a large gain.\nRobyn approaches Sean and asks if he is interested in a long-term role with the company.\nSean is interested in the training as he could use it to boost his career, but sees less benefit in staying long-term. He considers whether he should say he is interested or not.\nThe extensive form of the game is laid out below, with the payoffs (x,y) being for Robyn and Sean respectively.\n\na) Will Robyn offer the position to Sean?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe work through the problem by backward induction.\nSean can get 2 by leaving after training or 1 by staying. He leaves after training.\nWhen considering whether he will state that he is interested, he could get 2 for stating he is interested (as he will later leave) versus nothing for saying he is not interested. He states he is interested.\nRobyn compares the -1 she gets for hiring Sean (as he will leave) with the zero for no offer. She does not make an offer.\n\nThe subgame-perfect equilibrium is (No offer; State interested, Leave after training).\n\n\n\nb) What sort of strategic move could help John? What could make the move credible?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nOne option is to sign a binding contract with penalties if he leaves early. Any penalty greater than -1 would make staying more attractive.\nA contract is both observable and irreversible (at least without mutual agreement).",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Game theory exercises</span>"
    ]
  },
  {
    "objectID": "game-theory/game-theory-exercises.html#sec-investment",
    "href": "game-theory/game-theory-exercises.html#sec-investment",
    "title": "44  Game theory exercises",
    "section": "44.3 Investment",
    "text": "44.3 Investment\nLinda is looking for investment opportunities. She identifies a promising crypto-based start-up created by Marco. Marco is looking for seed funding.\nLinda can invest $10.\nIf Linda invests, her investment will triple in value. Marco can then decide to either shut down the start-up and keep the $30 or maintain the start-up in the market and pay a $15 dividend to each of Linda and himself.\nIf Linda does not invest, Linda keeps the $10. The start-up gets $0.\na) Draw the extensive form representation of the above sequential game.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\n\nb) What is the equilibrium of this game if Linda and Marco are purely self-interested?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMarco will shutdown (payoff 30 versus payoff of 15), so Linda will not invest (payoff of 10 versus payoff of zero).",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Game theory exercises</span>"
    ]
  },
  {
    "objectID": "game-theory/game-theory-exercises.html#war",
    "href": "game-theory/game-theory-exercises.html#war",
    "title": "44  Game theory exercises",
    "section": "44.4 War",
    "text": "44.4 War\nTwo city states, Atlantis and El Dorado, are divided by a body of water. In the middle is an island that both states claim sovereignty over.\nTo establish their claims, both states have built a bridge to the island. Atlantis then sent troops to the island.\nEl Dorado is deciding whether to attack Atlantis’s troops to reclaim the island or to concede.\nIf El Dorado attacks, Atlantis need to decide whether to defend against the attack or to retreat back across the bridge.\nIf El Dorado attacks and Atlantis defends, both countries will suffer large losses.\nThese decisions and the payoffs (x,y) from each decision for El Dorado and Atlantis respectively are as follows.\n\na) What is the subgame-perfect equilibrium of this game?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBy backward induction, Atlantis would prefer to retreat (payoff of 2) compared to fighting (payoff of 1). El Dorado then has a choice between attacking (payoff of 3) and conceding (payoff of 2). El Dorado attacks.\n\nThe subgame-perfect equilibrium is (Attack, Retreat).\n\n\n\nb) An adviser to the Atlantis army suggests that they burn the bridge behind them to remove the option of retreat.\nDraw the new extensive form game that would emerge if Atlantis had the option of burning the bridge. What is the subgame-perfect equilibrium?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe new game is as follows (maintaining the payoffs as x,y for El Dorado and Atlantis respectively):\n\nIf we work through this game by backward induction, starting with the upper branch:\n\nAtlantis would prefer to retreat (payoff of 2) compared to fighting (payoff of 1).\nEl Dorado would prefer to attack (payoff of 3) compared to conceding (payoff of 2).\n\nFor the lower branch:\n\nEl Dorado would prefer to concede (payoff of 2) compated to attack (payoff of 1).\n\nFor Atlantis’s final decision, they would prefer to burn (payoff of 3) compared to not burning (payoff of 2).\nAtlantis burns the bridge.\n\nThe subgame-perfect equilibrium is (Burn, Retreat; Attack, Concede).",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Game theory exercises</span>"
    ]
  },
  {
    "objectID": "game-theory/game-theory-exercises.html#buying-a-car",
    "href": "game-theory/game-theory-exercises.html#buying-a-car",
    "title": "44  Game theory exercises",
    "section": "44.5 Buying a car",
    "text": "44.5 Buying a car\nHayley wants to buy a car. The used-car salesman can sell her a good car (for which he earns a small profit) or a lemon (for which he earns a large profit).\nThe payoffs (x,y) for each decision are indicated in the game tree below, with x being the Hayley’s satisfaction and y being the salesman’s profit.\n\na) Assume the salesman only cares about his profit. What would the salesman do if Hayley chooses to purchase? Why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe salesman will compare payoffs of 8 for selling a lemon and 5 for selling a good car. He will choose to sell a lemon.\n\n\n\nb) Given the anticipated choice of the salesman, would Hayley purchase the car? Why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nHayley will compare a payoff of 0 for no purchase and a payoff of -1 for buying a car that will be a lemon. She chooses not to purchase.\n\n\n\nc) Suppose Hayley can take legal action if she is sold a lemon. If Hayley is successful in court, she will be refunded the purchase price but would suffer a cost of -5 due to the effort involved. Would this change the outcome? Why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nWorking by backward induction, Hayley has a choice between taking legal action for a payoff of -5 or not complaining for a payoff of -1. She will not complain.\nThe rest of the game plays out as per questions a) and b). There is no change to the outcome as she cannot commit to complain in advance. The threat to take legal action is not credible.\n\n\n\nd) Suppose Hayley has a reputation of being quick to anger and always carrying out her threats. Suppose Hayley would experience satisfaction of +6 from taking legal action (in addition to the effort cost of -5). The salesman knows this and believes it to be a credible commitment. Would this change the outcome? Why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nHayley now has a choice between a payoff of 1 by taking legal action and a payoff of -1 for accepting the lemon. She would take legal action.\nThe salesman now has a choice between a payoff of 0 for selling the lemon (as Hayley takes legal action and the sale is refunded) and 5 for selling a good car. He sells the good car\nHayley now has a choice of a payoff of 0 for not purchasing a car, and 5 for purchasing. She makes the purchase and gets a good car.",
    "crumbs": [
      "Game theory",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Game theory exercises</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/behavioural-game-theory.html",
    "href": "behavioural-game-theory/behavioural-game-theory.html",
    "title": "Behavioural game theory",
    "section": "",
    "text": "In our analysis of game theory, I assumed rational agents in that they use all available information and can successfully determine their best action given their opponent’s (also rational) action.\nBut what if agents have limited rationality or vary in their rationality?\nIn this part, I will examine several departures from rationality.\nThe first is level-k thinking, in which the agents are assumed to have a certain level of reasoning. For example, a level-0 agent would choose an action randomly. A level-1 agent would assume that the opponent is level-0 and choose the best response to that. A level-2 agent would assume that the opponent is level-1 and choose the best response to that. And so on. The players try to be one step ahead of their opponents.\nThe second departure involves the degree to which the players account for asymmetric information. We consider what happens if players act as though everyone has the same information or if they fail to appreciate the informational advantage they have relative to less-informed agents.\nThe third departure involves emotions. We consider the role of emotions in enabling players to commit to courses of action that they otherwise could not credibly stick with.",
    "crumbs": [
      "Behavioural game theory"
    ]
  },
  {
    "objectID": "behavioural-game-theory/level-k-thinking.html",
    "href": "behavioural-game-theory/level-k-thinking.html",
    "title": "45  Level-k thinking",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Level-k thinking</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/level-k-thinking.html#summary",
    "href": "behavioural-game-theory/level-k-thinking.html#summary",
    "title": "45  Level-k thinking",
    "section": "",
    "text": "Level-k thinking is a model of strategic reasoning where players try to be “one step ahead” of others. A level-k player assumes others are level-(k-1) and responds optimally to that assumption.\nLevel-0 players are non-strategic, often modelled as randomizing across all strategies. Level-1 players assume others are level-0, level-2 assumes others are level-1, and so on.\nThe p-beauty contest game illustrates level-k thinking. In this game, players choose numbers, aiming to be closest to (p) times the average of all choices. Different levels of thinking lead to different number choices, with experimental results often showing a mix of level-1, level-2, and level-3 players.",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Level-k thinking</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/level-k-thinking.html#introduction",
    "href": "behavioural-game-theory/level-k-thinking.html#introduction",
    "title": "45  Level-k thinking",
    "section": "45.1 Introduction",
    "text": "45.1 Introduction\nThe idea behind level-k thinking is that a player forms an expectation of what others will do and tries to be “one step ahead”.\nThat is, a level-k player plays the best response to level-(k-1) players.\nLevel-0 players do not engage in strategic thinking. This is usually modelled as randomisation across all strategies.\nLevel-1 players assume other players are level-0 and act optimally conditional on this assumption.\nLevel-2 players assume other players are level-1 and act optimally conditional on this assumption.\nAnd so on.",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Level-k thinking</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/level-k-thinking.html#examples",
    "href": "behavioural-game-theory/level-k-thinking.html#examples",
    "title": "45  Level-k thinking",
    "section": "45.2 Examples",
    "text": "45.2 Examples\n\n45.2.1 The beauty contest\nTo understand level-k thinking, consider the following thought experiment from Keynes (1936).\n\n[P]rofessional investment may be likened to those newspaper competitions in which the competitors have to pick out the six prettiest faces from a hundred photographs, the prize being awarded to the competitor whose choice most nearly corresponds to the average preferences of the competitors as a whole; so that each competitor has to pick, not those faces which he himself finds prettiest, but those which he thinks likeliest to catch the fancy of the other competitors, all of whom are looking at the problem from the same point of view. It is not a case of choosing those which, to the best of one’s judgment, are really the prettiest, nor even those which average opinion genuinely thinks the prettiest. We have reached the third degree where we devote our intelligences to anticipating what average opinion expects the average opinion to be. And there are some, I believe, who practise the fourth, fifth and higher degrees.\n\nThis thought experiment has since been developed into a game, the p-beauty contest (Moulin (1986)).\nIn the p-beauty contest, each of n players pick a number y\\in[0,100].\nThe winner is the player whose chosen number is closest to the mean of all the chosen numbers (\\bar y) multiplied by a parameter p. That is, the winner is the player with their chosen number closest to p\\bar y.\np is typically chosen such 0\\leq p\\leq 1, with p=1/2 and p=2/3 common.\nHow might level-k players play this game?\nSuppose p=2/3.\nA level-0 player does not think strategically. We will have the level-0 player randomly select a number between 0 and 100.\nThe level-1 player will play the best response to level-0 players. If level-0 players select across the interval [0, …, 100], the best response is:\n\ny_1=\\frac{2}{3}\\bar y=\\frac{2}{3}\\times 50=33.3\n\nThe level-2 player will play the best response to level-1 players. If all other players are level-1 and select 33.3, the best response is:\n\ny_2=\\frac{2}{3}\\bar y=2/3\\times 33.3=22.2\n\nThe level-3 player will play the best response to level-2 players. If all other players are level-2 and select 22.2, the best response is:\n\ny_3=\\frac{2}{3}\\bar y=2/3\\times 22.2=14.8\n\nAnd so on.\nThe following charts come from Nagel (1995), with p=1/2 and p=2/3. The charts show the distribution of chosen numbers in the p-beauty contest.\nThe chart with p=2/3 spikes at 22.2 and 33.3, suggesting players are playing at level-2 and level-1, respectively. This matches with other experimental evidence on the p-beauty game, with few level-0 players. Most are level-1, level-2 and level-3.\n\n\n\nFigure 45.1: Choices by players of the p-beauty game\n\n\n\n\n\n\np=1/2\n\n\n\n\n\n\n\np=2/3\n\n\n\n\n\n\n\n\nThe lab evidence doesn’t necessarily imply that level-k is the “right model”. Data and theory appear to match, but it is hard to know whether this is how subjects are thinking.\nFinally, it is worth noting that in the Nash equilibrium, each player picks 0. This is because the best response to all other players picking 0 is to pick 0. For any higher number, everyone has an incentive to lower their choice. However, if playing against level-k players, selecting 0 is not the best approach.\n\n\n45.2.2 The assignment game with level-k thinking\nLet’s consider another example of level-k thinking involving a game called the assignment game.\nEach player needs to decide if they will work or shirk. If they both work, they receive a good payoff. They receive an ever better payoff, however, if they shirk while the other works.\n\nWorking through the payoffs for each player, if player B works, player A is better off shirking, receiving payoff of 9. If player B shirks, player 1 is better off working, receiving payoff of 1. If player A works, player 2 is better off shirking, receiving payoff of 9. If player A shirks, player B is still better off shirking, receiving payoff of 0.\nThere is a unique Nash equilibrium (work, shirk), with shirk the dominant strategy for Player B.\n\nConsider, however, if instead of fully rational agents, we have level-k thinkers playing the game.\nIn this case, the outcome of the game will depend on the level of thinking of each player.\nIf both players are level-0, they will each play randomly.\nAt level-1, each player will play the best response to level-0 players. Each player determines this by calculating their best response to the random strategy of the other player.\nFor player A, their expected payoffs are calculated using the 50% probability with which player B could play each action.\nThe expected payoff from playing work is:\n\n\\frac{1}{2}\\times 7+\\frac{1}{2}\\times 1=4\n\nThe expected payoff from playing shirk is:\n\n\\frac{1}{2}\\times 9+\\frac{1}{2}\\times 0=4.5\n\nA level-1 player A chooses to shirk.\nFor player B, their expected payoff from playing work is:\n\n\\frac{1}{2}\\times 4+\\frac{1}{2}\\times -1=1.5\n\nTheir expected payoff from playing shirk is:\n\n\\frac{1}{2}\\times 9+\\frac{1}{2}\\times 0=4.5\n\nA level-1 player B also chooses to shirk.\nIf a player has a dominant strategy, they discover it at k=1. Any level-k thinker will always uses the dominant strategy for k\\geq 1. In that case, we know that any player B with k\\geq 1 will shirk.\nWhat if each player is level 2?\nPlayer A calculates their best response to a level-1 player B. A level-1 player B always plays shirk. Player A’s best response to shirk is to work. The level-2 player A works.\nAlthough we know a level-2 player B will shirk as as shirk is their dominant strategy, we can show this by considering their best response to a level-1 player A. A level-1 player A always plays shirk. Player B’s best response to shirk is to shirk. The level-2 player B shirks.\nAt a certain level of thinking, the players will discover the Nash equilibrium. Here, they have discovered it at level-2 thinking. For any higher level of thinking, they will remain at the Nash equilibrium. That is, if players endowed with level k=\\bar k rationality play Nash, all players with k&gt;\\bar k play Nash.\n\n\n\nLevel-k\nPlayer A\nPlayer B\n\n\n\n\nk=0\nRandom\nRandom\n\n\nk=1\nShirk\nShirk\n\n\nk=2\nWork\nShirk\n\n\nk=3\nWork\nShirk\n\n\nk=4\nWork\nShirk\n\n\n\n\n\n45.2.3 Centipede game\nAnother example of level-k thinking is the centipede game.\nThis centipede game has six stages. At each stage, a player can “take” and end the game or they can “pass”, increasing the total payoff. The other player then has a move.\nThe numbers 1 and 2 along the top of the centipede represent the decision nodes for two players. At the first node, player 1 has the choice to take or pass. If player 1 passes, player 2 has the choice to take or pass, and so on. At the final node, the game ends regardless of what player 2 chooses.\n\nThe payoff when a player takes and ends the game is represented by the numbers in the brackets. The first number is the payoff for player A and the second number is the payoff for player B.\nThere is a unique subgame perfect equilibrium for the centipede game: S_1=(\\text{take, take, take}) and S_2=(\\text{take, take, take}), where S_1 and S_2 are the set of strategies for player A and player B respectively. We solve for this in Section 41.3.1.\nWhat do people do when playing the centipede game in the lab?\nPeople tend to pass until a few stages before the end (depending on the length of the centipede) and then take. They do not play the Nash equilibrium strategy.\nCan level-k thinking provide insight into this behaviour?\nSuppose a level-0 player passes until the end. They are possibly lucky if they are player A playing against another level-0 player.\nA level-1 player B would take at (4,6) as the level-0 player A would pass until then. A Level-1 player A would be planning to take (6,5) at the end as they believe the level-0 player B will keep passing.\nA level-2 player B would plan to take at the final stage (4,6) as they believe the level-1 player A passes. A level-2 player A would take the payoff at (5,3) as they believe a level-1 player B would take at (4,6).\nA level-3 player B would plan to take at (2,4) as they believe the level-1 player A will take at (5,3). A level-3 player A would plan to take at (5,3) as they believe a level-2 player B would take at (4,6).\nAnd so on.\n\n\n\n\nKeynes, J. M. (1936). The general theory of employment, interest, and money. Macmillan. http://gutenberg.net.au/ebooks03/0300071h/printall.html\n\n\nMoulin, H. (1986). Game theory for social sciences. New York Press.\n\n\nNagel, R. (1995). Unraveling in guessing games: An experimental study. The American Economic Review, 85(5), 1313–1326. https://www.jstor.org/stable/2950991",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Level-k thinking</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/asymmetric-information-and-the-curse-of-knowledge.html",
    "href": "behavioural-game-theory/asymmetric-information-and-the-curse-of-knowledge.html",
    "title": "46  Asymmetric information and the curse of knowledge",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Asymmetric information and the curse of knowledge</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/asymmetric-information-and-the-curse-of-knowledge.html#summary",
    "href": "behavioural-game-theory/asymmetric-information-and-the-curse-of-knowledge.html#summary",
    "title": "46  Asymmetric information and the curse of knowledge",
    "section": "",
    "text": "Information asymmetry can cause market failures even with rational agents, but there’s evidence that people often don’t behave optimally in these situations.\nThe “curse of knowledge” occurs when better-informed agents fail to ignore their private information when predicting less-informed agents’ actions, even when it’s in their interest to do so.\nConversely, less-informed agents often fail to account for others’ informational advantages. This is demonstrated in the “market for lemons” example, where a “cursed” buyer might overpay for a car, not realizing only lemons would be sold at their offered price.\nSimilarly, in the “winner’s curse” scenario, a “cursed” bidder in an oil field auction might overbid by underestimating the significance of winning, failing to appreciate that winning implies the other bidder’s information was less favourable.",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Asymmetric information and the curse of knowledge</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/asymmetric-information-and-the-curse-of-knowledge.html#introduction",
    "href": "behavioural-game-theory/asymmetric-information-and-the-curse-of-knowledge.html#introduction",
    "title": "46  Asymmetric information and the curse of knowledge",
    "section": "46.1 Introduction",
    "text": "46.1 Introduction\nWe saw earlier in our examination of the market for lemons and the winner’s curse that asymmetric information can cause market failures even if agents are fully rational. However, the rational agents account for the information and behaviour of others and as a result, behave optimally despite that market imperfection.\nThere is substantial empirical evidence that people do not behave in this way.\nFor example, people tend to underestimate the extent to which informational differences drive others’ behaviour. They often act as if others have the same information set that they do. Where an agent has information that another doesn’t, this phenomenon is known as the curse of knowledge.\nFurther, better-informed agents often fail to take advantage of their informational advantage against less-informed agents because they don’t understand the link between information and behaviour.",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Asymmetric information and the curse of knowledge</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/asymmetric-information-and-the-curse-of-knowledge.html#the-curse-of-knowledge",
    "href": "behavioural-game-theory/asymmetric-information-and-the-curse-of-knowledge.html#the-curse-of-knowledge",
    "title": "46  Asymmetric information and the curse of knowledge",
    "section": "46.2 The curse of knowledge",
    "text": "46.2 The curse of knowledge\nThe idea behind the curse of knowledge is that better-informed agents should ignore the additional information they hold when predicting the actions of less-informed agents. Experimental evidence shows that people are unable to ignore their private information even when it is in their interests to do so.\nFor example, Newton (1990) had students participate in an experiment in one of two roles: “Tapper” and “Listener”.\nTappers received a list of 25 well-known songs and were asked to “tap out” the rhythm of one of the songs.\nListeners tried to identify the song based solely on the taps.\nTappers predicted that listeners would identify 50% of the songs.\nListeners only identified 3 of 120 songs correctly (a rate of about 2.5%).",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Asymmetric information and the curse of knowledge</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/asymmetric-information-and-the-curse-of-knowledge.html#the-market-for-lemons",
    "href": "behavioural-game-theory/asymmetric-information-and-the-curse-of-knowledge.html#the-market-for-lemons",
    "title": "46  Asymmetric information and the curse of knowledge",
    "section": "46.3 The market for lemons",
    "text": "46.3 The market for lemons\nWhile that experiment involved agents who had more information than the other players - they knew the song - we also see failures where the other player has additional information but the agent does not account for that fact.\nWe can explore this idea in the market for lemons.\nRecall our earlier example in Section 42.2 involving the purchase of a used car.\nThere are two types of cars, good cars and lemons, and only the seller knows the type. The buyer knows that the seller has this information.\nA car is good with probability q and a lemon with probability 1−q. To the seller, good cars are worth $10,000 and lemons $5,000. To potential buyers, good cars are worth $15,000 and lemons $7,500.\nA “cursed” buyer doesn’t think that the seller’s decision whether to trade depends on the seller’s knowledge of the car.\nSuppose that q=0.2. That is, only 20% of the cars are good.\nSuppose the cursed buyer believes that cars are sold with equal probability regardless of type.\nIn that case, the expected value of a car to a buyer is:\n\\begin{align*}\n\\hat {\\text{E}}&=0.2\\times 15000+0.8\\times 7500 \\\\[6pt]\n&=9000\n\\end{align*}\nA buyer would be willing to pay up to $9000 for a car.\nAt that price, however, the seller of a good car would not be willing to sell. The market will comprise only lemons, which sellers are more than happy to sell. The buyer will pay $9000 for a car worth only $7500 to them.",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Asymmetric information and the curse of knowledge</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/asymmetric-information-and-the-curse-of-knowledge.html#the-winners-curse",
    "href": "behavioural-game-theory/asymmetric-information-and-the-curse-of-knowledge.html#the-winners-curse",
    "title": "46  Asymmetric information and the curse of knowledge",
    "section": "46.4 The winner’s curse",
    "text": "46.4 The winner’s curse\nWe can also explore this phenomenon in the winner’s curse. Recall our example of the winner’s curse in Section 42.3 on bidding for an oil field.\nCompany 1 and company 2 hire a geologist to estimate the value of an oil field. The honest geologist of each company privately reports their estimated valuation to the company. Company 1 learns v_1 and company 2 learns v_2.\nv_1 and v_2 are uniformly distributed between $0 and $100 and independent.\nAssume the true value of the oil field is the mean of v_1 and v_2:\n\nV=\\frac{v_1+v_2}{2}\n\nThe two companies simultaneously bid for the field in a first-price auction. The highest bid wins and pays their bid.\nAssume company 1 is cursed and therefore assumes that company 2’s bid is independent of v_2. Company 1 assumes v_2 is on average $50 and that company 2 always bids.\nCompany 1’s expected profit, if they bid v_1, is:\n\\begin{align*}\n\\hat {\\text{E}}[\\pi_1|\\text{bid }v_1]&=\\frac{1}{2}\\pi_1(\\text{lose})+\\frac{1}{2}\\pi_1(\\text{win}) \\\\[12pt]\n&=\\frac{1}{2}\\times 0+\\frac{1}{2}\\bigg(\\frac{v_1+50}{2}-v_1\\bigg) \\\\[12pt]\n&=\\frac{1}{4}(50-v_1)\n\\end{align*}\nWe can see that:\n\n\\hat {\\text{E}}[\\pi_1|\\text{bid} v_1]&gt;0 \\Leftrightarrow v_1&gt;50\n\nThat is, company 1 expects to make a profit if they receive a private valaution of more than $50.\nHowever, as shown in Section 42.3, this bidding approach leads to, on average, a loss. Company 1 under-appreciates that company 2 is more likely not to bid when company 2’s information is bad. Therefore, company 1 under-appreciates the extent to which winning the auction is bad news.\n\n\n\n\nNewton, E. L. (1990). The rocky road from actions to intentions [PhD thesis]. https://www.proquest.com/openview/b740253d9b78599786f59d6b6055cc3b/1?pq-origsite=gscholar&cbl=18750&diss=y",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Asymmetric information and the curse of knowledge</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/emotions.html",
    "href": "behavioural-game-theory/emotions.html",
    "title": "47  Emotions",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Emotions</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/emotions.html#summary",
    "href": "behavioural-game-theory/emotions.html#summary",
    "title": "47  Emotions",
    "section": "",
    "text": "Emotions are mental states that signal positive or negative outcomes and can function as commitment devices in strategic interactions.\nEmotions like guilt and anger can serve as credible commitments, enabling trust and cooperation or deterring cheating, even when the emotional response appears “irrational” in the short term.\nIn everyday scenarios, like complaining about bad service or playing “chicken,” emotions can change the game’s payoff structure and equilibrium, making threats credible and influencing others’ behaviour to one’s advantage.",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Emotions</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/emotions.html#introduction",
    "href": "behavioural-game-theory/emotions.html#introduction",
    "title": "47  Emotions",
    "section": "47.1 Introduction",
    "text": "47.1 Introduction\nEmotions are mental states that signal positive or negative outcomes.\nOne function of emotions may be to act as a commitment device:\n\nThe emotion of guilt can constrain a desire to “cheat” where cheating delivers a higher pay-off. This in turn may allow people to trust you.\nThe emotion of anger may lead you to punish someone even where delivering the punishment also harms you. This in turn may lead people to be less likely to cheat you.\n\nWhile this behaviour may appear “irrational”, it allows people to make credible commitments that in turn allow them to enter beneficial trades and cooperative arrangements, while being less likely to being cheated.\nConsider the following quote from Richard Nixon:\n\nI call it the Madman Theory, Bob. I want the North Vietnamese to believe I’ve reached the point where I might do anything to stop the war. We’ll just slip the word to them that, “for God’s sake, you know Nixon is obsessed about communism. We can’t restrain him when he’s angry—and he has his hand on the nuclear button” and Ho Chi Minh himself will be in Paris in two days begging for peace.\n\nPushing the nuclear button is not in Nixon’s interest, and from a purely rational perspective may not be a credible threat. But if a madman has his finger on the button, the calculation changes.",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Emotions</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/emotions.html#examples",
    "href": "behavioural-game-theory/emotions.html#examples",
    "title": "47  Emotions",
    "section": "47.2 Examples",
    "text": "47.2 Examples\n\n47.2.1 Complaining for bad service\nRecall our earlier example in Section 43.2.3, illustrated below, of a customer threatening to complain if they receive bad service. Complaining is costly.\nWe determined this by backward induction. At the final node for the customer, they can complain for a payoff of -1 or not complain for a payoff of 1. They will not complain.\nThe company, therefore, has a choice between providing good service for a payoff of 1 or bad service for a payoff of 2. They will provide bad service. The company has the same payoff for bad service regardless of the presence of the threat to complain as the threat is not credible.\nFor the customer’s initial choice of whether to threaten to complain, it does not matter either way. Regardless of their threat, they receive bad service.\n\nBut what if the customer gets a strong sense of satisfaction from complaining worth +3? Then their payoffs become as follows:\n\nThe threat to complain is now credible. If they receive bad service, they complain for a payoff of 2 rather than not complain for a payoff of 1.\nThe company now provides good service following a threat to complain. Absent that threat, they would provide bad service.\n\n\n\n47.2.2 Chicken\nAs another example, recall the game of chicken. Two players are driving toward each other. Whoever swerves first loses. If neither swerves, they crash and die.\n\nThere are two pure-strategy Nash equilibria: (Straight, Swerve) and (Swerve, Straight). If the other player swerves, they want to go straight. If the other player goes straight, they want to swerve.\n\nNow suppose player A is crazy. They are afraid of nothing and will never swerve. Player B knows this.\nPlayer A’s craziness acts as a commitment device similar to that of removing the Steering Wheel. If player A will not swerve, player B will.\n\nThe Nash equilibrium is (Straight, Swerve). The crazy player A wins the game of chicken.",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Emotions</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/behavioural-game-theory-exercises.html",
    "href": "behavioural-game-theory/behavioural-game-theory-exercises.html",
    "title": "48  Behavioural game theory exercises",
    "section": "",
    "text": "48.1 Penalty kick\nA soccer player (the striker) has a penalty kick. The striker is deciding whether to kick to the left or right. If the goalkeeper dives in the correct direction, the goalkeeper will stop the ball and the two sides will tie. Otherwise, the striker will score a goal and win.\nLately, the striker has been having trouble kicking to the right, sometimes missing the goals even when the goalkeeper doesn’t dive in that direction.\nThe expected payoffs for each combination of actions are as follows, with the payoff (x,y) being the payoffs for the striker and goalkeeper respectively:\nAre there any pure-strategy Nash equilibria? If so, what are they?\nThere are no pure-strategy Nash equilibria. Whatever the striker does, the goalkeeper wants to match. If the goalkeeper matches, the striker wants to change.\na) Suppose the striker and goalkeeper are level-k thinkers.\nIf they were level-0, both would choose right or left with equal probability.\nWhat would each player do if they were a level-1 thinker? Explain.\nb) What would each player do if they were a level-2 thinker? Explain.",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Behavioural game theory exercises</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/behavioural-game-theory-exercises.html#penalty-kick",
    "href": "behavioural-game-theory/behavioural-game-theory-exercises.html#penalty-kick",
    "title": "48  Behavioural game theory exercises",
    "section": "",
    "text": "Answer\n\n\n\n\n\nA level-1 striker will assume they are playing a level-0 goalkeeper.\nThey will estimate the the payoff from each action responding to the random play of a level-0 goalkeeper.\n\\begin{align*}\nE[U_S(R)]&=0.5\\times 0+0.5\\times 8 \\\\\n&=4 \\\\\n\\\\\nE[U_S(L)]&=0.5\\times 10+0.5*\\times 0 \\\\\n&=5\n\\end{align*}\nThe level-1 striker has a higher expected payoff for kicking left, so kick left.\nA level-1 goalkeeper will assume they are playing a level-0 striker.\nThey will estimate the the payoff from each action responding to the random play of a level-0 striker.\n\\begin{align*}\nE[U_G(R)]&=0.5\\times 5+0.5\\times 0 \\\\\n&=2.5 \\\\\n\\\\\nE[U_G(L)]&=0.5\\times 2+0.5*\\times 5 \\\\\n&=3.5\n\\end{align*}\nThe level-1 goalkeeper has a higher expected payoff for going left, so go left.\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nA level-2 striker will assume they are playing a level-1 goalkeeper.\nThey believe the level-1 goalkeeper will go left, so they will go right (payoff 8 compared to payoff 0).\nA level-2 goalkeeper will assume they are playing a level-1 striker.\nThey believe the level-1 striker will go left, so they will go left (payoff 5 compared to payoff 0).",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Behavioural game theory exercises</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/behavioural-game-theory-exercises.html#hide-and-seek",
    "href": "behavioural-game-theory/behavioural-game-theory-exercises.html#hide-and-seek",
    "title": "48  Behavioural game theory exercises",
    "section": "48.2 Hide and seek",
    "text": "48.2 Hide and seek\nIn the hide-and-seek game, the Hider selects one of the four boxes marked A, B, A and A. The Seeker guesses the box selected by the hider.\nThe Seeker wins if they find the Hider. Otherwise, the Hider wins.\n\nThe payoffs are as follows. I have labelled the end boxes A1 and A2 to distinguish the “A”s from each other.\n\nAssume a level-0 seeker or hider selects a box by hiding in or looking in the “most salient” hiding spots. They choose A1 or A2 on the ends with p=0.3 each, or B (because it is different) with p=0.35. They hide or look in less salient middle A with probability 1−2\\times 0.3−0.35=0.05.\n(Note that this assumption for the level-0 agents is different to what we have assumed to date. We have typically assumed a level-0 agent randomly chooses an action.)\na) What box do the level-1 hider and seeker choose?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe level-1 hider calculates the expected payoff from hiding in each of the boxes if playing against a level-0 seeker.\n\\begin{align*}\nE[U(A1)]&=0×0.3+1×0.35+1×0.05+1×0.3=0.7 \\\\\n\\\\\nE[U(B)]&=1×0.3+0×0.35+1×0.05+1×0.3=0.65 \\\\\n\\\\\nE[U(A)]&=1×0.3+1×0.35+0×0.05+1×0.3=0.95 \\\\\n\\\\\nE[U(A2)]&=1×0.3+1×0.35+1×0.05+0×0.3=0.7\n\\end{align*}\nThe level-1 hider hides in the least salient box A.\nThe level-1 seeker calculates the expected payoff from looking in each of the boxes if playing against a level-0 hider.\n\\begin{align*}\nE[U(A1)]&=1×0.3+0×0.35+0×0.05+0×0.3=0.3 \\\\\n\\\\\nE[U(B)]&=0×0.3+1×0.35+0×0.05+0×0.3=0.35 \\\\\n\\\\\nE[U(A)]&=0×0.3+0×0.35+1×0.05+0×0.3=0.05 \\\\\n\\\\\nE[U(A2)]&=0×0.3+0×0.35+0×0.05+1×0.3=0.3\n\\end{align*}\nThe level-1 seeker looks in Box B.\nIf both the hider and seeker are level-1, the hider wins.\n\n\n\nb) What box do the level-2 hider and seeker choose?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe level-2 hider knows that the level-1 seeker chooses B. They select any box apart from B with equal probability, all of which they believe will give a pay-off of 1.\nThe level-2 seeker knows that the level-1 hider will select A. They select A.\nThe level-2 seeker wins with probability 1/3.\n\n\n\nc) What box do the level-3 hider and seeker choose?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe level-3 hider knows that the level-2 seeker chooses A. They select any box apart from A with equal probability, all of which they believe will give a pay-off of 1.\nThe level-3 seeker knows that the level-2 hider will select any box except B with equal probability. They select one of A1, A2 or A with equal probability.\nThe level-3 seeker wins with probability 1/3\\times 1/3+1/3\\times 1/3=2/9.\n\n\n\nd) What box do the level-4 hider and seeker choose?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe level-4 hider knows that the level-3 seeker selected A1, A2 and A with equal probability. They select B.\nThe level-4 seeker knows that the level-3 hider selected any box apart from A with equal probability. They also select those boxes with equal probability.\nThe level-4 seeker wins with probability 1/3.",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Behavioural game theory exercises</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/behavioural-game-theory-exercises.html#matching-pennies-with-a-twist",
    "href": "behavioural-game-theory/behavioural-game-theory-exercises.html#matching-pennies-with-a-twist",
    "title": "48  Behavioural game theory exercises",
    "section": "48.3 Matching pennies (with a twist)",
    "text": "48.3 Matching pennies (with a twist)\nConsider the following two-player game:\n\na) What are the two pure-strategy Nash equilibria of this game?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe two pure-strategy Nash equilibria of this game are (X,X) and (Y,Y). That is, if the players are jointly playing either of those combinations of strategies, neither has an incentive to deviate. Their response is a best response to the other players’ actions.\n\n\n\nb) Suppose players in this game think according to the level-k model. Assume a level-0 agent randomises between options with equal probability.\nWhat would player A and player B do if they were level-1 players?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nRemember the idea behind level-k thinking: given their own cognitive level, a player forms an expectation of what others will do and tries to be “one step ahead of them”.\nWe work out the utility of each option.\nFirst, for player A:\n\\begin{align*}\nEU ^{1}_{A}(X)&= 0.5\\times 6+0.5\\times 0=3 \\\\\n\\\\\nEU ^{1}_{A}(Y)&= 0.5\\times 0+0.5\\times 6.1=3.05\n\\end{align*}\nPlayer A chooses Y if they are a level-1 player.\nNext, for player B:\n\\begin{align*}\nEU ^{1}_{B}(X)&= 0.5\\times 6.1+0.5\\times 0=3.05 \\\\\n\\\\\nEU ^{1}_{B}(Y)&= 0.5\\times 0+0.5\\times 6=3\n\\end{align*}\nPlayer B chooses X if they are a level-1 player.\nIf both players are level-1, they will fail to coordinate.\n\n\n\nc) What would player A and player B do if they were level-2 players?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe again work out the utility of each option:\nFirst, for player A. They know that a level-1 player B will select X. Accordingly:\n\\begin{align*}\nEU^{2}_{A}(X)&=1\\times 6+0\\times 0=6 \\\\\n\\\\\nEU^{2}_{A}(Y)&=1\\times 0+0\\times 6.1=0\n\\end{align*}\nPlayer A chooses X if they are a level-2 player.\nNext, for player B. They know that a level-1 player A will select Y. Accordingly:\n\\begin{align*}\nEU ^{2}_{B}(X)&= 0\\times 6.1+1\\times0=0 \\\\\n\\\\\nEU ^{2}_{B}(Y)&= 0\\times 0+1\\times 6=6\n\\end{align*}\nPlayer B chooses Y if they are a level-2 player.\nIf both players are level-2, they will fail to coordinate.\n\n\n\nd) What would player A and player B do if they were level-3 players?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe again work out the utility of each option:\nFirst, for player A. They know that a level-2 player B will select Y. Accordingly:\n\\begin{align*}\nEU ^{3}_{A}(X)&= 0\\times 6+1\\times 0=0 \\\\\n\\\\\nEU ^{3}_{A}(Y)&= 0\\times 0+1\\times 6.1=6.1\n\\end{align*}\nPlayer A chooses Y if they are a level-3 player.\nNext, for player B. They know that a level-2 player A will select X. Accordingly:\n\\begin{align*}\nEU ^{3}_{B}(X)&= 1\\times 6.1+0\\times 0=6.1 \\\\\n\\\\\nEU ^{3}_{B}(Y)&= 1\\times 0+0\\times 6=0\n\\end{align*}\nPlayer B chooses X if they are a level-3 player.\nIf both players are level-3, they will fail to coordinate.\n\n\n\ne) When this game is played in the laboratory, the players mis-coordinate. About 3/4 of the row players (player A) choose X while about 3/4 of the column players (player B) choose Y.\nOf interest, each player tries to coordinate on the strategy that the other player would be better off coordinating on. That is, Player A receives 6 from successful coordination choosing X, which is less than the 6.1 Player A would get from coordinating on Y.\nGiven your answers to b) through d), what mix of level-k players might explain the mis-coordination described above?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThat 3/4 of Player “A”s choose X and 3/4 of Player “B”s choose Y suggests there are many level-2 players (or possibly level-4). They each assume that the other player is level-1 and has picked the option with the highest payoff for themselves. They are effectively trying to coordinate with the other player by assuming that the other will seek their highest paying option. However, if both do this, both receive nothing.",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Behavioural game theory exercises</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/behavioural-game-theory-exercises.html#buying-a-car",
    "href": "behavioural-game-theory/behavioural-game-theory-exercises.html#buying-a-car",
    "title": "48  Behavioural game theory exercises",
    "section": "48.4 Buying a car",
    "text": "48.4 Buying a car\nSuppose that you are considering purchasing a car.\nYou believe that the seller values it between $1000 and $5000, with an equal probability that it has a value at any point in this range. That is, you believe it is uniformly valued to the seller between $1000 and $5000.\nThe seller knows the car and its true value.\nAssume that whatever the car is worth to the seller, it is worth 1.33 times that to you (so a car worth $2400 to the owner is actually worth $3200 to you).\na) What offer should you make to ensure that you will not lose money?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSuppose you offer $x. If the seller accepts, the value must be between $1000 and $x.\nAs the value evenly distributed across that interval, its average value would be:\n\n1000+\\frac{x−1000}{2}=500+\\frac{x}{2}\n\nThe expected value of the car to you will be:\n\n\\frac{4}{3}\\bigg(500+\\frac{x}{2}\\bigg)\n\nTo ensure you don’t lose you want:\n\n\\frac{4}{3}\\bigg(500+\\frac{x}{2}\\bigg)&gt;x\n\nSolving this out, you expect to make a profit where x&lt;\\$2000.\n\n\n\nb) Suppose you are cursed player and you believe sellers will take the average optimal action of selling whenever they are offered more than $3000. As a result, you decide to offer $3000. What is your accepted profit if the seller accepts your offer?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIf seller accepts, the value must be between $1000 and $3000.\nIf value evenly distributed across that interval, its average value would be $2000.\nGiven it is worth 1.33 times more to you, it would be worth $2,667 on average.\nYou would lose, on average, $333.",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Behavioural game theory exercises</span>"
    ]
  },
  {
    "objectID": "behavioural-game-theory/behavioural-game-theory-exercises.html#advice",
    "href": "behavioural-game-theory/behavioural-game-theory-exercises.html#advice",
    "title": "48  Behavioural game theory exercises",
    "section": "48.5 Advice",
    "text": "48.5 Advice\nAgent A is going to their financial adviser to buy some life insurance. The adviser can sell them insurance that does not cover heart attacks but for which the adviser receives a huge sales commission (bad insurance). Or the adviser can sell Agent A comprehensive insurance for which their sales commission is lower (good insurance).\nThe payoffs (x,y) for each decision are indicated in the game tree below, with x being the satisfaction of Agent A and y being the satisfaction of the adviser.\n\na) Assume the adviser only cares about the payoffs indicated. What would the adviser do if Agent A chooses to purchase?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe adviser will compare payoffs of 4 for selling bad insurance and 2 for selling good insurance. They will choose to sell bad insurance.\n\n\n\nb) What would Agent A do, anticipating the choice of the adviser?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAgent A will compare a payoff of 0 for no purchase and a payoff of -2 for purchase (knowing that they will be sold bad insurance). They will choose not to buy insurance.\n\n\n\nc) Suppose now that Agent A can complain to the regulator if they are sold bad insurance. If Agent A is successful, they can cancel the insurance but would suffer a cost of -3 due to the effort involved. Would this change the outcome of the game?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nWorking by backward induction: Agent A has a choice between complaining for a payoff of -3 or not complaining for a payoff of -2. They do not complain.\nThe rest of the game plays out as per questions a) and b). There is no change to the outcome as they cannot commit to complain in advance (at least in this version of the game). The threat to complain is not credible.\n\n\n\nd) Suppose Agent A has a reputation for seeking revenge and would experience satisfaction of +4 from complaining to the regulator (in addition to the effort cost of -3) as reciprocation for the action of the adviser. How would this change the outcome of the game?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nThe agent now has a choice between a payoff of 0 for selling bad insurance (as Agent A complains and the insurance is cancelled) and 2 for selling good insurance. They sell the good insurance.\nAgent A now has a choice of a payoff of 0 for not purchasing insurance and 2 for purchasing. They make the purchase.",
    "crumbs": [
      "Behavioural game theory",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Behavioural game theory exercises</span>"
    ]
  },
  {
    "objectID": "social-preferences/social-preferences.html",
    "href": "social-preferences/social-preferences.html",
    "title": "Social preferences",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Social preferences"
    ]
  },
  {
    "objectID": "social-preferences/social-preferences.html#summary",
    "href": "social-preferences/social-preferences.html#summary",
    "title": "Social preferences",
    "section": "",
    "text": "Social preferences, or other-regarding preferences, encompass three main types: distribution, reputation, and reciprocity.\nDistribution preferences relate to how people care about resource division, driven by altruism or inequality aversion.\nReputation preferences involve concern for what others think and fear of social stigma from selfish behaviour.\nReciprocity preferences reflect how people care about others’ intentions and respond in kind to their actions.\nThe ultimatum and dictator games demonstrates social preferences, as dictators and proposers often offer more than the minimum and responders sometimes reject non-zero offers.",
    "crumbs": [
      "Social preferences"
    ]
  },
  {
    "objectID": "social-preferences/social-preferences.html#introduction",
    "href": "social-preferences/social-preferences.html#introduction",
    "title": "Social preferences",
    "section": "Introduction",
    "text": "Introduction\nPeople do not care solely about their own outcomes. They care about the outcomes and actions of others. These preferences are known as social preferences, or sometimes “other-regarding preferences”.\nIn this part, I will examine the three types of social preferences: distribution, reputation, and reciprocity.\nDistribution refers to how people care about the division of resources. This can be driven by either altruism, which is the desire to help others, or inequality aversion, which is concerned with the fairness of the distribution and the relative gaps between individuals.\nReputation relates to how people care about what other people think. People fear the social stigma that can result from “selfish” behaviour.\nReciprocity relates to how people care about the intentions of others and how they often respond in kind to their actions.",
    "crumbs": [
      "Social preferences"
    ]
  },
  {
    "objectID": "social-preferences/social-preferences.html#two-examples",
    "href": "social-preferences/social-preferences.html#two-examples",
    "title": "Social preferences",
    "section": "Two examples",
    "text": "Two examples\nThe results of the following games are evidence of social preferences.\n\nThe ultimatum game\nRecall our earlier discussion of the ultimatum game.\nThe ultimatum game involves two players: the proposer and the responder.\nThe proposer is given a fixed amount of money m. They then offer a portion x of the sum m to the responder.\nThe responder can either accept or reject the offer. They make this decision knowing the fixed amount m held by the proposer and the offer x.\nIf the responder accepts, the responder receives the offer x and the proposer gets the remainder m-x. If the responder rejects, both players receive nothing.\n\nGenerally, if the players have monotonic preferences and the offer strategy set is discrete:\n\nThe responder accepts any x&gt;0.\nThe proposer offers the smallest non-zero amount the proposer can offer.\n\nThe other (weak) subgame perfect Nash equilibrium is an offer of $0 and acceptance.\nWhat do people do in the ultimatum game?\nUnlike the game theoretic predictions, proposers rarely offer the minimum amount, and responders often reject non-zero offers.\nFor example, Henrich et al. (2001) recruited subjects from 15 small-scale societies to play the ultimatum game. The mean offer in all societies was substantially above zero. The rejection rate was low but non-zero.\n\nThese results cannot be explained by examining only the outcomes to the individual. We need to consider their social preferences.\n\n\nThe dictator game\nRecall our earlier discussion of the dictator game.\nIn the dictator game, the dictator is given a fixed amount of money m. They then offer a portion x of the sum m to the receiver. The game then ends.\nExchange is unilateral. Receivers have an empty strategy set.\n\nThe standard game theory prediction is that the dictator offers nothing. The dictator maximises their payoff by keeping all of the endowment themselves, receiving payoff m.\nHowever, in experiments, dictators tend to give a positive sum of money. The following shows distributions reported by Engel (2011). Most players offer more than zero, suggesting preferences beyond simply maximising their own payoff.\n\n\n\nFigure 1: Distribution of amount given in the dictator game (Engel, 2011).\n\n\n\n\n\n\n\n(a) Mean per treatment\n\n\n\n\n\n\n\n\n\n\n\n(b) Individual give rates\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEngel, C. (2011). Dictator games: a meta study. Experimental Economics, 14(4), 583–610. https://doi.org/10.1007/s10683-011-9283-7\n\n\nHenrich, J., Boyd, R., Bowles, S., Camerer, C., Fehr, E., Gintis, H., and McElreath, R. (2001). In Search of Homo Economicus: Behavioral Experiments in 15 Small-Scale Societies. American Economic Review, 91(2), 73–78. https://doi.org/10.1257/aer.91.2.73",
    "crumbs": [
      "Social preferences"
    ]
  },
  {
    "objectID": "social-preferences/distribution.html",
    "href": "social-preferences/distribution.html",
    "title": "49  People care about resource distribution",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>People care about resource distribution</span>"
    ]
  },
  {
    "objectID": "social-preferences/distribution.html#summary",
    "href": "social-preferences/distribution.html#summary",
    "title": "49  People care about resource distribution",
    "section": "",
    "text": "Distributional preferences relate to how people value the relative distribution of resources among people.\nDistributional preferences can be incorporated into economic analysis by including others’ outcomes in utility functions.\nAltruism is a type of distributional preference where an individual places a positive weight on others’ outcomes. It can be pure (genuine concern for others) or impure (deriving satisfaction from doing good).\nInequality aversion is a type of distributional preference where people dislike having less than others and may also dislike having more than others.\nWe can also model other distributional preferences, including status-seeking, Rawlsian and utilitarian preferences.",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>People care about resource distribution</span>"
    ]
  },
  {
    "objectID": "social-preferences/distribution.html#introduction",
    "href": "social-preferences/distribution.html#introduction",
    "title": "49  People care about resource distribution",
    "section": "49.1 Introduction",
    "text": "49.1 Introduction\nIn 2008, when the Sacramento Bee created a database of California state worker salaries, University of California (UC) employees could learn about their colleagues’ pay for the first time. Researchers at three UC campuses studied the impact by randomly emailing some employees about the database (Card et al., 2012).\nEmployees who learned they earned below the median for their department and role reported lower job satisfaction and began searching for new positions. The effect was strongest among workers in the bottom quartile of their unit’s pay scale. A follow-up two to three years later suggested more lower-paid employees had left their positions.\nIn contrast, employees above the median showed no changes in satisfaction or behaviour after learning about peer salaries.\nThis research shows that people care about their position relative to others, not just their absolute circumstances. The dissatisfaction and subsequent job-seeking of low-paid UC employees revealed ‘distributional preferences’, preferences about the allocation of resources across individuals.\nTo understand how social comparisons influence economic decisions, we can model these distributional preferences mathematically. Economists model distributional preferences by extending utility functions to include others’ outcomes, just as we model preferences over personal consumption.\nThis approach allows us to analyse how social considerations influence economic decision-making in contexts ranging from charitable giving to workplace compensation. Understanding distributional preferences can help us explain behaviour that deviates from pure self-interest in experimental games. We can use them to examine how inequality and social comparisons affect economic decisions. This can inform the design of workplace arrangements and economic policies that account for social preferences\nIn what follows, I examine two forms of distributional preferences in detail - altruism and inequality aversion - and consider other social preferences. Each helps explain different aspects of observed behaviour, from charitable giving motivated by altruism to rejection of unfair offers driven by inequality aversion.",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>People care about resource distribution</span>"
    ]
  },
  {
    "objectID": "social-preferences/distribution.html#altruism",
    "href": "social-preferences/distribution.html#altruism",
    "title": "49  People care about resource distribution",
    "section": "49.2 Altruism",
    "text": "49.2 Altruism\nAltruism is concern for the outcomes of others, with positive weights on others’ wellbeing.\nTo incorporate altruism, we give a positive weight to the utility of others in the utility function. Here’s a simple example where an individual’s utility depends on both their own outcome and another person’s:\n\nU_i(x_i,x_j)=x_i+\\alpha x_j\n\nThe utility of agent i, U_i, is a function of the the outcome for agent i, x_i, and agent j, x_j. \\alpha is some number greater than zero, with utility increasing linearly with an increased payoff for either agent.\nAltruism comes in two forms. Pure altruism reflects genuine concern for others’ wellbeing. Impure altruism occurs when people get a ‘warm glow’ from doing good, regardless of the actual impact on others.\n\n49.2.1 Example: the public goods game\nConsider a public goods game where two players each have $10 and must simultaneously decide how much to contribute to a public project. The total contributions are multiplied by 1.5 and split equally between both players, regardless of their individual contributions.\n\n\n\nFigure 49.1: Public goods game process\n\n\n\n\n\n\nThis game captures real-world situations: work teams deciding effort on shared projects, neighbors contributing to community improvements, or countries investing in climate change mitigation.\nFor this scenario, if both players contribute their full $10, the pot becomes $30 and each receives $15.\n\n\n\nFigure 49.2: Public goods game process with cooperation\n\n\n\n\n\n\nIf neither contributes, each keeps their $10.\n\n\n\nFigure 49.3: Public goods game process with no cooperation\n\n\n\n\n\n\nIf one contributes $10 and the other $0, the $15 pot is split equally so the contributor finishes with $7.50 and the non-contributor end up with $17.50.\n\n\n\nFigure 49.4: Public goods game process with defection\n\n\n\n\n\n\nA self-interested player would contribute nothing. For any contribution by the other player, keeping your money always gives a higher payoff. However, both players would be better off if they both contributed everything.\nNow suppose both players have altruistic preferences, placing a positive weight on the other’s outcome (albeit lower than the weight on their own outcome):\n\nU_i(x_i,x_j)=x_i+0.75x_j\n\nWith these preferences, we can calculate whether contributing is optimal if the other person contributes. If the agent contributes, they receive utility from their $15 and the $15 received by the other agent.\n\\begin{align*}\nU_i(\\text{contribute})&=15+0.75\\times 15\\\\[6pt]\n&=26.25\n\\end{align*}\nIf they do not contribute, they receive utility from their higher payoff of $17.50, but the lower payoff of $7.50 for the other agent acts as a drag.\n\\begin{align*}\nU_i(\\text{free ride})&=17.50+0.75\\times 7.50\\\\[6pt]\n&=23.125\n\\end{align*}\nWith these altruistic preferences, contributing is optimal when the other player contributes. The weight placed on the other player’s payoff (\\alpha=0.75) makes cooperation the best response to cooperation.\nContributing is actually the best response to any contribution by the other player. For example, here are the payoffs in response to a contribution of $0 by the other player. If the agent contributes, they receive utility from their $7.50 and the other player’s $17.50.\n\\begin{align*}\nU_i(\\text{contribute})&=7.5+0.75\\times 17.5 \\\\[6pt]\n&=20.625\n\\end{align*}\nIf they do not contribute, they receive utility from their higher payoff of $10, but the lower payoff of $10 for the other player reduces their utility more than they gain for the increased personal payoff.\n\\begin{align*}\nU_i(\\text{free ride})&=10+0.75\\times 10 \\\\[6pt]\n&=17.50\n\\end{align*}\nAn altruistic player would contribute even if the other player is not an altruist.\nThis example shows how moderate altruism can overcome the free-rider problem in public goods provision. The positive weight two altruistic players place on the other’s outcome makes mutual contribution a Nash equilibrium.\n\n\n49.2.2 Limitations of the altruism model\nWhile altruism helps explain behaviours like charitable giving, it has limitations.\nRecall the ultimatum game. The first player (the proposer) receives a sum of money (say $10) and must offer some portion of it to the second player (the responder). The responder then has two options:\n\nAccept the offer: both players get the proposed split\nReject the offer: both players get nothing\n\n\nAltruism can explain why proposers make generous offers, but it fails to explain why responders often reject low offers, knowingly reducing both players’ payoffs. Such rejection would require negative weights on outcomes, contradicting the altruism model.",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>People care about resource distribution</span>"
    ]
  },
  {
    "objectID": "social-preferences/distribution.html#inequality-aversion",
    "href": "social-preferences/distribution.html#inequality-aversion",
    "title": "49  People care about resource distribution",
    "section": "49.3 Inequality aversion",
    "text": "49.3 Inequality aversion\nInequality aversion offers an explanation for such rejections. We dislike being worse off than others, and to a lesser extent, we may feel uncomfortable being better off than others. This captures the intuition that people care about relative standing. Think of how employees react to learning their co-workers earn more, or the guilt some feel about their wealth relative to those in poverty.\n\n49.3.1 A model of inequality aversion\nTo understand how inequality aversion affects decision-making, we need a formal way to represent these preferences. Fehr and Schmidt (1999) developed an influential model that captures both the dislike of having less than others and the potential discomfort of having more.\nIn their model, the utility of agent i, u_i, is a function of the payoff of agent i and the payoff of agent j.\n\nu_i(x_i,x_j)=x_i-\\alpha\\text{max}\\{x_j-x_i,0\\}-\\beta\\text{max}\\{x_i-x_j,0\\} \\\\[12pt]\n\\alpha&gt;0 \\quad \\textrm{and} \\quad \\beta&gt;0\n\nEach term in this equation represents a distinct psychological effect:\n\nx_i is their own outcome, such as their payoff or salary\n\\alpha\\text{max}\\{x_j-x_i,0\\} captures the sting of disadvantageous inequality, like discovering your colleague earns more than you\n\\beta\\text{max}\\{x_i-x_j,0\\} represents the discomfort of advantageous inequality, like feeling guilty about your high salary compared to others or the guilt of making a low offer in the ultimatum game.\n\nThe \\text{max} function ensures that only the relevant term is included. If agent i has more than the other player, with x_i higher than x_j, the disadvantageous inequality term is zero. If agent i has less, the advantageous inequality term is zero.\nTo present the utility function in a form you may find more intuitive without the \\text{max} function, we can rewrite it with utility of agent i being their own payoff, minus a penalty for either advantageous or disadvantageous inequality.\n\nu_i(x_i,x_j)=x_i-\\left\\{\\begin{matrix}\n\\beta(x_i-x_j) \\quad &\\textrm{if} \\quad x_i \\geq x_j \\\\[6pt]\n\\alpha(x_j-x_i) \\quad &\\textrm{if} \\quad x_i &lt; x_j\n\\end{matrix}\\right.\n\nTypically \\alpha&gt;\\beta as people dislike having less than others more than they dislike having more than others. We could also set \\beta&lt;0 for an agent that likes to be better off than others.\nTo visualise how inequality aversion affects utility, the following graph shows a plot of utility as a function of x_i.\nThis utility function has a kink at x_j where agent i moves from having less to more than agent j. Below x_j, utility increases due to both the increasing material outcome for agent i, plus the reduction in inequality. If \\beta is between 0 and 1 as in this diagram, the utility of agent i, U(x_i), continues to increase in x_i above x_j, but at a decreasing rate, as inequality degrades the benefits of having more.\n\n\nCode\nlibrary(ggplot2)\n\n# Define parameter values\nx_i &lt;- seq(0, 10, by=0.1)  # Range of x_i values\nx_j &lt;- 5                    # Fixed reference point\nalpha &lt;- 0.5                # Disadvantageous inequality parameter\nbeta &lt;- 0.25                # Advantageous inequality parameter\n\n# Define utility function\n# Returns utility value given own payoff (x_i), reference payoff (x_j), and inequality parameters\nu_i &lt;- function(x_i, x_j, alpha, beta) {\n ifelse(x_i &gt;= x_j, \n        x_i - beta*(x_i - x_j),    # Case where x_i is higher\n        x_i - alpha*(x_j - x_i))    # Case where x_i is lower\n}\n\n# Create dataframe for plotting\ndf &lt;- data.frame(x_i=x_i, u_i=u_i(x_i, x_j, alpha, beta))\n\n# Generate plot\nggplot(df, aes(x=x_i, y=u_i)) +\n    geom_line() +\n    geom_vline(xintercept = 0, linewidth=0.25)+ \n    geom_hline(yintercept = 0, linewidth=0.25)+\n    geom_vline(xintercept=x_j, linetype=\"dashed\") +  # Reference point line\n    \n    # Add x_j label to vertical line\n    annotate(\"text\", x=x_j, y=max(df$u_i), label=expression(x[j]), vjust=-0, size=6) +\n    # Add slope labels at appropriate positions\n    annotate(\"text\", x=2, y=2, label=expression(paste(\"slope = \", 1 + alpha)), size=4) +\n    annotate(\"text\", x=8, y=6.3, label=expression(paste(\"slope = \", 1 - beta)), size=4) +\n\n    labs(\n      x=expression(x[i]),\n      y = expression(u[i](x[i]*\",\"*x[j]))\n      ) +\n\n theme_minimal() +\n theme(\n    axis.title.y=element_text(angle=0, hjust=0.5, size=14),\n    axis.title.x = element_text(hjust=0.95, vjust=29, size=14),\n    axis.text.x = element_blank(),    # Remove x-axis numbers\n    axis.text.y = element_blank()\n       )    # Remove y-axis numbers\n\n\n\n\n\nFigure 49.5: An inequality aversion utility function\n\n\n\n\n\n\n\n\n\n\n49.3.2 Example: the ultimatum game\nThis theoretical model of inequality aversion helps explain real-world behaviors that cannot explained by pure self-interest. This includes behaviour in the ultimatum game, a classic example where people often act against their material self-interest.\nA purely self-interested responder should accept any non-zero offer, as something is better than nothing. Yet people often reject unfair offers, such as job candidates rejecting a low salary even though this leaves both parties worse off. The pain of inequality outweighs the cash.\nSuppose the responder in the ultimatum game has inequality averse preferences with \\beta=0.25 and \\alpha=0.5. \nu_i(x_i,x_j)=x_i-0.5\\text{max}\\{x_j-x_i,0\\}-0.25\\text{max}\\{x_i-x_j,0\\}\n\nWhat offers x would the responder reject where the proposer has $10 to split between them?\nIf the responder rejects, the payoff to the proposer and responder is zero. That is:\n\nx_P=x_R=0\n\nIf the responder accepts, the responder receives x, and the proposer keeps the remainder. That is:\n\\begin{align*}\nx_P&=10−x \\\\[6pt]\nx_R&=x\n\\end{align*}\nThe responder will accept if the utility of accepting is greater than the utility of rejecting.\n\nU_R(\\text{accept})&gt;U_R(\\text{reject})\n\nI will examine offers above and then below $5. First, I will look at offers above.\nWe substitute the utility function into the inequality. As the \\alpha term equals zero, I do not include it here. We then enter the ultimatum game outcomes for acceptance and simplify.\n\\begin{align*}\nU_R(\\text{accept})&&gt;U_R(\\text{reject}) \\\\[6pt]\nx_R−\\beta(x_R−x_P)&&gt;0 \\\\[6pt]\nx-0.25(x-(10-x))&&gt;0 \\\\[6pt]\nx−0.25(2x−10)&&gt;0\n\\end{align*}\nThis inequality will hold for any \\beta&lt;1 as x \\geq 2x-10 for any x \\leq 10. Therefore, the condition will hold for the agent with \\beta=0.25. Recall that if \\beta&lt;1 the responder has higher utility from a higher payoff but at a decreasing rate when they have more than the proposer.\nWhen the offer is below $5, the responder gets less than the proposer, so only \\alpha matters. Again, I substitute the utility function into the inequality, enter the ultimatum game outcomes and simplify.\n\\begin{align*}\nU_R(\\text{accept})&&gt;U_R(\\text{reject}) \\\\[6pt]\nx_R−\\alpha(x_P−x_R)&&gt;0 \\\\[6pt]\nx−0.5(10−x-x)&&gt;0 \\\\[6pt]\nx&&gt;2.50\n\\end{align*}\nThe responder with \\alpha=1/2 will reject offers below $2.50.\nWe can plot the utility of the responder as a function of the offer x. As the offer is not independent of the proposer’s payoff, I will derive the shape of the utility curve as a function of x_R=x. I do this by substituting the payoffs and values of alpha into the utility function.\n\\begin{align*}\nU_R(x_P,x_R)&=x_R-\\alpha\\text{max}\\{x_P-x_R,0\\}-\\beta\\text{max}\\{x_R-x_P,0\\} \\\\[6pt]\n&=x-0.5\\text{max}\\{10-2x,0\\}-0.25\\text{max}\\{2x-10,0\\}\n\\end{align*}\nWe can also write this equation to explicitly show the slope of the curve. I first manipulate the equation into a form showing the slope times (x) plus intercept. I then simplify.\n\\begin{align*}\nU_R(x)&=\\left\\{\\begin{matrix}\n(1+2\\alpha)x−10\\alpha \\quad &\\textrm{if} \\quad x &lt; 5 \\\\[6pt]\n(1−2\\beta)x+10\\beta \\quad &\\textrm{if} \\quad x \\geq 5\n\\end{matrix}\\right. \\\\[12pt]\n&=\\left\\{\\begin{matrix}\n2x−5 \\qquad &\\textrm{if} \\quad x &lt; 5 \\\\[6pt]\n0.5x+2.5 \\qquad &\\textrm{if} \\quad x \\geq 5\n\\end{matrix}\\right.\n\\end{align*}\nThis diagram shows the responder’s utility curve as a function of the offer x. The slope of the curve for x&lt;5 is 1+2\\alpha=2 and for x\\geq5 is 1-2\\beta=0.5. These slopes differ from our earlier inequality aversion utility plot because, here, any gain for the responder means an equal loss for the proposer.\nThis relationship creates a double effect on inequality. Consider an offer increase from $4 to $5: the responder’s payoff rises by $1, but the gap between players shrinks by $2. This explains why the slope is steeper when behind.\nThe opposite happens when the responder is ahead. If the offer increases from $6 to $7, the responder gains $1 but inequality grows by $2. This larger penalty for inequality acts as a drag on utility, making the slope flatter.\n\n\nCode\nlibrary(ggplot2)\n\n# Define parameter values\nx_R &lt;- seq(0, 10, by=0.1)  # Range of x_R values\nx_5 &lt;- 5                    # Point where x_R = x_P\nalpha &lt;- 0.5                # Disadvantageous inequality parameter\nbeta &lt;- 0.25                # Advantageous inequality parameter\n\n# Define utility function\n# Returns utility value given own payoff (x_R), proposer payoff (x_P), and inequality parameters\nu_i &lt;- function(x_R, x_P, alpha, beta) {\n ifelse(x_R &gt;= x_P, \n        (1 - 2*beta)*x_R + 10*beta,    # Case where x_R is higher\n        (1 + 2*alpha)*x_R - 10*alpha\n        )    # Case where x_R is lower\n}\n\n# Create dataframe for plotting\ndf &lt;- data.frame(x_i=x_i, u_i=u_i(x_i, x_j, alpha, beta))\n\n# Generate plot\nggplot(df, aes(x=x_i, y=u_i)) +\n    geom_line() +\n    geom_vline(xintercept = 0, linewidth=0.25)+ \n    geom_hline(yintercept = 0, linewidth=0.25)+\n    geom_vline(xintercept=x_j, linetype=\"dashed\") +  # Reference point line\n    scale_x_continuous(breaks = seq(0, 10, by = 1)) +\n    \n    # Add slope labels at appropriate positions\n    annotate(\"text\", x=2, y=1.4, label=expression(paste(\"slope = \", 1 + 2*alpha)), size=4) +\n    annotate(\"text\", x=8, y=5.8, label=expression(paste(\"slope = \", 1 - 2*beta)), size=4) +\n\n    # Add arrow and text for high beta note\n    annotate(\"text\", x=8, y=8, label=\"For high enough β, the slope\\nof this part could be negative\", size=3.5) +\n    geom_segment(aes(x=8, y=7.5, xend=8, yend=6.5), arrow=arrow(length=unit(0.2, \"cm\"))) +\n\n    annotate(\"text\", x=4, y=-3, label=expression(paste(\"The responder would reject any offer below \", bar(x))), size=3.5) +\n    geom_segment(aes(x=3.5, y=-2.5, xend=2.8, yend=-0.5), arrow=arrow(length=unit(0.2, \"cm\"))) +\n\n    annotate(\"text\", x=2.5, y=0, label=expression(bar(x)), size=6, vjust=1.8) +\n\n    labs(\n      x=expression(x[R]*\"=\"*x),\n      y = expression(u[R](x))\n      ) +\n\n theme_minimal() +\n theme(\n    axis.title.y=element_text(angle=0, margin=margin(r=-20), vjust=1, size=14),\n    axis.title.x = element_text(hjust=0.98, vjust=47, size=14)\n       )\n\n\n\n\n\nFigure 49.6: Utility curve for the responder in the ultimatum game with inequality aversion\n\n\n\n\n\n\n\n\nThe curve has a kink at x=5 where the responder moves from having less to more than the proposer. The point where the curve crosses the x-axis represents the point below which the responder would reject the offer.\n\n\n49.3.3 Example: the dictator game\nWhile the ultimatum game shows how inequality aversion affects responses to unfair offers, the dictator game helps us understand how inequality aversion might influence giving behaviour.\nIn the dictator game, the dictator makes a unilateral offer to the receiver. The game then ends. The receiver has an empty strategy set.\n\nIn this version of the game, the dictator has a constrained choice set and must decide between the allocations (0, 1) and (1, 5). That is, the dictator must choose between 0 for themselves and 1 for the receiver, or 1 for themselves and 5 for the receiver. The dictator’s \\alpha=1/2. As the dictator has less than the other player under each distribution, \\alpha is the relevant parameter.\n\nWe can calculate the dictator’s utility of each allocation. The (0,1) allocation gives a utility of zero for the dictator’s payoff minus alpha times the inequality.\n\\begin{align*}\nU_D(0,1)&=0-\\alpha\\times (1-0) \\\\[6pt]\n&=-1/2 \\times 1 \\\\[6pt]\n&=−1/2\n\\end{align*}\nThe (1,5) allocation gives a utility of one for the dictator’s payoff minus alpha times the larger inequality.\n\\begin{align*}\nU_D(1,5)&=1-\\alpha\\times (5-1) \\\\[6pt]\n&=1-1/2 \\times 4 \\\\[6pt]\n&=−1\n\\end{align*}\nThe dictator prefers to allocate (0,1) as the cost of the inequality is greater than the benefit from the increased payoff.\n\\alpha&gt;0 can also account for the rejection of low offers in the ultimatum game.",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>People care about resource distribution</span>"
    ]
  },
  {
    "objectID": "social-preferences/distribution.html#other-distributional-preferences",
    "href": "social-preferences/distribution.html#other-distributional-preferences",
    "title": "49  People care about resource distribution",
    "section": "49.4 Other distributional preferences",
    "text": "49.4 Other distributional preferences\nWhile altruism and inequality aversion explain many observed behaviours, they are not the only types of social preference. Rearranging the inequality aversion model reveals the direct weights people place on others’ outcomes. Where x_i&gt;x_j, agent i places weight of \\beta on the other’s outcome and 1-\\beta on their own. Where x_i&lt;x_j, agent i places weight of -\\alpha on the other’s outcome and 1+\\alpha on their own.\n\nu_i(x_i,x_j)=\\left\\{\\begin{matrix}\n\\beta x_j+(1-\\beta)x_i \\quad &\\textrm{if} \\quad x_i \\geq x_j \\\\[6pt]\n-\\alpha x_j+(1+\\alpha)x_i \\quad &\\textrm{if} \\quad x_i &lt; x_j\n\\end{matrix}\\right.\n\nArranging in this way makes the weight given to the outcomes for each agent more transparent. It provides a more intuitive way to consider some distributional preferences.\nCharness and Rabin (2002) used this form with parameters \\sigma and \\rho (where \\sigma=-\\alpha and \\rho=\\beta). We’ll follow their approach since having parameters with the same sign makes the analysis more intuitive.\n\nu_i(x_i,x_j)=\\left\\{\\begin{matrix}\n\\rho x_j+(1-\\rho)x_i \\quad &\\textrm{if} \\quad x_i \\geq x_j \\\\[6pt]\n\\sigma x_j+(1-\\sigma)x_i \\quad &\\textrm{if} \\quad x_i &lt; x_j\n\\end{matrix}\\right.\n\n\n49.4.1 Forms of distributional preferences\nWe can adjust the values of \\rho and \\sigma to capture many forms of distributional preferences. Some are as follows.\nAn altruistic agent has \\sigma&gt;0 and \\rho&gt;0. They weight others’ payoffs positively in all situations. When someone else gains a dollar, it directly increases the agent’s utility, regardless of whether they are ahead or behind. Compared to our earlier altruism model, this model allows for different degrees of altruism depending on the relative payoffs of the two agents.\nAn inequality-averse agent has 1\\geq\\rho &gt; 0&gt;\\sigma. They like gains for others who are behind but dislike falling further behind themselves. This inequality is equivalent to \\alpha&gt;0 and \\beta&gt;0 in the Fehr-Schmidt model.\nA status-seeking agent has 0&gt;\\rho\\geq\\sigma. Not only do they dislike others gaining, they actively prefer having more than others. Their utility goes up when either they get more or the other player gets less.\nA classically self-interested agent has \\rho=\\sigma=0. Their utility depends only on their own payoff.\nA Rawlsian agent has \\rho=1 and \\sigma=0, making their utility u_i(x_i,x_j)=\\text{min}\\{x_i,x_j\\}. They maximise the minimum payoff across all players, showing pure concern for the worst-off individual.\nA utilitarian agent has \\rho=\\sigma=1/2, making their utility u_i(x_i,x_j)=x_i+x_j. They weight everyone’s payoff equally and simply sum the total, caring about efficiency rather than distribution.\n\n\n49.4.2 Example: the trust game\nLet’s use this form of the utility function to analyse the outcomes in a trust game, where an investor must decide whether to trust an entrepreneur with their money.\nThe trust game provides a lens for understanding how social preferences affect economic transactions where success requires sequential cooperation and trust. The trust game captures two key real-world dynamics. First, one party must choose whether to make themselves vulnerable to exploitation by trusting the other. Second, the trusted party must then decide whether to honour or betray that trust.\n\nThis structure mirrors some common economic situations. Investors must decide whether to trust entrepreneurs with capital before knowing if they will act in good faith. Business partners often need to commit resources before knowing if their counterparts will uphold their end of the deal. Even simple transactions, like paying in advance for services, involve one party trusting another to deliver as promised.\nIn the exercises in Section 44.3, I considered a scenario between Linda, a potential investor, and Marco, an entrepreneur. This mirrors common situations where investors must decide whether to trust entrepreneurs with capital, and entrepreneurs must choose between short-term gain and maintaining their reputation. Their choices will depend not just on monetary payoffs, but on how each values the other’s outcomes.\n\nLinda is looking for investment opportunities. She identifies a promising crypto-based start-up created by Marco. Marco is looking for seed funding.\nLinda can invest $10.\nIf Linda invests, her investment will triple in value. Marco can then decide to either shut down the start-up and keep the $30 or maintain the start-up in the market and pay a $15 dividend to each of Linda and himself.\nIf Linda does not invest, Linda keeps the $10. The start-up gets $0.\n\n\nMarco is effectively playing a dictator game. If he were purely self-interested, he would shut down and keep the $30. As a result, a purely self-interested Linda would not invest.\n\nLet’s examine both players’ actions if their utility functions place weight on the outcome of the other. U_L and U_M are Linda and Marco’s utility. x_L and x_M are the outcomes for Linda and Marco.\nLinda’s utility function shows moderate concern for Marco’s outcomes: \nU_L(x_M,x_L)=\\left\\{\\begin{matrix}\n\\frac{2}{3}x_M+\\frac{1}{3}x_L \\quad &\\textrm{if} \\quad x_L \\geq x_M\\\\[6pt]\n\\frac{1}{3}x_M+\\frac{2}{3}x_L \\quad &\\textrm{if} \\quad x_L &lt; x_M\n\\end{matrix}\\right.\n\nWhen Linda is ahead, she places more weight on Marco’s payoff (\\rho=2/3) than her own (1-\\rho=1/3), suggesting significant altruism. When behind, she still values Marco’s payoff positively (\\sigma=1/3), but prioritises her own outcome (1-\\sigma=2/3).\nMarco’s preferences are more asymmetric:\n\nU_M(x_L,x_M)=\\left\\{\\begin{matrix}\n\\frac{3}{4}x_L+\\frac{1}{4}x_M \\quad &\\textrm{if} \\quad x_M \\geq x_L\\\\[6pt]\nx_M \\quad &\\textrm{if} \\quad x_M &lt; x_L\n\\end{matrix}\\right.\n\nHe shows concern for Linda’s outcomes only when he’s ahead, otherwise focusing solely on his own payoff. This asymmetry reflects a mix of self-interest and conditional altruism.\nIf Marco and Linda know each other’s utility functions, what is the equilibrium with these distributional preferences?\nIf Linda chooses trust, Marco has a choice between $15 each and $30 for himself. Marco calculates the utility of each option.\n\\begin{align*}\nU_M(15,15)&=\\frac{3}{4}(15)+\\frac{1}{4}(15)\\\\[12pt]\n&=15 \\\\[12pt]\nU_M(0,30)&=\\frac{3}{4}(0)+\\frac{1}{4}(30) \\\\[12pt]\n&=7.5\n\\end{align*}\nMarco receives higher utility by paying the dividend to Linda.\nWe can also calculate Linda’s utility for each of Marco’s options if she chooses to trust.\n\\begin{align*}\nU_L(15,15)&=\\frac{2}{3}(15)+\\frac{1}{3}(15) \\\\[12pt]\n&=15 \\\\[12pt]\nU_L(0,30)&=\\frac{1}{3}(30)+\\frac{2}{3}(30) \\\\[12pt]\n&=10\n\\end{align*}\nLinda’s utility is higher if Marco pays a dividend.\nFor the other node, if Linda does not invest, she will keep $10. Marco will have nothing. Each has the following utility from that failure to invest.\n\\begin{align*}\nU_M(10,0)&=0 \\\\\n\\\\\nU_L(0,10)&=\\frac{2}{3}(0)+\\frac{1}{3}(10) \\\\[12pt]\n&=3.33\n\\end{align*}\nPutting those payoffs into the extensive form of the game, we get the following, with payoffs of (15,15) if Linda invests and Marco returns the dividend, (10,7.5) if Linda invests and Marco does not return the dividend, and (3.33,0) if Linda does not invest.\n\nTo solve for the game’s equilibrium, we use backward induction, starting with Marco’s decision if Linda invests.\nMarco can return a dividend for utility 15 or shut down for utility 7.5. He chooses to return the dividend. As a result, Linda will invest for utility 15, rather than not invest for utility 3.33. Linda invests.\n\n\n\n\n\nCard, D., Mas, A., Moretti, E., and Saez, E. (2012). Inequality at Work: The Effect of Peer Salaries on Job Satisfaction. American Economic Review, 102(6), 2981–3003. https://doi.org/10.1257/aer.102.6.2981\n\n\nCharness, G., and Rabin, M. (2002). Understanding social preferences with simple tests. The Quarterly Journal of Economics, 117(3), 817–869. https://www.jstor.org/stable/4132490\n\n\nFehr, E., and Schmidt, K. M. (1999). A theory of fairness, competition, and cooperation. The Quarterly Journal of Economics, 114(3), 817–868. https://www.jstor.org/stable/2586885",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>People care about resource distribution</span>"
    ]
  },
  {
    "objectID": "social-preferences/reputation.html",
    "href": "social-preferences/reputation.html",
    "title": "50  Reputation",
    "section": "",
    "text": "Summary",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Reputation</span>"
    ]
  },
  {
    "objectID": "social-preferences/reputation.html#summary",
    "href": "social-preferences/reputation.html#summary",
    "title": "50  Reputation",
    "section": "",
    "text": "People care about their social image and reputation, often fearing the stigma associated with selfish behaviour. This concern can influence decision-making beyond purely strategic considerations.\nAndreoni and Bernheim’s (2009) experiment demonstrates this effect: dictators in a modified dictator game changed their offers based on whether the receiver would infer that the offer came from them.",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Reputation</span>"
    ]
  },
  {
    "objectID": "social-preferences/reputation.html#introduction",
    "href": "social-preferences/reputation.html#introduction",
    "title": "50  Reputation",
    "section": "50.1 Introduction",
    "text": "50.1 Introduction\nPeople care about what other people think. They fear the social stigma that can result from “selfish” behaviour.\nPartly, this is for strategic reasons. For example, to attract reciprocal behaviour, people may need to be aware of your intentions.\nHowever, there is also evidence that people care about what other people think.",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Reputation</span>"
    ]
  },
  {
    "objectID": "social-preferences/reputation.html#example",
    "href": "social-preferences/reputation.html#example",
    "title": "50  Reputation",
    "section": "50.2 Example",
    "text": "50.2 Example\nOne example of this comes from Andreoni and Bernheim (2009), who ran a non-anonymous dictator game.\nEach dictator was endowed with $20.\nA computer then chose a distribution between the dictator and the receiver, selecting either ($0, $20) or ($20, $0) with equal probability. The dictator observes the computer’s allocation, but the receiver does not.\nThe computer’s allocation is then implemented with a probability p. Otherwise, the dictator’s allocation is made. This probability is known to both the dictator and the receiver.\nIf the dictator’s choice is to be implemented, the dictator makes a split of the $20, offering x to the receiver. The receiver learns only the allocation. They do not learn the dictator’s choice.\n\nDistributional preferences predict that p should not affect the dictator’s choice. The dictator should only think about the situation in which their choice matters.\nHowever, the experimental results did not conform with this prediction. Dictators condition their decision on the common knowledge of p.\nThis chart shows how offers change with (p) when the computer’s offer of 0 if selected. The x-axis shows p equal to 0, 0.25, 0.5 and 0.75. Each line represents a different bucket of offers. The red line is the proportion of dictators offering 0. The blue line represents the proportion of participants offering $10, a 50:50 split.\n\nFor p of 0.5 or 0.75 and a computer allocation of 0 to the receiver, most dictators will offer 0. If the receiver receives a low allocation, the receiver will likely infer it is due to the computer’s decision. They will not blame the dictator.\nFor p of 0 and a computer allocation of 0 to the receiver, more than half of dictators will offer $10 to the receiver. In this case, if the receiver receives a low allocation, the receiver will infer it is due to the dictator’s decision, not the computer’s.\nFor a p of 0.25, a slim majority of participants offer zero, with some plausible deniability due to the 25% probability of the offer coming from the computer.\nThese results suggest the dictator cares about their reputation in the eyes of the receiver.\n\n\n\n\nAndreoni, J., and Bernheim, B. D. (2009). Social Image and the 5050 Norm: A Theoretical and Experimental Analysis of Audience Effects. Econometrica, 77(5), 1607–1636. https://doi.org/10.3982/ECTA7384",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Reputation</span>"
    ]
  },
  {
    "objectID": "social-preferences/reciprocity.html",
    "href": "social-preferences/reciprocity.html",
    "title": "51  Reciprocity",
    "section": "",
    "text": "51.1 Intentions\nReciprocity involves like-for-like behaviour. Kindness is responded to with kindness. Unkindness is responded to with unkindness.\nReciprocity might be considered to have two forms.\nThe first is instrumental reciprocity. Agents reciprocate behaviour due to the long-term benefits of sustained cooperation. The behaviour is motivated by the positive trade-off between long-term and short-term gains.\nThe second is intrinsic reciprocity. Agents reciprocate behaviour despite the absence of long-term gains.\nWe can see evidence for reciprocity in how people respond to the intentions of others in the ultimatum game.\nThe ultimatum game involves two players: the proposer and the responder.\nThe proposer is given a fixed amount of money m. They then offer a portion x of the sum m to the responder.\nThe responder can either accept or reject the offer. They make this decision knowing the fixed amount m held by the proposer and the offer x.\nIf the responder accepts, the responder receives the offer x and the proposer gets the remainder m-x. If the responder rejects, both players receive nothing.\nConsider this variation of the ultimatum game. In each of two scenarios, the proposer has a constrained choice of offers.\nIn scenario 1, the proposer has a choice between offering a split of $8 for the proposer and $2 for the responder or $5 for the proposer and $5 for the responder. Responders tend to reject offers of $2.\nIn scenario 2, the proposer has a choice between offering a split of $8 for the proposer and $2 for the responder or keeping the full $10 for themselves. Responders tend to accept offers of $2.\nIn the first scenario, responders reject offers of $2. In the second, they accept them. How can ($8, $2) be better than ($0, $0) in one scenario but not in the other?\nDistributional concerns cannot explain rejection in this case. An offer of ($8, $2) leads to the same distribution in both scenarios.\nInstead, responders do not base their decision on the outcome alone. They use their knowledge of the proposer’s options, consider the proposer’s intentions and reciprocate them.\nA proposer who offers $2 instead of $0 is seen as having good intentions. A proposer who offers $2 instead of $5 is seen as having bad intentions.",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Reciprocity</span>"
    ]
  },
  {
    "objectID": "social-preferences/reciprocity.html#the-trust-game",
    "href": "social-preferences/reciprocity.html#the-trust-game",
    "title": "51  Reciprocity",
    "section": "51.2 The trust game",
    "text": "51.2 The trust game\nThe trust game, which I introduced in Section 41.4.3, provides another potential example of reciprocity.\nThe trust game involves two players: a sender and a receiver\nBoth the sender and receiver are given an initial sum m.\nThe sender sends a share x of their m to the receiver. This amount x is often called the investment.\nBefore the receiver receives the investment, it is multiplied by some factor k. Therefore, the receiver receives kx.\nThe receiver then returns to the sender some share y of their total allocation m+kx.\nThe final outcome is the sender has m-x+y and the receiver has m+kx-y.\n\nThe game theoretic equilibrium is for the receiver to return nothing, so the sender sends nothing.\nContrast this with what happens in experimental settings.\nSenders tend to send a positive amount, typically around half of their endowment.\nReceivers tend to send back a bit less than is sent.\nThese two figures from Johnson and Mislin (2011) illustrate the distribution of investments and returns in 162 replications of the trust game.\n\n\n\nFigure 51.1: Distribution of proportion sent and proportion returned (Johnson and Mislin, 2011).\n\n\n\n\n\n\n\n(a) Sent\n\n\n\n\n\n\n\n\n\n\n\n(b) Returned\n\n\n\n\n\n\n\n\n\n\n\nOne possible explanation for this behaviour is that the receiver feels they should reciprocate the sender’s investment. They are responding to the sender’s intentions. The sender trusts that some of their investment will be repaid due to reciprocation.\nThe receiver’s behaviour is also consistent with altruism and inequality aversion.",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Reciprocity</span>"
    ]
  },
  {
    "objectID": "social-preferences/reciprocity.html#the-public-goods-game",
    "href": "social-preferences/reciprocity.html#the-public-goods-game",
    "title": "51  Reciprocity",
    "section": "51.3 The public goods game",
    "text": "51.3 The public goods game\nAs a final example of reciprocity, consider the public goods game.\nEach of N participants is given an initial endowment.\nEach participant secretly and simultaneously chooses how much of their endowment they wish to contribute to a public pot.\nThe money in the public pot is multiplied by some amount and split evenly between the players. Typically, the multiple applied to the pot is greater than one but less than the number of players.\n\nIn Nash equilibrium in the public goods game, nobody transfers anything to the pot. Any contributions are split between all players, so if there are more players than the multiple, which is normally the case by design, contributions result in a loss to that individual player.\nThis is not what we see when people play the public goods game in the lab.\nIn a meta-analysis, Zelmer (2003) found an average contribution of 38% of the endowment. The amount contributed increased with the marginal per capita return; that is the higher k/N.\nOne possible explanation is that players trust that the other players will contribute, so they desire to reciprocate the expected contributions from others.\nAnother explanation hinges on social norms. Where a norm of behaviour exists, people tend to follow it.\n\n\n\n\nJohnson, N. D., and Mislin, A. A. (2011). Trust games: A meta-analysis. Journal of Economic Psychology, 32(5), 865–889. https://doi.org/10.1016/j.joep.2011.05.007\n\n\nZelmer, J. (2003). Linear Public Goods Experiments: A Meta-Analysis. Experimental Economics, 6(3), 299–310. https://doi.org/10.1023/A:1026277420119",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>Reciprocity</span>"
    ]
  },
  {
    "objectID": "social-preferences/social-preferences-exercises.html",
    "href": "social-preferences/social-preferences-exercises.html",
    "title": "52  Social preferences exercises",
    "section": "",
    "text": "52.1 Fehr-Schmidt preferences\nAlby has the following distributional preferences:\nu_A(x_A,x_j)=\\underbrace{x_A}_{(1)}\\underbrace{-\\alpha\\text{max}\\{x_j-x_A,0\\}}_{(2)}\\underbrace{-\\beta\\text{max}\\{x_A-x_j,0\\}}_{(3)}\nwhere:\nx_A is the outcome for Alby\nx_j is the outcome for any agent j with whom Alby interacts.\na) For \\alpha&gt;0 and \\beta&gt;0, what are preferences of this form are normally called?\nb) For \\alpha&gt;0 and \\beta&gt;0, describe the role of each of the three terms labelled (1), (2) and (3) in the utility function.\nc) Explain the intuition for why we normally set \\alpha&gt;\\beta.",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Social preferences exercises</span>"
    ]
  },
  {
    "objectID": "social-preferences/social-preferences-exercises.html#fehr-schmidt-preferences",
    "href": "social-preferences/social-preferences-exercises.html#fehr-schmidt-preferences",
    "title": "52  Social preferences exercises",
    "section": "",
    "text": "Answer\n\n\n\n\n\nInequality aversion.\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe first term captures the utility of Alby’s own outcome.\nThe second term captures Alby’s dislike of having less than others.\nThe third term captures Alby’s dislike of having more than others.\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMost people dislike having less than others more than they dislike having more than others. In some instances, \\beta&lt;0 in which case people like having more than others - they are fine with inequality as long as it is to their advantage.",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Social preferences exercises</span>"
    ]
  },
  {
    "objectID": "social-preferences/social-preferences-exercises.html#charness-rabin-preferences",
    "href": "social-preferences/social-preferences-exercises.html#charness-rabin-preferences",
    "title": "52  Social preferences exercises",
    "section": "52.2 Charness-Rabin preferences",
    "text": "52.2 Charness-Rabin preferences\nBob has the following distributional preferences:\n\nu_B(x_B,x_j)=\\left\\{\\begin{matrix}\n\\rho x_j+(1-\\rho)x_B\\quad &\\textrm{if} \\quad x_B \\geq x_j \\\\[6pt]\n\\sigma x_j+(1-\\sigma)x_B \\quad &\\textrm{if} \\quad x_B &lt; x_j\n\\end{matrix}\\right.\n\nwhere:\nx_B is the outcome of the game for Bob\nx_j is the outcome of the game for any agent j with whom Bob interacts.\na) For 1\\geq \\rho \\geq\\ 0 \\geq \\sigma, what are preferences of this form are normally called?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nInequality aversion.\n\n\n\nb) For 1\\geq \\rho \\geq\\ 0 \\geq \\sigma, describe the role of the terms in each of the two equations where x_B\\geq x_j and x_B&lt; x_j.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\\sigma and \\rho are the weight that is Bob gives to the outcome for agent j. \\sigma is applied where Bob’s outcome is better than or equal to that of agent j, and \\rho where it is worse.\nThe residual 1-\\sigma and 1-\\rho is the weight that Bob gives to his own outcome.\n\n\n\nc) Explain the intuition why we normally set \\rho&gt;\\sigma for the utility function.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nPeople tend to be more willing to see others have better outcomes when those others are worse off than them. Therefore, \\rho should be greater than \\sigma so that the agent cares more about the other agent when they are the one receiving more.\n\n\n\nd) What values of \\rho and \\sigma would result in a utility function where Bob is purely self-interested?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIf Bob were purely self interested, \\rho and \\sigma would have a value of zero. In that case, agent j’s outcomes would not enter into the utility function. The utility function would become u_B(x_B)=x_B.\n\n\n\ne) What value must \\sigma have to explain Bob’s rejection of low offers in the ultimatum game?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSigma must be negative such that, if agent i accepts, the decrease in utility from agent j’s payoff would be larger than the utility gain agent i would receive from its own payoff.\n\n\n\nf) Consider the following two scenarios involving the Ultimatum game.\nScenario 1: A proposer has a choice between offering a split of ($8, $2) or ($5, $5). In experiments with this choice, responders tend to reject offers of ($8, $2).\nScenario 2: A proposer has a choice between offering a split of ($8, $2) or ($10, $0). In experiments with this choice, responders tend to accept offers of ($8, $2).\nA utility function of the type that Bob has cannot result in this behaviour. Explain why.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIn both cases, the outcome is ($8, $2). This would result in the same level of utility regardless of the other option that the proposer had. If compared with the outcome ($0, $0) from rejecting the offer, the action should therefore be the same.\nAn explanation for the difference between scenarios is that people care not just about outcomes, but also the intentions of those with whom they interact. In that circumstance, the good (or otherwise) intentions of the proposer in offering either less than they could or as much as they could would shape the responder’s action. However, intentions do not enter into Bob’s utility function.",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Social preferences exercises</span>"
    ]
  },
  {
    "objectID": "social-preferences/social-preferences-exercises.html#a-government-grant",
    "href": "social-preferences/social-preferences-exercises.html#a-government-grant",
    "title": "52  Social preferences exercises",
    "section": "52.3 A government grant",
    "text": "52.3 A government grant\nJason, an academic, is seeking an industry research grant from the government and Bezzle Bank. Under the grant terms, a $50,000 contribution by Bezzle Bank will be matched by government. The total research funds of $100,000 are then under Jason’s control.\nJason could use these for research proposal A that benefits both himself and the bank, giving the bank $100,000 in business benefit and Jason $100,000 in career benefit. Alternatively, Jason could use the funds to research a new idea B, giving him $150,000 in career benefit, but little of use for the bank.\nBezzle Bank knows Jason’s options and is considering whether to make a contribution.\na) Show that the Nash equilibrium outcome is for the bank to make no contribution.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nI have represented this problem in the following extensive form game. The possible payoffs for Bezzel Bank are $50,000 for proposal A ($100,000 minus it’s $50,000 contribution) and -$50,000 for proposal B (loss of its contribution). If Bezzle Bank does not contribute, both Jason and the Bank have a payoff of zero.\nWe work through the problem by backward induction.\nFirst, Jason has a choice between Proposal A for a payoff of $100,000 and Proposal B for a payoff of $150,000. He chooses proposal B.\nBezzle Bank therefore has a choice between contributing $50,000 for a payoff of -$50,000 or not contributing to remain at the status quo. Bezzle Bank does not contribute.\n\n\n\n\nb) The bank decides to make the contribution and Jason decides to focus on research proposal A. Give possible reasons for this deviation from the Nash equilibrium.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nOne explanation involves reciprocation. Jason is responding to the Bank’s intentions and wants to reciprocate them. Relatedly, Bezzle Bank trusts Jason based on a belief that Jason will reciprocate their intentions.\nAnother explanation may relate to reputation. Jason might care about his reputation and be reluctant to take an action that harms it. This may be due to concerns about his self-image, or more instrumental reasons such as a poor reputation harming future opportunities.\nAltruism on the part of the bank may also be a factor. They may gain utility from the benefit to Jason (or the broader societal benefit from the research project).",
    "crumbs": [
      "Social preferences",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Social preferences exercises</span>"
    ]
  },
  {
    "objectID": "practice-problems/practice-problems.html",
    "href": "practice-problems/practice-problems.html",
    "title": "Practice problems",
    "section": "",
    "text": "This section comprises practice problems drawn from past assessments delivered in the subject.",
    "crumbs": [
      "Practice problems"
    ]
  },
  {
    "objectID": "practice-problems/expected-utility-theory-problems.html",
    "href": "practice-problems/expected-utility-theory-problems.html",
    "title": "53  Expected utility theory problems",
    "section": "",
    "text": "53.1 A 60:40 gamble\nPenny is an expected utility maximiser with utility function u(x)=\\ln(x) and wealth of $300.\nPenny is offered the following bet A:\na) Does Penny accept bet A?\nb) Following some bad economic news, Penny wealth declines to $150.\nPenny is offered bet A again. Does Penny accept the bet?",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Expected utility theory problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/expected-utility-theory-problems.html#a-6040-gamble",
    "href": "practice-problems/expected-utility-theory-problems.html#a-6040-gamble",
    "title": "53  Expected utility theory problems",
    "section": "",
    "text": "a 60% probability to win $150\na 40% probability to lose $100.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nPenny compares the utility of taking versus not taking the bet:\n\\begin{align*}\nU(\\text{A})&=p_1u(x_1)+p_2u(x_2) \\\\\n&=0.6\\ln(W+150)+0.4\\ln(W-100) \\\\\n&=0.6\\ln(450)+0.4\\ln(200) \\\\\n&=5.785 \\\\\n\\\\\nU(W)&=ln(W) \\\\\n&=\\ln(300) \\\\\n&=5.704\n\\end{align*}\nU(A)&gt;U(W), so Penny accepts the bet.\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nPenny compares the utility of taking versus not taking the bet:\n\\begin{align*}\nU(\\text{A})&=p_1u(x_1)+p_2u(x_2) \\\\\n&=0.6\\ln(W+150)+0.4\\ln(W-100) \\\\\n&=0.6\\ln(300)+0.4\\ln(50) \\\\\n&=4.987 \\\\\n\\\\\nU(W)&=\\ln(W) \\\\\n&=\\ln(150) \\\\\n&=5.011\n\\end{align*}\nU(A)&lt;U(W), so Penny rejects the bet.",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Expected utility theory problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/expected-utility-theory-problems.html#another-6040-gamble",
    "href": "practice-problems/expected-utility-theory-problems.html#another-6040-gamble",
    "title": "53  Expected utility theory problems",
    "section": "53.2 Another 60:40 gamble",
    "text": "53.2 Another 60:40 gamble\nGamble A is as follows:\n($100, 0.6; -$100, 0.4)\nThis is a gamble with a 60% chance of winning $100 and a 40% chance of losing $100.\na) Would a risk neutral decision-maker (who maximises expected value) be willing to pay $10 to play gamble A? What is the most they would be willing to pay to play?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nA risk neutral decision maker will accept any offer with positive expected value. The expected value of the bet is:\n\\begin{align*}\nE[A]&=p_1x_1+p_2x_2 \\\\\n&=0.6*100+0.4*(-100) \\\\\n&=\\$20\n\\end{align*}\nThe risk neutral decision maker would pay $10 as this is less than the expected value of the bet. They would be willing to pay up to the expected value of the bet: $20. At that point they would be indifferent between paying for the bet and refusing the bet.\n\n\n\nb) Would an expected utility maximiser with wealth $200 and utility function U(x)=ln(x) be willing to pay $10 to play gamble A? What is the most they would be willing to pay to play?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe expected utility maximiser will play if their utility from playing and paying is greater than their utility of refusing.\n\\begin{align*}\nU(W)&=ln(W) \\\\\n&=ln(\\$200) \\\\\n&=5.2983174 \\\\\n\\\\\nE[U(A-c)]&=p_1U(x_1)+p_2U(x_2) \\\\\n&=0.6U(W+100-10)+0.4U(W-100-10) \\\\\n&=0.6ln(200+100-10)+0.4ln(200-100-10) \\\\\n&=5.2018524\n\\end{align*}\nU(W)&gt;U(A-c) so the decision maker will not be willing to pay $10.\nTo determine the most they would be willing to pay, we will first check whether they will pay any positive sum. We will do that by examining the expected utility of the gamble with no payment.\n\\begin{align*}\nE[U(A)]&=p_1U(x_1)+p_2U(x_2) \\\\\n&=0.6U(W+100)+0.4U(W-100) \\\\\n&=0.6ln(200+100)+0.4ln(200-100) \\\\\n&=5.2643376\n\\end{align*}\nU(W)&gt;U() so the decision maker will not be willing to pay any amount. In fact, they would pay to avoid the bet.\nTo calculate how much, we determine what the certainty equivalent of the bet is:\n\\begin{align*}\nU(CE)&=E[U(A)] \\\\\nln(CE)&=5.2643376\\\\\nCE&=e^{5.2643376} \\\\\n&=\\$\n\\end{align*}\nHaving wealth of $200 and the bet is the equivalent of having wealth of $193.32. They would be willing to pay up to $6.68 to avoid the bet.\n\n\n\nc) Would the expected utility maximiser with utility function change their decision if they had $1000 in wealth? Explain.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe expected utility maximiser will play if their utility from playing and paying is greater than their utility of refusing.\n\\begin{align*}\nU(W)&=ln(W) \\\\\n&=ln(\\$1000) \\\\\n&=6.9077553 \\\\\n\\\\\nE[U(A-c)]&=p_1U(x_1)+p_2U(x_2) \\\\\n&=0.6U(W+100-10)+0.4U(W-100-10) \\\\\n&=0.6ln(1000+100-10)+0.4ln(1000-100-10) \\\\\n&=6.9128484\n\\end{align*}\nU(W)&lt;U(A-c) so the decision maker is now willing to pay $10.\nAs the agent’s wealth increases their utility function becomes increasingly linear (second derivative approaches zero) and they become closer to risk neutral. As a result, the positive expected value bet becomes increasingly attractive.\n\n\n\nd) At what wealth is the expected utility maximiser with utility function U(x)=ln(x) indifferent between accepting gamble A or not?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe expected utility maximiser will be indifferent when:\n\\begin{align*}\nU(W)&=E[U(A)] \\\\\nU(W)&=0.6U(W+100)+0.4U(W-100) \\\\\nln(W)&=0.6ln(W+100)+0.4ln(W-100)\n\\end{align*}\nThere isn’t a simple closed form solution to this equation, but we know from questions b) and c) that W is somewhere between $200 and $1000.\nIf we wanted to calculate exact solution, you could use tool such as Mathematica or Matlab to solve, write a short code to solve in R or even iterate toward a solution using Excel.\n\n\nCode\nequation &lt;- function(W){\n  log(W) - 0.6 * log(W + 100) - 0.4 * log(W - 100)\n}\n\nindifference &lt;- uniroot(equation, c(200, 1000))\n\n\nThe expected utility maximiser is indifferent when W=$256.81.",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Expected utility theory problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/expected-utility-theory-problems.html#shannon-and-simon",
    "href": "practice-problems/expected-utility-theory-problems.html#shannon-and-simon",
    "title": "53  Expected utility theory problems",
    "section": "53.3 Shannon and Simon",
    "text": "53.3 Shannon and Simon\nShannon and Simon are offered a choice between options A and B:\nA: Lottery X=(0.5, -\\$100; 0.5, -\\$20). This is a gamble with a 50% chance of losing $100 and a 50% chance of losing $20.\nB: A loss of $30 for certain.\n(a) Shannon is risk-neutral. Will Shannon choose A or B?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nA risk-neutral decision-maker maximises expected value.\nThe expected value of option A is:\n\\begin{align*}\n\\text{E}[A]&=p_1x_1+p_2x_2 \\\\[6pt]\n&=0.5\\times -\\$100+0.5\\times -\\$20 \\\\[6pt]\n&=-\\$60\n\\end{align*}\nThe expected value of option B is -$30.\nShannon will choose the certain loss because -$30 is a better outcome than -$60.\n\n\n\n(b) Simon is risk averse with wealth $200 and utility function U(x)=x^{0.5}. Will Simon choose A or B?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSimon will select the option that gives the highest expected utility.\nThe expected utility of option A is:\n\\begin{align*}\n\\text{E}[U(A)]&=p_1u(x_1)+p_2u(x_2) \\\\[6pt]\n&=0.5\\times (W-100)^{0.5}+0.5\\times (W-20)^{0.5} \\\\[6pt]\n&=0.5\\times (100)^{0.5}+0.5\\times (180)^{0.5} \\\\[6pt]\n&=11.71\n\\end{align*}\nThe expected utility of option B is:\n\\begin{align*}\n\\text{E}[U(B)]&=u(W+x) \\\\[6pt]\n&=(200-30)^{0.5} \\\\[6pt]\n&=13.04\n\\end{align*}\nSimon will choose option B because \\text{E}[U(A)]=11.71&lt;13.04=\\text{E}[U(B)].\n\n\n\n(c) Draw a graph showing the choices faced by Simon, his utility curve and the expected utility of each option. Indicate the certainty equivalent of option A. Explain how the graph shows which option Simon will choose.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThis chart shows the choices faced by Simon, his utility curve and the expected utility of each option. The horizontal axis is the outcome and the vertical axis is utility of each outcome. The utility curve is the function U(x)=x^{0.5}.\nThe two possible outcomes of gamble A are W-100=100 and W-20=180, which deliver U(W-100) and U(W-20) respectively. Each are labelled on the chart.\nThe expected utility of gamble A is the weighted average of these two utilities and lies on the straight line between U(W-100) and U(W-20). As each outcome has a 50% chance of occurring, the expected utility of gamble A is the midpoint of this line (as is the expected value of the gamble). The vertical line from W+E[A]=140 identifies that point, with the expected utility E[U(A)] marked on the vertical axis.\nThe certain outcome from option B, the loss of $30 resulting in wealth of $170 is also marked on the x-axis, leading to utility of U(W-B).\nIt can be seen that the expected utility of gamble A, E[U(A)], is less than the utility of the certain outcome U(W-B). Simon will therefore choose B.\nThe certainty equivalent of option A is identified as the point where U(CE)=E[U(A)]. This is identified by drawing a horizontal line from the expected utility of gamble A to the utility curve. The point where this line intersects the utility curve is the certainty equivalent of gamble A, shown by projecting a vertical line downward.\nThis diagram is not drawn to scale.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  x^0.5\n}\n\ndf &lt;- data.frame(\n  x=seq(0,220,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;-30 #loss\nx2&lt;-200 #win\nev&lt;-115 #expected value of gamble\nxc&lt;-140 #certain outcome\nce&lt;-95 #certainty equivalent\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"U(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-25, 220), ylim = c(0,15))+\n\n  #Add labels W-100, U(W-100) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"W-100\", size = 4, hjust = 0.5, vjust = 1.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"U(W-100)\", size = 4, hjust = 1.05, vjust = 0.6)+\n\n  #Add labels W-B, U(W-B) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"W-B\", size = 4, hjust = 0.6, vjust = 1.5)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"U(W-B)\", size = 4, hjust = 1.05, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels W-20, U(W-20) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"W-20\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"U(W-20)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels W+E[A], E[U(W+A)] and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"W+E[A]\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"E[U(A)]\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add vertical line indicating certainty equivalent and labelled \"CE\"\n  annotate(\"segment\", x = ce, xend = ce, y = 0, yend = u(ce), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = ce, y = 0, label = \"CE\", size = 4, hjust = 0.4, vjust = 1.5)\n\n\n\n\nSimon’s consideration of option A and B",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Expected utility theory problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/expected-utility-theory-problems.html#starting-a-business",
    "href": "practice-problems/expected-utility-theory-problems.html#starting-a-business",
    "title": "53  Expected utility theory problems",
    "section": "53.4 Starting a business",
    "text": "53.4 Starting a business\n(a) Stacey, an expected utility maximiser, was considering quitting her job to start a new business. She calculated that her business proposal had a positive expected value but that there is a material risk of a loss. She decided not to start the business.\nUse concepts from expected utility theory to explain why Stacey may have decided not to start the business.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nStacey may have decided not to pursue the business opportunity as she is risk averse. Someone who is risk averse will value the expected value of a gamble less than the equivalent amount paid with certainty. This means that a positive value bet might be turned down.\n\n\n\n(b) Use a graph to demonstrate your answer to part (a).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThis graph shows Stavey’s utility curve. As she is risk averse, the curve is concave (at least over the domain of the decisions we are considering).\nSuppose there are two possible outcomes from starting the business. a moderate loss and a large gain, each having equal probability. Each of the outcomes of the business are labelled. Stacey finishes with his wealth minus the business loss (W-L) or her wealth plus the business gains (W+G). If she does not start the business, her wealth remains at W. The utility of each possible outcome (U(W-L), U(W), U(W+G)) is also indicated on the vertical axis.\nThe expected value of starting the business is labelled (E[X]). As the business has positive expected value, E[X] is greater than W.\nThe expected utility of the business lies on the straight line between the utility of the two possible business outcomes. The place on the line is determined by the probability of winning and is in line with the expected value of the business. We can identify the expected utility of the business by projecting a line up from E[X] to the straight line.\nFinally, the certainty equivalent of the business is also marked. As U(CE)=E[U(X)], we can identify the certainty equivalent by projecting a line up from E[U(X)] to the utility curve.\nDue to the convex curve, we can see that E[U(X)] is less than U(W). Stacey prefers the certain outcome of W to starting the business. Alternatively, we can see that the certainty equivalent of the business is lower than current wealth.\n\n\nCode\n#| fig-cap: Stacey's consideration of whether to purchase a business ticket\n\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  x^0.5\n}\n\ndf &lt;- data.frame(\n  x=seq(1,220,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;-30 #loss\nx2&lt;-200 #win\nev&lt;-90 #expected value of gamble\nxc&lt;-80 #certain outcome\nce&lt;-70 #certainty equivalent\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"U(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-25, 220), ylim = c(0, 15))+\n\n  #Add labels W-L, U(W-L) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"W-L\", size = 4, hjust = 0.5, vjust = 1.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"U(W-L)\", size = 4, hjust = 1.05, vjust = 0.6)+\n\n  #Add labels W, U(W) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"W\", size = 4, hjust = 0.6, vjust = 1.5)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"U(W)\", size = 4, hjust = 1.05, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels W+G, U(W+G) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"W+G\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"U(W+G)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels E[X], E[U(X)] and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[X]\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"E[U(X)]\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add vertical line indicating certainty equivalent and labelled \"CE\"\n  annotate(\"segment\", x = ce, xend = ce, y = 0, yend = u(ce), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = ce, y = 0, label = \"CE\", size = 4, hjust = 0.4, vjust = 1.5)\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Later, Stacey received a large inheritance from her Aunt. She then decided to quit work and go ahead with her business plan.\nUse concepts from expected utility theory to explain why Stacey may have changed her mind.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThat Stacey later decided to pursue the business opportunity is likely because she is more risk neutral (or possibly even risk seeking) at higher wealth. The result is that the positive expected value gamble is more likely to be accepted at the higher wealth level.\nOne mechanism by which this could occur is the utility function becomes increasingly linear with higher wealth (as is the case with u(x)=\\ln(x) or u(x)=x^{0.5}).",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Expected utility theory problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/expected-utility-theory-problems.html#risk-neutrality-versus-risk-aversion",
    "href": "practice-problems/expected-utility-theory-problems.html#risk-neutrality-versus-risk-aversion",
    "title": "53  Expected utility theory problems",
    "section": "53.5 Risk neutrality versus risk aversion",
    "text": "53.5 Risk neutrality versus risk aversion\nAnika and Anthony are offered a choice between options A and B:\nA: Lottery A=(0.5, \\$100; 0.5, \\$20). This is a gamble with a 50% chance of winning $100 and a 50% chance of winning $20.\nB: $40 for certain.\n(a) Anika is risk-neutral. Will Anika choose A or B?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nA risk-neutral decision-maker maximises expected value.\nThe expected value of option A is:\n\\begin{align*}\n\\text{E}[A]&=p_1x_1+p_2x_2 \\\\[6pt]\n&=0.5\\times \\$100+0.5\\times \\$20 \\\\[6pt]\n&=\\$60\n\\end{align*}\nThe expected value of option B is $40.\nAnika will choose option A because $60 is greater than $40.\n\n\n\n(b) Anthony is risk averse with wealth $100 and utility function U(x)=\\text{ln}(x). Will Anthony choose A or B?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAnthony will select the option that gives the highest expected utility.\nThe expected utility of option A is:\n\\begin{align*}\n\\text{E}[U(A)]&=p_1u(x_1)+p_2u(x_2) \\\\[6pt]\n&=0.5\\times \\text{ln}(W+100)+0.5\\times \\text{ln}(W+20) \\\\[6pt]\n&=0.5\\times \\text{ln}(200)+0.5\\times \\text{ln}(120) \\\\[6pt]\n&=5.04\n\\end{align*}\nThe expected utility of option B is:\n\\begin{align*}\n\\text{E}[U(B)]&=u(W+x) \\\\[6pt]\n&=\\text{ln}(140) \\\\[6pt]\n&=4.94\n\\end{align*}\nAnthony will choose option A because \\text{E}[U(A)]=5.04&gt;4.94=\\text{E}[U(B)].\n\n\n\n(c) Draw a graph showing the choices faced by Anthony, his utility curve and the expected utility of each option. Indicate the certainty equivalent of option A. Explain how the graph shows which option Anthony will choose.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFigure 53.1 shows the choices faced by Anthony, his utility curve and the expected utility of each option. The horizontal axis is the outcome and the vertical axis is utility of each outcome. The utility curve is the function U(x)=\\text{ln}(x).\nThe two possible outcomes of gamble A are W+20=120 and W+100=200, which deliver U(W+20) and U(W+100) respectively. Each are labelled on the chart.\nThe expected utility of gamble A is the weighted average of these two utilities and lies on the straight line between U(W+20) and U(W+100). As each outcome has a 50% chance of occurring, the expected utility of gamble A is the midpoint of this line (as is the expected value of the gamble). The vertical line from W+E[A]=160 identifies that point, with the expected utility E[U(A)] marked on the vertical axis.\nThe certain outcome from option B, the receipt of $40 resulting in wealth of $140 is also marked on the x-axis, leading to utility of U(W+B).\nIt can be seen that the expected utility of gamble A E[U(A)] is greater than the utility of the certain outcome U(W+B). Anthony will therefore choose gamble A.\nThe certainty equivalent of option A is identified as the point where U(CE)=E[U(A)]. This is identified by drawing a horizontal line from the expected utility of gamble A to the utility curve. The point where this line intersects the utility curve is the certainty equivalent of gamble A, shown by projecting a vertical line downward.\nThis diagram is not drawn to scale.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  log(x)\n}\n\ndf &lt;- data.frame(\n  x=seq(1,220,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;-30 #loss\nx2&lt;-200 #win\nev&lt;-115 #expected value of gamble\nxc&lt;-60 #certain outcome\nce&lt;-79 #certainty equivalent\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"U(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n#set limits - need to include room for labels\n  coord_cartesian(xlim = c(-25, 220), ylim = c(-0.25, 6))+\n\n  #Add labels W+20, U(W+20) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"W+20\", size = 4, hjust = 0.5, vjust = 1.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"U(W+20)\", size = 4, hjust = 1.05, vjust = 0.6)+\n\n  #Add labels W+B, U(W+B) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"W+B=140\", size = 4, hjust = 0.6, vjust = 1.5)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"U(W+B)\", size = 4, hjust = 1.05, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels W+100, U(W+100) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"W+100\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"U(W+100)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels W+E[A], E[U(W+A)] and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"W+E[A]=160\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"E[U(A)]\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add vertical line indicating certainty equivalent and labelled \"CE\"\n  annotate(\"segment\", x = ce, xend = ce, y = 0, yend = u(ce), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = ce, y = 0, label = \"CE\", size = 4, hjust = 0.4, vjust = 1.5)\n\n\n\n\n\nFigure 53.1: Anthony’s consideration of option A and B",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Expected utility theory problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/expected-utility-theory-problems.html#lottery-ticket",
    "href": "practice-problems/expected-utility-theory-problems.html#lottery-ticket",
    "title": "53  Expected utility theory problems",
    "section": "53.6 Lottery ticket",
    "text": "53.6 Lottery ticket\nBuying a lottery ticket has a negative expected value. Andrew is an expected utility maximiser. He purchases a lottery ticket.\n(a) What risk preferences (attitude to risk) does Andrew have?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIf an expected utility maximiser purchases a lottery ticket with negative expected value, he is risk seeking. He values the gamble over and above the expected value of the gamble.\n\n\n\n(b) Use a graph to demonstrate your answer to part (a).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFigure 53.2 shows Andrew’s utility curve. As he is risk seeking it is convex (at least over the domain of the lottery).\nEach of the outcomes of the lottery are labelled. Andrew finishes with his wealth minus the cost of the lottery ticket (W-T) or his wealth minus the cost of the lottery ticket plus his lottery winnings (W-T+L). If he does not purchase the ticket, his wealth remains at W. The utility of each possible outcome (U(W-T), U(W), U(W-T+L)) is also indicated on the vertical axis.\nThe expected value of the lottery after buying the ticket is labelled (E[X]). As the lottery has a negative expected value, E[X] is less than W.\nThe expected utility of the lottery lies on the straight line between the utility of the two possible lottery outcomes. The place on the line is determined by the probability of winning and is in line with the expected value of the lottery. We can identify the expected utility of the lottery by projecting a line up from E[X] to the straight line.\nFinally, the certainty equivalent of the lottery is also marked. As U(CE)=E[U(X)], we can identify the certainty equivalent by projecting a line up from E[U(X)] to the utility curve.\nDue to the convex curve, we can see that E[U(X)] is greater than U(W). Andrew prefers the lottery to the certain outcome of W. Alternatively, we can see that the certainty equivalent of the lottery is higher than current wealth. Andrew would require a payment of at least CE-W to forgo his opportunity to partake in the lottery.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  x^2\n}\n\ndf &lt;- data.frame(\n  x=seq(1,220,0.1),\n  y=NA\n)\n\ndf$y &lt;- u(df$x)\n\n#Variables for plot (may not match labels as not done to scale)\n#Payoffs from gamble\nx1&lt;-30 #loss\nx2&lt;-200 #win\nev&lt;-65 #expected value of gamble\nxc&lt;-80 #certain outcome\nce&lt;-95 #certainty equivalent\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"U(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n#set limits - need to include room for labels\n  coord_cartesian(xlim = c(-25, 220), ylim = c(-1000, 40000))+\n\n  #Add labels W-T, U(W-T) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"W-T\", size = 4, hjust = 0.5, vjust = 1.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"U(W-T)\", size = 4, hjust = 1.05, vjust = 0.6)+\n\n  #Add labels W, U(W) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"W\", size = 4, hjust = 0.6, vjust = 1.5)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"U(W)\", size = 4, hjust = 1.05, vjust = 0.3)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels W-T+L, U(W-T+L) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"W-T+L\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"U(W-T+L)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels E[X], E[U(X)] and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[X]\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"E[U(X)]\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add vertical line indicating certainty equivalent and labelled \"CE\"\n  annotate(\"segment\", x = ce, xend = ce, y = 0, yend = u(ce), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = ev, y = u(x1)+(u(x2)-u(x1))*px2, xend = ce, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = ce, y = 0, label = \"CE\", size = 4, hjust = 0.4, vjust = 1.5)\n\n\n\n\n\nFigure 53.2: Andrew’s consideration of whether to purchase a lottery ticket",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>Expected utility theory problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/prospect-theory-problems.html",
    "href": "practice-problems/prospect-theory-problems.html",
    "title": "54  Prospect theory problems",
    "section": "",
    "text": "54.1 Question 1\nSuppose Lisa has the following reference-dependent value function:\nv(x)=\\left\\{\\begin{matrix}\nx^{1/2} \\qquad &\\textrm{where} &\\space x \\geq 0\\\\\n-2(-x)^{1/2} \\quad &\\textrm{where} &\\space x &lt; 0\n\\end{matrix}\\right.\nx is the change in Lisa’s position relative to his reference point.\n(a) Explain what element of Lisa’s value function leads her to exhibit loss aversion.\n(b) Lisa considers a choice between:\nWill Lisa prefer the certain loss or gamble A?\n(c) Explain what features of the value function leads Lisa to accept or reject the gamble.\n(d) Draw a diagram illustrating the choice in part (b). Show the possible payoffs, Lisa’s value function and the value of each option. Explain how this diagram illustrates Lisa’s decision.\n(e) Suppose Lisa were to win $100 in a raffle. The win does not change her reference point. Could this win cause her to change her decision concerning the loss of $100 and gamble A?\n(f) Explain what features of the value function lead Lisa to accept or reject the gamble in part (e). How does this differ from your answer in part (c)?\n(g) Draw a diagram illustrating the choices in parts (e). Show the possible payoffs, Lisa’s value function and the value of each option. Explain how this diagram illustrates Lisa’s decision after the raffle win.",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Prospect theory problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/prospect-theory-problems.html#question-1",
    "href": "practice-problems/prospect-theory-problems.html#question-1",
    "title": "54  Prospect theory problems",
    "section": "",
    "text": "Answer\n\n\n\n\n\nThe multiplier of 2 applied to outcomes in the loss domain leads to greater weight for losses relative to gains.\n\n\n\n\n\na loss of $100 for certain or\ngamble A: (0.6, -$250; 0.4, 0). That is, gamble A gives a 60% chance of losing $250 and a 40% chance of losing nothing.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe weighted value of gamble A is:\n\\begin{align*}\nv(A)&=0.6v(-250)+0.4v(0) \\\\[6pt]\n&=0.6(-2(250)^{0.5})+0.4(0) \\\\[6pt]\n&=-18.97\n\\end{align*}\nThe value of the certain $100 loss is:\n\\begin{align*}\nv(\\$100)&=v(-100) \\\\[6pt]\n&=-2(100)^{0.5} \\\\[6pt]\n&=-20\n\\end{align*}\nAs V(A) &gt; V(-\\$100), Lisa will prefer the gamble to the certain $100 loss.\nAnother way to think about this problem is to calculate the certainty equivalent of gamble A and compare that to the certain loss. The certainty equivalent is the amount of money that Lisa would be indifferent between receiving for certain and the gamble. A benefit of calculating the certainty equivalent is that you can then easily determine whether Lisa would prefer the gamble to a certain loss of any particular amount.\nThe certainty equivalent (CE) of gamble A is calculated as:\n\\begin{align*}\nv(CE)&=V(A)=-18.97 \\\\[6pt]\n-2\\times (-CE)^{0.5}&=-18.97 \\\\[6pt]\n(-CE)^{0.5}&=9.49 \\\\[6pt]\nCE&=-90\n\\end{align*}\nThe certainty equivalent of gamble A is a loss of $90. Lisa would be indifferent between losing $90 for certain and the gamble. For any loss greater than $90, Lisa would prefer the gamble. Given this information, we can say that Lisa will prefer the gamble to the certain loss of $100.\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe bet has a lower expected value (a loss of $150) relative to the certain outcome of a loss of $100. Lisa would need to be risk seeking to find the bet attractive.\nLisa’s diminishing sensitivity to losses leads her to be risk seeking in the loss domain, which is where the gamble is located. This is why she prefers the gamble to a certain loss.\nLoss aversion does not affect her decision, as all possible outcomes (at least under our assumed reference point) are in the loss domain.\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe diagram below shows the possible payoffs, Lisa’s value function and the value of each option.\nThe possible outcomes from the gamble are zero and a loss of $250. The certain outcome on offer is a loss of $100. The expected value of the gamble is 0.6\\times -\\$250+0.4\\times 0=-\\$150.\nAs Lisa is risk seeking, the value of the certain $100 loss is lower than the weighted value of the gamble. This can be seen through v(A) being greater than v(-\\$100). Lisa will, therefore, choose the gamble.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -2*(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-300, 300, 0.1),\n  y = u(seq(-300, 300, 0.1))\n)\n\n#Variables for plot (may not match labels as not necessarily done to scale)\n#Payoffs from gamble\nx1&lt;- -250 #loss\nx2&lt;- 0 #win\nev&lt;- -150 #expected value of gamble\nxc&lt;- -100 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-260, 150), ylim = c(-33, 15))+\n\n  #Add labels -250, v(-250) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"-250\", size = 4, hjust = 0.6, vjust = -0.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"v(-250)\", size = 4, hjust = -0.1, vjust = 0.3)+\n\n  #Add labels -100, v(-100) and line to curve indicating each\n  annotate(\"text\", x = xc, y = 0, label = \"-100\", size = 4, hjust = 0.6, vjust = -0.5)+\n  annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(xc), label = \"v(-100)\", size = 4, hjust = -0.1, vjust = 0.7)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels 0, v(0) and line to curve indicating each\n  #annotate(\"text\", x = x2, y = 0, label = \"0\", size = 4, hjust = 0.4, vjust = 1.5)+\n  #annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  #annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  #annotate(\"text\", x = 0, y = u(x2), label = \"v(0)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels E[A], V(A) and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[A]=-150\", size = 4, hjust = 0.6, vjust = -0.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"V(A)\", size = 4, hjust = -0.1, vjust = 0.1)\n\n\n\n\n\nFigure 54.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe weighted value of gamble A is:\n\\begin{align*}\nv(A)&=0.6v(100-250)+0.4v(100-0) \\\\\nv(A)&=0.6v(-150)+0.4v(100) \\\\\n&=0.6(-2(150)^{0.5})+0.4(100)^{0.5} \\\\\n&=-10.7\n\\end{align*}\nThe value of the certain $100 loss is:\n\\begin{align*}\nv(\\$100)&=v(100-100) \\\\\nv(\\$100)&=v(0) \\\\\n&=-2(0)^{0.5} \\\\\n&=0\n\\end{align*}\nAs V(A) &lt; V(-\\$100), Lisa will prefer the certain loss.\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe bet has a lower expected value (a loss of $150) relative to the certain outcome of a loss of $100. Or to put it another way, the expected outcome of the gamble relative to her reference point (a loss of $50) is less than the certain outcome of $0 relative to her reference point.\nTherefore, Lisa would need to be risk seeking across most of the relevant domain to find the bet attractive. She is risk seeking across some of the domain (loss), but risk averse across some (gain). The net result of that curvature is an insufficient level of risk seeking to make the bet attractive.\nSimilarly, loss aversion makes the bet less attractive, but it would still be rejected even in the absence of loss aversion. (We can see this by calculating the weighted value of the gamble without the loss aversion multiplier.)\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThis diagram illustrates Lisa’s decision after the win.\nThe possible outcomes from the gamble relative to the reference point are a gain of $100 (a loss of zero plus the $100 win) and a loss of $150 (a loss of $250 plus the $100 win). The certain outcome on offer is zero (a certain loss of $100 plus the $100 win). The expected value of the outcome after the gamble is 0.6\\times -\\$150+0.4\\times 100=-\\$50.\nAs the bet has negative expecrted value, plus Lisa is loss averse, V(A) is less than the alternative outcome of zero.\n\n\nCode\nlibrary(ggplot2)\n\nu &lt;- function(x){\n  ifelse (x &gt;= 0, x^0.5, -2*(-x)^0.5)\n}\n\ndf &lt;- data.frame(\n  x = seq(-300, 300, 0.1),\n  y = u(seq(-300, 300, 0.1))\n)\n\n#Variables for plot (may not match labels as not necessarily done to scale)\n#Payoffs from gamble\nx1&lt;- -150 #loss\nx2&lt;- 100 #win\nev&lt;- -50 #expected value of gamble\nxc&lt;- 0 #certain outcome\npx2&lt;-(ev-x1)/(x2-x1)\n\nggplot(mapping = aes(x, y)) +\n\n  #Plot the utility curve\n  geom_line(data = df) +\n  geom_vline(xintercept = 0, linewidth=0.25)+ \n  geom_hline(yintercept = 0, linewidth=0.25)+\n  labs(x = \"x\", y = \"v(x)\")+\n\n  # Set the theme\n  theme_minimal()+\n\n  #remove numbers on each axis\n  theme(axis.text.x = element_blank(),\n            axis.text.y = element_blank(),\n            axis.title=element_text(size=14,face=\"bold\"),\n            axis.title.y = element_text(angle=0, vjust=0.5))+\n\n  #limit to y greater than zero and x greater than -8 (need -8 so space for y-axis labels)\n  coord_cartesian(xlim = c(-260, 150), ylim = c(-33, 15))+\n\n  #Add labels -150, v(-150) and line to curve indicating each\n  annotate(\"text\", x = x1, y = 0, label = \"-150\", size = 4, hjust = 0.6, vjust = -0.5)+\n  annotate(\"segment\", x = x1, y = 0, xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x1), xend = x1, yend = u(x1), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x1), label = \"v(-150)\", size = 4, hjust = -0.1, vjust = 0.3)+\n\n  #Add labels -100, v(-100) and line to curve indicating each\n  #annotate(\"text\", x = xc, y = 0, label = \"-100\", size = 4, hjust = 0.6, vjust = -0.5)+\n  #annotate(\"segment\", x = xc, y = 0, xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  #annotate(\"segment\", x = 0, y = u(xc), xend = xc, yend = u(xc), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  #annotate(\"text\", x = 0, y = u(xc), label = \"v(-100)\", size = 4, hjust = -0.1, vjust = 0.7)+\n\n  #Add expected utility line\n  annotate(\"segment\", x = x1, xend = x2, y = u(x1), yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotdash\")+\n\n  #Add labels 100, v(1000) and line to curve indicating each\n  annotate(\"text\", x = x2, y = 0, label = \"100\", size = 4, hjust = 0.4, vjust = 1.5)+\n  annotate(\"segment\", x = x2, y = 0, xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"segment\", x = 0, y = u(x2), xend = x2, yend = u(x2), linewidth = 0.5, colour = \"black\", linetype=\"dotted\")+\n  annotate(\"text\", x = 0, y = u(x2), label = \"v(100)\", size = 4, hjust = 1.05, vjust = 0.45)+\n\n  #Add labels E[A], V(A) and curve indicating each\n  annotate(\"text\", x = ev, y = 0, label = \"E[A]=-50\", size = 4, hjust = 0.6, vjust = -0.5)+\n  annotate(\"segment\", x = ev, y = 0, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"segment\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, xend = ev, yend = u(x1)+(u(x2)-u(x1))*px2, linewidth = 0.5, colour = \"black\", linetype=\"dashed\")+\n  annotate(\"text\", x = 0, y = u(x1)+(u(x2)-u(x1))*px2, label = \"V(A)\", size = 4, hjust = -0.1, vjust = 0.1)\n\n\n\n\n\nFigure 54.2: Lisa’s consideration of gamble A and the $100 loss after the win",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Prospect theory problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/prospect-theory-problems.html#question-2",
    "href": "practice-problems/prospect-theory-problems.html#question-2",
    "title": "54  Prospect theory problems",
    "section": "54.2 Question 2",
    "text": "54.2 Question 2\nEarly in the COVID-19 pandemic, the hope was that vaccines would prevent transmission and death. Later, it became apparent that vaccination dramatically reduced death rates but did not wholly prevent it.\nUse the concept of probability weighting to explain why citizens would see a massive reduction as much less valuable than elimination.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThere is strong evidence that we overweight certain events, when the probability of the event is one, relative to near certain events, such as when the probability is, say, 99%. This overweighting of certainty is effectively the same as overweighting very low-probability events.\nThe elimination of COVID-19 would be seen as a certain event, and therefore overweighted relative to a near-certain event, such as a 99% reduction in deaths. Hence elimination would be seen as much more valuable even though near-elimination has nearly the same number of lives saved\nPut another way, the remaining small probability of death would be overweighted, meaning the near elimination of deaths would be seen as having much less value than the complete elimination.",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>Prospect theory problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/intertemporal-choice-problems.html",
    "href": "practice-problems/intertemporal-choice-problems.html",
    "title": "55  Intertemporal choice problems",
    "section": "",
    "text": "55.1 Work or party?\nRuby is a sophisticated present-biased agent with \\beta=0.5 and \\delta=1. She has utility function u(x)=x.\nRuby is deciding today (t=0) whether she will either:\nThat is, she is deciding between (2, 10) and (1,8).\na) What does Ruby decide?\nb) Ruby is able to commit to working at t=1 by posting a letter at t=0 declining the party invitation (at no cost). Once she sends the letter, she cannot change her mind. Will she decline the invitation?\nc) Suppose declining the party invitation comes at a cost to Ruby’s reputation at t=2. What is the largest utility cost that Ruby would be willing to incur such that she would still use the commitment device of declining the invitation?\nd) Victoria is a naive present-biased agent with \\beta=0.5 and \\delta=1. She has utility function u(x)=x.\nVictoria faces the same choice as Ruby and also has the chance to decline at t=0 the party invitation at a cost to Victoria’s reputation at t=2. Will Victoria decline the invitation?",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Intertemporal choice problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/intertemporal-choice-problems.html#work-or-party",
    "href": "practice-problems/intertemporal-choice-problems.html#work-or-party",
    "title": "55  Intertemporal choice problems",
    "section": "",
    "text": "work tomorrow (t=1) for $10 income to be received the day after she works (t=2) or\nparty tomorrow (t=1) for immediate utility of 8 but no income.\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nRuby is sophisticated, so uses backward induction to decide her preferred course of action.\nAt t=2 there is no decision to make. Ruby bears the consequences of her earlier decisions.\nAt t=1 she compares the discounted utility of the two options:\n\\begin{align*}\nU_1(\\text{work})&=\\beta\\delta u(\\text{work}) \\\\\n&=0.5\\times 1\\times 10 \\\\\n&=5 \\\\\n\\\\\nU_1(\\text{party})&=u(\\text{party}) \\\\\n&=8\n\\end{align*}\nAt t=1 the discounted utility partying is higher than that of working (U_1(\\text{party})&gt;U_1(\\text{work})), so Penny prefers to party.\nAt t=0 Penny knows that she will party at t=1 no matter what she decides at t=0, so she accepts that she will party.\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe presence of the commitment device allows Ruby to include the option of working when she makes a decision at t=0. She will now compare the discounted utility of using the commitment device with the discounted utility of working.\n\\begin{align*}\nU_0(\\text{commit+work})&=\\beta\\delta^2 u(\\text{commit+work}) \\\\\n&=0.5\\times 1^2\\times 10 \\\\\n&=5 \\\\\n\\\\\nU_0(\\text{party})&=\\beta\\delta u(\\text{party}) \\\\\n&=0.5\\times 1\\times 8 \\\\\n&=4\n\\end{align*}\nU_0(\\text{commit+work})&gt;U_0(\\text{party}), so Ruby commits to working by declining the invitation.\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe largest cost she would be willing to incur is the cost where the discounted utility of each option is equal. Setting the cost as c:\n\\begin{align*}\nU_0(\\text{commit})&=\\beta\\delta^2 u(\\text{work}-c) \\\\\n&=0.5\\times 1^2\\times (10-c) \\\\\n&=5-0.5c \\\\\n\\\\\nU_0(\\text{party})&=\\beta\\delta u(\\text{party}) \\\\\n&=0.5\\times 1\\times 8 \\\\\n&=4\n\\end{align*}\nRuby will be indifferent where 5-0.5c=4 or where c=2. The largest utility cost she would be willing to incur is 2.\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAs Victoria has the same discount function as Ruby, we know from question b) that Victoria will decide to work at t=0. We also know from question a) that she will then change her mind and party at t=1.\nHowever, as Victoria is naive she does not see her future self-control problem and does not have the foresight to realise at t=0 that she will not work as planned. As a result, she would see no need in the commitment device and would not be willing to incur any cost to use it.",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Intertemporal choice problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/intertemporal-choice-problems.html#surfboard-vs-nft",
    "href": "practice-problems/intertemporal-choice-problems.html#surfboard-vs-nft",
    "title": "55  Intertemporal choice problems",
    "section": "55.2 Surfboard vs NFT",
    "text": "55.2 Surfboard vs NFT\nJames is a naive present-biased agent with \\beta=0.5, \\delta=0.95 and u(x)=x.\nJames is planning to purchase a surfboard. James also likes to purchase Bored Ape non-fungible tokens (NFTs).\nThe surfboard that James wants to purchase will be available for sale in 2 weeks (t=2). Purchasing the surfboard will give him utility of 10 on the day of purchase.\nJames also knows a new Bored Ape NFT will be available for sale next week (t=1). Purchasing the Bored Ape NFT will give him utility of 8 on the day of purchase.\nJames has enough money to buy only the surfboard or the Bored Ape NFT. He cannot afford both.\n(a) What does James choose at t=0? Explain.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTo determine what James chooses at t=0, we need to compare the discounted utility of the two options.\nThe discounted utility of the NFT received at t=1 is:\n\\begin{align*}\nU_0(1,8)&=0.5\\times 0.95^1 \\times 8 \\\\\n&=3.8\n\\end{align*}\nThe discounted utility of the surfboard received at t=2 is:\n\\begin{align*}\nU_0(2,10)&=0.5\\times 0.95^2 \\times 10 \\\\\n&=4.51\n\\end{align*}\nJames chooses the option with the highest discounted utility, which is the surfboard at t=2.\n\n\n\n(b) At t=1 the NFT becomes available for sale. James is sitting at his laptop contemplating what he should do. What does James choose?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTo determine what James chooses at t=1, we need to compare the discounted utility of the two options.\nThe discounted utility of the NFT received at t=1 is:\n\\begin{align*}\nU_1(1,8)&=0.95^0 \\times 8 \\\\\n&=8\n\\end{align*}\nThe discounted utility of the surfboard received at t=2 is:\n\\begin{align*}\nU_1(2,10)&=0.5\\times 0.95^1 \\times 10 \\\\\n&=4.75\n\\end{align*}\nJames chooses the option with the highest discounted utility, which is the NFT at t=1. He has changed his mind. This is because the NFT at t=1 is no longer subject to the short-term discount factor \\beta.\n\n\n\n(c) Draw a graph illustrating James’s choices and his decisions.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe following chart shows each of the two options presented to James, the NFT at t=1 and the surfboard at t=2. The line extended from each back to t=0 represents the discounted utility of each option at time t.\nIt can be seen that at t=0, the discounted utility of the surfboard at t=2 is higher than the discounted utility of the NFT at t=1. However, at t=1, the discounted utility of the NFT is higher than the discounted utility of the surfboard. Hence James changes his mind.\n\n\n\n\n(d) Jane is a sophisticated present-biased agent with \\beta=0.5, \\delta=0.95 and u(x)=x. Jane also likes surfing and Bored Ape NFTs. She faces the same set of choices as James in part a). What does Jane choose at t=0? Explain.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTo determine what Jane chooses at t=0, Janes considers the discounted utility of the two options by backward induction.\nAt t=2, Jane will choose the surfboard if she has not already purchased the NFT.\nAt t=1, the discounted utility of the NFT is:\n\\begin{align*}\nU_1(1,8)&=0.95^0 \\times 8 \\\\\n&=8\n\\end{align*}\nAt t=1, the discounted utility of the surfboard received at t=2 is:\n\\begin{align*}\nU_1(2,10)&=0.5\\times 0.95^1 \\times 10 \\\\\n&=4.75\n\\end{align*}\nJane would choose the NFT.\nJane now considers what she would choose at t=0. She knows that no matter what she chooses now, she will choose the NFT at t=1. Hence, she chooses the NFT at t=0, the only feasible option.\n\n\n\n(e) Jane discovers that she can place an early deposit of $100 on the surfboard at t=0. If she does so, she cannot afford the Bored Ape NFT at t=1. Unfortunately, she will have to walk to the surf shop to place the deposit at a cost of 0.1 utility. What does Jane choose at t=0? Explain.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nJane’s logic runs as per part d) until she considers what she would choose at t=0.\nAt t=0, she has two choices available to her: place the deposit on the surfboard or purchase the NFT.\nThe discounted utility of the NFT at t=1 is:\n\\begin{align*}\nU_0(1,8)&=0.5\\times 0.95^1 \\times 8 \\\\\n&=3.8\n\\end{align*}\nThe discounted utility of the surfboard at t=2 when making the deposit is:\n\\begin{align*}\nU_0(2,10)&=-0.1+0.5\\times 0.95^2 \\times 10 \\\\\n&=4.41\n\\end{align*}\nAs the deposit binds Jane in the future, she can stick to her plan. She chooses buying the surfboard with the deposit rather than buying without the deposit as she knows that the latter choice is not viable: she will change her plans at t=1.",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Intertemporal choice problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/intertemporal-choice-problems.html#clearing-credit-card-debt",
    "href": "practice-problems/intertemporal-choice-problems.html#clearing-credit-card-debt",
    "title": "55  Intertemporal choice problems",
    "section": "55.3 Clearing credit card debt",
    "text": "55.3 Clearing credit card debt\nYvonne and Wendy each have a credit card with a credit limit of $3,000. They had used the available credit on the card. They faced a 20% interest rate on their debts.\nYvonne and Wendy also had $3,000 in their bank accounts. They were not earning any interest on this sum.\nYvonne used her savings to clear her credit card debt, saving her interest. Unfortunately, over the next three months, she used the credit card to make purchases and ended up with a credit card debt of $3000 again. She is now paying 20% interest on her debt and has no savings.\nWendy put her savings into a term deposit, earning 5% interest. She cannot access her savings for the next year. She kept the credit card debt and made no further purchases but is still paying the 20% interest.\nUse concepts from the subject material on intertemporal choice to explore why Yvonne and Wendy might have each made the decisions that they did. You should not make any mathematical calculations in answering this question. Explain the intuition only.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWendy is likely a sophisticated present-biased agent. She can see that if she pays off her credit card with her savings, she will likely spend in the future.\nThe term deposit and maxed-out credit card provide Wendy with a commitment device. She cannot access her savings for the next year or use the credit card. This prevents her from spending in the future. Her decision is sub-optimal compared to the option of paying off the card with her savings and not spending on her credit card, but she knows that in the future she will not be able to stick with that course of action. Although this comes at a cost - the higher interest rate - the commitment device was still the preferred option.\nYvonne may be a naive present-biased agent. She paid off her credit card debt with her savings, the apparently wise choice for that moment in time. However, Yvonne would not have foreseen that her present bias would lead her to spend in the future and make a time inconisistent decision. She would not foresee the need for a commitment device.\nAlternatively, Yvonne may simply have a high exponential discount rate who prefers to spend at all times.",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>Intertemporal choice problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/beliefs-problems.html",
    "href": "practice-problems/beliefs-problems.html",
    "title": "56  Beliefs problems",
    "section": "",
    "text": "56.1 Soccer\nYour favourite soccer team is a terrible team that rarely wins. You know the following about your team:\na) You hear that they scored at least two goals in their most recent game. Use Bayes’ rule to calculate the probability that they won.\nb) Use natural frequencies to calculate the probability that they won.",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Beliefs problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/beliefs-problems.html#soccer",
    "href": "practice-problems/beliefs-problems.html#soccer",
    "title": "56  Beliefs problems",
    "section": "",
    "text": "5% of the time they win.\nWhen they win, they score at least two goals 60% of the time.\nWhen they lose, they score at least two goals 20% of the time.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTo answer this question, we need to use Bayes’ rule.\n\\begin{align*}\nP(\\text{win}|\\text{2 goals})&=\\frac{P(\\text{2 goals}|\\text{win})P(\\text{win})}{P(\\text{2 goals})} \\\\[12pt]\n&=\\frac{P(\\text{2 goals}|\\text{win})P(\\text{win})}{P(\\text{2 goals}|\\text{win})P(\\text{win})+P(\\text{2 goals}|\\text{lose})P(\\text{lose})} \\\\[12pt]\n&=\\frac{0.6\\times 0.05}{0.6\\times 0.05+0.2\\times 0.95} \\\\[12pt]\n&=0.136\n\\end{align*}\nThe team won with 13.6% probability.\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSuppose there are 100 games.\nThat would mean there are 5 wins and 95 losses.\nIn those five wins, they would score at least two goals in three of them.\nIn the 95 losses, they would score at least two goals in 0.2\\times 95=19 of them.\nThat means 3 of the 3+19=22 games in which they score two goals are wins.\nTherefore:\n\\begin{align*}\nP(\\text{win}|\\text{2 goals})&=\\frac{\\text{wins when they score two goals}}{\\text{games where they score two goals}} \\\\[12pt]\n&=\\frac{3}{22} \\\\[12pt]\n&=13.6\\%\n\\end{align*}",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Beliefs problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/beliefs-problems.html#roulette",
    "href": "practice-problems/beliefs-problems.html#roulette",
    "title": "56  Beliefs problems",
    "section": "56.2 Roulette",
    "text": "56.2 Roulette\nImagine you are in a casino and observing a roulette wheel. The last five spins of the wheel have all resulted in the ball landing on a red number. Now, the wheel is about to spin again.\na) What is the probability that the next spin will be black?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe probability that the next spin will be black is ~50%. Each spin is independent of the previous spin. (Technically, the probability is slightly less than 50% because of the presence of the green 0 and, in the case of American roulette wheels, 00. I’ve ignored this for simplicity.)\n\n\n\nb) Tommy is watching the same game of roulette. He suffers from the gambler’s fallacy. What is he likely to believe? Give a potential explanation for his belief.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nTom is likely to believe that the next spin will be black. As he has the gambler’s fallacy, he will believe that an outcome not recently realised in a sequence of independent draws - in this case, black - is more likely to occur on the next draw.\n\n\n\nc) Sammy is at the next table watching a game of craps. He has seen a player win by rolling 7 three times in a row. The player makes the same bet and is about to roll again. Sammy suffers from the hot hand fallacy. What is he likely to believe? Why?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSammy is likely to believe that the next roll will be a 7. As he has the hot hand fallacy, he believes the streak will persist despite each outcome being independent of the last.",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Beliefs problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/beliefs-problems.html#buying-a-business",
    "href": "practice-problems/beliefs-problems.html#buying-a-business",
    "title": "56  Beliefs problems",
    "section": "56.3 Buying a business",
    "text": "56.3 Buying a business\nDylan is considering buying a small business. The selling agent tells Dylan that the business is worth $1.5 million. Dylan knows that the business is not worth that much.\na) Use concepts from the material on beliefs to explain why an agent might tell Dylan the business is worth so much.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe agent is likely attempting to create an anchor. If Dylan uses the anchoring and adjustment heuristic in determining the price, he will start from that anchor and then inadequately adjust downwards. So despite knowing it is too high, it may still bias his estimate up.\n\n\n\nb) To determine the value of the business, you estimate the revenue and profit the business will generate. Dylan accounts for his belief that he will be able to increase the revenue substantially from current levels. He determines a fair valuation is $1.1 million.\nHe purchases the business. However, after running the business for several months, he does not realise the profit he anticipated.\nWhat form of overconfidence is this? Explain. Under what conditions does this form of overconfidence tend to emerge?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nDylan suffers from overestimation. Overestimation is the belief that we can perform at a level beyond that which we realistically can. In this case, Dylan did not generate the profit that he believed he could.\nPeople typically overestimate when attempting a difficult task.\n\n\n\nc) When developing his valuation, Dylan determined there was a 95% probability that the business was worth between $1.08 million and $1.12 million.\nThe business ultimately sold for $1 million.\nWhat form of overconfidence is this? Explain.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nDylan suffers from overprecision. Overprecision is the tendency to believe that our predictions or estimates are more accurate than they are. Dylan’s overprecision is indicated by the narrow confidence interval he gave for the value of the business.",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Beliefs problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/beliefs-problems.html#a-loaded-dice",
    "href": "practice-problems/beliefs-problems.html#a-loaded-dice",
    "title": "56  Beliefs problems",
    "section": "56.4 A loaded dice",
    "text": "56.4 A loaded dice\nYou have two six-sided dice.\n\nOne die is fair with the numbers 1 through to 6 occurring with equal probability.\nThe other die is loaded and always rolls an even number. It rolls a 2, 4 or 6 with equal probability.\n\nYou pull one die out of your pocket and roll it. You did not check which die it was before you rolled. (Assume you could have pulled either die out of your pocket with equal probability.)\na) The die shows a six. What is the probability that it is the loaded die? Calculate your answer using Bayes’ rule.\n\\begin{align*}\nP(\\text{D1 loaded}|6)&=\\frac{P(6|\\text{D1 loaded})P(\\text{D1 loaded})}{P(6)} \\\\[6pt]\n&=\\frac{P(6|\\text{D1 loaded})P(\\text{D1 loaded})}{P(6|\\text{D1 loaded})P(\\text{D1 loaded})+P(6|\\text{D1 fair})P(\\text{D1 fair})} \\\\[6pt]\n&=\\frac{\\frac{1}{3}\\times 0.5}{\\frac{1}{3}\\times 0.5+\\frac{1}{6}\\times 0.5} \\\\[6pt]\n&=0.67\n\\end{align*}\nThe first die is the loaded die with 66.7% probability.\nb) You pull the other die out of your pocket and roll it. It shows a 5. What is the updated probability that the first die you pulled out of your pocket is the loaded die? Calculate your answer using Bayes’ rule.\n\\begin{align*}\nP(\\text{D2 fair}|5)&=\\frac{P(5|\\text{D2 fair})P(\\text{D2 fair})}{P(5)} \\\\[6pt]\n&=\\frac{P(5|\\text{D2 fair})P(\\text{D2 fair})}{P(5|\\text{D2 fair})P(\\text{D2 fair})+P(5|\\text{D2 loaded})P(\\text{D2 loaded})} \\\\[6pt]\n&=\\frac{\\frac{1}{6}\\times \\frac{2}{3}}{\\frac{1}{6}\\times \\frac{2}{3}+0\\times \\frac{1}{3}} \\\\[6pt]\n&=1\n\\end{align*}\nThe first die is the loaded die with 100% probability. This should make intuitive sense. The second die showed a 5 and is, therefore, fair with 100% probability. The loaded die never shows a 5.",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>Beliefs problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/behavioural-game-theory-problems.html",
    "href": "practice-problems/behavioural-game-theory-problems.html",
    "title": "57  Behavioural game theory problems",
    "section": "",
    "text": "57.1 Airline competition\nQuokka Airlines and Viper Air are competitor airlines. Each is considering how it should price its tickets. They have two options: a high price or a low price. Each must choose the price simultaneously.\nIf one airline offers a lower price than the other, they gain more market share but a lower profit margin. If both airlines offer the same price, Quokka takes more of the market as the incumbent airline.\nThe expected payoffs for each combination of actions are as follows, with the payoff (x,y) being the payoffs for Quokka and Viper respectively.\na) Are there any pure-strategy Nash equilibria? If so, what are they?\nb) Suppose the managers of Quokka and Viper are level-k thinkers.\nIf they were level-0, both would choose high or low with equal probability.\nWhat would each player do if they were a level-1 thinker?\nc) What would each player do if they were a level-2 thinker?\nd) What would each player do if they were a level-3 or above thinker?\ne) Suppose now that the managers of Quokka and Viper are perfectly rational. Each is considering how they could make more profit.\nA staff member in Viper suggests launching an advertising campaign with high prices before they and Quokka choose. Once Viper has advertised their prices, they will be constrained to setting them high.\nIs this a good idea? What concept does this illustrate?",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Behavioural game theory problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/behavioural-game-theory-problems.html#airline-competition",
    "href": "practice-problems/behavioural-game-theory-problems.html#airline-competition",
    "title": "57  Behavioural game theory problems",
    "section": "",
    "text": "Answer\n\n\n\n\n\nWe determine the pure-strategy Nash equilibria by considering the best response of each player to each of the other player’s strategies.\nIf Viper sets prices high, Quokka can choose high for a payoff of 100 or low for a payoff of 60. High is the best response.\nIf Viper sets prices low, Quokka can choose high for a payoff of 40 or low for a payoff of 50. Low is the best response.\nIf Quokka sets prices high, Viper can choose high for a payoff of 20 or low for a payoff of 30. Low is the best response.\nIf Quokka sets prices low, Viper can choose high for a payoff of 0 or low for a payoff of 10. Low is the best response.\nThe pure Nash equilibrium is therefore (low, low). Neither has an incentive to deviate.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nA level-1 thinker assumes that the other player is a level-0 thinker. Each level-1 thinker plays the optimal strategy on this assumption.\nA level-1 Quokka plays the optimal strategy against a level-0 Viper. A level-0 Viper plays high or low with equal probability. The payoffs to Quokka from each option are:\n\\begin{align*}\nU_Q(\\text{high})&=0.5\\times 100+0.5\\times 40 \\\\\n&=70\n\\end{align*} \\begin{align*}\nU_Q(\\text{low})&=0.5\\times 60+0.5\\times 50 \\\\\n&=55\n\\end{align*}\nQuokka chooses high.\nThe payoffs to Viper from each option are:\n\\begin{align*}\nU_V(\\text{high})&=0.5\\times 20+0.5\\times 0 \\\\\n&=10\n\\end{align*} \\begin{align*}\nU_V(\\text{low})&=0.5\\times 30+0.5\\times 10 \\\\\n&=20\n\\end{align*}\nViper chooses low.\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nA level-2 thinker assumes that the other player is a level-1 thinker. Each level-2 thinker plays the optimal strategy on this assumption.\nA level-2 Quokka knows that the level-1 Viper will choose low. Therefore, the payoff from high is 40 and from low is 50. Quokka chooses low.\nA level-2 Viper knows that the level-1 Quokka will choose high. Therefore, the payoff from high is 20 and from low is 30. Viper chooses low.\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nAt whatever level of thinking the players discover the Nash equilibrium, for any higher level of thinking they will remain at the Nash equilibrium.\nTherefore, at level-3 and above, both players will choose low.\n\n\n\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSuppose Viper advertises high prices and is committed to that choice. The game therefore becomes:\n\nWith this game, Viper plays high no matter what choice is made by Quokka. They effectively have no choice.\nQuokka can choose high for a payoff of 100 or low for a payoff of 60. High is the best response.\n\nThe new Nash equilibrium is (high, high). Viper has increased its payoff from 10 to 20 by making the strategic move. The move is therefore a good idea.\nThis example illustrates the concept of commitment via a strategic move.",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Behavioural game theory problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/behavioural-game-theory-problems.html#valuing-a-business",
    "href": "practice-problems/behavioural-game-theory-problems.html#valuing-a-business",
    "title": "57  Behavioural game theory problems",
    "section": "57.2 Valuing a business",
    "text": "57.2 Valuing a business\nYou are considering buying a small business. You research the business, attempting to estimate the revenue and profit it will generate. Based on your research, you determine a fair valuation is $850,000.\nThe business ultimately sells for $1.1 million to another person. You discover that many other parties were interested in buying the business.\nYou later hear that the purchaser is disappointed with the business and that it is worth less than they paid. What phenomenon could this be an example of? Explain.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThis is an example of the winner’s curse.\nThe winner’s curse occurs when the winner of an auction is the bidder who most overestimates the value of the item. The winner therefore pays more than the item is worth.",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Behavioural game theory problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/behavioural-game-theory-problems.html#cafe",
    "href": "practice-problems/behavioural-game-theory-problems.html#cafe",
    "title": "57  Behavioural game theory problems",
    "section": "57.3 Cafe",
    "text": "57.3 Cafe\nTwo friends, Player 1 and Player 2, have arranged to meet at a cafe. Neither can remember which of the two cafes in town they had arranged to meet at.\nEach player has a favourite cafe. However, they would prefer to go to their less-favourite cafe with a friend than go to their favourite cafe alone.\nEach chooses a cafe and goes there. The payoffs for each combination of choices are in the table below, with the payoffs (x, y) being the payoffs for Player 1 and Player 2 respectively.\n\na) What are the pure-strategy Nash equilbria of this game?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIf player 2 chooses cafe A, player 1 wants to choose cafe A.\nIf player 2 chooses cafe B, player 1 wants to choose cafe B.\nIf player 1 chooses cafe A, player 1 wants to choose cafe A.\nIf player 1 chooses cafe B, player 1 wants to choose cafe B.\n\nThe two pure-strategy Nash equilibria are (cafe A, cafe A) and (cafe B, cafe B).\n\n\n\nb) What would Player 1 and Player 2 do if each was a level-1 thinker? Explain.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIf Player 2 chooses randomly, Player 1’s payoff’s from each option are:\n\\begin{align*}\nU_1(\\text{cafe A})&=0.5\\times 2+0.5\\times 0=1 \\\\[6pt]\nU_1(\\text{cafe B})&=0.5\\times 0+0.5\\times 1=0.5\n\\end{align*}\nPlayer 1 chooses cafe A.\nIf Player 1 chooses randomly, Player 2’s payoff’s from each option are:\n\\begin{align*}\nU_2(\\text{cafe A})&=0.5\\times 1+0.5\\times 0=0.5 \\\\[6pt]\nU_2(\\text{cafe B})&=0.5\\times 0+0.5\\times 3=1.5\n\\end{align*}\nPlayer 2 chooses cafe B.\n\n\n\nc) What would Player 1 and Player 2 do if each was a level-2 thinker? Explain.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe level-2 Player 1 assumes that Player 2 is level-1. Therefore, they assume that Player 2 will choose cafe B. Accordingly, they choose cafe B.\nThe level-2 Player 2 assumes that Player 1 is level-1. Therefore, they assume that Player 1 will choose cafe A. Accordingly, they choose cafe A.",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Behavioural game theory problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/behavioural-game-theory-problems.html#a-military-attack",
    "href": "practice-problems/behavioural-game-theory-problems.html#a-military-attack",
    "title": "57  Behavioural game theory problems",
    "section": "57.4 A military attack",
    "text": "57.4 A military attack\nAn army from the North is about to attack the South.\nThe North can attack one of two cities: Hobart or Launceston. Launceston is easier to attack as it is closer.\nThe South needs to decide which city it will plan to defend.\nIf the North attacks an undefended city, it will win. The South can repel any attack on a city it has chosen to defend.\nThe expected payoffs for each combination of actions are as follows, with the payoff (x,y) being the payoffs for the North and South respectively.\n\na) Are there any pure-strategy Nash equilibria? If so, what are they?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe determine the pure-strategy Nash equilibria by considering the best response of each player to each of the other player’s strategies.\nIf the South defends Hobart, North can choose Hobart for a payoff of -1 or Launceston for a payoff of 4. Launceston is the best response.\nIf the South defends Launceston, North can choose Hobart for a payoff of 4 or Launceston for a payoff of 0. Hobart is the best response.\nIf the North attacks Hobart, South can defend Hobart for a payoff of 4 or Launceston for a payoff of 0. Hobart is the best response.\nIf the North attacks Launceston, South can defend Hobart for a payoff of 0 or Launceston for a payoff of 4. Launceston is the best response.\nThere is no pure-strategy Nash equilibrium. For any combination of choices, one of the armies has an incentive to change their choice.\n\n\n\n\nb) Suppose the commanders of the North and South are level-k thinkers.\nIf they were level-0, both would choose Hobart or Launceston with equal probability.\nWhat would each player do if they were a level-1 thinker?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nA level-1 thinker assumes that the other player is a level-0 thinker. Each level-1 thinker plays the optimal strategy on this assumption.\nA level-1 North plays the optimal strategy against a level-0 South. A level-0 South plays Hobart or Launceston with equal probability. The payoffs to North from each option are:\n\\begin{align*}\nU_N(\\text{Hobart})=0.5\\times -1+0.5\\times 4=1.5 \\\\\n\\\\\nU_N(\\text{Launceston})=0.5\\times 4+0.5\\times 0=2\n\\end{align*}\nNorth attacks Launceston.\n\\begin{align*}\nU_S(\\text{Hobart})=0.5\\times 4+0.5\\times 0=2 \\\\\n\\\\\nU_S(\\text{Launceston})=0.5\\times 4+0.5\\times 0=2\n\\end{align*}\nSouth is indifferent between defending Hobart and Launceston. They can choose either.\n\n\n\nc) What would each player do if they were a level-2 thinker?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nA level-2 thinker assumes that the other player is a level-1 thinker. Each level-2 thinker plays the optimal strategy on this assumption.\nA level-2 North knows that the level-1 South is indifferent between defending Hobart and Launceston. If North assumes that South will defend each with equal probability, the payoffs to North from each option are:\n\\begin{align*}\nU_N(\\text{Hobart})=0.5\\times -1+0.5\\times 4=1.5 \\\\\n\\\\\nU_N(\\text{Launceston})=0.5\\times 4+0.5\\times 0=2\n\\end{align*}\nNorth attacks Launceston.\nA level-2 South knows that the level-1 North attacks Launceston. The South defends Launceston for payoff of 4 (rather than Hobart for payoff of 0).",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Behavioural game theory problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/behavioural-game-theory-problems.html#acquiring-a-company",
    "href": "practice-problems/behavioural-game-theory-problems.html#acquiring-a-company",
    "title": "57  Behavioural game theory problems",
    "section": "57.5 Acquiring a company",
    "text": "57.5 Acquiring a company\nThe following example draws on Bazerman and Moore (2013).\nCompany A is considering acquiring Company T.\nThe value of Company T depends on the outcome of an oil exploration project. If the project fails, the company under current management will be worth nothing ($0 per share). If the project succeeds, the value of the company under current management could be as high as $100 per share. All values between $0 and $100 are equally likely.\nCompany T will be worth 50 per cent more in the hands of Company A than under current management. If the project fails, the company will be worth $0 per share under either management. If the exploration project generates a $50 per share value under current management, the value under Company A will be $75 per share. And so on.\nCompany A is considering what price per share they should offer. This offer must be made before Company A knows the outcome of the drilling project, but after Company T learns the result. Company T will accept any offer from Company A if it is profitable for them.\na) Show that for any offer above zero Company A expects to lose money.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nIf Company A offers \\$x, Company T will accept x% of the time, whenever the firm is worth between $0 and \\$x. Since all those values are equally likely, the firm will be worth on average \\$x/2 to company T when they accept. The shares will therefore be worth 1.5\\times x/2=3x/4 on average for company A. That gives Company A profit of:\n\\begin{align*}\n\\pi_A&=\\frac{3x}{4}-x \\\\[6pt]\n&=-\\frac{x}{4}\n\\end{align*}\nAny offer above $0 generates a negative expected return, a loss of 25% of the offer.\nTo give an example, if Company A offered $60, it will be accepted 60% of the time - whenever the firm is worth between $0 and $60 for company T. Since all those values are equally likely, the firm will be worth on average $30 to company T when they accept, meaning it will be worth $45 on average for company A. A $60 offer will result in an average loss of $15.\n\n\n\nb) People given this problem tend to bid between $50 and $75 per share (Samuelson and Bazerman (1985)). A typical explanation offered by these people is that the average outcome for Company T is $50, making the value for Company A $75. Any offer in the range between these two values would be agreeable to both parties.\nExplain why a “cursed” player representing Company A might make a non-zero offer.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nA “cursed” player representing company A does not think that company T’s decision to sell depends on company T’s knowledge of the oil exploration. As a result, they are likely to bid based on their unconditional expected value of the field, not the value conditional on acceptance.\nThis bidding approach leads to, on average, a loss. The cursed player under-appreciates that company T is more likely to accept when company T’s valuation is low.",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Behavioural game theory problems</span>"
    ]
  },
  {
    "objectID": "practice-problems/behavioural-game-theory-problems.html#receiving-a-faulty-product",
    "href": "practice-problems/behavioural-game-theory-problems.html#receiving-a-faulty-product",
    "title": "57  Behavioural game theory problems",
    "section": "57.6 Receiving a faulty product",
    "text": "57.6 Receiving a faulty product\nA customer received a faulty product from a firm and requested a refund as per consumer law. The customer also threatened to complain to the Department of Fair Trading if they did not receive the refund. A customer complaint would be costly to the firm as they would be required to provide a refund in addition to incurring the cost of dealing with the complaint.\nThe firm offered a store credit instead, believing that the customer would not complain as the time and effort involved would not be worth the potential refund.\nHowever, the customer still complained to the Department of Fair Trading.\na) Use concepts from game theory to explain why the firm might have held that belief.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe can draw the extensive form of the game as follows:\n\nWe work through this game by backward induction. If the cost to to the customer of complaining is greater than the benefit of obtaining the refund, the customer will not complain. In that case, the firm will offer the store credit.\nAs the firm believed that the cost to to the customer of complaining is greater than the benefit of obtaining the refund, the customer’s threat to complain would not normally be considered credible.\n\n\n\nb) Use concepts from behavioural game theory to explain why the firm’s belief was ultimately incorrect.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe customer’s emotional response may lead them to complain. They might be angry or obtain satisfaction from seeing the firm punished. In that case, the customer will complain even though it is not in their material best interest to do so. Emotionally, it is worthwhile. They incur the cost of complaining but get the benefit of both the refund and the satisfaction from punishing the firm.\n\n\n\n\n\n\n\nBazerman, M. H., and Moore, D. A. (2013). Judgment in managerial decision making (8. ed). Wiley.\n\n\nSamuelson, W. F., and Bazerman, M. (1985). Negotiation under the winner’s curse (V. Smith, Ed.). JAI Press.",
    "crumbs": [
      "Practice problems",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>Behavioural game theory problems</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Akerlof, G. A. (1970). The market for\n“lemons”: Quality uncertainty and the market\nmechanism*. The Quarterly Journal of Economics, 84(3),\n488–500. https://doi.org/10.2307/1879431\n\n\nAllais, M. (1953). Le comportement de l’homme rationnel devant le\nrisque: Critique des postulats et axiomes de l’ecole americaine.\nEconometrica, 21(4), 503–546. https://doi.org/10.2307/1907921\n\n\nAndreoni, J., and Bernheim, B. D. (2009). Social Image and the\n5050 Norm: A Theoretical and Experimental Analysis of\nAudience Effects. Econometrica, 77(5), 1607–1636. https://doi.org/10.3982/ECTA7384\n\n\nAshraf, N., Karlan, D., and Yin, W. (2006). Tying odysseus to the mast:\nEvidence from a commitment savings product in the philippines*. The\nQuarterly Journal of Economics, 121(2), 635–672. https://doi.org/10.1162/qjec.2006.121.2.635\n\n\nAyton, P., and Fischer, I. (2004). The hot hand fallacy and the\ngambler’s fallacy: Two faces of subjective randomness?\nMemory & Cognition, 32(8), 1369–1378. https://doi.org/10.3758/BF03206327\n\n\nBarber, B. M., and Odean, T. (2001). Boys will be boys: Gender,\noverconfidence, and common stock investment*. The Quarterly Journal\nof Economics, 116(1), 261–292. https://doi.org/10.1162/003355301556400\n\n\nBarberis, N., Huang, M., and Thaler, R. H. (2006). Individual\nPreferences, Monetary Gambles, and Stock Market Participation: A Case\nfor Narrow Framing. American Economic Review, 96(4),\n1069–1090. https://doi.org/10.1257/aer.96.4.1069\n\n\nBar-Eli, M., Avugos, S., and Raab, M. (2006). Twenty years of\n“hot hand” research: Review and critique.\nPsychology of Sport and Exercise, 7(6), 525–553. https://doi.org/10.1016/j.psychsport.2006.03.001\n\n\nBazerman, M. H., and Moore, D. A. (2013). Judgment in managerial\ndecision making (8. ed). Wiley.\n\n\nBeshears, J., Choi, J. J., Harris, C., Laibson, D., Madrian, B. C., and\nSakong, J. (2020). Which early withdrawal penalty attracts the most\ndeposits to a commitment savings account? Journal of Public\nEconomics, 183, 104144. https://doi.org/10.1016/j.jpubeco.2020.104144\n\n\nCamerer, C., Babcock, L., Loewenstein, G., and Thaler, R. (1997). Labor\nsupply of new york city cabdrivers: One day at a time*. The\nQuarterly Journal of Economics, 112(2), 407–441. https://doi.org/10.1162/003355397555244\n\n\nCamerer, C., and Lovallo, D. (1999). Overconfidence and Excess Entry: An\nExperimental Approach. The American Economic Review,\n89(1), 13.\n\n\nCard, D., Mas, A., Moretti, E., and Saez, E. (2012). Inequality at Work:\nThe Effect of Peer Salaries on Job Satisfaction. American Economic\nReview, 102(6), 2981–3003. https://doi.org/10.1257/aer.102.6.2981\n\n\nCharness, G., and Rabin, M. (2002). Understanding social preferences\nwith simple tests. The Quarterly Journal of Economics,\n117(3), 817–869. https://www.jstor.org/stable/4132490\n\n\nCosmides, L., and Tooby, J. (1996). Are humans good intuitive\nstatisticians after all? Rethinking some conclusions from the literature\non judgment under uncertainty. Cognition, 58(1), 1–73.\nhttps://doi.org/10.1016/0010-0277(95)00664-8\n\n\nCzerlinski, J., Gigerenzer, G., and Goldstein, D. G. (1999). How good\nare simple heuristics. In G. Gigerenzer, P. Todd, and The ABC Research\nGroup (Eds.), Simple heuristics that make us smart. Oxford\nUniversity Press.\n\n\nDavidson, D., McKinsey, J. C. C., and Suppes, P. (1955). Outlines of a\nFormal Theory of Value, I. Philosophy of Science,\n22(2), 140–160. https://doi.org/10.1086/287412\n\n\nDe Bondt, W. F. M., and Thaler, R. H. (1995). Chapter 13 Financial\ndecision-making in markets and firms: A behavioral perspective. In R. A.\nJarrow, V. Maksimovic, and W. T. Ziemba (Eds.), Handbooks in\nOperations Research and Management Science (Vol. 9, pp. 385–410).\nElsevier. https://www.sciencedirect.com/science/article/pii/S092705070580057X\n\n\nEngel, C. (2011). Dictator games: a meta study. Experimental\nEconomics, 14(4), 583–610. https://doi.org/10.1007/s10683-011-9283-7\n\n\nFarber, H. S. (2005). Is tomorrow another day? The labor supply of new\nyork city cabdrivers. Journal of Political Economy,\n113(1), 46–82. https://doi.org/10.1086/426040\n\n\nFarber, H. S. (2008). Reference-Dependent Preferences and Labor Supply:\nThe Case of New York City Taxi Drivers. American Economic\nReview, 98(3), 1069–1082. https://doi.org/10.1257/aer.98.3.1069\n\n\nFarber, H. S. (2015). Why you can’t find a taxi in the rain\nand other labor supply lessons from cab drivers. The Quarterly\nJournal of Economics, 130(4), 1975–2026. https://doi.org/10.1093/qje/qjv026\n\n\nFehr, E., and Schmidt, K. M. (1999). A theory of fairness, competition,\nand cooperation. The Quarterly Journal of Economics,\n114(3), 817–868. https://www.jstor.org/stable/2586885\n\n\nFrederick, S., Loewenstein, G., and O’Donoghue, T. (2002). Time\ndiscounting and time preference: A critical review. Journal of\nEconomic Literature, 40(2), 351–401. https://www.jstor.org/stable/2698382\n\n\nGenesove, D., and Mayer, C. (2001). Loss aversion and seller behavior:\nEvidence from the housing market. The Quarterly Journal of\nEconomics, 116(4), 1233–1260. https://www.jstor.org/stable/2696458\n\n\nGigerenzer, G. (2011). What are natural frequencies? BMJ,\n343, d6386. https://doi.org/10.1136/bmj.d6386\n\n\nGigerenzer, G. (2021). Embodied heuristics. Frontiers in\nPsychology, 12. https://www.frontiersin.org/articles/10.3389/fpsyg.2021.711289\n\n\nGilovich, T., Vallone, R., and Tversky, A. (1985). The hot hand in\nbasketball: On the misperception of random sequences. Cognitive\nPsychology, 17(3), 295–314. https://doi.org/10.1016/0010-0285(85)90010-6\n\n\nGiné, X., Karlan, D., and Zinman, J. (2010). Put Your Money Where Your\nButt Is: A Commitment Contract for Smoking Cessation. American\nEconomic Journal: Applied Economics, 2(4), 213–235. https://doi.org/10.1257/app.2.4.213\n\n\nGreen, L., Fristoe, N., and Myerson, J. (1994). Temporal discounting and\npreference reversals in choice between delayed outcomes. Psychonomic\nBulletin & Review, 1(3), 383–389. https://doi.org/10.3758/BF03213979\n\n\nHeath, C., Larrick, R. P., and Wu, G. (1999). Goals as Reference Points.\nCognitive Psychology, 38(1), 79–109. https://doi.org/10.1006/cogp.1998.0708\n\n\nHenrich, J., Boyd, R., Bowles, S., Camerer, C., Fehr, E., Gintis, H.,\nand McElreath, R. (2001). In Search of Homo Economicus: Behavioral\nExperiments in 15 Small-Scale Societies. American Economic\nReview, 91(2), 73–78. https://doi.org/10.1257/aer.91.2.73\n\n\nHertwig, R., and Gigerenzer, G. (1999). The ‘conjunction\nfallacy’ revisited: how intelligent inferences look like\nreasoning errors. Journal of Behavioral Decision Making,\n12(4), 275–305. https://doi.org/10.1002/(SICI)1099-0771(199912)12:4&lt;275::AID-BDM323&gt;3.0.CO;2-M\n\n\nHoffrage, U., and Gigerenzer, G. (1998). Using natural frequencies to\nimprove diagnostic inferences. Academic Medicine,\n73(5), 53840. https://doi.org/10.1097/00001888-199805000-00024\n\n\nHoffrage, U., Krauss, S., Martignon, L., and Gigerenzer, G. (2015).\nNatural frequencies improve bayesian reasoning in simple and complex\ninference tasks. Frontiers in Psychology, 6, 1473. https://doi.org/10.3389/fpsyg.2015.01473\n\n\nJohnson, E. J., and Goldstein, D. (2003). Do Defaults Save Lives?\nScience, 302(5649), 1338–1339. https://doi.org/10.1126/science.1091721\n\n\nJohnson, N. D., and Mislin, A. A. (2011). Trust games: A meta-analysis.\nJournal of Economic Psychology, 32(5), 865–889. https://doi.org/10.1016/j.joep.2011.05.007\n\n\nKahneman, D. (2011). Thinking, fast and slow (1st edition).\nFarrar, Straus; Giroux.\n\n\nKahneman, D., Knetsch, J. L., and Thaler, R. H. (1991). Anomalies: The\nEndowment Effect, Loss Aversion, and Status Quo Bias. Journal of\nEconomic Perspectives, 5(1), 193–206. https://doi.org/10.1257/jep.5.1.193\n\n\nKahneman, D., and Tversky, A. (1979). Prospect theory: An analysis of\ndecision under risk. Econometrica, 47(2), 263–291. https://doi.org/10.2307/1914185\n\n\nKahneman, D., and Tversky, A. (1984). Choices, values, and frames.\nAmerican Psychologist, 39(4), 341–350. https://doi.org/10.1037/0003-066X.39.4.341\n\n\nKeynes, J. M. (1936). The general theory of employment, interest,\nand money. Macmillan. http://gutenberg.net.au/ebooks03/0300071h/printall.html\n\n\nKirby, K. N., and Herrnstein, R. J. (1995). Preference Reversals Due to\nMyopic Discounting of Delayed Reward. Psychological Science,\n6(2), 83–89. https://doi.org/10.1111/j.1467-9280.1995.tb00311.x\n\n\nKirgios, E. L., Mandel, G. H., Park, Y., Milkman, K. L., Gromet, D. M.,\nKay, J. S., and Duckworth, A. L. (2020). Teaching temptation bundling to\nboost exercise: A field experiment. Organizational Behavior and\nHuman Decision Processes, 161, 20–35. https://doi.org/10.1016/j.obhdp.2020.09.003\n\n\nKőszegi, B., and Rabin, M. (2006). A model of reference-dependent\npreferences. The Quarterly Journal of Economics,\n121(4), 1133–1165. https://www.jstor.org/stable/25098823\n\n\nMartin, V. (2017). When to quit: Narrow bracketing and reference\ndependence in taxi drivers. Journal of Economic Behavior &\nOrganization, 144, 166–187. https://doi.org/10.1016/j.jebo.2017.09.024\n\n\nMiller, J. B., and Sanjurjo, A. (2018). Surprised by the Hot Hand\nFallacy? A Truth in the Law of Small Numbers. Econometrica,\n86(6), 2019–2047. https://doi.org/10.3982/ECTA14943\n\n\nMoore, D. A., Oesch, J. M., and Zietsma, C. (2007). What Competition?\nMyopic Self-Focus in Market-Entry Decisions. Organization\nScience, 18(3), 440–454. https://doi.org/10.1287/orsc.1060.0243\n\n\nMoulin, H. (1986). Game theory for social sciences. New York\nPress.\n\n\nNagel, R. (1995). Unraveling in guessing games: An experimental study.\nThe American Economic Review, 85(5), 1313–1326. https://www.jstor.org/stable/2950991\n\n\nNewton, E. L. (1990). The rocky road from actions to intentions\n[PhD thesis]. https://www.proquest.com/openview/b740253d9b78599786f59d6b6055cc3b/1?pq-origsite=gscholar&cbl=18750&diss=y\n\n\nPage, L. (2022). Optimally Irrational: The Good Reasons We Behave\nthe Way We Do. Cambridge University Press. https://www.cambridge.org/au/academic/subjects/economics/microeconomics/optimally-irrational-good-reasons-we-behave-way-we-do,\nhttps://www.cambridge.org/au/academic/subjects/economics/microeconomics\n\n\nPrelec, D. (1998). The probability weighting function.\nEconometrica, 66(3), 497–527. https://doi.org/10.2307/2998573\n\n\nRabin, M. (2000). Risk Aversion and Expected-Utility Theory: A\nCalibration Theorem. Econometrica, 68(5), 1281–1292.\nhttp://www.jstor.org/stable/2999450\n\n\nRabin, M. (2002). Inference by believers in the law of small numbers.\nThe Quarterly Journal of Economics, 117(3), 775–816.\nhttps://doi.org/10.1162/003355302760193896\n\n\nRabin, M., and Thaler, R. H. (2001). Anomalies: Risk Aversion.\nJournal of Economic Perspectives, 15(1), 219–232. https://doi.org/10.1257/jep.15.1.219\n\n\nRabin, M., and Vayanos, D. (2010). The gambler’s and hot-hand fallacies:\nTheory and applications. The Review of Economic Studies,\n77(2), 730–778. https://doi.org/10.1111/j.1467-937X.2009.00582.x\n\n\nRapoport, A., and Budescu, D. V. (1997). Randomization in individual\nchoice behavior. Psychological Review, 104, 603–617.\nhttps://doi.org/10.1037/0033-295X.104.3.603\n\n\nRead, D., and Leeuwen, B. van. (1998). Predicting Hunger: The Effects of\nAppetite and Delay on Choice. Organizational Behavior and Human\nDecision Processes, 76(2), 189–205. https://doi.org/10.1006/obhd.1998.2803\n\n\nSamuelson, W. F., and Bazerman, M. (1985). Negotiation under the\nwinner’s curse (V. Smith, Ed.). JAI Press.\n\n\nSavant, M. vos. (1990). Game show problem. PARADE Magazine,\n16. https://web.archive.org/web/20130121183432/http://marilynvossavant.com/game-show-problem/\n\n\nShefrin, H., and Statman, M. (1985). The Disposition to Sell Winners Too\nEarly and Ride Losers Too Long: Theory and Evidence. The Journal of\nFinance, 40(3), 777–790. https://doi.org/10.1111/j.1540-6261.1985.tb05002.x\n\n\nSpiegelhalter, D., and Gage, J. (2015). What can education learn from\nreal-world communication of risk and uncertainty? The Mathematics\nEnthusiast, 12(1), 4–10. https://doi.org/10.54870/1551-3440.1329\n\n\nThaler, R. (1980). Toward a positive theory of consumer choice.\nJournal of Economic Behavior & Organization, 1(1),\n39–60. https://doi.org/10.1016/0167-2681(80)90051-7\n\n\nThaler, R. (1981). Some empirical evidence on dynamic inconsistency.\nEconomics Letters, 8(3), 201–207. https://doi.org/10.1016/0165-1765(81)90067-7\n\n\nThaler, Richard H., and Benartzi, S. (2004). Save More\nTomorrow: Using Behavioral Economics to Increase Employee\nSaving. Journal of Political Economy, 112(S1),\nS164–S187. https://doi.org/10.1086/380085\n\n\nTversky, A., and Kahneman, D. (1974). Judgment under Uncertainty:\nHeuristics and Biases. Science, 185(4157), 1124–1131.\nhttps://doi.org/10.1126/science.185.4157.1124\n\n\nTversky, A., and Kahneman, D. (1982). Evidential impact of base rates.\nIn A. Tversky, D. Kahneman, and P. Slovic (Eds.), Judgment under\nuncertainty: Heuristics and biases (pp. 153–160). Cambridge\nUniversity Press. https://www.cambridge.org/core/books/judgment-under-uncertainty/evidential-impact-of-base-rates/CC35C9E390727085713C4E6D0D1D4633\n\n\nTversky, A., and Kahneman, D. (1983). Extensional versus intuitive\nreasoning: The conjunction fallacy in probability judgment.\nPsychological Review, 90(4), 293–315. https://doi.org/10.1037/0033-295X.90.4.293\n\n\nTversky, A., and Kahneman, D. (1992). Advances in prospect theory:\nCumulative representation of uncertainty. Journal of Risk and\nUncertainty, 5, 297–323. https://doi.org/10.1007/BF00122574\n\n\nZelmer, J. (2003). Linear Public Goods Experiments: A Meta-Analysis.\nExperimental Economics, 6(3), 299–310. https://doi.org/10.1023/A:1026277420119",
    "crumbs": [
      "References"
    ]
  }
]