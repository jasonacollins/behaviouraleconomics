{
  "hash": "ea05a5be30a9077b4b0b7b9736501b95",
  "result": {
    "engine": "knitr",
    "markdown": "---\nengine: knitr #added as otherwise inline r code does not execute\n---\n# Expected utility examples\n\n## Summary {.unnumbered}\n\n- In the following examples I demonstrate the operation of expected utility theory and concepts such as expected value, expected utility and certainty equivalent through various betting scenarios, illustrating how individuals with risk-averse utility functions make decisions under uncertainty.\n- In a 50:50 bet example with a logarithmic utility function, a gamble with zero expected value reduces utility, demonstrating risk aversion.\n- An 80:20 bet example shows that even risk-averse individuals may accept favourable bets, but the certainty equivalent is still less than the expected value.\n- A bet involving proportions of wealth demonstrates that positive expected value does not always lead to acceptance of a gamble for risk-averse individuals.\n- The St. Petersburg game demonstrates a paradox where the expected value is infinite, yet most people would not pay an infinite amount to play. This paradox can be resolved by introducing expected utility theory, which shows that risk-averse individuals with diminishing marginal utility would only pay a finite amount to play the game.\n\n---\n\n::: {.content-visible when-format=\"html\"}\n\n{{< video https://youtu.be/EQFexIPUaFI >}}\n\n---\n\n:::\n\n## Introduction\n\nIn this section, I present a series of mathematical examples of expected utility theory.\n\n## A 50:50 bet\n\nSuppose your utility function is $U(x)=\\text{ln}(x)$.\n\nYou have a 50% chance of winning \\$10 and a 50% chance of losing \\$10. Assume your starting wealth is \\$20.\n\nWhat is the expected value of this game?\n\n\\begin{align*}\nE[X]&=\\sum_{i=1}^n p_ix_i \\\\[6pt]\n&=0.5\\times 10+0.5\\times (-10) \\\\[6pt]\n&=0\n\\end{align*}\n\nThe expected value of the game is \\$0.\n\nWhat is the expected utility of this game?\n\n\\begin{align*}\nE[U(W+X)]&=\\sum_{i=1}^n p_iU(x_i+W) \\\\[6pt]\n&=0.5U(20-10)+0.5U(20+10) \\\\[6pt]\n&=0.5\\text{ln}(10)+0.5\\text{ln}(30) \\\\[6pt]\n&=2.85\n\\end{align*}\n\nWhat does an expected utility of 2.85 mean? To make it tangible, we can ask what wealth would give that utility.\n\n$$U(W)=\\text{ln}(W)=2.85$$\n$$W=e^{2.85}=\\$17.30$$\n\nThis gamble with an expected value of zero reduces utility by an amount equivalent to \\$2.70. \n\nWe could also say that the certainty equivalent of this gamble is the final wealth of \\$17.30, or a loss of \\$2.70.\n\n@fig-fiftyfifty illustrates the example.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![A 50:50 bet](expected-utility-examples_files/figure-pdf/fig-fiftyfifty-1.png){#fig-fiftyfifty}\n:::\n:::\n\n\nOn the x-axis, we have the outcomes and on the y-axis, we have the utility.\n\nI have added points on the x-axis for the outcomes of the two gambles, being $W-10$ and $W+10$. They deliver utility $U(W+10)$ and $U(W-10)$ respectively. The expected utility of the gamble is the probability-weighted average of these two points. It sits on the straight dash-dot-dot line between those two outcomes.\n\nYou can see that the expected utility of the gamble is lower than the utility of the expected value (being current wealth).\n\nAlso plotted is the certainty equivalent. We can identify it as the point on the utility curve where the utility of that certainty equivalent is equal to the expected utility.\n\n## An 80:20 bet\n\nSuppose your utility function is $U(x)=\\text{ln}(x)$.\n\nYou have an 80% chance of winning \\$10 and a 20% chance of losing \\$10. Assume your starting wealth is \\$20.\n\nWhat are the expected value and the expected utility of this game?\n\n\\begin{align*}\nE[X]&=\\sum_{i=1}^n p_ix_i \\\\[6pt]\n&=0.8\\times 10+0.2\\times (-10) \\\\[6pt]\n&=\\$6\n\\end{align*}\n\nThe expected value of the game is \\$6.\n\nWhat is the expected utility of this game?\n\n\\begin{align*}\nE[U(W+x)]&=\\sum_{i=1}^n p_iU(x_i+W) \\\\[6pt]\n&=0.8U(20+10)+0.2U(20-10) \\\\[6pt]\n&=0.8\\text{ln}(30)+0.2\\text{ln}(10) \\\\[6pt]\n&=3.18\n\\end{align*}\n\nWhat does an expected utility of 3.18 mean? To make it tangible, we can ask what wealth would give that utility.\n\n$$U(W)=\\text{ln}(W)=3.18$$\n$$W=e^{3.18}=\\$24.08$$\n\nThis gamble with an expected value of \\$6 increases utility by an amount equivalent to \\$4.08.\n\nWe could also say that the certainty equivalent of this gamble is the final wealth of \\$24.08.\n\n@fig-eightytwenty illustrates the example.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![An 80:20 bet](expected-utility-examples_files/figure-pdf/fig-eightytwenty-1.png){#fig-eightytwenty}\n:::\n:::\n\n\nThe expected utility of the gamble $\\text{E}[U(X)]$ is higher than the utility from current wealth but lower than the utility of the expected value. That is, they are risk averse but would still accept this highly favourable bet.\n\nAlso plotted is the certainty equivalent. We can identify it as the point on the utility curve where the utility of that certainty equivalent is equal to the expected utility. In this case, it is at \\$4.08 above current wealth.\n\n## Betting a proportion of wealth\n\nSuppose your utility function is $U(x)=\\text{ln}(x)$.\n\nYou have a 50% chance of increasing your wealth by 50% and a 50% chance of decreasing your wealth by 40%.\n\nWhat are the expected value and the expected utility of this game?\n\n\\begin{align*}\nE[X]&=\\sum_{i=1}^n p_ix_i \\\\[6pt]\n&=0.5\\times 0.6W+0.5\\times 1.5W \\\\[6pt]\n&=0.3W+0.75W \\\\[6pt]\n&=1.05W\n\\end{align*}\n\nThe expected value of the gamble is 5% of your wealth. The gamble has a positive expected value.\n\n\\begin{align*}\nE[U(X)]&=\\sum_{i=1}^n p_iU(X_i) \\\\[6pt]\n&=0.5U(0.6W)+0.5U(1.5W) \\\\[6pt]\n&=0.5\\text{ln}(0.6)+0.5\\times \\text{ln}(W)+0.5\\text{ln}(1.5)+0.5\\times \\text{ln}(W) \\\\[6pt]\n&=-0.255+0.203+\\text{ln}(W) \\\\[6pt]\n&=−0.053+\\text{ln}(W)\n\\end{align*}\n\nHere we have a gamble with a positive expected value, 5% of your wealth, but lower expected utility. Someone with log utility would reject this bet.\n\n@fig-wealth illustrates the example.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Betting a proportion of wealth](expected-utility-examples_files/figure-pdf/fig-wealth-1.png){#fig-wealth}\n:::\n:::\n\n\nI have added points on the x-axis for the outcomes of the two gambles, a 40% reduction in wealth and a 50% gain in wealth. The expected utility of the gamble is the probability-weighted average of these two points. It sits on the straight dash-dot-dot line between those two outcomes.\n\nYou can see that the expected utility of the gamble is lower than the utility of current wealth. They would reject an offer of this bet.\n\n## The St. Petersburg game\n\n::: {.content-visible when-format=\"html\"}\n\n{{< video https://youtu.be/aIdPcOiE7Ec >}}\n\n---\n\n:::\n\nThe St. Petersburg game was invented by the Swiss mathematician Nicolas Bernoulli.\n\nThe game starts with a pot containing \\$2. A dealer then flips a coin. The pot doubles every time a head appears. The game ends, and the player wins the pot when a tail appears.\n\n- A tail on the first flip leads to a payment of \\$2.\n- A tail on the second flip leads to a payment of \\$4\n- A tail on the third flip leads to a payment of  \\$8\n\nAnd so on.\n\nConsider what you would be willing to pay to play this game. Would you pay \\$5? \\$10? \\$25? \\$50? More?\n\nThe expected value of this game is equal to the sum of the following series.\n\n\\begin{align*}\nE[X]&=\\underbrace{\\frac{1}{2}\\times 2}_\\textrm{Tail first}+\\underbrace{\\bigg(\\frac{1}{2}\\times \\frac{1}{2}\\bigg)\\times 4}_\\textrm{Tail second}+\\underbrace{\\bigg(\\frac{1}{2}\\times \\frac{1}{2}\\times \\frac{1}{2}\\bigg)\\times 8}_\\textrm{Tail third} \\\\[24pt]\n&\\qquad +\\underbrace{\\bigg(\\frac{1}{2}\\times \\frac{1}{2}\\times \\frac{1}{2}\\times \\frac{1}{2}\\bigg)\\times 16}_\\textrm{Tail fourth}+... \\\\[24pt]\n&=1+1+1+1+... \\\\\n&=\\sum_{k=1}^\\infty 1 \\\\\n&=\\infty\n\\end{align*}\n\nThe first term in the series captures the 50% chance of a tail on the first flip, paying \\$2. The second term represents the 50% chance of a head on the first flip, followed by the 50% chance of the tail second flip, paying \\$4. The third term represents the 50% chance of a head on the first flip, followed by the 50\\% chance of a head on the second flip, followed by the 50\\% chance of a tail on the third flip, paying \\$8. And so on.\n\nMultiplying out each of those terms results in a series of 1s.\n\nThe $\\sum$ operator means “sum for $k=1$ to $k=\\infty$”.\n\nContrast this expected value of $\\infty$ with the sum you would pay to play the game. You were likely not willing to pay an infinite amount.\n\nThis \"paradox\" is often resolved by introducing an expected utility function.\n\nThe expected utility of this game is equal to:\n\n\\begin{align*}\nE[U(X)]&=\\underbrace{\\frac{1}{2}\\times U(W+2)}_\\textrm{Tail first}+\\underbrace{\\bigg(\\frac{1}{2}\\times \\frac{1}{2}\\bigg)\\times U(W+4)}_\\textrm{Tail second} \\\\[24pt] \n&\\qquad +\\underbrace{\\bigg(\\frac{1}{2}\\times \\frac{1}{2}\\times \\frac{1}{2}\\bigg)\\times U(W+8)}_\\textrm{Tail third}  \\\\[24pt]\n&\\qquad +\\underbrace{\\bigg(\\frac{1}{2}\\times \\frac{1}{2}\\times \\frac{1}{2}\\times \\frac{1}{2}\\bigg)\\times U(W+16)}_\\textrm{Tail fourth}+... \\\\[24pt]\n&=\\frac{1}{2}U(W+2)+\\frac{1}{4}U(W+4)+\\frac{1}{8}U(W+8)+\\frac{1}{16}U(W+16)+...  \\\\[12pt]\n&=\\sum_{k=1}^{k=\\infty}\\frac{1}{2^k}U(W+2^k)\n\\end{align*}\n\nSimilar to the calculation of the expected value, the first term in the series captures the 50% chance of a tail on the first flip, paying \\$2. The second term represents the 50\\% chance of a head on the first flip, followed by the 50\\% chance of the tail on the second flip, paying \\$4. And so on. But here, we are using the utility function $U(x)$.\n\nIn the second line, I multiplied the probabilities of each coin flip together.\n\nIn the third line, I expressed this infinite sum more compactly.\n\nTo take this equation further, we need to consider the particular utility function of the decision maker.\n\nWhat maximum sum would a risk-neutral player with $U(x)=x$ be willing to pay to play the game?\n\nOne strategy to determine this sum is to ask what sum would result in the player being indifferent between paying and rejecting a chance to play. That is the maximum sum $c$ that they would be willing to pay. They will be indifferent when $U(W)=E[U(X-c)]$.\n\nWe can solve this equation as follows.\n\n\\begin{align*}\nU(W)&=E[U(X-c)] \\\\[6pt]\n&=\\sum_{k=1}^{k=\\infty}\\frac{1}{2^k}U(W+\\$2^k-c) \\\\[6pt]\nW&=\\sum_{k=1}^{k=\\infty}\\frac{1}{2^k}(W+2^k-c)  \\qquad \\text{(substituting in the utility function)}\\\\[6pt]\n&=W-c+\\sum_{k=1}^{k=\\infty}1 \\qquad \\Bigg(\\text{as }\\sum_{k=1}^{k=\\infty}\\frac{1}{2^k}=1\\Bigg) \\\\[12pt]\nc&=\\sum_{k=1}^{k=\\infty}1 \\\\[6pt]\n&=\\infty\n\\end{align*}\n\nIn the second line, we use the sum we created earlier. In the third line, I substitute the utility function $U(x)=x$. We can then simplify as in the fourth line, which allows us to see that, given the infinite expected value of the game, the player would be willing to pay an infinite amount to play. \n\nThat is, a risk-neutral player would pay any amount \\$$c$ to play.\n\nWe could also have inferred this from the game's expected value being infinite.\n\nWhat is the maximum sum a risk-averse player with $U(x)=\\text{ln}(x)$ would be willing to pay to play the game? How does their wealth affect their willingness to pay?\n\nAgain we will determine at what \\$$c$ the player is indifferent between accepting and rejecting a chance to play, which occurs when $U(W)=E[U(X-c)]$.\n\n\\begin{align*}\nU(W)&=E[U(X-c)] \\\\[6pt]\nU(W)&=\\sum_{k=1}^{k=\\infty}\\frac{1}{2^k}U(W+\\$2^k-c) \\\\[6pt]\n\\text{ln}(W)&=\\sum_{k=1}^{k=\\infty}\\frac{1}{2^k}\\text{ln}(W+\\$2^k-c)\n\\end{align*}\n\n\n::: {.cell}\n\n:::\n\n\nThere is no closed-form solution to this equation to enable us to determine $c$. We need to solve via numerical methods (such as testing and iterating to a solution).\n\nIf we did solve this, we would find that someone who has wealth of \\$0.01 would be willing to pay up to \\$2.01. They would need to borrow. Someone with wealth \\$1000 would be willing to pay \\$10.95. A person with a wealth of \\$1 million would be willing to pay \\$20.87.\n\nWe cannot solve for a person with no wealth as $\\text{ln}⁡(0)$ is undefined. \n\nWhy does willingness to pay increase with wealth?\n\nWith log utility, as wealth increases, the slope of the log function increasingly approximates a linear function (the second derivative approaches zero). Hence, the gambler displays less risk-averse (closer to risk-neutral) behaviour.\n\nOne way to gain an intuition for why this gamble now has a finite value is to calculate the utility of a risk-averse player whose only asset is the opportunity to play this game.\n\n\\begin{align*}\nE[U(X)]&=\\sum_{k=1}^{k=\\infty}\\frac{1}{2^k}U(\\$2^k) \\\\[12pt]\n&=\\sum_{k=1}^{k=\\infty}\\frac{1}{2^k}\\text{ln}(2^k) \\qquad \\text{(substituting in the utility function)}\\\\[12pt]\n&=\\sum_{k=1}^{k=\\infty}\\frac{k}{2^k}\\text{ln}(2)  \\qquad \\text{(using the rule }\\ln(x^a)=a\\ln(x)) \\\\[12pt]\n&=\\bigg(\\frac{1}{2}+\\frac{2}{4}+\\frac{3}{8}+\\frac{4}{16}+\\frac{5}{32}+...\\bigg)\\text{ln}(2) \\\\[12pt]\n&=2\\text{ln}(2)\n\\end{align*}\n\nThe change in the utility from each flip rapidly declines. Ultimately the series of fractions sum to two. \n\nWe can then calculate what wealth is equivalent to this expected utility.\n\n\\begin{align*}\nU(W)&=\\text{ln}(W)=2\\text{ln}(2) \\\\[6pt]\nW&=e^{2\\text{ln}2}=4\n\\end{align*}\n\nThe expected utility from the game is equal to the utility of \\$4.\n",
    "supporting": [
      "expected-utility-examples_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}